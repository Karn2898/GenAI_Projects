{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "P58Csam3fH-X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "02642c16-bced-420e-ff61-037d23743575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 1.2.10\n",
            "Uninstalling langchain-1.2.10:\n",
            "  Successfully uninstalled langchain-1.2.10\n",
            "Found existing installation: langchain-community 0.4.1\n",
            "Uninstalling langchain-community-0.4.1:\n",
            "  Successfully uninstalled langchain-community-0.4.1\n",
            "Found existing installation: langchain-core 1.2.14\n",
            "Uninstalling langchain-core-1.2.14:\n",
            "  Successfully uninstalled langchain-core-1.2.14\n",
            "Found existing installation: langchain-huggingface 1.2.0\n",
            "Uninstalling langchain-huggingface-1.2.0:\n",
            "  Successfully uninstalled langchain-huggingface-1.2.0\n",
            "Collecting langchain\n",
            "  Using cached langchain-1.2.10-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting langchain_community\n",
            "  Using cached langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-core\n",
            "  Using cached langchain_core-1.2.14-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.2)\n",
            "Collecting langchain_huggingface\n",
            "  Using cached langchain_huggingface-1.2.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.13.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.7.3)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.3)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.6)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Using cached langchain-1.2.10-py3-none-any.whl (111 kB)\n",
            "Using cached langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "Using cached langchain_core-1.2.14-py3-none-any.whl (501 kB)\n",
            "Using cached langchain_huggingface-1.2.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: langchain-core, langchain_huggingface, langchain_community, langchain\n",
            "Successfully installed langchain-1.2.10 langchain-core-1.2.14 langchain_community-0.4.1 langchain_huggingface-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "langchain",
                  "langchain_core"
                ]
              },
              "id": "efefc5e3eb0949c8ae12bcb8d09c884f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.7.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (24.1.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.129.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.41.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (3.1.6)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (0.0.22)\n",
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2.32.5)\n",
            "Requirement already satisfied: starlette<1.0.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.52.1)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (2.12.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.4.2)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2) (3.0.3)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (26.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.0->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.7.0->fastapi) (2.41.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.26.0->tiktoken) (2026.1.4)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<1.0.0,>=0.40.0->fastapi) (4.12.1)\n"
          ]
        }
      ],
      "source": [
        "%pip uninstall -y langchain langchain_community langchain-core langchain_huggingface\n",
        "%pip install langchain langchain_community langchain-core huggingface_hub langchain_huggingface\n",
        "%pip install pypdf tiktoken aiofiles fastapi uvicorn jinja2 python-multipart pypdf2 faiss-cpu python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "TX18V51J6Rly"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_key='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'"
      ],
      "metadata": {
        "id": "T1bBURs29KQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv\n",
        "huggingface_key=os.getenv(\"huggingface_key\")\n"
      ],
      "metadata": {
        "id": "OxZhDA6I7GDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_key='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'\n",
        "os.environ[\"huggingface_key\"]=huggingface_key"
      ],
      "metadata": {
        "id": "gEPPxUCX9JWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ef26b7"
      },
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = '/content/dl intervie.pdf'\n",
        "loader = PyPDFLoader(file_path)\n",
        "data = loader.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['data']=df['data'].str.lower()"
      ],
      "metadata": {
        "id": "QPUhbVESDmDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "746a2892"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.DataFrame([{'data': doc.page_content} for doc in data])\n",
        "\n",
        "display(df.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(data):\n",
        "  pattern=re.compile(r'http?://S+|.S+')\n",
        "  return pattern.sub(r'',text)\n",
        "  remove_url(data)"
      ],
      "metadata": {
        "id": "EoS3IovyD9LH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string,time\n",
        "exclude=string.punctuation\n",
        "\n",
        "def remove_punct(text_input):\n",
        "  text = text_input\n",
        "  for char in exclude:\n",
        "    text=text.replace(char , '')\n",
        "  return text\n",
        "\n",
        "start=time.time()\n",
        "\n",
        "print(remove_punct(df['data'][5]))\n",
        "time1=time.time()-start\n",
        "print(time1*50000)\n",
        "\n",
        "def remove_punc1(text_input):\n",
        "  return text_input.translate(str.maketrans('','',exclude))\n",
        "\n",
        "start = time.time()\n",
        "print(remove_punc1(df['data'][5]))\n",
        "time2 = time.time() - start\n",
        "print(time2*50000)\n",
        "\n",
        "df['data'][5]"
      ],
      "metadata": {
        "id": "Vah_JPwxEXGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "-m6j_6jP-L7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OyXx6VEvp9Ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "UECxIgwS-71i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_gen=\"\"\n",
        "for page in data:\n",
        "  question_gen+=page.page_content"
      ],
      "metadata": {
        "id": "rlom9Wkb-9Ue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_gen"
      ],
      "metadata": {
        "id": "1kz_N6Yo_Kvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter, TokenTextSplitter\n",
        "split_question_gen=TokenTextSplitter(\n",
        "    encoding_name=\"cl100k_base\",\n",
        "    chunk_size=10000,\n",
        "    chunk_overlap=200\n",
        ")"
      ],
      "metadata": {
        "id": "3GXELFlA_MDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_ques_gen=split_question_gen.split_text(question_gen)\n"
      ],
      "metadata": {
        "id": "iA_6MKSFA7qf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_ques_gen"
      ],
      "metadata": {
        "id": "D2vlikSKBIu-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunk_ques_gen)"
      ],
      "metadata": {
        "id": "Dc4uBzLXBOhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(chunk_ques_gen)"
      ],
      "metadata": {
        "id": "K2WNZEiZBQG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "document_question_gen=[Document(page_content=t) for t in chunk_ques_gen]\n",
        "document_question_gen"
      ],
      "metadata": {
        "id": "KyumoXF7BTpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(document_question_gen[0])"
      ],
      "metadata": {
        "id": "TkaxeSyzBvMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "splitter_ans_gen=TokenTextSplitter(\n",
        "  encoding_name=\"cl100k_base\",\n",
        "  chunk_size=1000,\n",
        "  chunk_overlap=100\n",
        ")"
      ],
      "metadata": {
        "id": "QQ3RwMkGBxPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_ans_gen=splitter_ans_gen.split_documents(\n",
        "    document_question_gen\n",
        ")"
      ],
      "metadata": {
        "id": "_hMawTlBCI6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_ans_gen"
      ],
      "metadata": {
        "id": "B83FduWZCUXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "305fe551"
      },
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "\n",
        "huggingface_key = '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'\n",
        "os.environ['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'] = huggingface_key\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"Qwen/Qwen1.5-7B-Chat\",\n",
        "    temperature=0.1,\n",
        "    max_length=500\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template=\"\"\"\n",
        "you are an expert at creating questions based on coding materials an documentation,\n",
        "your goal is to prepare a coder or programmer for their exam and coding tests\n",
        "youdo this by asking questions about the text below:\n",
        "\n",
        "-------------------------\n",
        "{text}\n",
        "-------------------------\n",
        "create questions that will prepare the coders or programers for the test\n",
        "make sure ot to lose any important information.\n",
        "\n",
        "QUESTIONS:\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "KwoOUDheFyp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "PROMPT_QUESTIONS=PromptTemplate(template=prompt_template, input_variables=['text'])"
      ],
      "metadata": {
        "id": "_s2nIAn_HAeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "refine_template=(\"\"\"\n",
        "you are an expert at creating practice questions based on coding materials and documentations .\n",
        "your goal is to help a coder or programmer prepare for a coding test .\n",
        "we have recieved some practice questions to a certain extent :{existing_answer},\n",
        "we have the option to refine the existing  questions or add new ones .\n",
        "(only if necessary) with some more context below.and\n",
        "_______________\n",
        "{text}\n",
        "_______________\n",
        "\n",
        "Given the new context , refine the original questions in English .\n",
        "If the context is not helpful , please provide original questions\n",
        "QUESTIONS:\n",
        "\"\"\"\n",
        " )"
      ],
      "metadata": {
        "id": "hXn7g37jvige"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "REFINE_PROMPT_TEMPLATE= PromptTemplate(\n",
        "    input_variables=[\"existing_answer\", \"text\"],\n",
        "    template=refine_template,\n",
        ")"
      ],
      "metadata": {
        "id": "j1R4ccscy1mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "\n",
        "ques_gen_chain = load_summarize_chain(\n",
        "    llm=llm,\n",
        "    chain_type=\"refine\",\n",
        "    verbose=True,\n",
        "    question_prompt=PROMPT_QUESTIONS,\n",
        "    refine_prompt=REFINE_PROMPT_TEMPLATE\n",
        ")"
      ],
      "metadata": {
        "id": "NLNqXBXRzE3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques=ques_gen_chain.run(document_question_gen)\n",
        "print(ques)"
      ],
      "metadata": {
        "id": "KAW-30fIzmQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques"
      ],
      "metadata": {
        "id": "JlrDp9Wo5Bnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "import os\n",
        "\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")"
      ],
      "metadata": {
        "id": "PlF-Sj3mz-4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstore import FAISS\n",
        "vector_store=FAISS.from_documents(document_answer_gen , embedings)"
      ],
      "metadata": {
        "id": "zPzBTLCF4bu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_ans_gen=ChatOpenAI(temperature=0.1 ,\n",
        "                       model=model_name)"
      ],
      "metadata": {
        "id": "zAOVBwZ_4tzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques_list=ques.split(\"\\n\")"
      ],
      "metadata": {
        "id": "mbcN_kKA5EV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ques_list"
      ],
      "metadata": {
        "id": "9jBxNKsm5HTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "answer_generation_chain=RetrievalQA.from_chain_type(\n",
        "    llm=llm_ans_gen,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever(),\n",
        ")"
      ],
      "metadata": {
        "id": "_SVpMQzM5J8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97xoiAyQ5d5F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}