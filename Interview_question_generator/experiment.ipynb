{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "P58Csam3fH-X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b421b337-f5a5-48e1-e6bc-39458c63385e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (0.36.2)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-1.4.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.3)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub) (0.24.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub) (0.1.2)\n",
            "Downloading huggingface_hub-1.4.1-py3-none-any.whl (553 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.3/553.3 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface_hub 0.36.2\n",
            "    Uninstalling huggingface_hub-0.36.2:\n",
            "      Successfully uninstalled huggingface_hub-0.36.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-huggingface 1.2.0 requires huggingface-hub<1.0.0,>=0.33.4, but you have huggingface-hub 1.4.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface_hub-1.4.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "huggingface_hub"
                ]
              },
              "id": "7531a406445e46c0918a1cabda4fd785"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.10)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.12/dist-packages (1.2.13)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.7.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (0.12.0)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.12/dist-packages (24.1.0)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.12/dist-packages (0.129.0)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.12/dist-packages (0.41.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (3.1.6)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (0.0.22)\n",
            "Requirement already satisfied: pypdf2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "Requirement already satisfied: langchain_huggingface in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.8 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.13.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.7.3)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (26.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core) (0.14.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken) (2025.11.3)\n",
            "Requirement already satisfied: starlette<1.0.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.52.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.4.2)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from fastapi) (0.0.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (8.3.1)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2) (3.0.3)\n",
            "Collecting huggingface-hub<1.0.0,>=0.33.4 (from langchain_huggingface)\n",
            "  Using cached huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tokenizers<1.0.0,>=0.19.1 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.22.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (3.24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (1.2.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0.0,>=0.33.4->langchain_huggingface) (4.67.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: langchain-text-splitters<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-classic<2.0.0,>=1.0.0->langchain_community) (1.1.1)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (0.3.6)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.8->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<1.0.0,>=0.40.0->fastapi) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.8->langchain) (1.12.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n",
            "Using cached huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
            "Installing collected packages: huggingface-hub\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface_hub 1.4.1\n",
            "    Uninstalling huggingface_hub-1.4.1:\n",
            "      Successfully uninstalled huggingface_hub-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "transformers 5.0.0 requires huggingface-hub<2.0,>=1.3.0, but you have huggingface-hub 0.36.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.36.2\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade huggingface_hub\n",
        "%pip install langchain langchain_community langchain-core pypdf tiktoken aiofiles fastapi uvicorn jinja2 python-multipart pypdf2 faiss-cpu python-dotenv langchain_huggingface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv"
      ],
      "metadata": {
        "id": "TX18V51J6Rly"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_key='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'"
      ],
      "metadata": {
        "id": "T1bBURs29KQL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_dotenv\n",
        "huggingface_key=os.getenv(\"huggingface_key\")\n"
      ],
      "metadata": {
        "id": "OxZhDA6I7GDT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "huggingface_key='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'\n",
        "os.environ[\"huggingface_key\"]=huggingface_key"
      ],
      "metadata": {
        "id": "gEPPxUCX9JWC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98ef26b7"
      },
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "file_path = '/content/dl intervie.pdf'\n",
        "loader = PyPDFLoader(file_path)\n",
        "data = loader.load()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['data']=df['data'].str.lower()"
      ],
      "metadata": {
        "id": "QPUhbVESDmDv"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "746a2892",
        "outputId": "9525c705-c7a8-4c10-fb2c-0d9bb5516563"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "df = pd.DataFrame([{'data': doc.page_content} for doc in data])\n",
        "\n",
        "display(df.head())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                data\n",
              "0  SHLOMO KASHANI\\nDeep Learning Interviews is ho...\n",
              "1  SHLOMO KASHANI\\nDEEP LEARNING INTERVIEWS\\nBy S...\n",
              "2  COPYRIGHT.\\n© 2016-2020 Shlomo Kashani, entrop...\n",
              "3  the publisher nor author shall be liable for a...\n",
              "4  FOREWORD.\\nWe will build a machine that will ﬂ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50b15204-a7c9-4701-9c66-894d277772b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SHLOMO KASHANI\\nDeep Learning Interviews is ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SHLOMO KASHANI\\nDEEP LEARNING INTERVIEWS\\nBy S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>COPYRIGHT.\\n© 2016-2020 Shlomo Kashani, entrop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the publisher nor author shall be liable for a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FOREWORD.\\nWe will build a machine that will ﬂ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50b15204-a7c9-4701-9c66-894d277772b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50b15204-a7c9-4701-9c66-894d277772b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50b15204-a7c9-4701-9c66-894d277772b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"data\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"SHLOMO KASHANI\\nDEEP LEARNING INTERVIEWS\\nBy Shlomo Kashani, M.Sc, QMUL, UK.\\n\\u03b81\\n\\u03b82\\nH1\\nH2\\nH3\\n\\u03b31\\nPublished by Shlomo Kashani, Tel-Aviv , ISRAEL.\\nVisit: http://www.interviews.ai\\nCopyright, 2020\\nThis book is protected by copyright.\\nNo part may be reproduced in any manner without written permission from the publisher.\\nPrinting version: VER . 26 TH OCTOBER 2021\\nPrinted in the United States of America.\\nLibrary of Congress Cataloging-in-Publication Data\\nA catalog record for this book is available from the Library of Congress\",\n          \"FOREWORD.\\nWe will build a machine that will \\ufb02y.\\n\\u2014 Joseph Michael Montgol\\ufb01er, French Inventor/Aeronaut (1740-1810)\\nD\\nEEP learning interviews are technical, dense, and thanks to the \\ufb01elds com-\\npetitiveness, often high-stakes. The prospect of preparing for one can be\\ndaunting, and the fear of failure can be paralyzing and many interviewees\\n\\ufb01nd their ideas slipping away alongside their con\\ufb01dence.\\nThis book was written for you: an aspiring data scientist with a quantitative back-\\nground, facing down the gauntlet of the interview process in an increasingly competit-\\nive \\ufb01eld. For most of you, the interview process is the most signi\\ufb01cant hurdle between\\nyou and a dream job. Even though you have the ability , the background, and the mo-\\ntivation to excel in your target position, you might need some guidance on how to get\\nyour foot in the door.\\nThough this book is highly technical it is not too dense to work through quickly . It\\naims to be comprehensive, including many of the terms and topics involved in modern\\ndata science and deep learning. That thoroughness makes it unique; no other single\\nwork offers such breadth of learning targeted so speci\\ufb01cally at the demands of the\\ninterview.\\nMost comparable information is available in a variety of formats, locations, struc-\\ntures, and resourcesblog posts, tech articles, and short books scattered across the inter-\\nnet. Those resources are simply not adequate to the demands of deep learning inter-\\nview or exam preparation and were not assembled with this explicit purpose in mind.\\nIt is hoped that this book does not suffer the same shortcomings.\\nT\\nHIS books creation was guided by a few key principles: clarity and depth,\\nthoroughness and precision, interest and accuracy . The volume was de-\\nsigned for use by job seekers in the \\ufb01elds of machine learning and deep\\nlearning whose abilities and background locate them \\ufb01rmly within STEM\\n(science, technology , engineering, and mathematics). The book will still be of use to\\nother readers, such as those still undergoing their initial education in a STEM \\ufb01eld.\\nHowever, it is tailored most directly to the needs of active job seekers and stu-\\ndents attending M.Sc/Ph.D programmes in AI . It is, in any case, a book for engineers,\\nmathematicians, and computer scientists: nowhere does it include the kind of very\\nbasic background material that would allow it to be read by someone with no prior\",\n          \"COPYRIGHT.\\n\\u00a9 2016-2020 Shlomo Kashani, entropy@interviews.ai\\nA\\nLL RIGHTS RESERVED .The content contained within this book may not be\\nreproduced, duplicated or transmitted without direct written permission\\nfrom the author or the publisher. Under no circumstances will any blame\\nor legal responsibility be held against the publisher, or author, for any dam-\\nages, reparation, or monetary loss due to the information contained within this book.\\nEither directly or indirectly . This book is copyright protected. This book is only for\\npersonal use. You cannot amend, distribute, sell, use, quote or paraphrase any part, or\\nthe content within this book, without the consent of the author or publisher.\\nPlease note the information contained within this document is for educational and\\nentertainment purposes only . All effort has been executed to present accurate, up to\\ndate, and reliable, complete information. No warranties of any kind are declared or\\nimplied. Readers acknowledge that the author is not engaging in the rendering of\\nlegal, \\ufb01nancial, medical or professional advice. The content within this book has been\\nderived from various sources. Please consult a licensed professional before attempt-\\ning any techniques outlined in this book. By reading this document, the reader agrees\\nthat under no circumstances is the author responsible for any losses, direct or indirect,\\nwhich are incurred as a result of the use of information contained within this docu-\\nment, including, but not limited to errors, omissions, or inaccuracies.\\nNo part of this publication may be reproduced, stored in a retrieval system, or trans-\\nmitted in any form or by any means, electronic, mechanical, photocopying, record-\\ning, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976\\nUnited States Copyright Act, without the prior written permission of the Publisher.\\nLimit of Liability/Disclaimer of Warranty . While the publisher and author have used\\ntheir best efforts in preparing this book, they make no representations or warranties\\nwith respect to the accuracy or completeness of the contents of this book and spe-\\nci\\ufb01cally disclaim any implied warranties of merchantability or \\ufb01tness for a particular\\npurpose. No warranty may be created or extended by sales representatives or writ-\\nten sales materials. The advice and strategies contained herein may not be suitable\\nfor your situation. You should consult with a professional where appropriate. Neither\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_url(data):\n",
        "  pattern=re.compile(r'http?://S+|.S+')\n",
        "  return pattern.sub(r'',text)\n",
        "  remove_url(data)"
      ],
      "metadata": {
        "id": "EoS3IovyD9LH"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string,time\n",
        "exclude=string.punctuation\n",
        "\n",
        "def remove_punct(text_input):\n",
        "  text = text_input\n",
        "  for char in exclude:\n",
        "    text=text.replace(char , '')\n",
        "  return text\n",
        "\n",
        "start=time.time()\n",
        "\n",
        "print(remove_punct(df['data'][5]))\n",
        "time1=time.time()-start\n",
        "print(time1*50000)\n",
        "\n",
        "def remove_punc1(text_input):\n",
        "  return text_input.translate(str.maketrans('','',exclude))\n",
        "\n",
        "start = time.time()\n",
        "print(remove_punc1(df['data'][5]))\n",
        "time2 = time.time() - start\n",
        "print(time2*50000)\n",
        "\n",
        "df['data'][5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Vah_JPwxEXGc",
        "outputId": "f9e29694-e7dd-427b-cb8d-62cc90519325"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "knowledge of quantitative and mathematical processes\n",
            "The books contents are a large inventory of numerous topics relevant to deep learn\n",
            "ing job interviews and graduate level exams Ideas that are interesting or pertinent\n",
            "have been excluded if they are not valuable in that context That places this work at\n",
            "the forefront of the growing trend in education and in business to emphasize a core\n",
            "set of practical mathematical and computational skills It is now widely understood\n",
            "that the training of every computer scientist must include a course dealing with the\n",
            "fundamental theorems of machine learning in a rigorous manner Deep Learning ap\n",
            "pears in the curriculum of nearly every university and this volume is designed as a\n",
            "convenient ongoing reference for graduates of such courses and programs\n",
            "The book is grounded in both academic expertise and onthejob experience and\n",
            "thus has two goals First it compresses all of the necessary information into a coher\n",
            "ent package And second it renders that information accessible and makes it easy to\n",
            "navigate As a result the book helps the reader develop a thorough understanding of\n",
            "the principles and concepts underlying practical data science None of the textbooks I\n",
            "read met all of those needs which are\n",
            "1 Appropriate presentation level I wanted a friendly introductory text accessible\n",
            "to graduate students who have not had extensive applied experience as data\n",
            "scientists\n",
            "2 A text that is rigorous and builds a solid understanding of the subject without\n",
            "getting bogged down in too many technicalities\n",
            "3 Logical and notational consistency among topics  There are intimate connec\n",
            "tions between calculus logistic regression entropy  and deep learning theory \n",
            "which I feel need to be emphasized and elucidated if the reader is to fully under\n",
            "stand the ﬁeld Differences in notation and presentation style in existing sources\n",
            "make it very difﬁcult for students to appreciate these kinds of connections\n",
            "4 Manageable size It is very useful to have a text compact enough that all of the\n",
            "material in it can be covered in few weeks or months of intensive review Most\n",
            "candidates will have only that much time to prepare for an interview so a longer\n",
            "text is of no use to them\n",
            "The text that follows is an attempt to meet all of the above challenges It will\n",
            "inevitably prove more successful at handling some of them than others but it\n",
            "has at least made a sincere and devoted effort\n",
            "20.062923431396484\n",
            "knowledge of quantitative and mathematical processes\n",
            "The books contents are a large inventory of numerous topics relevant to deep learn\n",
            "ing job interviews and graduate level exams Ideas that are interesting or pertinent\n",
            "have been excluded if they are not valuable in that context That places this work at\n",
            "the forefront of the growing trend in education and in business to emphasize a core\n",
            "set of practical mathematical and computational skills It is now widely understood\n",
            "that the training of every computer scientist must include a course dealing with the\n",
            "fundamental theorems of machine learning in a rigorous manner Deep Learning ap\n",
            "pears in the curriculum of nearly every university and this volume is designed as a\n",
            "convenient ongoing reference for graduates of such courses and programs\n",
            "The book is grounded in both academic expertise and onthejob experience and\n",
            "thus has two goals First it compresses all of the necessary information into a coher\n",
            "ent package And second it renders that information accessible and makes it easy to\n",
            "navigate As a result the book helps the reader develop a thorough understanding of\n",
            "the principles and concepts underlying practical data science None of the textbooks I\n",
            "read met all of those needs which are\n",
            "1 Appropriate presentation level I wanted a friendly introductory text accessible\n",
            "to graduate students who have not had extensive applied experience as data\n",
            "scientists\n",
            "2 A text that is rigorous and builds a solid understanding of the subject without\n",
            "getting bogged down in too many technicalities\n",
            "3 Logical and notational consistency among topics  There are intimate connec\n",
            "tions between calculus logistic regression entropy  and deep learning theory \n",
            "which I feel need to be emphasized and elucidated if the reader is to fully under\n",
            "stand the ﬁeld Differences in notation and presentation style in existing sources\n",
            "make it very difﬁcult for students to appreciate these kinds of connections\n",
            "4 Manageable size It is very useful to have a text compact enough that all of the\n",
            "material in it can be covered in few weeks or months of intensive review Most\n",
            "candidates will have only that much time to prepare for an interview so a longer\n",
            "text is of no use to them\n",
            "The text that follows is an attempt to meet all of the above challenges It will\n",
            "inevitably prove more successful at handling some of them than others but it\n",
            "has at least made a sincere and devoted effort\n",
            "27.251243591308594\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'knowledge of quantitative and mathematical processes.\\nThe books contents are a large inventory of numerous topics relevant to deep learn-\\ning job interviews and graduate level exams. Ideas that are interesting or pertinent\\nhave been excluded if they are not valuable in that context. That places this work at\\nthe forefront of the growing trend in education and in business to emphasize a core\\nset of practical mathematical and computational skills. It is now widely understood\\nthat the training of every computer scientist must include a course dealing with the\\nfundamental theorems of machine learning in a rigorous manner; Deep Learning ap-\\npears in the curriculum of nearly every university; and this volume is designed as a\\nconvenient ongoing reference for graduates of such courses and programs.\\nThe book is grounded in both academic expertise and on-the-job experience and\\nthus has two goals. First, it compresses all of the necessary information into a coher-\\nent package. And second, it renders that information accessible and makes it easy to\\nnavigate. As a result, the book helps the reader develop a thorough understanding of\\nthe principles and concepts underlying practical data science. None of the textbooks I\\nread met all of those needs, which are:\\n1. Appropriate presentation level. I wanted a friendly introductory text accessible\\nto graduate students who have not had extensive applied experience as data\\nscientists.\\n2. A text that is rigorous and builds a solid understanding of the subject without\\ngetting bogged down in too many technicalities.\\n3. Logical and notational consistency among topics . There are intimate connec-\\ntions between calculus, logistic regression, entropy , and deep learning theory ,\\nwhich I feel need to be emphasized and elucidated if the reader is to fully under-\\nstand the ﬁeld. Differences in notation and presentation style in existing sources\\nmake it very difﬁcult for students to appreciate these kinds of connections.\\n4. Manageable size. It is very useful to have a text compact enough that all of the\\nmaterial in it can be covered in few weeks or months of intensive review. Most\\ncandidates will have only that much time to prepare for an interview, so a longer\\ntext is of no use to them.\\nThe text that follows is an attempt to meet all of the above challenges. It will\\ninevitably prove more successful at handling some of them than others, but it\\nhas at least made a sincere and devoted effort.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m6j_6jP-L7f",
        "outputId": "253f90e1-da76-46d3-fb80-c25ce627bc5f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 0, 'page_label': '1'}, page_content='SHLOMO KASHANI\\nDeep Learning Interviews is home to hundreds of fully-solved problems, \\nfrom a wide range of key topics in AI. It is designed to both rehearse \\ninterview or exam-specific topics and provide machine learning M.Sc./Ph.D. \\nstudents, and those awaiting an interview a well-organized overview of the \\nfield. The problems it poses are tough enough to cut your teeth on and to \\ndramatically improve your skills-but they’re framed within thought-\\nprovoking questions and engaging stories.\\nThat is what makes the volume so specifically valuable to students and job \\nseekers: it provides them with the ability to speak confidently and quickly on \\nany relevant topic, to answer technical questions clearly and correctly, and to \\nfully understand the purpose and meaning \\nof interview questions and \\nanswers. These are powerful, indispensable advantages to have when walking \\ninto the interview room.\\nThe book’s contents is a large inventory of numerous topics relevant to DL \\njob interviews and graduate-level exams. That places \\nthis work at the \\nforefront \\nof the growing trend in science to teach a core set of practical \\nmathematical and computational \\nskills. It is widely accepted that the \\ntraining of every computer scientist must include the fundamental theorems \\nof ML, and AI appears in the curriculum of \\nnearly every \\nuniversity. This \\nvolume is designed as an excellent reference for graduates of \\nsuch programs.\\nShlomo Kashani, Author. \\nwww.interviews.ai\\nDEEP LEARNING INTERVIEWS\\nDEEP LEARNING \\nINTERVIEWS\\nSHLOMO KASHANI deep learning interviews\\nAmir Ivry, Chief Editor.\\n    REAL-WORLD DEEP LEARNING INTERVIEW \\nPROBLEMS & SOLUTIONS\\n• Logistic Regression\\n• Information Theory\\n• Calculus\\n• Algorithmic Differentiation\\n• Bayesian Deep Learning\\n• Probabilistic Programming\\n• Ensemble Learning\\n• CNN Feature Extraction\\n• Deep Learning: Expanded Chapter\\nsecond edition'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 1, 'page_label': '2'}, page_content='SHLOMO KASHANI\\nDEEP LEARNING INTERVIEWS\\nBy Shlomo Kashani, M.Sc, QMUL, UK.\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nPublished by Shlomo Kashani, Tel-Aviv , ISRAEL.\\nVisit: http://www.interviews.ai\\nCopyright, 2020\\nThis book is protected by copyright.\\nNo part may be reproduced in any manner without written permission from the publisher.\\nPrinting version: VER . 26 TH OCTOBER 2021\\nPrinted in the United States of America.\\nLibrary of Congress Cataloging-in-Publication Data\\nA catalog record for this book is available from the Library of Congress'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 2, 'page_label': '3'}, page_content='COPYRIGHT.\\n© 2016-2020 Shlomo Kashani, entropy@interviews.ai\\nA\\nLL RIGHTS RESERVED .The content contained within this book may not be\\nreproduced, duplicated or transmitted without direct written permission\\nfrom the author or the publisher. Under no circumstances will any blame\\nor legal responsibility be held against the publisher, or author, for any dam-\\nages, reparation, or monetary loss due to the information contained within this book.\\nEither directly or indirectly . This book is copyright protected. This book is only for\\npersonal use. You cannot amend, distribute, sell, use, quote or paraphrase any part, or\\nthe content within this book, without the consent of the author or publisher.\\nPlease note the information contained within this document is for educational and\\nentertainment purposes only . All effort has been executed to present accurate, up to\\ndate, and reliable, complete information. No warranties of any kind are declared or\\nimplied. Readers acknowledge that the author is not engaging in the rendering of\\nlegal, ﬁnancial, medical or professional advice. The content within this book has been\\nderived from various sources. Please consult a licensed professional before attempt-\\ning any techniques outlined in this book. By reading this document, the reader agrees\\nthat under no circumstances is the author responsible for any losses, direct or indirect,\\nwhich are incurred as a result of the use of information contained within this docu-\\nment, including, but not limited to errors, omissions, or inaccuracies.\\nNo part of this publication may be reproduced, stored in a retrieval system, or trans-\\nmitted in any form or by any means, electronic, mechanical, photocopying, record-\\ning, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976\\nUnited States Copyright Act, without the prior written permission of the Publisher.\\nLimit of Liability/Disclaimer of Warranty . While the publisher and author have used\\ntheir best efforts in preparing this book, they make no representations or warranties\\nwith respect to the accuracy or completeness of the contents of this book and spe-\\nciﬁcally disclaim any implied warranties of merchantability or ﬁtness for a particular\\npurpose. No warranty may be created or extended by sales representatives or writ-\\nten sales materials. The advice and strategies contained herein may not be suitable\\nfor your situation. You should consult with a professional where appropriate. Neither'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 3, 'page_label': '4'}, page_content='the publisher nor author shall be liable for any loss of proﬁt or any other commer-\\ncial damages, including but not limited to special, incidental, consequential, or other\\ndamages.\\nNotices. Knowledge and best practice in this ﬁeld are constantly changing. As new\\nresearch and experience broaden our understanding, changes in research methods,\\nprofessional practices, or medical treatment may become necessary . Practitioners and\\nresearchers must always rely on their own experience and knowledge in evaluating\\nand using any information, methods, compounds, or experiments described herein.\\nIn using such information or methods they should be mindful of their own safety and\\nthe safety of others, including parties for whom they have a professional responsibil-\\nity . To the fullest extent of the law, neither the Publisher nor the authors, contributors,\\nor editors, assume any liability for any injury and/or damage to persons or property\\nas a matter of products liability , negligence or otherwise, or from any use or operation\\nof any methods, products, instructions, or ideas contained in the material herein.'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 4, 'page_label': '5'}, page_content='FOREWORD.\\nWe will build a machine that will ﬂy.\\n— Joseph Michael Montgolﬁer, French Inventor/Aeronaut (1740-1810)\\nD\\nEEP learning interviews are technical, dense, and thanks to the ﬁelds com-\\npetitiveness, often high-stakes. The prospect of preparing for one can be\\ndaunting, and the fear of failure can be paralyzing and many interviewees\\nﬁnd their ideas slipping away alongside their conﬁdence.\\nThis book was written for you: an aspiring data scientist with a quantitative back-\\nground, facing down the gauntlet of the interview process in an increasingly competit-\\nive ﬁeld. For most of you, the interview process is the most signiﬁcant hurdle between\\nyou and a dream job. Even though you have the ability , the background, and the mo-\\ntivation to excel in your target position, you might need some guidance on how to get\\nyour foot in the door.\\nThough this book is highly technical it is not too dense to work through quickly . It\\naims to be comprehensive, including many of the terms and topics involved in modern\\ndata science and deep learning. That thoroughness makes it unique; no other single\\nwork offers such breadth of learning targeted so speciﬁcally at the demands of the\\ninterview.\\nMost comparable information is available in a variety of formats, locations, struc-\\ntures, and resourcesblog posts, tech articles, and short books scattered across the inter-\\nnet. Those resources are simply not adequate to the demands of deep learning inter-\\nview or exam preparation and were not assembled with this explicit purpose in mind.\\nIt is hoped that this book does not suffer the same shortcomings.\\nT\\nHIS books creation was guided by a few key principles: clarity and depth,\\nthoroughness and precision, interest and accuracy . The volume was de-\\nsigned for use by job seekers in the ﬁelds of machine learning and deep\\nlearning whose abilities and background locate them ﬁrmly within STEM\\n(science, technology , engineering, and mathematics). The book will still be of use to\\nother readers, such as those still undergoing their initial education in a STEM ﬁeld.\\nHowever, it is tailored most directly to the needs of active job seekers and stu-\\ndents attending M.Sc/Ph.D programmes in AI . It is, in any case, a book for engineers,\\nmathematicians, and computer scientists: nowhere does it include the kind of very\\nbasic background material that would allow it to be read by someone with no prior'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 5, 'page_label': '6'}, page_content='knowledge of quantitative and mathematical processes.\\nThe books contents are a large inventory of numerous topics relevant to deep learn-\\ning job interviews and graduate level exams. Ideas that are interesting or pertinent\\nhave been excluded if they are not valuable in that context. That places this work at\\nthe forefront of the growing trend in education and in business to emphasize a core\\nset of practical mathematical and computational skills. It is now widely understood\\nthat the training of every computer scientist must include a course dealing with the\\nfundamental theorems of machine learning in a rigorous manner; Deep Learning ap-\\npears in the curriculum of nearly every university; and this volume is designed as a\\nconvenient ongoing reference for graduates of such courses and programs.\\nThe book is grounded in both academic expertise and on-the-job experience and\\nthus has two goals. First, it compresses all of the necessary information into a coher-\\nent package. And second, it renders that information accessible and makes it easy to\\nnavigate. As a result, the book helps the reader develop a thorough understanding of\\nthe principles and concepts underlying practical data science. None of the textbooks I\\nread met all of those needs, which are:\\n1. Appropriate presentation level. I wanted a friendly introductory text accessible\\nto graduate students who have not had extensive applied experience as data\\nscientists.\\n2. A text that is rigorous and builds a solid understanding of the subject without\\ngetting bogged down in too many technicalities.\\n3. Logical and notational consistency among topics . There are intimate connec-\\ntions between calculus, logistic regression, entropy , and deep learning theory ,\\nwhich I feel need to be emphasized and elucidated if the reader is to fully under-\\nstand the ﬁeld. Differences in notation and presentation style in existing sources\\nmake it very difﬁcult for students to appreciate these kinds of connections.\\n4. Manageable size. It is very useful to have a text compact enough that all of the\\nmaterial in it can be covered in few weeks or months of intensive review. Most\\ncandidates will have only that much time to prepare for an interview, so a longer\\ntext is of no use to them.\\nThe text that follows is an attempt to meet all of the above challenges. It will\\ninevitably prove more successful at handling some of them than others, but it\\nhas at least made a sincere and devoted effort.'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 6, 'page_label': '7'}, page_content='A note about Bibliography\\nThe book provides a carefully curated bibliography to guide further study , whether\\nfor interview preparation or simply as a matter of interest or job-relevant research. A\\ncomprehensive bibliography would be far too long to include here, and would be of\\nlittle immediate use, so the selections have been made with deliberate attention to the\\nvalue of each included text.\\nOnly the most important books and articles on each topic have been included, and\\nonly those written in English that I personally consulted. Each is given a brief annota-\\ntion to indicate its scope and applicability . Many of the works cited will be found to\\ninclude very full bibliographies of the particular subject treated, and I recommend\\nturning there if you wish to dive deeper into a speciﬁc topic, method, or process.\\nWe have a web page for this book, where we list errata, examples, and any ad-\\nditional information. You can access this page at: http://www.interviews.ai.\\nTo comment or ask technical questions about this book, send email to: entropy@\\ninterviews.ai.\\nI would also like to solicit corrections, criticisms, and suggestions from students\\nand other readers. Although I have tried to eliminate errors over the multi year\\nprocess of writing and revising this text, a few undoubtedly remain. In particular,\\nsome typographical infelicities will no doubt ﬁnd their way into the ﬁnal version. I\\nhope you will forgive them .\\nTHE AUTHOR .\\nTEL AVIV ISRAEL, D ECEMBER , 2020. F IRST PRINTING , D ECEMBER 2020.'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 7, 'page_label': '8'}, page_content='ACKNOWLEDGEMENTS.\\nThe thanks and acknowledgements of the publisher are due to the following:\\nMy dear son, Amir Ivry , Matthew Isaac Harvey , Sandy Noymer, Steve foot and V elimir\\nGayevskiy .'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 8, 'page_label': '9'}, page_content='AUTHOR ’S BIOGRAPHY .\\nWhen Shlomo typed his book in LATEX, he wanted it to\\nreﬂect some of his passions: AI, design, typography , and\\nmost notably coding. On a typical day , his two halves - the\\nscientist and the artist - spend hours meticulously design-\\ning AI systems, from epilepsy prediction and pulmonary\\nnodule detection, to training a computer-vision model on\\na cluster.\\nShlomo spends whole days in a lab full of GPUs work-\\ning on his many interesting research projects. Though re-\\nsearch satisﬁes his itch for discovery , his most important\\nscientiﬁc contribution, he says, is helping other researchers.\\nAnd the results are evident in his publications. But, al-\\nthough theoretical studies are important, practical experi-\\nence has many great virtues. As the Head of AI at DeepOncology , he developed uses\\nof Deep Learning for precise tumour detection, expanding and reﬁning what human\\nexperts are capable of. The work, which relies on CNN’s, marks the culmination of a\\ncareer spent applying AI techniques to problems in medical AI. Shlomo holds an MSc\\nin Digital Signal Processing (Distinction) from the University of London.\\nA PERSONAL NOTE : In this ﬁrst volume, I purposely present a coherent, cumu-\\nlative, and content-speciﬁc core curriculum of the data science ﬁeld, including topics\\nsuch as information theory , Bayesian statistics, algorithmic differentiation, logistic re-\\ngression, perceptrons, and convolutional neural networks.\\nI hope you will ﬁnd this book stimulating. It is my belief that you the postgradu-\\nate students and job-seekers for whom the book is primarily meant will beneﬁt from\\nreading it; however, it is my hope that even the most experienced researchers will ﬁnd\\nit fascinating as well.\\nSHLOMO KASHANI ,T EL-AVIV,ISRAEL.'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 9, 'page_label': '10'}, page_content='ABOUT\\nTHE CHIEF\\nEDITOR .\\nAmir Ivry has been an applied research scientist in the ﬁelds\\nof deep learning and speech signal processing since 2015. A direct\\nPhD candidate in the Electrical and Computer Engineering Fac-\\nulty in the Technion - Israel Institute of Technology , Amir is the\\nauthor of over a dozen academic papers in leading IEEE journ-\\nals and top-tier conferences. For his contribution to the ﬁeld of\\nhands-free speech communication using deep neural networks,\\nAmir has received more than a dozen awards and honors, in-\\ncluding back-to-back Jacobs citations for research excellence, and\\nmost recently the international speech communication associ-\\nation grant. Being only 28 years old, he has been cemented as a popular lecturer in the\\nmachine learning community , and delivered technological sessions for MIT, Google\\nfor startups, Alibaba, and more. Amir is currently holding a position as an applied\\nresearch intern in Microsoft Advanced Technology Labs.'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 10, 'page_label': '11'}, page_content=''),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 11, 'page_label': '12'}, page_content='Contents\\nI Rusty Nail 1\\nHOW-TO USE THIS BOOK 3\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\nII Kindergarten 9\\nLOGISTIC REGRESSION 11\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 12, 'page_label': '13'}, page_content=\"PROBABILISTIC PROGRAMMING & BA YESIAN DL 41\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nIII High School 83\\nINFORMATION THEORY 85\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 87\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 101\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 13, 'page_label': '14'}, page_content=\"Kullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION 121\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 155\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 14, 'page_label': '15'}, page_content='The Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\nIV Bachelors 183\\nDEEP LEARNING: NN ENSEMBLES 185\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 202\\nDEEP LEARNING: CNN FEATURE EXTRACTION 205\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 15, 'page_label': '16'}, page_content='Neural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\nDEEP LEARNING 227\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 253\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 306\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nV Practice Exam 339\\nJOB INTERVIEW MOCK EXAM 341\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 16, 'page_label': '17'}, page_content='Classiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nVI V olume two 357\\nVOLUME TWO - PLAN 359\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nVariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . . . 361\\nText to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nxvi'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 17, 'page_label': '18'}, page_content='RUSTY NAIL\\nPART I'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 18, 'page_label': '19'}, page_content=''),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 19, 'page_label': '20'}, page_content='CHAPTER\\n1\\nHOW-TO USE THIS BOOK\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nStarting Your Career . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nAdvancing Your Career . . . . . . . . . . . . . . . . . . . . . . . 5\\nDiving Into Deep Learning . . . . . . . . . . . . . . . . . . . . . 5\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.1 Introduction\\nFirst of all, welcome to world of Deep Learning Interviews.\\n1.1.1 What makes this book so valuable\\nT\\nARGETED advertising. Deciphering dead languages. Detecting malignant\\ntumours. Predicting natural disasters. Every year we see dozens of new\\nuses for deep learning emerge from corporate R&R, academia, and plucky\\nentrepreneurs. Increasingly , deep learning and artiﬁcial intelligence are in-\\ngrained in our cultural consciousness. Leading universities are dedicating programs\\nto teaching them, and they make the headlines every few days.\\nThat means jobs. It means intense demand and intense competition. It means a\\ngeneration of data scientists and machine learning engineers making their way into'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 20, 'page_label': '21'}, page_content='1.1. INTRODUCTION\\nthe workforce and using deep learning to change how things work. This book is for\\nthem, and for you. It is aimed at current or aspiring experts and students in the ﬁeld\\npossessed of a strong grounding in mathematics, an active imagination, engaged cre-\\nativity , and an appreciation for data. It is hand-tailored to give you the best possible\\npreparation for deep learning job interviews by guiding you through hundreds of\\nfully solved questions.\\nThat is what makes the volume so speciﬁcally valuable to students and job seekers:\\nit provides them with the ability to speak conﬁdently and quickly on any relevant\\ntopic, to answer technical questions clearly and correctly , and to fully understand the\\npurpose and meaning of interview questions and answers.\\nThose are powerful, indispensable advantages to have when walking into the in-\\nterview room.\\nThe questions and problems the book poses are tough enough to cut your teeth\\non-and to dramatically improve your skills but theyre framed within thought provok-\\ning questions, powerful and engaging stories, and cutting edge scientiﬁc information.\\nWhat are bosons and fermions? What is choriionic villus? Where did the Ebola virus\\nﬁrst appear, and how does it spread? Why is binary options trading so dangerous?\\nYour curiosity will pull you through the book’s problem sets, formulas, and in-\\nstructions, and as you progress, you’ll deepen your understanding of deep learning.\\nThere are intricate connections between calculus, logistic regression, entropy , and deep\\nlearning theory; work through the book, and those connections will feel intuitive.\\n1.1.2 What will I learn\\nStarting Your Career\\nAre you actively pursuing a career in deep learning and data science, or hoping to do\\nso? If so, you’re in luck everything from deep learning to artiﬁcial intelligence is in\\nextremely high demand in the contemporary workforce. Deep learning professionals\\nare highly sought after and also ﬁnd themselves among the highest-paid employee\\ngroups in companies around the world.\\nSo your career choice is spot on, and the ﬁnancial and intellectual beneﬁts of land-\\ning a solid job are tremendous. But those positions have a high barrier to entry: the\\ndeep learning interview. These interviews have become their own tiny industry , with\\nHR employees having to specialize in the relevant topics so as to distinguish well-\\nprepared job candidates from those who simply have a loose working knowledge of\\nthe material. Outside the interview itself, the difference doesn’t always feel import-\\n4'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 21, 'page_label': '22'}, page_content='Chapter 1 HOW-TO USE THIS BOOK\\nant. Deep learning libraries are so good that a machine learning pipeline can often be\\nassembled with little high-skill input from the researcher themselves. But that level\\nof ability won’t cut it in the interview. You’ll be asked practical questions, technical\\nquestions, and theoretical questions, and expected to answer them all conﬁdently and\\nﬂuently .\\nFor unprepared candidates, that’s the end of the road. Many give up after repeated\\npost-interview rejections.\\nAdvancing Your Career\\nSome of you will be more conﬁdent. Those of you with years on the job will be highly\\nmotivated, exceptionally numerate, and prepared to take an active, hands-on role in\\ndeep learning projects. You probably already have extensive knowledge in applied\\nmathematics, computer science, statistics, and economics. Those are all formidable\\nadvantages.\\nBut at the same time, it’s unlikely that you will have prepared for the interview\\nitself. Deep learning interviews especially those for the most interesting, autonom-\\nous, and challenging positions demand that you not only know how to do your job\\nbut that you display that knowledge clearly , eloquently , and without hesitation. Some\\nquestions will be straightforward and familiar, but others might be farther aﬁeld or\\ndraw on areas you haven’t encountered since college.\\nThere is simply no reason to leave that kind of thing to chance. Make sure you’re\\nprepared. Conﬁrm that you are up-to-date on terms, concepts, and algorithms. Refresh\\nyour memory of fundamentals, and how they inform contemporary research practices.\\nAnd when the interview comes, walk into the room knowing that you’re ready for\\nwhat’s coming your way .\\nDiving Into Deep Learning\\n\"Deep Learning Job Interviews\" is organized into chapters that each consist of an Intro-\\nduction to a topic, Problems illustrating core aspects of the topic, and complete Solu-\\ntions. You can expect each question and problem in this volume to be clear, practical,\\nand relevant to the subject. Problems fall into two groups, conceptual and application-\\nbased. Conceptual problems are aimed at testing and improving your knowledge of\\nbasic underlying concepts, while applications are targeted at practicing or applying\\nwhat you’ve learned (most of these are relevant to Python and PyTorch). The chapters\\nare followed by a reference list of relevant formulas and a selective bibliography for\\nguide further reading.\\n5'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 22, 'page_label': '23'}, page_content='1.1. INTRODUCTION\\n1.1.3 How to Work Problems\\nIn real life, like in exams, you will encounter problems of varying difﬁculty . A good\\nskill to practice is recognizing the level of difﬁculty a problem poses. Job interviews\\nwill have some easy problems, some standard problems, and some much harder prob-\\nlems.\\nEach chapter of this book is usually organized into three sections: Introduction,\\nProblems, and Solutions. As you are attempting to tackle problems, resist the tempta-\\ntion to prematurely peek at the solution; It is vital to allow yourself to struggle for\\na time with the material. Even professional data scientists do not always know right\\naway how to resolve a problem. The art is in gathering your thoughts and ﬁguring\\nout a strategy to use what you know to ﬁnd out what you don’t.\\nPRB-1 \\uf059 CH.PRB- 1.1.\\nProblems outlined in grey make up the representative question set . This set of prob-\\nlems is intended to cover the most essential ideas in each section. These problems are usually\\nhighly typical of what you’d see on an interview, although some of them are atypical but\\ncarry an important moral. If you ﬁnd yourself unconﬁdent with the idea behind one of these,\\nit’s probably a good idea to practice similar problems. This representative question set is our\\nsuggestion for a minimal selection of problems to work on. Y ou are highly encouraged to\\nwork on more.\\nSOL-1 \\uf14b CH.SOL- 1.1. I am a solution. \\x04\\nIf you ﬁnd yourself at a real stand-off, go ahead and look for a clue in one of the\\nrecommended theory books. Think about it for a while, and don’t be afraid to read\\nback in the notes to look for a key idea that will help you proceed. If you still can’t\\nsolve the problem, well, we included the Solutions section for a reason! As you’re\\nreading the solutions, try hard to understand why we took the steps we did, instead\\nof memorizing step-by-step how to solve that one particular problem.\\nIf you struggled with a question quite a lot, it’s probably a good idea to return to it\\nin a few days. That might have been enough time for you to internalize the necessary\\nideas, and you might ﬁnd it easily conquerable. If you’re still having troubles, read\\nover the solution again, with an emphasis on understanding why each step makes\\nsense. One of the reasons so many job candidates are required to demonstrate their\\nability to resolves data science problems on the board, is that it hiring managers as-\\nsume it reﬂects their true problem-solving skills.\\n6'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 23, 'page_label': '24'}, page_content='Chapter 1 HOW-TO USE THIS BOOK\\nIn this volume, you will learn lots of concepts, and be asked to apply them in\\na variety of situations. Often, this will involve answering one really big problem by\\nbreaking it up into manageable chunks, solving those chunks, then putting the pieces\\nback together. When you see a particularly long question, remain calm and look for a\\nway to break it into pieces you can handle.\\n1.1.4 Types of Problems\\nTwo main types of problems are presented in this book.\\nCONCEPTUAL : The ﬁrst category is meant to test and improve your understanding\\nof basic underlying concepts. These often involve many mathematical calculations.\\nThey range in difﬁculty from very basic reviews of deﬁnitions to problems that require\\nyou to be thoughtful about the concepts covered in the section.\\nAn example in Information Theory follows.\\nPRB-2 \\uf059 CH.PRB- 1.2.\\nWhat is the distribution of maximum entropy, that is, the distribution which has the\\nmaximum entropy among all distributions on the bounded interval [a, b],(−∞, +∞)\\nSOL-2 \\uf14b CH.SOL- 1.2.\\nThe uniform distribution has the maximum entropy among all distributions on the\\nbounded interval: [a, b],(−∞, +∞).\\nThe variance of U (a, b) is σ2 = 1/12(b − a)2.\\nTherefore the entropy is:\\n1/2 log 12 + log σ. (1.1)\\n\\x04\\nAPPLICATION : Problems in this category are for practicing skills. It’s not enough to\\nunderstand the philosophical grounding of an idea: you have to be able to apply it in\\nappropriate situations. This takes practice! mostly in Python or in one of the available\\nDeep Learning Libraries such as PyTorch.\\nAn example in PyTorch follows.\\n7'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 24, 'page_label': '25'}, page_content='1.1. INTRODUCTION\\nPRB-3 \\uf059 CH.PRB- 1.3.\\nDescribe in your own words, what is the purpose of the following code in the context of\\ntraining a Convolutional Neural Network.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\nSOL-3 \\uf14b CH.SOL- 1.3.\\nDuring the training of a Convolutional Neural Network, data augmentation, and to some\\nextent dropout are used as core methods to decrease overﬁtting. Data augmentation is a regu-\\nlarization scheme that synthetically expands the data-set by utilizing label-preserving trans-\\nformations to add more invariant examples of the same data samples. It is most commonly\\nperformed in real time on the CPU during the training phase whilst the actual training mode\\ntakes place on the GPU. This may consist for instance, random rotations, random ﬂips, zoom-\\ning, spatial translations etc. \\x04\\n8'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 25, 'page_label': '26'}, page_content='KINDERGARTEN\\nPART II'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 26, 'page_label': '27'}, page_content=''),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 27, 'page_label': '28'}, page_content='CHAPTER\\n2\\nLOGISTIC REGRESSION\\nY ou should call it entropy for two reasons. In the ﬁrst place, your uncertainty\\nfunction has been used in statistical mechanics under that name. In the second\\nplace, and more importantly, no one knows what entropy really is, so in a debate\\nyou will always have the advantage.\\n— John von Neumann to Claude Shannon\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 28, 'page_label': '29'}, page_content='2.1. INTRODUCTION\\n2.1 Introduction\\nM\\nUltivariable methods are routinely utilized in statistical analyses across a\\nwide range of domains. Logistic regression is the most frequently used\\nmethod for modelling binary response data and binary classiﬁcation.\\nWhen the response variable is binary , it characteristically takes the form of 1/0,\\nwith 1 normally indicating a success and 0 a failure. Multivariable methods usually\\nassume a relationship between two or more independent, predictor variables, and\\none dependent, response variable. The predicted value of a response variable may be\\nexpressed as a sum of products, wherein each product is formed by multiplying the\\nvalue of the variable and its coefﬁcient. How the coefﬁcients are computed? from a\\nrespective data set. Logistic regression is heavily used in supervised machine learning\\nand has become the workhorse for both binary and multiclass classiﬁcation problems.\\nMany of the questions introduced in this chapter are crucial for truly understanding\\nthe inner-workings of artiﬁcial neural networks.\\n2.2 Problems\\n2.2.1 General Concepts\\nPRB-4 \\uf059 CH.PRB- 2.1.\\nTrue or False: For a ﬁxed number of observations in a data set, introducing more vari-\\nables normally generates a model that has a better ﬁt to the data. What may be the drawback\\nof such a model ﬁtting strategy?\\nPRB-5 \\uf059 CH.PRB- 2.2.\\nDeﬁne the term “odds of success” both qualitatively and formally. Give a numerical\\nexample that stresses the relation between probability and odds of an event occurring.\\nPRB-6 \\uf059 CH.PRB- 2.3.\\n1. Deﬁne what is meant by the term \"interaction\", in the context of a logistic regression\\npredictor variable.\\n12'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 29, 'page_label': '30'}, page_content='Chapter 2 LOGISTIC REGRESSION\\n2. What is the simplest form of an interaction? Write its formulae.\\n3. What statistical tests can be used to attest the signiﬁcance of an interaction term?\\nPRB-7 \\uf059 CH.PRB- 2.4.\\nTrue or False: In machine learning terminology, unsupervised learning refers to the\\nmapping of input covariates to a target response variable that is attempted at being predicted\\nwhen the labels are known.\\nPRB-8 \\uf059 CH.PRB- 2.5.\\nComplete the following sentence: In the case of logistic regression, the response vari-\\nable is the log of the odds of being classiﬁed in [...].\\nPRB-9 \\uf059 CH.PRB- 2.6.\\nDescribe how in a logistic regression model, a transformation to the response variable is\\napplied to yield a probability distribution. Why is it considered a more informative repres-\\nentation of the response?\\nPRB-10 \\uf059 CH.PRB- 2.7.\\nComplete the following sentence: Minimizing the negative log likelihood also means\\nmaximizing the [...] of selecting the [...] class.\\n2.2.2 Odds, Log-odds\\nPRB-11 \\uf059 CH.PRB- 2.8.\\nAssume the probability of an event occurring is p = 0.1.\\n1. What are the odds of the event occurring?.\\n2. What are the log-odds of the event occurring?.\\n13'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 30, 'page_label': '31'}, page_content='2.2. PROBLEMS\\n3. Construct the probability of the event as a ratio that equals 0.1.\\nPRB-12 \\uf059 CH.PRB- 2.9.\\nTrue or False: If the odds of success in a binary response is 4, the corresponding probab-\\nility of success is 0.8.\\nPRB-13 \\uf059 CH.PRB- 2.10.\\nDraw a graph of odds to probabilities , mapping the entire range of probabilities to\\ntheir respective odds.\\nPRB-14 \\uf059 CH.PRB- 2.11.\\nThe logistic regression model is a subset of a broader range of machine learning models\\nknown as generalized linear models (GLMs), which also include analysis of variance (AN-\\nOV A), vanilla linear regression, etc. There are three components to a GLM; identify these\\nthree components for binary logistic regression.\\nPRB-15 \\uf059 CH.PRB- 2.12.\\nLet us consider the logit transformation, i.e., log-odds. Assume a scenario in which the\\nlogit forms the linear decision boundary:\\nlog\\n(\\nPr(Y = 1|X)\\nPr(Y = 0|X)\\n)\\n= θ0 + θT X, (2.1)\\nfor a given vector of systematic components X and predictor variables θ. Write the mathem-\\natical expression for the hyperplane that describes the decision boundary.\\nPRB-16 \\uf059 CH.PRB- 2.13.\\nTrue or False: The logit function and the natural logistic (sigmoid) function are inverses\\nof each other.\\n14'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 31, 'page_label': '32'}, page_content='Chapter 2 LOGISTIC REGRESSION\\n2.2.3 The Sigmoid\\nThe sigmoid (Fig. 2.1) also known as the logistic function, is widely used in binary\\nclassiﬁcation and as a neuron activation function in artiﬁcial neural networks.\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−4x\\nσ(x) = 1\\n1+e−15x\\nFIGURE 2.1: Examples of two sigmoid functions.\\nPRB-17 \\uf059 CH.PRB- 2.14.\\nCompute the derivative of the natural sigmoid function:\\nσ(x) = 1\\n1 + e−x ∈ (0, 1). (2.2)\\nPRB-18 \\uf059 CH.PRB- 2.15.\\nRemember that in logistic regression, the hypothesis function for some parameter vector\\nβ and measurement vector x is deﬁned as:\\nhβ(x) = g(βT x) = 1\\n1 + e−βT x\\n= P (y = 1|x; β), (2.3)\\n15'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 32, 'page_label': '33'}, page_content='2.2. PROBLEMS\\nwhere y holds the hypothesis value.\\nSuppose the coefﬁcients of a logistic regression model with independent variables are as\\nfollows: β0 = −1.5, β1 = 3, β2 = −0.5.\\nAssume additionally, that we have an observation with the following values for the dependent\\nvariables: x1 = 1, x2 = 5. As a result, the logit equation becomes:\\nlogit = β0 + β1x1 + β2x2. (2.4)\\n1. What is the value of the logit for this observation?\\n2. What is the value of the odds for this observation?\\n3. What is the value of P (y = 1) for this observation?\\n2.2.4 Truly Understanding Logistic Regression\\nPRB-19 \\uf059 CH.PRB- 2.16.\\nProton therapy (PT) [ 2] is a widely adopted form of treatment for many types of cancer\\nincluding breast and lung cancer (Fig. 2.2).\\nFIGURE 2.2: Pulmonary nodules (left) and breast cancer (right).\\nA PT device which was not properly calibrated is used to simulate the treatment of\\ncancer. As a result, the PT beam does not behave normally. A data scientist collects inform-\\nation relating to this simulation. The covariates presented in T able 2.1 are collected during\\n16'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 33, 'page_label': '34'}, page_content='Chapter 2 LOGISTIC REGRESSION\\nthe experiment. The columns Yes and No indicate if the tumour was eradicated or not, re-\\nspectively.\\nTumour eradication\\nCancer Type Yes No\\nBreast 560 260\\nLung 69 36\\nTABLE 2.1: Tumour eradication statistics.\\nReferring to T able2.1:\\n1. What is the explanatory variable and what is the response variable?\\n2. Explain the use of relative risk and odds ratio for measuring association.\\n3. Are the two variables positively or negatively associated?\\nFind the direction and strength of the association using both relative risk and odds\\nratio.\\n4. Compute a 95% conﬁdence interval (CI) for the measure of association.\\n5. Interpret the results and explain their signiﬁcance.\\nPRB-20 \\uf059 CH.PRB- 2.17.\\nConsider a system for radiation therapy planning (Fig. 2.3). Given a patient with a ma-\\nlignant tumour, the problem is to select the optimal radiation exposure time for that patient.\\nA key element in this problem is estimating the probability that a given tumour will be erad-\\nicated given certain covariates. A data scientist collects information relating to this radiation\\ntherapy system.\\n17'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 34, 'page_label': '35'}, page_content='2.2. PROBLEMS\\nFIGURE 2.3: A multi-detector positron scanner used to locate tumours.\\nThe following covariates are collected; X1 denotes time in milliseconds that a patient is\\nirradiated with, X2 = holds the size of the tumour in centimeters, and Y notates a binary re-\\nsponse variable indicating if the tumour was eradicated. Assume that each response’ variable\\nYi is a Bernoulli random variable with success parameter pi, which holds:\\npi = eβ0+β1x1+β2x2\\n1 + eβ0+β1x1+β2x2\\n. (2.5)\\nThe data scientist ﬁts a logistic regression model to the dependent measurements and pro-\\nduces these estimated coefﬁcients:\\nˆβ0 = −6,\\nˆβ1 = 0.05,\\nˆβ2 = 1.\\n(2.6)\\n1. Estimate the probability that, given a patient who undergoes the treatment for 40\\nmilliseconds and who is presented with a tumour sized 3.5 centimetres, the system\\neradicates the tumour.\\n2. How many milliseconds the patient in part (a) would need to be radiated with to have\\nexactly a 50% chance of eradicating the tumour?\\n18'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 35, 'page_label': '36'}, page_content='Chapter 2 LOGISTIC REGRESSION\\nPRB-21 \\uf059 CH.PRB- 2.18.\\nRecent research [ 3] suggests that heating mercury containing dental amalgams may\\ncause the release of toxic mercury fumes into the human airways. It is also presumed that\\ndrinking hot coffee, stimulates the release of mercury vapour from amalgam ﬁllings (Fig.\\n2.4).\\nFIGURE 2.4: A dental amalgam.\\nT o study factors that affect migraines, and in particular, patients who have at least four\\ndental amalgams in their mouth, a data scientist collects data from 200K users with and\\nwithout dental amalgams. The data scientist then ﬁts a logistic regression model with an\\nindicator of a second migraine within a time frame of one hour after the onset of the ﬁrst mi-\\ngraine, as the binary response variable (e.g., migraine=1, no migraine=0). The data scientist\\nbelieves that the frequency of migraines may be related to the release of toxic mercury fumes.\\nThere are two independent variables:\\n1. X1 = 1 if the patient has at least four amalgams; 0 otherwise.\\n2. X2 = coffee consumption (0 to 100 hot cups per month).\\nThe output from training a logistic regression classiﬁer is as follows:\\nAnalysis of LR Parameter Estimates\\nParameter Estimate Std.Err Z-val Pr>|Z|\\nIntercept -6.36347 3.21362 -1.980 0.0477\\n$X_1$ -1.02411 1.17101 -0.875 0.3818\\n$X_2$ 0.11904 0.05497 2.165 0.0304\\n19'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 36, 'page_label': '37'}, page_content='2.2. PROBLEMS\\n1. Using X1 and X2, express the odds of a patient having a migraine for a second time.\\n2. Calculate the probability of a second migraine for a patient that has at least four\\namalgams and drank 100 cups per month?\\n3. For users that have at least four amalgams, is high coffee intake associated with an\\nincreased probability of a second migraine?\\n4. Is there statistical evidence that having more than four amalgams is directly associ-\\nated with a reduction in the probability of a second migraine?\\nPRB-22 \\uf059 CH.PRB- 2.19.\\nT o study factors that affect Alzheimer’s disease using logistic regression, a researcher\\nconsiders the link between gum (periodontal) disease and Alzheimer as a plausible risk factor\\n[1]. The predictor variable is a count of gum bacteria (Fig. 2.5) in the mouth.\\nFIGURE 2.5: A chain of spherical bacteria.\\nThe response variable, Y , measures whether the patient shows any remission (e.g. yes=1).\\nThe output from training a logistic regression classiﬁer is as follows:\\nParameter DF Estimate Std\\nIntercept 1 -4.8792 1.2197\\ngum bacteria 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of gum bacteria of a patient\\nis 33.\\n20'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 37, 'page_label': '38'}, page_content='Chapter 2 LOGISTIC REGRESSION\\n2. Find out the gum bacteria count at which the estimated probability of improvement is\\n0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1 in the total gum\\nbacteria count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total gum bacteria count. Remember that the most common conﬁdence levels\\nare 90%, 95%, 99%, and 99.9%. T able9.1 lists the z values for these levels.\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 2.2: Common conﬁdence levels.\\nPRB-23 \\uf059 CH.PRB- 2.20.\\nRecent research [ 4] suggests that cannabis (Fig. 2.6) and cannabinoids administration\\nin particular, may reduce the size of malignant tumours in rats.\\nFIGURE 2.6: Cannabis.\\n21'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 38, 'page_label': '39'}, page_content='2.2. PROBLEMS\\nT o study factors affecting tumour shrinkage, a deep learning researcher collects data from\\ntwo groups; one group is administered with placebo (a substance that is not medicine) and\\nthe other with cannabinoids. His main research revolves around studying the relationship\\n(T able2.3) between the anticancer properties of cannabinoids and tumour shrinkage:\\nTumour Shrinkage In Rats\\nGroup Yes No Sum\\nCannabinoids 60 6833 6893\\nPlacebo 130 6778 6909\\nSum 190 13611 13801\\nTABLE 2.3: Tumour shrinkage in rats.\\nFor the true odds ratio:\\n1. Find the sample odds ratio.\\n2. Find the sample log-odds ratio.\\n3. Compute a 95% conﬁdence interval ( z0.95 = 1.645; z0.975 = 1.96) for the true log odds\\nratio and true odds ratio.\\n2.2.5 The Logit Function and Entropy\\nPRB-24 \\uf059 CH.PRB- 2.21.\\nThe entropy (see Chapter 4) of a single binary outcome with probability p to receive 1 is\\ndeﬁned as:\\nH(p) ≡ −p log p − (1 − p) log(1 − p). (2.7)\\n1. At what p does H(p) attain its maximum value?\\n2. What is the relationship between the entropy H(p) and the logit function, given p?\\n22'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 39, 'page_label': '40'}, page_content='Chapter 2 LOGISTIC REGRESSION\\n2.2.6 Python/PyTorch/CPP\\nPRB-25 \\uf059 CH.PRB- 2.22.\\nThe following C++ code (Fig. 2.7) is part of a (very basic) logistic regression implement-\\nation module. For a theoretical discussion underlying this question, refer to problem 2.17.\\n1 #include ...\\n2 std::vector<double> theta { -6,0.05,1.0};\\n3 double sigmoid(double x) {\\n4 double tmp =1.0 / (1.0 + exp(-x));\\n5 std::cout << \"prob=\" << tmp<<std::endl;\\n6 return tmp;\\n7 }\\n8 double hypothesis(std::vector<double> x){\\n9 double z;\\n10 z=std::inner_product(std::begin(x), std ::end(x),\\nstd::begin(theta), 0.0);↪→\\n11 std::cout << \"inner_product=\" << z<<std::endl;\\n12 return sigmoid(z);\\n13 }\\n14 int classify(std::vector<double> x){\\n15 int hypo=hypothesis(x) > 0.5f;\\n16 std::cout << \"hypo=\" << hypo<<std::endl;\\n17 return hypo;\\n18 }\\n19 int main() {\\n20 std::vector<double> x1 { 1,40,3.5};\\n21 classify(x1);\\n22 }\\nFIGURE 2.7: Logistic regression in CPP\\n1. Explain the purpose of line 10, i.e., inner_product.\\n2. Explain the purpose of line 15, i.e., hypo(x) > 0.5f.\\n23'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 40, 'page_label': '41'}, page_content='2.2. PROBLEMS\\n3. What does θ (theta) stand for in line 2?\\n4. Compile and run the code, you can use:\\nhttps://repl.it/languages/cpp11 to evaluate the code.\\nWhat is the output?\\nPRB-26 \\uf059 CH.PRB- 2.23.\\nThe following Python code (Fig. 2.8) runs a very simple linear model on a two-dimensional\\nmatrix.\\n1 import torch\\n2 import torch.nn as nn\\n3\\n4 lin = nn.Linear(5, 7)\\n5 data = (torch.randn(3, 5))\\n6\\n7 print(lin(data).shape)\\n8 >?\\nFIGURE 2.8: A linear model in PyTorch\\nWithout actually running the code, determine what is the size of the matrix printed as a\\nresult of applying the linear model on the matrix.\\nPRB-27 \\uf059 CH.PRB- 2.24.\\nThe following Python code snippet (Fig. 2.9) is part of a logistic regression implementa-\\ntion module in Python.\\n24'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 41, 'page_label': '42'}, page_content='Chapter 2 LOGISTIC REGRESSION\\n1 from scipy.special import expit\\n2 import numpy as np\\n3 import math\\n4\\n5 def Func001(x):\\n6 e_x = np.exp(x - np.max(x))\\n7 return e_x / e_x.sum()\\n8\\n9 def Func002(x):\\n10 return 1 / (1 + math.exp(-x))\\n11\\n12 def Func003(x):\\n13 return x * (1-x)\\nFIGURE 2.9: Logistic regression methods in Python.\\nAnalyse the methods Func001 , Func002 and Func003 presented in Fig. 2.9, ﬁnd their\\npurposes and name them.\\nPRB-28 \\uf059 CH.PRB- 2.25.\\nThe following Python code snippet (Fig. 2.10) is part of a machine learning module in\\nPython.\\n25'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 42, 'page_label': '43'}, page_content='2.2. PROBLEMS\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5 ^^I^^I\\n6 def Func006(y_hat, y):\\n7 if y == 1:\\n8 return -np.log(y_hat)\\n9 else:\\n10 return -np.log(1 - y_hat)^^I\\nFIGURE 2.10: Logistic regression methods in Python.\\nAnalyse the method Func006 presented in Fig. 2.10. What important concept in machine-\\nlearning does it implement?\\nPRB-29 \\uf059 CH.PRB- 2.26.\\nThe following Python code snippet (Fig. 2.11) presents several different variations of the\\nsame function.\\n26'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 43, 'page_label': '44'}, page_content='Chapter 2 LOGISTIC REGRESSION\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5\\n6 def Ver001(x):\\n7 return 1 / (1 + math.exp(-x))\\n8\\n9 def Ver002(x):\\n10 return 1 / (1 + (np.exp(-x)))\\n11\\n12 WHO_AM_I = 709\\n13\\n14 def Ver003(x):\\n15 return 1 / (1 + np.exp(-(np.clip(x, -WHO_AM_I, None))))\\nFIGURE 2.11: Logistic regression methods in Python.\\n1. Which mathematical function do these methods implement?\\n2. What is signiﬁcant about the number 709 in line 11?\\n3. Given a choice, which method would you use?\\n2.3 Solutions\\n2.3.1 General Concepts\\nSOL-4 \\uf14b CH.SOL- 2.1.\\nTrue. However, when an excessive and unnecessary number of variables is used in a lo-\\ngistic regression model, peculiarities (e.g., speciﬁc attributes) of the underlying data set dis-\\nproportionately affect the coefﬁcients in the model, a phenomena commonly referred to as\\n“overﬁtting”. Therefore, it is important that a logistic regression model does not start training\\nwith more variables than is justiﬁed for the given number of observations. \\x04\\n27'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 44, 'page_label': '45'}, page_content='2.3. SOLUTIONS\\nSOL-5 \\uf14b CH.SOL- 2.2.\\nThe odds of success are deﬁned as the ratio between the probability of success p ∈ [0, 1]\\nand the probability of failure 1 − p. Formally:\\nOdds(p) ≡\\n(\\np\\n1 − p\\n)\\n. (2.8)\\nFor instance, assuming the probability of success of an event is p = 0 .7. Then, in our\\nexample, the odds of success are 7/3, or 2.333 to 1. Naturally, in the case of equal probabilities\\nwhere p = 0.5, the odds of success is 1 to 1.\\n\\x04\\nSOL-6 \\uf14b CH.SOL- 2.3.\\n1. An interaction is the product of two single predictor variables implying a non-additive\\neffect.\\n2. The simplest interaction model includes a predictor variable formed by multiplying two\\nordinary predictors. Let us assume two variables X and Z. Then, the logistic regression\\nmodel that employs the simplest form of interaction follows:\\nβ0 + β1X + β2Z + β3XZ, (2.9)\\nwhere the coefﬁcient for the interaction term XZ is represented by predictor β3.\\n3. For testing the contribution of an interaction, two principal methods are commonly\\nemployed; the Wald chi-squared test or a likelihood ratio test between the model with\\nand without the interaction term. Note: How does interaction relates to information\\ntheory? What added value does it employ to enhance model performance?\\n\\x04\\nSOL-7 \\uf14b CH.SOL- 2.4.\\nFalse. This is exactly the deﬁnition of supervised learning; when labels are known then\\nsupervision guides the learning process. \\x04\\n28'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 45, 'page_label': '46'}, page_content='Chapter 2 LOGISTIC REGRESSION\\nSOL-8 \\uf14b CH.SOL- 2.5.\\nIn the case of logistic regression, the response variable is the log of the odds of being clas-\\nsiﬁed in a group of binary or multi-class responses. This deﬁnition essentially demonstrates\\nthat odds can take the form of a vector. \\x04\\nSOL-9 \\uf14b CH.SOL- 2.6.\\nWhen a transformation to the response variable is applied, it yields a probability distribu-\\ntion over the output classes, which is bounded between 0 and 1; this transformation can be\\nemployed in several ways, e.g., a softmax layer, the sigmoid function or classic normalization.\\nThis representation facilitates a soft-decision by the logistic regression model, which permits\\nconstruction of probability-based processes over the predictions of the model. Note: What are\\nthe pros and cons of each of the three aforementioned transformations? \\x04\\nSOL-10 \\uf14b CH.SOL- 2.7.\\nMinimizing the negative log likelihood also means maximizing the likelihood of selecting\\nthe correct class. \\x04\\n2.3.2 Odds, Log-odds\\nSOL-11 \\uf14b CH.SOL- 2.8.\\n1. The odds of the event occurring are, by deﬁnition:\\nodds = ( 0.1\\n0.9 ) = 0 .11. (2.10)\\n2. The log-odds of the event occurring are simply taken as the log of the odds:\\nlog-odds = ln(0.1/0.9) = −2.19685. (2.11)\\n3. The probability may be constructed by the following representation:\\nprobability = odds\\nodds + 1 = 0.11\\n1.11 = 0.1, (2.12)\\n29'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 46, 'page_label': '47'}, page_content='2.3. SOLUTIONS\\nor, alternatively:\\np = exp (ln odds)\\nexp (ln odds) + 1 = 0.11\\n1.11 = 0.1. (2.13)\\nNote: What is the intuition behind this representation?\\n\\x04\\nSOL-12 \\uf14b CH.SOL- 2.9.\\nTrue. By deﬁnition of odds, it is easy to notice that p = 0.8 satisﬁes the following relation:\\nodds = ( 0.8\\n0.2) = 4 (2.14)\\n\\x04\\nSOL-13 \\uf14b CH.SOL- 2.10.\\nThe graph of odds to probabilities is depicted in Figure 2.12.\\n0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 0,9\\n2,0\\n4,0\\n6,0\\n8,0\\n10,0\\nProbability\\nOdds odds(p) = p\\n1−p\\nFIGURE 2.12: Odds vs. probability values.\\n\\x04\\n30'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 47, 'page_label': '48'}, page_content='Chapter 2 LOGISTIC REGRESSION\\nSOL-14 \\uf14b CH.SOL- 2.11.\\nA binary logistic regression GLM consists of there components:\\n1. Random component: refers to the probability distribution of the response variable (Y ),\\ne.g., binomial distribution for Y in the binary logistic regression, which takes on the\\nvalues Y = 0 or Y = 1.\\n2. Systematic component: describes the explanatory variables:\\n(X1, X2, ...) as a combination of linear predictors. The binary case does not constrain\\nthese variables to any degree.\\n3. Link function: speciﬁes the link between random and systematic components. It says\\nhow the expected value of the response relates to the linear predictor of explanatory\\nvariables.\\nNote: Assume that Y denotes whether a human voice activity was detected ( Y = 1 )\\nor not ( Y = 0 ) in a give time frame. Propose two systematic components and a link\\nfunction adjusted for this task.\\n\\x04\\nSOL-15 \\uf14b CH.SOL- 2.12.\\nThe hyperplane is simply deﬁned by:\\nθ0 + θT X = 0. (2.15)\\nNote: Recall the use of the logit function and derive this decision boundary rigorously. \\x04\\nSOL-16 \\uf14b CH.SOL- 2.13.\\nTrue. The logit function is deﬁned as:\\nz(p) = logit(p) = log\\n(\\np\\n1 − p\\n)\\n, (2.16)\\n31'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 48, 'page_label': '49'}, page_content='2.3. SOLUTIONS\\nfor any p ∈ [0, 1]. A simple set of algebraic equations yields the inverse relation:\\np(z) = exp z\\n1 + exp z , (2.17)\\nwhich exactly describes the relation between the output and input of the logistic function, also\\nknown as the sigmoid. \\x04\\n2.3.3 The Sigmoid\\nSOL-17 \\uf14b CH.SOL- 2.14.\\nThere are various approaches to solve this problem, here we provide two; direct derivation\\nor derivation via the softmax function.\\n1. Direct derivation:\\nd\\ndx σ(x) = d\\ndx ((1 + e−x)−1) = −((1 + e−x)(−2)) d\\ndx (1 + e−x) = e−x\\n(1+e−x)2 .\\n2. Softmax derivation:\\nIn a classiﬁcation problem with mutually exclusive classes, where all of the values are\\npositive and sum to one, a softmax activation function may be used. By deﬁnition, the\\nsoftmax activation function consists of n terms, such that ∀i ∈ [1, n]:\\nf (θi) = eθi\\n∑\\nk evk\\n= 1\\n1 + e−θi\\n∑\\nk̸=i eθk\\n. (2.18)\\nT o compute the partial derivative of 2.18, we treat all θk where k ̸= i as constants and\\nthen differentiate θi using regular differentiation rules. For a given θi, let us deﬁne:\\nβ =\\n∑\\nk̸=i\\neθk, (2.19)\\nand\\nf (θi) = 1\\n1 + βe−θi\\n= (1 + βe−θi)−1. (2.20)\\nIt can now be shown that the derivative with respect to θi holds:\\nf ′(θi) =\\n(\\n1 + βe−θi\\n) −2\\nβe−θi, (2.21)\\n32'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 49, 'page_label': '50'}, page_content='Chapter 2 LOGISTIC REGRESSION\\nwhich can take on the informative form of:\\nf ′(θi) = f (θi)(1 − f (θi)). (2.22)\\nIt should be noted that 2.21 holds for any constant β, and for β = 1 it clearly reduces\\nto the sigmoid activation function.\\nNote: Characterize the sigmoid function when its argument approaches 0, ∞ and −∞.\\nWhat undesired properties of the sigmoid function do this values entail when considered as an\\nactivation function?\\n\\x04\\nSOL-18 \\uf14b CH.SOL- 2.15.\\n1. The logit value is simply obtained by substituting the values of the dependent variables\\nand model coefﬁcients into the linear logistic regression model, as follows:\\nlogit = β0 + β1x1 + β2x2 = −1.5 + 3 · 1 + −0.5 · 5 = −1. (2.23)\\n2. According to the natural relation between the logit and the odds, the following holds:\\nodds = elogit = eβ0+β1x1+β2x2 = e−1 = 0.3678794. (2.24)\\n3. The odds ratio is, by deﬁnition:\\nodds = P (y = 1)\\nP (y = 0) , (2.25)\\nso the logistic response function is:\\nP (y = 1) = 1\\n1 + e−logit = 1\\n1 + e1 = 0.2689414. (2.26)\\n\\x04\\n2.3.4 Truly Understanding Logistic Regression\\n33'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 50, 'page_label': '51'}, page_content='2.3. SOLUTIONS\\nSOL-19 \\uf14b CH.SOL- 2.16.\\n1. T umour eradication (Y ) is the response variable and cancer type ( X) is the explanatory\\nvariable.\\n2. Relative risk (RR) is the ratio of risk of an event in one group (e.g., exposed group)\\nversus the risk of the event in the other group (e.g., non-exposed group). The odds ratio\\n(OR) is the ratio of odds of an event in one group versus the odds of the event in the\\nother group.\\n3. If we calculate odds ratio as a measure of association:\\nˆθ = 560 × 36\\n69 × 260 = 1.23745. (2.27)\\nAnd the log-odds ratio is (log(1.23745)) = 0 .213052:\\nThe odds ratio is larger than one, indicating that the odds for a breast cancer is more\\nthan the odds for a lung cancer to be eradicated. Notice however, that this result is too\\nclose to one, which prevents conclusive decision regarding the odds relation.\\nAdditionally, if we calculate relative risk as a measure of association:\\nRR =\\n560\\n560+260\\n69\\n69+36\\n= 1.0392. (2.28)\\n4. The 95% conﬁdence interval for the odds-ratio, θ is computed from the sample conﬁd-\\nence interval for log odds ratio:\\nˆσ\\n(\\nlog(ˆθ)\\n)\\n=\\n√\\n1\\n560 + 1\\n260 + 1\\n69 + 1\\n36 = 0.21886. (2.29)\\nTherefore, the 95% CI for log (θ) is:\\n0.213052 ± 1.95 × 0.21886 = (0 .6398298, −0.2137241). (2.30)\\n34'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 51, 'page_label': '52'}, page_content='Chapter 2 LOGISTIC REGRESSION\\nTherefore, the 95% CI for θ is:\\n(e−0.210, e0.647) = (0 .810, 1.909). (2.31)\\n5. The CI (0.810, 1.909) contains 1, which indicates that the true odds ratio is not signi-\\nﬁcantly different from 1 and there is not enough evidence that tumour eradication is\\ndependent on cancer type.\\n\\x04\\nSOL-20 \\uf14b CH.SOL- 2.17.\\n1. By using the deﬁned values for X1 and X2, and the known logistic regression model,\\nsubstitution yields:\\nˆp(X) = e−6+0.05X1+X2\\n(1 + e−6+0.05X1+X2) = 0.3775. (2.32)\\n2. The equation for the predicted probability tells us that:\\ne−6+0.05X1+3.5\\n(1 + e−6+0.05X1+3.5) = 0.5, (2.33)\\nwhich is equivalent to constraining:\\ne−6+0.05X1+3.5 = 1. (2.34)\\nBy taking the logarithm of both sides, we get that the number of milliseconds needed is:\\nX1 = 2.5\\n0.05 = 50. (2.35)\\n\\x04\\nSOL-21 \\uf14b CH.SOL- 2.18.\\n35'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 52, 'page_label': '53'}, page_content='2.3. SOLUTIONS\\nFor the purpose of this exercise, it is instructive to pre-deﬁne z as:\\nz (X1, X2) = −6.36 − 1.02 × X1 + 0.12 × X2. (2.36)\\n1. By employing the classic logistic regression model:\\nodds = exp(z (X1, X2)). (2.37)\\n2. By substituting the given values of X1, X2 into z (X1, X2), the probability holds:\\np = exp(z (1, 100))/(1 + exp(z (1, 100))) = 0 .99. (2.38)\\n3. Y es. The coefﬁcient for coffee consumption is positive ( 0.119) and the p-value is less\\nthan 0.05 (0.0304).\\nNote: Can you describe the relation between these numerical relations and the positive\\nconclusion?\\n4. No. The p-value for this predictor is 0.3818 > 0.05.\\nNote: Can you explain why this inequality implicates a lack of statistical evidence?\\n\\x04\\nSOL-22 \\uf14b CH.SOL- 2.19.\\n1. The estimated probability of improvement is:\\nˆπ(gum bacteria) =\\nexp(−4.8792 + 0.0258 × gum bacteria)\\n1 + exp(−4.8792 + 0.0258 × gum bacteria).\\nHence, ˆπ(33) = 0 .01748.\\n36'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 53, 'page_label': '54'}, page_content='Chapter 2 LOGISTIC REGRESSION\\n2. For ˆπ(gum bacteria) = 0 .5 we know that:\\nˆπ(gum) = exp( ˆα + ˆβx)\\n1 + exp( ˆα + ˆβx)\\n= 0.5 (2.39)\\ngum bacteria = −ˆα/ ˆβ = 4.8792/0.0258 = 189 .116. (2.40)\\n3. The estimated odds ratio are given by:\\nexp( ˆβ) = exp(0 .0258) = 1 .0504. (2.41)\\n4. A 99% conﬁdence interval for β is calculated as follows:\\nˆβ ± z0.005 × ASE( ˆβ) = (2.42)\\n0.0258 ± 2.576 × 0.0194 (2.43)\\n= (−0.00077, 0.9917). (2.44)\\nTherefore, a 99% conﬁdence interval for the true odds ratio exp(β) is given by:\\n(exp(−0.00077), exp(0.9917)) = (0 .99923, 2.6958). (2.45)\\n\\x04\\nSOL-23 \\uf14b CH.SOL- 2.20.\\n1. The sample odds ratio is:\\nˆθ = 130 × 6833\\n60 × 6778 = 2.1842. (2.46)\\n37'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 54, 'page_label': '55'}, page_content='2.3. SOLUTIONS\\n2. The estimated standard error for log\\n(\\nˆθ\\n)\\nis:\\nˆσ\\n(\\nlog ˆθ\\n)\\n=\\n√\\n1\\n60 + 1\\n6833 + 1\\n130 + 1\\n6778 = 0.1570. (2.47)\\n3. According to previous sections, the 95% CI for the true log odds ratio is:\\n0.7812 ± 1.96 × 0.1570 = (0 .4734, 1.0889). (2.48)\\nCorrespondingly, the 95% CI for the true odds ratio is:\\n(e0.4734, e1.0889) = (1 .6060, 2.9710). (2.49)\\n\\x04\\n2.3.5 The Logit Function and Entropy\\nSOL-24 \\uf14b CH.SOL- 2.21.\\n1. The entropy (Fig. 2.13) has a maximum value of log2(2) for probability p = 1/2, which\\nis the most chaotic distribution. A lower entropy is a more predictable outcome, with\\nzero providing full certainty.\\n2. The derivative of the entropy with respect to p yields the negative of the logit func-\\ntion:\\ndH(p)\\ndp = −logit(p). (2.50)\\nNote: The curious reader is encouraged to rigorously prove this claim.\\n\\x04\\n2.3.6 Python, PyTorch, CPP\\nSOL-25 \\uf14b CH.SOL- 2.22.\\n38'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 55, 'page_label': '56'}, page_content='Chapter 2 LOGISTIC REGRESSION\\nFIGURE 2.13: Binary entropy .\\n1. During inference, the purpose of inner_product is to multiply the vector of logistic re-\\ngression coefﬁcients with the vector of the input which we like to evaluate, e.g., calculate\\nthe probability and binary class.\\n2. The line hypo(x) > 0.5f is commonly used for the evaluation of binary classiﬁcation\\nwherein probability values above 0.5 (i.e., a threshold) are regarded as TRUE whereas\\nvalues below 0.5 are regarded as F ALSE.\\n3. The term θ (theta) stands for the logistic regression coefﬁcients which were evaluated\\nduring training.\\n4. The output is as follows:\\n1 > inner_product=-0.5\\n2 > prob=0.377541\\n3 > hypo=0\\nFIGURE 2.14: Logistic regression in C++\\n\\x04\\nSOL-26 \\uf14b CH.SOL- 2.23.\\n39'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 56, 'page_label': '57'}, page_content='2.3. SOLUTIONS\\nBecause the second dimension of lin is 7, and the ﬁrst dimension of data is 3, the result-\\ning matrix has a shape of torch.Size([3, 7]) .\\n\\x04\\nSOL-27 \\uf14b CH.SOL- 2.24.\\nIdeally, you should be able to recognize these functions immediately upon a request from\\nthe interviewer.\\n1. A softmax function.\\n2. A sigmoid function.\\n3. A derivative of a sigmoid function.\\n\\x04\\nSOL-28 \\uf14b CH.SOL- 2.25.\\nThe function implemented in Fig. 2.10 is the binary cross-entropy function. \\x04\\nSOL-29 \\uf14b CH.SOL- 2.26.\\n1. All the methods are variations of the sigmoid function.\\n2. In Python, approximately 1.797e + 308 holds the largest possible valve for a ﬂoating\\npoint variable. The logarithm of which is evaluated at 709.78. If you try to execute the\\nfollowing expression in Python, it will result in inf : np.log(1.8e + 308).\\n3. I would use Ver003 because of its stability. Note: Can you entail why is this method\\nmore stable than the others?\\n\\x04\\n40'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 57, 'page_label': '58'}, page_content='CHAPTER\\n3\\nPROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAnyone who considers arithmetical methods of producing random digits is, of\\ncourse, in a state of sin.\\n— John von Neumann (1903-1957)\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nThe Beta-Binomial distribution . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 77'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 58, 'page_label': '59'}, page_content='3.1. INTRODUCTION\\n3.1 Introduction\\nT\\nHE Bayesian school of thought has permeated ﬁelds such as mechanical\\nstatistics, classical probability , and ﬁnancial mathematics [ 13]. In tandem,\\nthe subject matter itself has gained attraction, particularly in the ﬁeld of\\nBML. It is not surprising then, that several new Python based probabilistic\\nprogramming libraries such as PyMc3 and Stan [ 11] have emerged and have become\\nwidely adopted by the machine learning community .\\nThis chapter aims to introduce the Bayesian paradigm and apply Bayesian infer-\\nences in a variety of problems. In particular, the reader will be introduced with real-\\nlife examples of conditional probability and also discover one of the most important\\nresults in Bayesian statistics: that the family of beta distributions is conjugate to a bi-\\nnomial likelihood . It should be stressed that Bayesian inference is a subject matter\\nthat students evidently ﬁnd hard to grasp, since it heavily relies on rigorous probab-\\nilistic interpretations of data. Speciﬁcally , several obstacles hamper with the prospect\\nof learning Bayesian statistics:\\n1. Students typically undergo merely basic introduction to classical probability and\\nstatistics. Nonetheless, what follows requires a very solid grounding in these\\nﬁelds.\\n2. Many courses and resources that address Bayesian learning do not cover essen-\\ntial concepts.\\n3. A strong comprehension of Bayesian methods involves numerical training and\\nsophistication levels that go beyond ﬁrst year calculus.\\nConclusively , this chapter may be much harder to understand than other chapters.\\nThus, we strongly urge the readers to thoroughly solve the following questions and\\nverify their grasp of the mathematical concepts in the basis of the solutions [ 8].\\n3.2 Problems\\n3.2.1 Expectation and Variance\\nPRB-30 \\uf059 CH.PRB- 3.1.\\nDeﬁne what is meant by a Bernoulli trial.\\n42'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 59, 'page_label': '60'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPRB-31 \\uf059 CH.PRB- 3.2.\\nThe binomial distribution is often used to model the probability that k out of a group of n\\nobjects bare a speciﬁc characteristic. Deﬁne what is meant by a binomial random variable\\nX.\\nPRB-32 \\uf059 CH.PRB- 3.3.\\nWhat does the following shorthand stand for?\\nX ∼ Binomial(n, p ) (3.1)\\nPRB-33 \\uf059 CH.PRB- 3.4.\\nFind the probability mass function (PMF) of the following random variable:\\nX ∼ Binomial(n, p ) (3.2)\\nPRB-34 \\uf059 CH.PRB- 3.5.\\nAnswer the following questions:\\n1. Deﬁne what is meant by (mathematical) expectation.\\n2. Deﬁne what is meant by variance.\\n3. Derive the expectation and variance of a the binomial random variable X ∼ Binomial(n, p )\\nin terms of p and n.\\nPRB-35 \\uf059 CH.PRB- 3.6.\\nProton therapy (PT) is a widely adopted form of treatment for many types of cancer [ 6].\\nA PT device which was not properly calibrated is used to treat a patient with pancreatic\\ncancer (Fig. 3.1). As a result, a PT beam randomly shoots 200 particles independently and\\ncorrectly hits cancerous cells with a probability of 0.1.\\n43'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 60, 'page_label': '61'}, page_content='3.2. PROBLEMS\\nFIGURE 3.1: Histopathology for pancreatic cancer cells.\\n1. Find the statistical distribution of the number of correct hits on cancerous cells in\\nthe described experiment. What are the expectation and variance of the corresponding\\nrandom variable?\\n2. A radiologist using the device claims he was able to hit exactly 60 cancerous cells.\\nHow likely is it that he is wrong?\\n3.2.2 Conditional Probability\\nPRB-36 \\uf059 CH.PRB- 3.7.\\nGiven two events A and B in probability space H, which occur with probabilities P (A)\\nand P (B), respectively:\\n1. Deﬁne the conditional probability of A given B. Mind singular cases.\\n2. Annotate each part of the conditional probability formulae.\\n3. Draw an instance of Venn diagram, depicting the intersection of the events A and B.\\nAssume that A ⋃ B = H.\\nPRB-37 \\uf059 CH.PRB- 3.8.\\nBayesian inference amalgamates data information in the likelihood function with known\\nprior information. This is done by conditioning the prior on the likelihood using the Bayes\\nformulae. Assume two events A and B in probability space H, which occur with probabilities\\n44'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 61, 'page_label': '62'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nP (A) and P (B), respectively. Given that A ⋃ B = H, state the Bayes formulae for this case,\\ninterpret its components and annotate them.\\nPRB-38 \\uf059 CH.PRB- 3.9.\\nDeﬁne the terms likelihood and log-likelihood of a discrete random variable X given\\na ﬁxed parameter of interest γ. Give a practical example of such scenario and derive its\\nlikelihood and log-likelihood.\\nPRB-39 \\uf059 CH.PRB- 3.10.\\nDeﬁne the term prior distribution of a likelihood parameter γ in the continuous case.\\nPRB-40 \\uf059 CH.PRB- 3.11.\\nShow the relationship between the prior, posterior and likelihood probabilities.\\nPRB-41 \\uf059 CH.PRB- 3.12.\\nIn a Bayesian context, if a ﬁrst experiment is conducted, and then another experiment is\\nfollowed, what does the posterior become for the next experiment?\\nPRB-42 \\uf059 CH.PRB- 3.13.\\nWhat is the condition under which two events A and B are said to be statistically\\nindependent?\\n3.2.3 Bayes Rule\\nPRB-43 \\uf059 CH.PRB- 3.14.\\nIn an experiment conducted in the ﬁeld of particle physics (Fig. 3.2), a certain particle\\nmay be in two distinct equally probable quantum states: integer spin or half-integer spin.\\nIt is well-known that particles with integer spin are bosons, while particles with half-integer\\nspin are fermions [ 4].\\n45'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 62, 'page_label': '63'}, page_content='3.2. PROBLEMS\\nFIGURE 3.2: Bosons and fermions: particles with half-integer spin are fermions.\\nA physicist is observing two such particles, while at least one of which is in a half-integer\\nstate. What is the probability that both particles are fermions?\\nPRB-44 \\uf059 CH.PRB- 3.15.\\nDuring pregnancy, the Placenta Chorion T est [1] is commonly used for the diagnosis of\\nhereditary diseases (Fig. 3.3). The test has a probability of 0.95 of being correct whether or\\nnot a hereditary disease is present.\\n46'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 63, 'page_label': '64'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.3: Foetal surface of the placenta\\nIt is known that 1% of pregnancies result in hereditary diseases. Calculate the probability\\nof a test indicating that a hereditary disease is present.\\nPRB-45 \\uf059 CH.PRB- 3.16.\\nThe Dercum disease [ 3] is an extremely rare disorder of multiple painful tissue growths.\\nIn a population in which the ratio of females to males is equal, 5% of females and 0.25% of\\nmales have the Dercum disease (Fig. 3.4).\\nFIGURE 3.4: The Dercum disease\\nA person is chosen at random and that person has the Dercum disease. Calculate the\\nprobability that the person is female.\\nPRB-46 \\uf059 CH.PRB- 3.17.\\nThere are numerous fraudulent binary options websites scattered around the Internet,\\nand for every site that shuts down, new ones are sprouted like mushrooms. A fraudulent AI\\n47'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 64, 'page_label': '65'}, page_content='3.2. PROBLEMS\\nbased stock-market prediction algorithm utilized at the New Y ork Stock Exchange, (Fig. 3.6)\\ncan correctly predict if a certain binary option [ 7] shifts states from 0 to 1 or the other way\\naround, with 85% certainty.\\nFIGURE 3.5: The New York Stock Exchange.\\nA ﬁnancial engineer has created a portfolio consisting twice as many state-1 options then\\nstate-0 options. A stock option is selected at random and is determined by said algorithm to\\nbe in the state of 1. What is the probability that the prediction made by the AI is correct?\\nPRB-47 \\uf059 CH.PRB- 3.18.\\nIn an experiment conducted by a hedge fund to determine if monkeys (Fig. 3.6) can\\noutperform humans in selecting better stock market portfolios, 0.05 of humans and 1 out of\\n15 monkeys could correctly predict stock market trends correctly.\\n48'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 65, 'page_label': '66'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.6: Hedge funds and monkeys.\\nFrom an equally probable pool of humans and monkeys an “expert” is chosen at ran-\\ndom. When tested, that expert was correct in predicting the stock market shift. What is the\\nprobability that the expert is a human?\\nPRB-48 \\uf059 CH.PRB- 3.19.\\nDuring the cold war, the U.S.A developed a speech to text (STT) algorithm that could\\ntheoretically detect the hidden dialects of Russian sleeper agents. These agents (Fig. 3.7),\\nwere trained to speak English in Russia and subsequently sent to the US to gather intelli-\\ngence. The FBI was able to apprehend ten such hidden Russian spies [ 9] and accused them\\nof being \"sleeper\" agents.\\nFIGURE 3.7: Dialect detection.\\n49'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 66, 'page_label': '67'}, page_content='3.2. PROBLEMS\\nThe Algorithm relied on the acoustic properties of Russian pronunciation of the word\\n(v-o-k-s-a-l) which was borrowed from English V-a-u-x-h-a-l-l. It was alleged that it is im-\\npossible for Russians to completely hide their accent and hence when a Russian would\\nsay V-a-u-x-h-a-l-l, the algorithm would yield the text \"v-o-k-s-a-l\". T o test the algorithm\\nat a diplomatic gathering where 20% of participants are Sleeper agents and the rest Americ-\\nans, a data scientist randomly chooses a person and asks him to say V-a-u-x-h-a-l-l. A single\\nletter is then chosen randomly from the word that was generated by the algorithm, which\\nis observed to be an \"l\". What is the probability that the person is indeed a Russian sleeper\\nagent?\\nPRB-49 \\uf059 CH.PRB- 3.20.\\nDuring World War II, forces on both sides of the war relied on encrypted communica-\\ntions. The main encryption scheme used by the German military was an Enigma machine\\n[5], which was employed extensively by Nazi Germany. Statistically, the Enigma machine\\nsent the symbols X and Z Fig. ( 3.8) according to the following probabilities:\\nP (X) = 2\\n9 (3.3)\\nP (Z) = 7\\n9 (3.4)\\nFIGURE 3.8: The Morse telegraph code.\\nIn one incident, the German military sent encoded messages while the British army used\\ncountermeasures to deliberately tamper with the transmission. Assume that as a result of the\\nBritish countermeasures, an X is erroneously received as a Z (and mutatis mutandis) with a\\n50'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 67, 'page_label': '68'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nprobability 1\\n7. If a recipient in the German military received a Z, what is the probability that\\na Z was actually transmitted by the sender?\\n3.2.4 Maximum Likelihood Estimation\\nPRB-50 \\uf059 CH.PRB- 3.21.\\nWhat is likelihood function of the independent identically distributed (i.i.d) random\\nvariables:\\nX1, · · · , Xn where Xi ∼ binomial(n, p ), ∀i ∈ [1, n],\\nand where p is the parameter of interest?\\nPRB-51 \\uf059 CH.PRB- 3.22.\\nHow can we derive the maximum likelihood estimator (MLE) of the i.i.d samples\\nX1, · · · , Xn introduced in Q. 3.21?\\nPRB-52 \\uf059 CH.PRB- 3.23.\\nWhat is the relationship between the likelihood function and the log-likelihood function?\\nPRB-53 \\uf059 CH.PRB- 3.24.\\nDescribe how to analytically ﬁnd the MLE of a likelihood function?\\nPRB-54 \\uf059 CH.PRB- 3.25.\\nWhat is the term used to describe the ﬁrst derivative of the log-likelihood function?\\nPRB-55 \\uf059 CH.PRB- 3.26.\\nDeﬁne the term Fisher information.\\n3.2.5 Fisher Information\\n51'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 68, 'page_label': '69'}, page_content='3.2. PROBLEMS\\nPRB-56 \\uf059 CH.PRB- 3.27.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history [ 2] with a death tool far exceeding all\\npast outbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976\\nin Sudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 3.9: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the center for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ | y) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y, γ ∈ [0, 1], y = 1, 2, . . . , n (3.5)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ,\\nthe proportion of infected humans in the entire population. The expectation and variance of\\nthe binomial distribution are:\\nE(y|γ, n) = nγ, V (y|γ, n) = nγ(1 − γ) (3.6)\\nAnswer the following; for the likelihood function of the form Lx(γ):\\n1. Find the log-likelihood function lx(γ) = ln Lx(γ).\\n52'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 69, 'page_label': '70'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. Find the gradient of lx(γ).\\n3. Find the Hessian matrix H(γ).\\n4. Find the Fisher information I(γ).\\n5. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\nPRB-57 \\uf059 CH.PRB- 3.28.\\nIn this question, you are going to derive the Fisher information function for several\\ndistributions. Given a probability density function (PDF) f (X|γ), you are provided with\\nthe following deﬁnitions:\\n1. The natural logarithm of the PDF ln f (X|γ) = Φ(X|γ).\\n2. The ﬁrst partial derivative Φ′(X|γ).\\n3. The second partial derivative Φ′′(X|γ).\\n4. The Fisher Information for a continuous random variable:\\nI(γ) = −Eγ\\n[\\nΦ′(X|γ)2\\n]\\n. (3.7)\\nFind the Fisher Information I(γ) for the following distributions:\\n1. The Bernoulli Distribution X ∼ B(1, γ).\\n2. The Poisson Distribution X ∼ P oiss(θ).\\nPRB-58 \\uf059 CH.PRB- 3.29.\\n1. True or False: The Fisher Information is used to compute the Cramer-Rao bound on\\nthe variance of any unbiased maximum likelihood estimator.\\n2. True or False: The Fisher Information matrix is also the Hessian of the symmetrized\\nKL divergence.\\n53'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 70, 'page_label': '71'}, page_content='3.2. PROBLEMS\\n3.2.6 Posterior & prior predictive distributions\\nPRB-59 \\uf059 CH.PRB- 3.30.\\nIn chapter 3 we discussed the notion of a prior and a posterior distribution.\\n1. Deﬁne the term posterior distribution.\\n2. Deﬁne the term prior predictive distribution.\\nPRB-60 \\uf059 CH.PRB- 3.31.\\nLet y be the number of successes in 5 independent trials, where the probability of success\\nis θ in each trial. Suppose your prior distribution for θ is as follows: P (θ = 1 /2) = 0 .25,\\nP (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y) after observing y.\\n2. Derive the prior predictive distribution for y.\\n3.2.7 Conjugate priors\\nPRB-61 \\uf059 CH.PRB- 3.32.\\nIn chapter 3 we discussed the notion of a prior and a posterior.\\n1. Deﬁne the term conjugate prior.\\n2. Deﬁne the term non-informative prior.\\nThe Beta-Binomial distribution\\nPRB-62 \\uf059 CH.PRB- 3.33.\\nThe Binomial distribution was discussed extensively in chapter 3. Here, we are going to\\nshow one of the most important results in Bayesian machine learning. Prove that the family\\nof beta distributions is conjugate to a binomial likelihood , so that if a prior is in that\\n54'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 71, 'page_label': '72'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nfamily then so is the posterior. That is, show that:\\nx ∼ Ber(γ), γ ∼ B (α, β) ⇒ γ|x ∼ B (α′, β′) (3.8)\\nFor instance, for h heads and t tails, the posterior is:\\nB(h + α, t + β) (3.9)\\n3.2.8 Bayesian Deep Learning\\nPRB-63 \\uf059 CH.PRB- 3.34.\\nA recently published paper presents a new layer for a new Bayesian neural network\\n(BNN). The layer behaves as follows. During the feed-forward operation, each of the hidden\\nneurons Hn , n ∈ 1, 2 in the neural network (Fig. 3.10) may, or may not ﬁre independently\\nof each other according to a known prior distribution.\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 3.10: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ binomial(n, γ ) random variable\\nand ﬁres with a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U nif orm(0, γ) random variable\\nand ﬁres with a probability of γ.\\nPRB-64 \\uf059 CH.PRB- 3.35.\\nY our colleague, a veteran of the Deep Learning industry, comes up with an idea for for\\n55'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 72, 'page_label': '73'}, page_content='3.2. PROBLEMS\\na BNN layer entitled OnOffLayer. He suggests that each neuron will stay on (the other\\nstate is off) following the distribution f (x) = e−x for x > 0 and f (x) = 0 otherwise\\n(Fig. 3.11). X indicates the time in seconds the neuron stays on . In a BNN, 200 such\\nneurons are activated independently in said OnOffLayer. The OnOffLayer is set to off (e.g.\\nnot active) only if at least 150 of the neurons are shut down . Find the probability that\\nthe OnOffLayer will be active for at least 20 seconds without being shut down.\\non offtime = f (x) = e−x\\nFIGURE 3.11: OnOffLayer in a BNN model.\\nPRB-65 \\uf059 CH.PRB- 3.36.\\nA Dropout layer [12] (Fig. 3.12) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 3.12: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [10], a Dropout layer is declared as follows ( 3.1):\\n56'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 73, 'page_label': '74'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 3.1: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 3.1) indicates that the probability of zeroing an\\nelement is 0.2.\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 3.13: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 3.12). Here, for illustration purposes, all two\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\nY ou are interested in the proportionθ of dropped-out neurons. Assume that the chance of\\ndrop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the posterior\\nof θ.\\nPRB-66 \\uf059 CH.PRB- 3.37.\\nA new data scientist in your team, who was formerly a Quantum Physicist, suggests\\nthe following procedure for a Dropout layer entitled QuantumDrop which is based on\\nQuantum principles and the Maxwell Boltzmann distribution. In the Maxwell-Boltzmann\\n57'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 74, 'page_label': '75'}, page_content='3.2. PROBLEMS\\ndistribution, the likelihood of ﬁnding a particle with a particular velocity v is provided by:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.10)\\n0 1 000 2 000 3 000 4 000 5 000\\n0\\n2\\n4\\n·10−4\\nv in m·s−1\\nP (v)\\nHelium\\nFIGURE 3.14: The Maxwell-Boltzmann distribution.\\nIn the suggested QuantumDrop layer ( 3.15), each of the neurons behaves like a molecule\\nand is distributed according to the Maxwell-Boltzmann distribution and ﬁres only when\\nthe most probable speed is reached . This speed is the velocity associated with the highest\\npoint in the Maxwell distribution ( 3.14). Using calculus, brain power and some mathem-\\natical manipulation, ﬁnd the most likely value (speed) at which the neuron will ﬁre .\\noff firedneuron − f ires\\nFIGURE 3.15: A QuantumDrop layer.\\n58'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 75, 'page_label': '76'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3.3 Solutions\\n3.3.1 Expectation and Variance\\nSOL-30 \\uf14b CH.SOL- 3.1.\\nThe notion of a Bernoulli trial refers to an experiment with two dichotomous binary out-\\ncomes; success (x = 1), and failure (x = 0). \\x04\\nSOL-31 \\uf14b CH.SOL- 3.2.\\nA binomial random variable X = k represents k successes in n mutually independent\\nBernoulli trials. \\x04\\nSOL-32 \\uf14b CH.SOL- 3.3.\\nThe shorthand X ∼ Binomial(n, p ) indicates that the random variable X has the bi-\\nnomial distribution (Fig. 3.16). The positive integer parameter n indicates the number of\\nBernoulli trials and the real parameter p, 0 < p < 1 holds the probability of success in each of\\nthese trials.\\n0 10 20 30 40 50\\n0,0\\n0,2\\n0,4\\np(x = k) =\\n( n\\nk\\n)\\n· pk · (1 − p)n−k\\nx\\np(x)\\nn = 50, p = 0.3\\nn = 50, p = 0.7\\nn = 50, p = 0.9\\nFIGURE 3.16: The binomial distribution.\\n\\x04\\nSOL-33 \\uf14b CH.SOL- 3.4.\\n59'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 76, 'page_label': '77'}, page_content='3.3. SOLUTIONS\\nThe random variable X ∼ Binomial(n, p ) has the following PMF:\\nP (X = k) =\\n(\\nn\\nk\\n)\\npk (1 − p)n−k ; k = 0, 1, 2, . . . , n. (3.11)\\n\\x04\\nSOL-34 \\uf14b CH.SOL- 3.5.\\nThe answers below regard a discrete random variable. The curious reader is encouraged to\\nexpend them to the continuous case.\\n1. For a random variable X with probability mass function P (X = k) and a set of out-\\ncomes K, the expected value of X is deﬁned as:\\nE[X] :=\\n∑\\nk∈K\\nkP (X = k). (3.12)\\nNote: The expectation of X may also be denoted by µX.\\n2. The variance of X is deﬁned as:\\nVar[X] := E\\n[\\n(X − E[X])2\\n]\\n. (3.13)\\nNote: The variance of X may also be denoted by σ2\\nX, while σX itself denotes the stand-\\nard deviation of X.\\n3. The population mean and variance of a binomial random variable with parameters n\\nand p are:\\nE[X] = np V [X] = np(1 − p) (3.14)\\nNote: Why is this solution intuitive? What information theory-related phenomenon\\noccurs when p = 1/2?\\n\\x04\\nSOL-35 \\uf14b CH.SOL- 3.6.\\n60'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 77, 'page_label': '78'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1. This scenario describes an experiment that is repeated 200 times independently with a\\nsuccess probability of 0.1. Thus, if the random variable X denotes the number of times\\nsuccess was obtained, then it is best characterized by the binomial distribution with\\nparameters n = 200 and p = 0.1. Formally:\\nX ∼ Binomial(200, 0.1). (3.15)\\nThe expectation of X is given by:\\nx = E(x) = 200 × 0.1 = 20 , (3.16)\\nand its respective variance is:\\nV ar = 200 × 0.10(1 − 0.10) = 18 .0. (3.17)\\n2. Here we propose two distinguished methods to answer the question.\\nPrimarily, the straightforward solution is to employ the deﬁnition of the binomial dis-\\ntribution and substitute the value of X in it. Namely:\\nP (X = 60; n = 200, p = 0.1)\\n=\\n(\\n200\\n60\\n)\\n0.160 (1 − 0.1)200−60\\n=≈ 2.7 × e−15.\\n(3.18)\\nThis leads to an extremely high probability that the radiologist is mistaken.\\nThe following approach is longer and more advanced, but grants the reader with insights\\nand intuition regarding the results. T o derive how wrong the radiologist is, we can\\nemploy an approximation by considering the standard normal distribution. In statistics,\\nthe Z-score allows us to understand how far from the mean is a data point in units of\\nstandard deviation, thus revealing how likely it is to occur (Fig. 3.17).\\n61'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 78, 'page_label': '79'}, page_content='3.3. SOLUTIONS\\nZ-score\\nz =\\nData point\\nx − µ\\nExpectation\\nσ\\nStandard dev .\\n. (3.19)\\nFIGURE 3.17: Z-score\\nTherefore, the probability of correctly hitting 60 cells is:\\nP (X ≥ 60) = P (Z ≥ 60 − 20√\\n18.0 ) = P (Z ≥ 9.428) ≈ 0. (3.20)\\nAgain, the outcome shows the likelihood that the radiologist was wrong approaches 1.\\nNote: Why is the relation depicted in Fig. 3.17 deduces that Z is a standard Gaussian?\\nUnder what terms is this conclusion valid? Why does eq. (3.20) employs the cumulative\\ndistribution function and not the probability mass function?\\n\\x04\\n3.3.2 Conditional Probability\\nSOL-36 \\uf14b CH.SOL- 3.7.\\n1. For two events A and B with P (B) > 0, the conditional probability of A given that\\nB has occurred is deﬁned as:\\nP (A|B) = P (A ∩ B)\\nP (B) . (3.21)\\nIt is easy to note that if P (B) = 0 , this relation is not deﬁned mathematically. In this\\ncase, P (A|B) = P (A ∩ B) = P (A).\\n2. The annotated probabilities are displayed in Fig. 3.18:\\n62'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 79, 'page_label': '80'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nA given B\\nP (A|B) =\\nA and B\\nP (A ∩ B)\\nP (B)\\nB only\\n. (3.22)\\nFIGURE 3.18: Conditional probability\\n3. An example of a diagram depicting the intersected events A and B is displayed in Fig.\\n3.19:\\nA B\\nH\\nFIGURE 3.19: V enn diagram of the intersected events A and B in probability space H\\n\\x04\\nSOL-37 \\uf14b CH.SOL- 3.8.\\nThe Bayes formulae reads:\\nP (A|B) = P (B|A)P (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac), (3.23)\\nwhere P (Ac) is the complementary probability of P (A). The interpretation of the elements in\\n63'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 80, 'page_label': '81'}, page_content='3.3. SOLUTIONS\\nBayes formulae is as follows:\\nposterior probability = likelihood of the data × prior probability\\nnormalization constant . (3.24)\\nNote: What is the important role of the normalization constant? Analyze the cases where\\nP (B) → 0 and P (B) → 1. The annotated probabilities are displayed in (Fig. 3.20):\\nPosterior\\nP (A|B) =\\nLikelihood\\nP (B|A)\\nPrior\\nP (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac)\\nB only\\n. (3.25)\\nFIGURE 3.20: Annotated components of the Bayes formula (eq. 3.23)\\n\\x04\\nSOL-38 \\uf14b CH.SOL- 3.9.\\nGiven X as a discrete randomly distributed variable and given γ as the parameter of\\ninterest, the likelihood and the log-likelihood of X given γ follows respectively:\\nLγ(X = x) = p(X = x|γ) (3.26)\\nℓγ(X = x) = ln ( p(X = x|γ)) (3.27)\\nThe term likelihood can be intuitively understood from this deﬁnition; it deduces how likely is\\nto obtain a value x when a prior information is given regarding its distribution, namely the\\nparameter γ. For example, let us consider a biased coin toss with ph = γ. Then:\\nLγ(X = “h′′) = p(X = “h′′|γ) = γ. (3.28)\\nℓγ(X = “h′′) = ln ( p(X = “h′′|γ)) = ln ( γ) . (3.29)\\n64'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 81, 'page_label': '82'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nNote: The likelihood function may also follow continuous distributions such as the normal\\ndistribution. In the latter, it is recommended and often obligatory to employ the log-likelihood.\\nWhy? We encourage the reader to modify the above to the continuous case of normal distribu-\\ntion and derive the answer. \\x04\\nSOL-39 \\uf14b CH.SOL- 3.10.\\nThe continuous prior distribution, f (Γ = γ) represents what is known about the probab-\\nility of the value γ before the experiment has commenced. It is termed as being subjective,\\nand therefore may vary considerably between researchers. By proceeding the previous example,\\nf (Γ = 0.8) holds the probability of randomly ﬂipping a coin that yields “heads” with chance\\nof 80% of times. \\x04\\nSOL-40 \\uf14b CH.SOL- 3.11.\\nThe essence of Bayesian analysis is to draw inference of unknown quantities or quantiles\\nfrom the posterior distribution p(Γ = γ|X = x), which is traditionally derived from prior\\nbeliefs and data information. Bayesian statistical conclusions about chances to obtain the para-\\nmeter Γ = γ or unobserved values of random variable X = x, are made in terms of prob-\\nability statements. These probability statements are conditional on the observed values of X,\\nwhich is denoted as p(Γ = γ|X = x), called posterior distributions of parameter γ. Bayesian\\nanalysis is a practical method for making inferences from data and prior beliefs using probab-\\nility models for quantities we observe and for quantities which we wish to learn. Bayes rule\\nprovides a relationship of this form:\\nposterior ∝ p(x|γ)p(γ) ∝ data given prior × chance of prior . (3.30)\\n\\x04\\nSOL-41 \\uf14b CH.SOL- 3.12.\\nThe posterior density summarizes what is known about the parameter of interest γ after\\nthe data is observed. In Bayesian statistics, the posterior density p(Γ = γ|X = x) becomes\\nthe prior for this next experiment. This is part of the well-known Bayesian updating mech-\\nanism wherein we update our knowledge to reﬂect the actual distribution of data that we\\nobserved. T o summarize, from the perspective of Bayes Theorem, we update the prior distri-\\nbution to a posterior distribution after seeing the data. \\x04\\n65'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 82, 'page_label': '83'}, page_content='3.3. SOLUTIONS\\nSOL-42 \\uf14b CH.SOL- 3.13.\\nTwo events A and B are statistically independent if (and only if):\\nP (A ∩ B) = P (A)P (B). (3.31)\\nNote: Use conditional probability and rationalize this outcome. How does this property be-\\ncome extremely useful in practical researches that consider likelihood of normally distributed\\nfeatures? \\x04\\n3.3.3 Bayes Rule\\nSOL-43 \\uf14b CH.SOL- 3.14.\\nLet γ stand for the number of half-integer spin states, and given the prior knowledge that\\nboth states are equally probable:\\nP (γ = 2|γ ≥ 1) (3.32)\\n= P (γ = 2, γ ≥ 1)\\nP (γ ≥ 1) (3.33)\\n= P (γ = 2)\\n1 − P (γ = 0) = 1/4\\n1 − 1/4 = 1\\n3 (3.34)\\nNote: Under what statistical property do the above relations hold? \\x04\\nSOL-44 \\uf14b CH.SOL- 3.15.\\nLet event A indicate present hereditary-disease and let event B to hold a positive test result.\\nThe calculated probabilities are presented in T able 3.1. We were asked to ﬁnd the probability\\nof a test indicating that hereditary-disease is present, namely P (B). According to the law of\\ntotal probability:\\nP (B) = P (B|A) ∗ P (A) + P (B|A) ∗ P (A)\\n= [0.95 ∗ 0.01] + [0.05 ∗ 0.99] = 0 .059 (3.35)\\nNote: In terms of performance evaluation, P (B|A) is often referred to as the probability of\\n66'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 83, 'page_label': '84'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPROBABILITY EXPLANATION\\nP(A)= 0.01 The probability of hereditary-disease.\\nP(A)=1-0.01=.99 The probability of no hereditary-disease.\\nP(B|A)=0.95 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is NOT present [Ã].\\nP(B|B)=1-0.95=.05 The probability that the test will yield a positive result [B]\\nif hereditary-disease is NOT present [Ã] (probability of false\\nalarm).\\nP(B|A)=0.95 The probability that the test will yield a positive result [B] if\\nhereditary-disease is present [A] (probability of detection).\\nP(B|A)=1-0.95=.05 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is present [A].\\nTABLE 3.1: Probability values of hereditary-disease detection.\\ndetection and P (B|A) is considered the probability of false alarm. Notice that these measures\\ndo not, neither logically nor mathematically, combine to probability of 1. \\x04\\nSOL-45 \\uf14b CH.SOL- 3.16.\\nWe ﬁrst enumerate the probabilities one by one:\\nP (Dercum|f emale) = 0 .05, (3.36)\\nP (Dercum|male) = 0 .0025, (3.37)\\nP (male) = P (f emale) = 0 .5. (3.38)\\nWe are asked to ﬁnd P (f emale|Dercum). Using Bayes Rule:\\nP (f emale|Dercum) = P (Dercum|f emale)P (f emale)\\nP (Dercum) . (3.39)\\n67'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 84, 'page_label': '85'}, page_content='3.3. SOLUTIONS\\nHowever we are missing the term P (Dercum). T o ﬁnd it, we apply the Law of T otal Probab-\\nility:\\nP (Dercum) = P (Dercum|f emale)P (f emale)\\n+P (Dercum|male)P (male)\\n=\\n0.05 · 0.5 + 0.0025 · 0.5 = 0 .02625.\\nAnd ﬁnally, returning to eq. ( 3.39):\\nP (f emale|Dercum) = 0.05 · 0.5\\n0.02625 ≈ 0.9524 (3.40)\\nNote: How could this result be reached with one mathematical equation? \\x04\\nSOL-46 \\uf14b CH.SOL- 3.17.\\nIn order to solve this problem, we introduce the following events:\\n1. AI: the AI predicts that the state of the stock option is 1.\\n2. State1: the state of the stock option is 1.\\n3. State0: the state of the stock option is 0.\\nA direct application of Bayes formulae yields:\\nP (State1|AI) = (3.41)\\nP (AI|State1)P (State1)\\nP (AI|State1)P (State1)+P (AI|State0)P (State0) (3.42)\\n= 0.85·2/3\\n0.85·2/3+0.15·1/3 ≈ 0.9189.\\n\\x04\\nSOL-47 \\uf14b CH.SOL- 3.18. In order to solve this problem, we introduce the following events:\\n1. H: a human.\\n68'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 85, 'page_label': '86'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. M : a monkey.\\n3. C: a correct prediction.\\nBy employing Bayes theorem and the Law of T otal probability:\\nP (H|C) = P (H ∩ C)\\nP (C)\\n= P (C|H)P (H)\\nP (C|H)P (H) + P (C|M )P (M )\\n=\\n1\\n20 · 1\\n2\\n1\\n20 · 1\\n2 + 1\\n15 · 1\\n2\\n≈ 0.42.\\n(3.43)\\nNote: If something seems off in this outcome, do not worry - it is a positive sign for\\nunderstanding of conditional probability. \\x04\\nSOL-48 \\uf14b CH.SOL- 3.19.\\nIn order to solve this problem, we introduce the following events:\\n1. RU S: a Russian sleeper agent is speaking.\\n2. AM : an American is speaking.\\n3. L: the TTS system generates an “l”.\\nWe are asked to ﬁnd the value of P (RU S|L). Using Bayes Theorem we can write:\\nP (RU S|L) = P (L|RU S)P (RU S)\\nP (L) . (3.44)\\nWe were told that the Russians consist 1/5 of the attendees at the gathering, therefore:\\nP (RU S) = 1\\n5. (3.45)\\n69'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 86, 'page_label': '87'}, page_content='3.3. SOLUTIONS\\nAdditionally, because \"v-o-k-s-a-l\" has a single l out of a total of six letters:\\nP (L|RU S) = 1\\n6. (3.46)\\nAdditionally, because \"V-a-u-x-h-a-l-l\" has two l’s out of a total of eight letters:\\nP (L|AM ) = 2\\n8. (3.47)\\nAn application of the Law of T otal Probability yields:\\nP (L) = P (AM )P (L|AM ) + P (RU S)P (L|RU S) (3.48)\\n=\\n( 4\\n5\\n) ( 2\\n8\\n)\\n+\\n( 1\\n5\\n) ( 1\\n6\\n)\\n= 7\\n30.\\nUsing Bayes Theorem we can write:\\nP (RU S|L) =\\n1\\n5\\n(\\n1\\n6\\n)\\n7\\n30\\n= 1\\n7. (3.49)\\nNote: What is the letter by which the algorithm is most likely to discover a Russian sleeper\\nagent? \\x04\\nSOL-49 \\uf14b CH.SOL- 3.20.\\nWe are given that:\\nP (X is erroneously received as a Z ) = 1 /7. Using Bayes Theorem we can write:\\nP (Z trans |Z received ) =\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received ) . (3.50)\\n70'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 87, 'page_label': '88'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAn application of the Law of T otal Probability yields:\\nP (Z received ) =\\nP (Z received |Z trans )P (Z trans )\\n+P (Z received |X trans )P (X trans )\\n= 6\\n7 · 7\\n9 + 1\\n7 · 2\\n9\\n= 44\\n63.\\nSo, using Bayes Rule, we have that\\nP (Z trans |Z received )\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received )\\n=\\n6\\n7\\n7\\n9\\n44\\n63\\n= 44\\n63 = 0.95.\\n(3.51)\\n\\x04\\n3.3.4 Maximum Likelihood Estimation\\nSOL-50 \\uf14b CH.SOL- 3.21.\\nFor the set of i.i.d samples X1, · · · , Xn, the likelihood function is the product of the\\nprobability functions:\\nL(p) = p(X1 = x1; p)p(X2 = x2; p) · · ·p(Xn = xn; p)\\n=\\nn∏\\ni=1\\n(\\nn\\nxi\\n)\\npxi(1 − p)n−xi. (3.52)\\nNote: What is the distribution of X n when X is a Bernoulli distributed random variable?\\n\\x04\\n71'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 88, 'page_label': '89'}, page_content='3.3. SOLUTIONS\\nSOL-51 \\uf14b CH.SOL- 3.22.\\nThe maximum likelihood estimator (MLE) of p is the value of all possible p values that\\nmaximizes L(p). Namely, the p value that renders the set of measurements X1, · · · , Xn as the\\nmost likely. Formally:\\nˆp = arg max0≤p≤1L(p) (3.53)\\nNote: The curious student is highly encouraged to derive ˆp from L(p). Notice that L(p) can\\nbe extremely simpliﬁed. \\x04\\nSOL-52 \\uf14b CH.SOL- 3.23.\\nThe log-likelihood is the logarithm of the likelihood function. Intuitively, maximizing\\nthe likelihood function L(γ) is equivalent to maximizing ln L(γ) in terms of ﬁnding the MLE\\nˆγ, since ln is a monotonically increasing function. Often, we maximize ln(f (γ)) instead of\\nthe f (γ). A common example is when L(γ) is comprised of normally distribution random\\nvariables.\\nFormally, if X1, · · · , Xn are i.i.d, each with probability mass function (PMF) of fXi(xi | γ),\\nthen\\nf (γ) =\\nn∏\\ni=1\\nfXi(xi | γ), (3.54)\\nln(f (γ)) =\\nn∑\\ni=1\\nln fXi(xi | γ). (3.55)\\n\\x04\\nSOL-53 \\uf14b CH.SOL- 3.24.\\nThe general procedure for ﬁnding the MLE, given that the likelihood function is differen-\\ntiable, is as follows:\\n1. Start by differentiating the log-likelihood function ln (L(γ)) with respect to a parameter\\nof interest γ.\\n2. Equate the result to zero.\\n72'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 89, 'page_label': '90'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3. Solve the equation to ﬁnd ˆγ that holds:\\n∂ ln L(ˆγ | x1, · · ·xn)\\n∂γ = 0 (3.56)\\n4. Compute the second derivative to verify that you indeed have a maximum rather than\\na minimum.\\n\\x04\\nSOL-54 \\uf14b CH.SOL- 3.25.\\nThe ﬁrst derivative of the log-likelihood function is commonly known as the Fisher score\\nfunction, and is deﬁned as:\\nu(γ) = ∂ ln L(γ | x1, · · ·xn)\\n∂γ (3.57)\\n\\x04\\nSOL-55 \\uf14b CH.SOL- 3.26.\\nFisher information, is the term used to describe the expected value of the second derivat-\\nives (the curvature) of the log-likelihood function, and is deﬁned by:\\nI(γ) = −E\\n[\\n∂2 ln L(γ | x1, · · ·xn)\\n∂γ2\\n]\\n(3.58)\\n\\x04\\n3.3.5 Fisher Information\\nSOL-56 \\uf14b CH.SOL- 3.27.\\n1. Given L(γ):\\nln L(γ) = ln\\n(\\nny\\n)\\n+ y ∗ ln(γ) + (n − y) ln(1 − γ). (3.59)\\n73'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 90, 'page_label': '91'}, page_content='3.3. SOLUTIONS\\n2. T o ﬁnd the gradient, we differentiate once:\\ng(γ) = yγ −1 − (n − y)(1 − γ)−1 =\\n(γ(1 − γ))−1y − n(1 − γ)−1. (3.60)\\n3. The Hessian is generated by differentiating g(γ):\\nH(γ) = −yγ −2 − (n − y)(1 − γ)−2 (3.61)\\n4. The Fisher information is calculated as follows:\\nI(γ) = −E(H(γ)) = n\\nγ(1 − γ), (3.62)\\nsince:\\nE(y|γ, n) = n ∗ γ (3.63)\\n5. Equating the gradient to zero and solving for our parameter γ, we get:\\nˆγ = y\\nn (3.64)\\nIn our case this equates to: 300/10000 = 0 .03. Regarding the error, there is a close\\nrelationship between the variance of γ and the Fisher information, as the former is the\\ninverse of the latter:\\nvar(γ) = [ I(γ)]−1\\nV (γ) = γ(1 − γ)\\nn\\n(3.65)\\nPlugging the numbers from our question:\\nˆV (ˆγ) = 0.03(1 − 0.03)\\n10000 = 2.9 × 10−7. (3.66)\\n74'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 91, 'page_label': '92'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nStatistically, the standard error that we are asked to ﬁnd is the square root of eq. 3.66\\nwhich equals 5.3 × 10−4. Note: What desired property is revealed in this experiment?\\nAt was cost could we ensure a low standard error?\\n\\x04\\nSOL-57 \\uf14b CH.SOL- 3.28.\\nThe Fisher Information for the distributions is as follows:\\n1. Bernoulli:\\nΦ(x|γ) = x log γ + (1 − x) log(1 − γ), (3.67)\\nΦ′(x|γ) = x\\nγ − 1 − x\\n1 − γ , (3.68)\\nΦ′′(x|γ) = − x\\nγ2 − 1 − x\\n(1 − γ)2 , (3.69)\\nI(γ) = −Eγ\\n[\\nX(1 − γ)2 + (1 − X)γ2\\nγ2(1 − γ)2\\n]\\n= 1\\nγ(1 − γ). (3.70)\\n2. Poisson:\\nλ(x|θ) = x log θ − log x! − θ,\\nλ′(x|θ) = x − θ\\nθ ,\\nλ′′(x|θ) = − x\\nθ2 ,\\nI(θ) = −Eθ\\n[\\n(X − θ)2\\nθ2\\n]\\n= 1\\nθ .\\n(3.71)\\n\\x04\\nSOL-58 \\uf14b CH.SOL- 3.29.\\n75'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 92, 'page_label': '93'}, page_content='3.3. SOLUTIONS\\n1. T rue.\\n2. T rue.\\n\\x04\\n3.3.6 Posterior & prior predictive distributions\\nSOL-59 \\uf14b CH.SOL- 3.30.\\n1. Given a sample of the form x = ( x1, · · · , xn) drawn from a density p(θ; x) and θ is\\nrandomly generated according to a prior density of p(θ). Then the posterior density is\\ndeﬁned by:\\np(θ|x) = p(θ; x)p(θ)\\np(x) . (3.72)\\n2. The prior predictive density is:\\np(x) =\\n∫\\nθ∈Θ p(θ; x)p(θ)dθ (3.73)\\n\\x04\\nSOL-60 \\uf14b CH.SOL- 3.31.\\n1. The posterior p(θ|y) ∝ p(y|θ)p(θ) is:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3\\n( 5\\ny\\n)\\n(1/2)y(1/2)5−y0.25, θ = 1/2( 5\\ny\\n)\\n(1/6)y(5/6)5−y0.5, θ = 1/6( 5\\ny\\n)\\n(1/4)y(3/4)5−y0.25, θ = 1/4\\n0, otherwise\\n2. The prior predictive distribution p(y):\\n(\\n5\\ny\\n)\\n((1/2)y(1/2)5−y0.25 (3.74)\\n76'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 93, 'page_label': '94'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n+\\n(1/6)y(5/6)5−y0.5 + (1/4)y(3/4)5−y0.25). (3.75)\\n\\x04\\n3.3.7 Conjugate priors\\nSOL-61 \\uf14b CH.SOL- 3.32.\\n1. A class F of prior distributions is said to form a conjugate family if the posterior density\\nis in F for all each sample, whenever the prior density is in F.\\n2. Often we would like a prior that favours no particular values of the parameter over\\nothers. Bayesian analysis requires prior information, however sometimes there is no\\nparticularly useful information before data is collected. In these situations, priors with\\n“no information” are expected. Such priors are called non-informative priors.\\n\\x04\\nSOL-62 \\uf14b CH.SOL- 3.33.\\nIf x ∼ B(n, γ) so\\np(x|γ) ∝ γx(1 − γ)n−x\\nand the prior for γ is B(α, β) so\\np(γ) ∝ γα−1(1 − γ)β−1\\nthen the posterior is\\nγ|x ∼ B (α + x, β + n − x)\\nIt is immediately clear the family of beta distributions is conjugate to a\\nbinomial likelihood.\\n\\x04\\n3.3.8 Bayesian Deep Learning\\n77'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 94, 'page_label': '95'}, page_content='3.3. SOLUTIONS\\nSOL-63 \\uf14b CH.SOL- 3.34.\\n1. The hidden neuron is distributed according to:\\nX ∼ binomial(n, γ ) random variable and ﬁres with a probability of γ. There are 100\\nneurons and only 20 are ﬁred.\\nP (x = 20|θ) =\\n\\uf8eb\\n\\uf8ed 100\\n20\\n\\uf8f6\\n\\uf8f8 θ20(1 − θ)80 (3.76)\\n2. The hidden neuron is distributed according to:\\nX unif orm(0, γ) random variable and ﬁres with a probability of γ.\\nThe uniform distribution is, of course, a very simple case:\\nf (x; a, b) = 1\\nb − a for a ≤ x ≤ b (3.77)\\nTherefore:\\nf (x|γ) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0 if γ < x or x < 0\\n1/γ if 0 ≤ x ≤ θ\\n(3.78)\\n\\x04\\nSOL-64 \\uf14b CH.SOL- 3.35.\\nThe provided distribution is from the exponential family. Therefore, a single neuron be-\\ncomes inactive with a probability of:\\np = P (X < 20) =\\n∫ 20\\n0\\ne−x dx = 1 − e−20. (3.79)\\nThe OnOffLayer is off only if at least 150 out of 200 neurons are off. Therefore, this may be\\nrepresented as a Binomial distribution and the probability for the layer to be off is:\\nV =\\n∑\\nn≥150\\n\\uf8eb\\n\\uf8ed 200\\nn\\n\\uf8f6\\n\\uf8f8 ˜pn(1 − ˜p)200−n (3.80)\\n78'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 95, 'page_label': '96'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nHence, the probability of the layer being active for at least 20 seconds is 1 minus this value:\\n[1 − V ]. (3.81)\\n\\x04\\nSOL-65 \\uf14b CH.SOL- 3.36.\\nThe observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (3.82)\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (3.83)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (3.84)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (3.85)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(3.86)\\n\\x04\\nSOL-66 \\uf14b CH.SOL- 3.37.\\nNeurons are dropped whenever their value (or the equivalent quantum term- speed) reach\\n79'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 96, 'page_label': '97'}, page_content='REFERENCES\\nthe most likely value:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.87)\\nFrom calculus, we know that in order to maximize a function, we have to equate its ﬁrst\\nderivative to zero:\\nd\\ndv n(v) = 0 (3.88)\\nThe constants can be taken out as follows:\\nd\\ndv v2e− mv2\\n2kT = 0 (3.89)\\nApplying the chain rule from calculus:\\n2ve− mv2\\n2kT + v2\\n(\\n− m\\n2kT 2v\\n)\\ne− mv2\\n2kT = 0 (3.90)\\nWe notice that several terms cancel out:\\nv2 m\\n2kT = 1 (3.91)\\nNow the quadratic equation can be solved yielding:\\nvmost_probable =\\n√\\n2kT\\nm\\n(3.92)\\nTherefore, this is the most probable value at which the dropout layer will ﬁre.\\n\\x04\\nReferences\\n[1] M. Barati and P . ‘Comparison of complications of chorionic villus sampling and\\namniocentesis’. In: 5.4 (2012), pp. 241–244 (cit. on p. 46).\\n[2] J. D. e. a. Bell BP Damon IK. ‘Overview, Control Strategies, and Lessons Learned\\nin the CDC Response to the 20142016 Ebola Epidemic.’ In: Morbidity and Mortal-\\nity Weekly Report 65.3 (2016), pp. 4–11 (cit. on p. 52).\\n80'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 97, 'page_label': '98'}, page_content='Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n[3] J. C. Cook and G. P . Gross. Adiposis Dolorosa (Dercum, Anders Disease) . StatPearls\\n[Internet], 2019 (cit. on p. 47).\\n[4] G. Ecker. Particles, Field, From Quantum Mechanics to the Standard Model of Particle\\nPhysics. Springer., 2019 (cit. on p. 45).\\n[5] K. Gaj and A. Orlowski. ‘Facts and Myths of Enigma: Breaking Stereotypes’. In:\\nInternational Conference on the Theory and Applications of Cryptographic T echniques .\\n2003 (cit. on p. 50).\\n[6] B. Gottschalk. ‘Techniques of Proton Radiotherapy: Transport Theory’. In: arXiv\\n(2012) (cit. on p. 43).\\n[7] T. S. O. of Investor Education and Advocacy. Binary options and Fraud (cit. on\\np. 48).\\n[8] E. T. Jaynes. Probability Theory as Logic . Ed. by P . F. Fougère. Maximum-Entropy\\nand Bayesian Methods. Kluwer, Dordrecht, 1990 (cit. on p. 42).\\n[9] D. o. J. National Security Division. Conspiracy to Act as Unregistered Agents of a\\nForeign Government. 2010 (cit. on p. 49).\\n[10] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on p. 56).\\n[11] J. Salvatier, T. V . Wiecki and C. Fonnesbeck. ‘Probabilistic programming in Py-\\nthon using PyMC3’. In: PeerJ Computer Science 2 (Jan. 2016), e55 (cit. on p. 42).\\n[12] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 56).\\n[13] E. B. Starikov. ‘Bayesian Statistical Mechanics: Entropy Enthalpy Compensation\\nand Universal Equation of State at the Tip of Pen’. In: Frontiers in Physics 6 (2018),\\np. 2 (cit. on p. 42).\\n81'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 98, 'page_label': '99'}, page_content='REFERENCES\\n82'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 99, 'page_label': '100'}, page_content='HIGH SCHOOL\\nPART III'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 100, 'page_label': '101'}, page_content=''),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 101, 'page_label': '102'}, page_content=\"CHAPTER\\n4\\nINFORMATION THEORY\\nA basic idea in information theory is that information can be treated very much\\nlike a physical quantity, such as mass or energy.\\n— Claude Shannon, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 87\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 101\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\nKullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 102, 'page_label': '103'}, page_content='4.1. INTRODUCTION\\n4.1 Introduction\\nI\\nNDUCTIVE inference, is the problem of reasoning under conditions of in-\\ncomplete information, or uncertainty. According to Shannon’s theory [ 2],\\ninformation and uncertainty are two sides of the same coin: the more uncer-\\ntainty there is, the more information we gain by removing the uncertainty .\\nEntropy plays central roles in many scientiﬁc realms ranging from physics and statist-\\nics to data science and economics. A basic problem in information theory is encoding\\nlarge quantities of information [ 2].\\nShannon’s discovery of the fundamental laws of data compression and transmis-\\nsion marked the birth of information theory . In his fundamental paper of 1948, “ A\\nMathematical Theory of Communication ” [4], Shannon proposed a measure of the uncer-\\ntainty associated with a random memory-less source, called Entropy.\\nH(X) H(Y )\\nH(Z)\\nH(Y |X)\\nH(Z|XY )\\nI(X; Z|Y )\\nFIGURE 4.1: Mutual information\\nEntropy ﬁrst emerged in thermodynamics in the 18 th century by\\nCarnot, [1] in his pioneering work on steam entitled “ Reﬂection on the Motive Power of\\nFire” (Fig. 4.2). Subsequently it appeared in statistical mechanics where it was viewed\\nas a measure of disorder. However, it was Boltzmann ( 4.30) who found the connection\\nbetween entropy and probability , and the notion of information as used by Shannon is\\na generalization of the notion of entropy . Shannon’s entropy shares some instinct with\\nBoltzmann’s entropy , and likewise the mathematics developed in information theory\\nis highly relevant in statistical mechanics.\\n86'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 103, 'page_label': '104'}, page_content='Chapter 4 INFORMATION THEORY\\nFIGURE 4.2: Reﬂection on the motive power of ﬁre.\\nThe majority of candidates I interview fail to come up with an answer to the fol-\\nlowing question: what is the entropy of tossing a non-biased coin? Surprisingly , even after\\nI explicitly provide them with Shannon’s formulae for calculating entropy ( 4.4), many\\nare still unable to calculate simple logarithms. The purpose of this chapter is to present\\nthe aspiring data scientist with some of the most signiﬁcant notions of entropy and\\nto elucidate its relationship to probability . Therefore, it is primarily focused on basic\\nquantities in information theory such as entropy , cross-entropy , conditional entropy ,\\nmutual information and Kullback-Leibler divergence, also known as relative entropy .\\nIt does not however, discuss more advanced topics such as the concept of ’active in-\\nformation’ introduced by Bohm and Hiley [ 3].\\n4.2 Problems\\n4.2.1 Logarithms in Information Theory\\nIt is important to note that all numerical calculations in this chapter use the binary\\nlogarithm log2. This speciﬁc logarithm produces units of bits, the commonly used units\\nof information in the ﬁeld on information theory .\\n87'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 104, 'page_label': '105'}, page_content='4.2. PROBLEMS\\nPRB-67 \\uf059 CH.PRB- 4.1.\\nRun the following Python code ( 4.3) in a Python interpreter. What are the results?\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n5\\n6 print (math.log10(1.0/0.98)) # Common log (base 10)\\n7 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n8\\n9 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n10 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\nFIGURE 4.3: Natural ( ln), binary (log2) and common ( log10) logarithms.\\nPRB-68 \\uf059 CH.PRB- 4.2.\\nThe three basic laws of logarithms:\\n1. First law\\nlog A + log B = log AB. (4.1)\\nCompute the following expression:\\nlog10 3 + log10 4.\\n2. Second law\\nlog An = n log A. (4.2)\\n88'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 105, 'page_label': '106'}, page_content=\"Chapter 4 INFORMATION THEORY\\nCompute the following expression:\\nlog2 46.\\n3. Third law\\nlog A − log B = log A\\nB . (4.3)\\nTherefore, subtracting log B from log A results in log A\\nB .\\nCompute the following expression:\\nloge 15 − loge 3.\\n4.2.2 Shannon's Entropy\\nPRB-69 \\uf059 CH.PRB- 4.3.\\nWrite Shannon's famous general formulae for uncertainty.\\nPRB-70 \\uf059 CH.PRB- 4.4.\\nChoose exactly one, and only one answer.\\n1. For an event which is certain to happen, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N ), N being the number of possible events\\n89\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 106, 'page_label': '107'}, page_content=\"4.2. PROBLEMS\\n2. For N equiprobable events, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N )\\nPRB-71 \\uf059 CH.PRB- 4.5.\\nShannon found that entropy was the only function satisfying three natural properties.\\nEnumerate these properties.\\nPRB-72 \\uf059 CH.PRB- 4.6.\\nIn information theory, minus the logarithm of the probability of a symbol (essentially\\nthe number of bits required to represent it efﬁciently in a binary code) is deﬁned to be the\\ninformation conveyed by transmitting that symbol. In this context, the entropy can be\\ninterpreted as the expected information conveyed by transmitting a single symbol from an\\nalphabet in which the symbols occur with the probabilities πk.\\nMark the correct answer : Information is a/an [decrease/increase] in uncertainty.\\nPRB-73 \\uf059 CH.PRB- 4.7.\\nClaud Shannon's paper “A mathematical theory of communication” [ 4], marked the\\nbirth of information theory. Published in 1948, it has become since the Magna Carta of the\\ninformation age. Describe in your own words what is meant by the term Shannon bit.\\nPRB-74 \\uf059 CH.PRB- 4.8.\\nWith respect to the notion of surprise in the context of information theory:\\n1. Deﬁne what it actually meant by being surprised.\\n90\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 107, 'page_label': '108'}, page_content=\"Chapter 4 INFORMATION THEORY\\n2. Describe how it is related to the likelihood of an event happening.\\n3. True or False: The less likely the occurrence of an event, the smaller information it\\nconveys.\\nPRB-75 \\uf059 CH.PRB- 4.9.\\nAssume a source of signals that transmits a given message a with probability Pa. Assume\\nfurther that the message is encoded into an ordered series of ones and zeros (a bit string) and\\nthat a receiver has a decoder that converts the bit string back into its respective message.\\nShannon devised a formulae that describes the size that the mean length of the bit string can\\nbe compressed to. Write the formulae.\\nPRB-76 \\uf059 CH.PRB- 4.10.\\nAnswer the following questions:\\n1. Assume a source that provides a constant stream of N equally likely symbols\\n{x1, x2, . . . , xN }. What does Shannon's formulae ( 4.4) reduce to in this particular\\ncase?\\n2. Assume that each equiprobable pixel in a monochrome image that is fed to a DL classi-\\nﬁcation pipeline, can have values ranging from 0 to 255. Find the entropy in bits.\\nPRB-77 \\uf059 CH.PRB- 4.11.\\nGiven Shannon's famous general formulae for uncertainty ( 4.4):\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.4)\\n1. Plot a graph of the curve of probability vs. uncertainty.\\n2. Complete the sentence: The curve is [symmetrical/asymmetrical].\\n91\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 108, 'page_label': '109'}, page_content='4.2. PROBLEMS\\n3. Complete the sentence: The curve rises to a [minimum/maximum] when the two\\nsymbols are equally likely ( Pa = 0.5).\\nPRB-78 \\uf059 CH.PRB- 4.12.\\nAssume we are provided with biased coin for which the event ‘heads’ is assigned probab-\\nility p, and ‘tails’ - a probability of 1 − p. Using (4.4), the respective entropy is:\\nH(p) = −p log p − (1 − p) log (1 − p) . (4.5)\\nTherefore, H ≥ 0 and the maximum possible uncertainty is attained when p = 1 /2, is\\nHmax = log 2 2.\\nGiven the above formulation, describe a helpful property of the entropy that follows from\\nthe concavity of the logarithmic function.\\nPRB-79 \\uf059 CH.PRB- 4.13.\\nTrue or False: Given random variables X, Y and Z where Y = X + Z then:\\nH(X, Y ) = H(X, Z). (4.6)\\nPRB-80 \\uf059 CH.PRB- 4.14.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n92'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 109, 'page_label': '110'}, page_content='Chapter 4 INFORMATION THEORY\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh)+ p(xt) = 1 , what is formulae\\nfor the average surprise?\\n6. What is the value of the average surprise in bits?\\n4.2.3 Kullback-Leibler Divergence (KLD)\\nPRB-81 \\uf059 CH.PRB- 4.15.\\nWrite the formulae for the Kullback-Leibler divergence between two discrete probability\\ndensity functions P and Q.\\nPRB-82 \\uf059 CH.PRB- 4.16.\\nDescribe one intuitive interpretation of the KL-divergence with respect to bits.\\nPRB-83 \\uf059 CH.PRB- 4.17.\\n1. True or False: The KL-divergence is not a symmetric measure of similarity, i.e.:\\nDKL(P ∥Q) ̸= D KL(Q∥P ).\\n2. True or False: The KL-divergence satisﬁes the triangle inequality.\\n3. True or False: The KL-divergence is not a distance metric.\\n4. True or False: In information theory, KLD is regarded as a measure of the informa-\\ntion gained when probability distribution Q is used to approximate a true probability\\ndistribution P .\\n5. True or False: The units of KL-divergence are units of information.\\n6. True or False: The KLD is always non-negative, namely:\\nDKL(P ∥Q) ≥ 0.\\n93'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 110, 'page_label': '111'}, page_content='4.2. PROBLEMS\\n.\\n7. True or False: In a decision tree, high information gain indicates that adding a split\\nto the decision tree results in a less accurate model.\\nPRB-84 \\uf059 CH.PRB- 4.18.\\nGiven two distributions f1 and f2 and their respective joint distribution f , write the\\nformulae for the mutual information of f1 and f2.\\nPRB-85 \\uf059 CH.PRB- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem.\\n4.2.4 Classification and Information Gain\\nPRB-86 \\uf059 CH.PRB- 4.20.\\nThere are several measures by which one can determine how to optimally split attributes\\nin a decision tree. List the three most commonly used measures and write their formulae.\\nPRB-87 \\uf059 CH.PRB- 4.21.\\nComplete the sentence: In a decision tree, the attribute by which we choose to split is\\nthe one with [minimum/maximum] information gain.\\nPRB-88 \\uf059 CH.PRB- 4.22.\\nT o study factors affecting the decision of a frog to jump (or not), a deep learning re-\\nsearcher from a Brazilian rain-forest, collects data pertaining to several independent binary\\nco-variates.\\n94'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 111, 'page_label': '112'}, page_content='Chapter 4 INFORMATION THEORY\\nFIGURE 4.4: A Frog in its natural habitat. Photo taken by my son.\\nThe binary response variable Jump indicates whether a jump was observed. Referring to\\nT able (4.1), each row indicates the observed values, columns denote features and rows denote\\nlabelled instances while class label ( Jump) denotes whether the frog had jumped.\\nObservation Green Rain Jump\\nx1 1 0 +\\nx2 1 1 +\\nx3 1 0 +\\nx4 1 1 +\\nx5 1 0 +\\nx6 0 1 +\\nx7 0 0 −\\nx8 0 1 −\\nTABLE 4.1: Decision trees and frogs.\\nWithout explicitly determining the information gain values for each of the three attrib-\\nutes, which attribute should be chosen as the attribute by which the decision tree should be\\nﬁrst partitioned? e.g which attribute has the highest predictive power regarding the decision\\nof the frog (Fig. 4.4) to jump.\\n95'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 112, 'page_label': '113'}, page_content='4.2. PROBLEMS\\nPRB-89 \\uf059 CH.PRB- 4.23.\\nThis question discusses the link between binary classiﬁcation, information gain and de-\\ncision trees. Recent research [ 5] suggests that Cannabis (Fig. 4.5), and Cannabinoids ad-\\nministration in particular may reduce the size of malignant tumours in rodents. The data\\n(T able9.2) comprises a training set of feature vectors with corresponding class labels which\\na researcher intents classifying using a decision tree.\\nFIGURE 4.5: Cannabis\\nT o study factors affecting tumour shrinkage, the deep learning researcher collects data\\nregrading two independent binary variables; θ1 (T/F) indicating whether the rodent is a fe-\\nmale, and θ2 (T/F) indicating whether the rodent was administrated with Cannabinoids. The\\nbinary response variable, γ, indicates whether tumour shrinkage was observed (e.g. shrink-\\nage=+, no shrinkage=-). Referring to T able ( 9.2), each row indicates the observed values,\\ncolumns (θi) denote features and class label ( γ) denotes whether shrinkage was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 4.2: Decision trees and Cannabinoids administration\\n96'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 113, 'page_label': '114'}, page_content='Chapter 4 INFORMATION THEORY\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\nPRB-90 \\uf059 CH.PRB- 4.24.\\nT o study factors affecting the expansion of stars, a physicist is provided with data re-\\ngrading two independent variables; θ1 (T/F) indicating whether a star is dense, and θ2 (T/F)\\nindicating whether a star is adjacent to a black-hole. He is told that the binary response vari-\\nable, γ, indicates whether expansion was observed.\\ne.g.:\\nexpansion=+, no expansion=-. Referring to table ( 4.3), each row indicates the observed val-\\nues, columns (θi) denote features and class label (γ) denotes whether expansion was observed.\\nγ (expansion) θ1 (dense) θ2 (black-hole)\\n+ F T\\n+ T T\\n+ T T\\n- F T\\n+ T F\\n- F F\\n- F F\\nTABLE 4.3: Decision trees and star expansion.\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (expansion)\\nbefore splitting.\\n2. Using log2 and the provided dataset, calculate the information gain of H(γ|θ1).\\n97'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 114, 'page_label': '115'}, page_content='4.2. PROBLEMS\\n3. Using log2 and the provided dataset, calculate the information gain of H(γ|θ2).\\nPRB-91 \\uf059 CH.PRB- 4.25.\\nT o study factors affecting tumour shrinkage in humans, a deep learning researcher is\\nprovided with data regrading two independent variables; θ1 (S/M/L) indicating whether the\\ntumour is small(S), medium(M) or large(L), and θ2 (T/F) indicating whether the tumour\\nhas undergone radiation therapy. He is told that the binary response variable, γ, indicates\\nwhether tumour shrinkage was observed (e.g. shrinkage=+, no shrinkage=-).\\nReferring to table ( 4.4), each row indicates the observed values, columns ( θi) denote\\nfeatures and class label ( γ) denotes whether shrinkage was observed.\\nγ (shrinkage) θ1 θ2\\n- S F\\n+ S T\\n- M F\\n+ M T\\n+ H F\\n+ H T\\nTABLE 4.4: Decision trees and radiation therapy .\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (shrinkage).\\n2. Using log2 and the provided dataset, calculate the entropy of H(γ|θ1).\\n3. Using log2 and the provided dataset, calculate the entropy of H(γ|θ2).\\n4. True or false: We should split on a speciﬁc variable that minimizes the information\\ngain, therefore we should split on θ2 (radiation therapy).\\n4.2.5 Mutual Information\\nPRB-92 \\uf059 CH.PRB- 4.26.\\n98'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 115, 'page_label': '116'}, page_content=\"Chapter 4 INFORMATION THEORY\\nShannon described a communications system consisting ﬁve elements (4.6), two of which\\nare the source S and the destination D.\\nSourse S Trans\\nT\\nChannel\\nCH\\nReceiver\\nR\\nDest\\nD\\nMESSAGE\\nSIGNAL\\nSIGNAL\\nMESSAGE\\nFIGURE 4.6: Shannon's ﬁve element communications system.\\n1. Draw a Venn diagram depicting the relationship between the entropies of the source\\nH(S) and of the destination H(D).\\n2. Annotate the part termed equivocation.\\n3. Annotate the part termed noise.\\n4. Annotate the part termed mutual information.\\n5. Write the formulae for mutual information.\\nPRB-93 \\uf059 CH.PRB- 4.27.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\n99\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 116, 'page_label': '117'}, page_content='4.2. PROBLEMS\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\nPRB-94 \\uf059 CH.PRB- 4.28.\\nComplete the sentence: Mutual information is a Shannon entropy-based measure of\\ndependence between random variables. The mutual information between X and Z can be\\nunderstood as the (a) [___] of the (b) [___] in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.7)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X.\\n4.2.6 Mechanical Statistics\\nSome books have a tendency of sweeping \"unseen\" problems under the rug. We will\\nnot do that here. This subsection may look intimidating and for a good reason; it\\ninvolves equations that, unless you are a physicists, you have probably never en-\\ncountered before. Nevertheless, the ability to cope with new concepts lies at the heart\\nof every job interview.\\nFor some of the questions, you may need these constants:\\nPHYSICAL CONSTANTS\\nk Boltzmanns constant 1.381 × 10−23 J K−1\\nc Speed of light in vacum 2.998 × 108m s−1\\nh Planck’s constant 6.626 × 10−34 J s\\nPRB-95 \\uf059 CH.PRB- 4.29.\\nWhat is the expression for the Boltzmann probability distribution?\\nPRB-96 \\uf059 CH.PRB- 4.30.\\nInformation theory, quantum physics and thermodynamics are closely interconnected.\\nThere are several equivalent formulations for the second law of thermodynamics. One ap-\\nproach to describing uncertainty stems from Boltzmanns fundamental work on entropy in\\n100'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 117, 'page_label': '118'}, page_content=\"Chapter 4 INFORMATION THEORY\\nstatistical mechanics. Describe what is meant by Boltzmanns entropy.\\nPRB-97 \\uf059 CH.PRB- 4.31.\\nFrom Boltzmanns perspective, what is the entropy of an octahedral dice ( 4.7)?\\nFIGURE 4.7: An octahedral dice.\\n4.2.7 Jensen's inequality\\nPRB-98 \\uf059 CH.PRB- 4.32.\\n1. Deﬁne the term concave function.\\n2. Deﬁne the term convex function.\\n3. State Jensen's inequality and its implications.\\nPRB-99 \\uf059 CH.PRB- 4.33.\\nTrue or False: Using Jensen's inequality, it is possible to show that the KL divergence\\nis always greater or equal to zero.\\n4.3 Solutions\\n4.3.1 Logarithms in Information Theory\\n101\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 118, 'page_label': '119'}, page_content='4.3. SOLUTIONS\\nSOL-67 \\uf14b CH.SOL- 4.1.\\nNumerical results (4.8) are provided using Python interpreter version 3.6.\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 > 0.02020270731751947\\n5 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n6 > 3.912023005428146\\n7 print (math.log10(1.0/0.98)) # Common log (base 10)\\n8 > 0.008773924307505152\\n9 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n10 > 1.6989700043360187\\n11 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n12 > 0.02914634565951651\\n13 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n14 > 5.643856189774724\\nFIGURE 4.8: Logarithms in information theory .\\n\\x04\\nSOL-68 \\uf14b CH.SOL- 4.2.\\nThe logarithm base is explicitly written in each solution.\\n1.\\nlog10 3 + log10 4 = log 10(3 × 4) = log 10 12.\\n2.\\nlog2 46 = 6 log2 4.\\n3.\\nloge 15 − loge 3 = log e\\n15\\n3 = log e 5.\\n102'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 119, 'page_label': '120'}, page_content=\"Chapter 4 INFORMATION THEORY\\n\\x04\\n4.3.2 Shannon's Entropy\\nSOL-69 \\uf14b CH.SOL- 4.3.\\nShannons famous general formulae for uncertainty is:\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.8)\\n\\x04\\nSOL-70 \\uf14b CH.SOL- 4.4.\\n1. No information is conveyed by an event which is a-priori known to occur for certain\\n(Pa = 1), therefore the entropy is 0.\\n2. Equiprobable events mean that Pi = 1 /N ∀i ∈ [1, N]. Therefore for N equally-likely\\nevents, the entropy is log2(N ).\\n\\x04\\nSOL-71 \\uf14b CH.SOL- 4.5.\\nThe three properties are as follows:\\n1. H(X) is always non-negative, since information cannot be lost.\\n2. The uniform distribution maximizes H(X), since it also maximizes uncertainty.\\n3. The additivity property which relates the sum of entropies of two independent events.\\nFor instance, in thermodynamics, the total entropy of two isolated systems which co-\\nexist in equilibrium is the sum of the entropies of each system in isolation.\\n\\x04\\n103\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 120, 'page_label': '121'}, page_content='4.3. SOLUTIONS\\nSOL-72 \\uf14b CH.SOL- 4.6.\\nInformation is an [increase] in uncertainty. \\x04\\nSOL-73 \\uf14b CH.SOL- 4.7.\\nThe Shannon bit has two distinctive states; it is either 0 or 1, but never both at the same\\ntime. Shannon devised an experiment in which there is a question whose only two possible\\nanswers were equally likely to happen .\\nHe then deﬁned one bit as the amount of information gained (or alternatively, the amount\\nof entropy removed) once an answer to the question has been learned. He then continued to\\nstate that when the a-priori probability of any one possible answer is higher than the other, the\\nanswer would have conveyed less than one bit of information. \\x04\\nSOL-74 \\uf14b CH.SOL- 4.8.\\nThe notion of surprise is directly related to the likelihood of an event happening. Mathem-\\natically is it inversely proportional to the probability of that event.\\nAccordingly, learning that a high-probability event has taken place, for instance the sun rising,\\nis much less of a surprise and gives less information than learning that a low-probability\\nevent, for instance, rain in a hot summer day, has taken place. Therefore, the less likely the\\noccurrence of an event, the greater information it conveys.\\nIn the case where an event is a-priori known to occur for certain ( Pa = 1 ), then no inform-\\nation is conveyed by it. On the other hand, an extremely intermittent event conveys a lot of\\ninformation as it surprises us and informs us that a very improbable state exists. Therefore,\\nthe statement in part 3 is false.\\n\\x04\\nSOL-75 \\uf14b CH.SOL- 4.9.\\nThis quantity ISh, represented in the formulae is called the Shannon information of the\\nsource:\\nISh = −\\n∑\\na\\npa log2 pa. (4.9)\\nIt refers to the mean length in bits, per message, into which the messages can be compressed\\n104'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 121, 'page_label': '122'}, page_content=\"Chapter 4 INFORMATION THEORY\\nto. It is then possible for a communications channel to transmit ISh bits per message with a\\ncapacity of ISh. \\x04\\nSOL-76 \\uf14b CH.SOL- 4.10.\\n1. For N equiprobable events it holds that Pi = 1 /N, ∀i ∈ [1, N]. Therefore if we substi-\\ntute this into Shannon's equation we get:\\nHequiprobable = −\\nN∑\\ni=1\\n1\\nN log2\\n1\\nN . (4.10)\\nSince N does not depend on i, we can pull it out of the sum:\\nHequiprobable = −( 1\\nN log2\\n1\\nN )\\nN∑\\ni=1\\n1 (4.11)\\n= −\\n( 1\\nN log2\\n1\\nN\\n)\\nN\\n= − log2\\n1\\nN (4.12)\\n= log 2 N.\\nIt can be shown that for a given number of symbols (i.e., N is ﬁxed) the uncertainty H\\nhas its largest value only when the symbols are equally probable.\\n2. The probability for each pixel to be assigned a value in the given range is:\\npi = 1/256. (4.13)\\nTherefore the entropy is:\\nH = −(256)(1/256)(−8) = 8 [bits/symbol]. (4.14)\\n\\x04\\nSOL-77 \\uf14b CH.SOL- 4.11.\\n105\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 122, 'page_label': '123'}, page_content='4.3. SOLUTIONS\\nRefer to Fig. 4.9 for the corresponding illustration of the graph, where information is\\nshown as a function of p. It is equal to 0 for p = 0 and for p = 1. This is reasonable because for\\nsuch values of p the outcome is certain, so no information is gained by learning the outcome.\\nThe entropy in maximal uncertainty equals to 1 bit for p = 0 .5. Thus, the information gain\\nis maximal when the probabilities of two possible events are equal. Furthermore, for the entire\\nrange of probabilities between p = 0.4 and p = 0.6 the information is close to 1 bit. \\x04\\nFIGURE 4.9: H vs. Probability\\nSOL-78 \\uf14b CH.SOL- 4.12.\\nAn important set of properties of the entropy follows from the concavity of the entropy,\\nwhich follows from the concavity of the logarithm. Suppose that in an experiment, we cannot\\ndecide whether the actual probability of ‘heads’ is p1 or p2. We may decide to assign probability\\nq to the ﬁrst alternative and probability 1 − q to the second. The actual probability of ‘heads’\\nthen is the mixture qp1 + (1 − q)p2. The corresponding entropies satisfy the inequality:\\nS (qp1 + (1 − q)p2) ≥ qS (p1) + (1 − q) S (p2) , (4.15)\\n106'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 123, 'page_label': '124'}, page_content='Chapter 4 INFORMATION THEORY\\nThese probabilities, are equal in the extreme cases where p1 = p2, or q = 0, or q = 1. \\x04\\nSOL-79 \\uf14b CH.SOL- 4.13.\\nGiven (X, Y ), we can determine X and Z = Y − X. Conversely, given (X, Z), we can\\ndetermine X and Y = X + Z. Hence, H(X, Y ) = H(X, Z) due to the existence of this\\nbijection. \\x04\\nSOL-80 \\uf14b CH.SOL- 4.14.\\nThe solution and numerical calculations are provided using log2.\\n1. We can predict ‘heads’ for each ﬂip with an accuracy of p(xh) = 98 %.\\n2. According to Fig. ( 4.10), if the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is log2(1/0.98) [bits] .\\n1 import math\\n2 import numpy\\n3 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n4 > 0.02914634565951651\\n5 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n6 > 5.643856189774724\\nFIGURE 4.10: Shannon information gain for a biased coin toss.\\n3. Likewise, if the result of the coin toss is ‘tails’, the amount of Shannon information\\ngained is log2(1/0.02) [bits] .\\n4. It is always true that the more information is associated with an outcome, the more\\nsurprising it is.\\n5. The formulae for the average surprise is:\\nH(x) = p(xh) log 1\\np(xh) + p(xt) log 1\\np(xt). (4.16)\\n107'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 124, 'page_label': '125'}, page_content='4.3. SOLUTIONS\\n6. The value of the average surprise in bits is ( 4.11):\\nH(x) = [0 .98 × 0.0291] + [0.02 × 5.643] (4.17)\\n= 0.1414 [bits].\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4 print (\"binaryEntropy(p) is:{}\\nbits\".format(binaryEntropy(0.98)))↪→\\n5 > binaryEntropy(p) is:0.1414 bits\\nFIGURE 4.11: Average surprise\\n\\x04\\n4.3.3 Kullback-Leibler Divergence\\nSOL-81 \\uf14b CH.SOL- 4.15.\\nFor discrete probability distributions P and Q, the Kullback-Leibler divergence from P\\nto Q, the KLD is deﬁned as:\\nD(P ∥ Q) =\\n∑\\nx\\nP (x) log P (x)\\nQ(x) (4.18)\\n= EP\\n[\\nlog 1\\nQ(x) − log 1\\nP (x)\\n]\\n= HP (Q)\\ued19 \\ued18\\ued17 \\ued1a\\nCross Entropy\\n− H(P )\\ued19 \\ued18\\ued17 \\ued1a\\nEntropy\\n.\\n\\x04\\n108'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 125, 'page_label': '126'}, page_content='Chapter 4 INFORMATION THEORY\\nSOL-82 \\uf14b CH.SOL- 4.16.\\nOne interpretation is the following: the KL-divergence indicates the average number of\\nadditional bits required for transmission of values x ∈ X which are distributed according\\nto P (x), but we erroneously encoded them according to distribution Q(x). This makes sense\\nsince you have to “pay” for additional bits to compensate for not knowing the true distribution,\\nthus using a code that was optimized according to other distribution. This is one of the reason\\nthat the KL-divergence is also known as relative entropy. Formally, the cross entropy has an\\ninformation interpretation quantifying how many bits are wasted by using the wrong code:\\nHP (Q) =\\n∑\\nx\\nP (x)\\ued19 \\ued18\\ued17 \\ued1a\\nSending P\\ncode for Q\\n\\ued17 \\ued1a\\ued19 \\ued18\\nlog 1\\nQ(x) . (4.19)\\n\\x04\\nSOL-83 \\uf14b CH.SOL- 4.17.\\n1. True KLD is a non-symmetric measure, i.e. D(P ∥ Q) ̸= D(Q ∥ P ).\\n2. False KLD does not satisfy the triangle inequality.\\n3. True KLD is not a distance metric.\\n4. True KLD is regarded as a measure of the information gain. Notice that, however, KLD\\nis the amount of information lost.\\n5. True The units of KL divergence are units of information (bits, nats, etc.).\\n6. True KLD is a non-negative measure.\\n7. True Performing splitting based on highly informative event usually leads to low model\\ngeneralization and a less accurate one as well.\\n\\x04\\nSOL-84 \\uf14b CH.SOL- 4.18.\\n109'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 126, 'page_label': '127'}, page_content='4.3. SOLUTIONS\\nFormally, mutual information attempts to measure how correlated two variables are with\\neach other:\\nI(X; Y ) =\\n∑\\nx,y\\nP (x, y) log P (x, y)\\nP (x)P (y) (4.20)\\n= E\\n[\\nlog 1\\nP (x) + log 1\\nP (y) − log 1\\nP (x, y)\\n]\\n= H(X) + H(Y ) − H(X, Y ).\\nRegarding the question at hand, given two distributions f1 and f2 and their joint distri-\\nbution f , the mutual information of f1 and f2 is deﬁned as I(f1, f2) = H(f, f1f2). If the\\ntwo distributions are independent, i.e. f = f1 · f2, the mutual information will vanish. This\\nconcept has been widely used as a similarity measure in image analysis. \\x04\\nSOL-85 \\uf14b CH.SOL- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem. \\x04\\n4.3.4 Classification and Information Gain\\nSOL-86 \\uf14b CH.SOL- 4.20.\\nThe three most widely used methods are:\\n1.\\nEntropy (t) = −\\nc−1∑\\ni=0\\np(i) log2 p(i). (4.21)\\n2.\\n1 −\\nc−1∑\\ni=0\\n[p(i)]2 (4.22)\\n110'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 127, 'page_label': '128'}, page_content='Chapter 4 INFORMATION THEORY\\n3.\\nClassiﬁcation error (t) = 1 − max\\ni\\n[p(i)]. (4.23)\\n\\x04\\nSOL-87 \\uf14b CH.SOL- 4.21.\\nIn a decision tree, the attribute by which we choose to split is the one with [maximum]\\ninformation gain. \\x04\\nSOL-88 \\uf14b CH.SOL- 4.22.\\nIt is clear that the entropy will be decreased more by ﬁrst splitting on Green rather than\\non Rain.\\nFIGURE 4.12: First split.\\n\\x04\\nSOL-89 \\uf14b CH.SOL- 4.23.\\n1. Information gain is the expected reduction in entropy caused by partitioning values in\\na dataset according to a given attribute.\\n2. A decision tree learning algorithm chooses the next attribute to partition the currently\\nselected node, by ﬁrst computing the information gain from the entropy, for instance,\\nas a splitting criterion.\\n3. There are 3 positive examples corresponding to Shrinkage=+, and 2 negative examples\\n111'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 128, 'page_label': '129'}, page_content='4.3. SOLUTIONS\\ncorresponding to Shrinkage=-. Using the formulae:\\nH(Y ) = −\\nk∑\\ni=1\\nP (Y = yi) log2 P (Y = yi) (4.24)\\nand the probabilities:\\nP (γ = +) = 3\\n5 , (4.25)\\nP (γ = −) = 2\\n5 , (4.26)\\nthe overall entropy before splitting is ( 4.13):\\nEorig = −(3/5) log(3/5) − (2/5) log(2/5)\\n= H(γ) ≈ 0.97095[bits/symbol]. (4.27)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is: 0.97095 bits\\nFIGURE 4.13: Entropy before splitting.\\n4. If we split on θ1, (4.5) the relative shrinkage frequency is:\\n112'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 129, 'page_label': '130'}, page_content='Chapter 4 INFORMATION THEORY\\nTotal θ1 = T θ1 = F\\n+ 3 0\\n- 1 1\\nTABLE 4.5: Splitting on θ1.\\nT o compute the information gain (IG) based on feature θ1, we must ﬁrst compute the\\nentropy of γ after a split based on θ1, H(γ|θ1):\\nH(γ|θ1)\\n= −\\nv∑\\nj=1\\n[ k∑\\ni=1\\nP (γ = γi|θ1 = θj) log2 P (γ = γi|θ1 = θj)\\n]\\nP (θ1 = θj).\\nTherefore, using the data for the the relative shrinkage frequency ( 4.5), the information\\ngain after splitting on θ1 is:\\nEθ1=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.8112,\\nEθ1=F = −0\\n1 log 0\\n1 − 1\\n1 log 1\\n1 = 0.0.\\n(4.28)\\nNow we know that P (θ1 = T ) = 4/5 and P (θ1 = F ) = 1/5 , therefore:\\n∆ = Eorig − (4/5) Eθ1=T − (1/5) Eθ1=F\\n= 0.97095 − (4/5) ∗ 0.8112 − (1/5) ∗ (0.0)\\n=≈ 0.32198 [bits/symbol].\\n(4.29)\\n\\x04\\nSOL-90 \\uf14b CH.SOL- 4.24.\\nThere are 4 positive examples corresponding to Expansion=+, and 3 negative examples\\n113'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 130, 'page_label': '131'}, page_content='4.3. SOLUTIONS\\ncorresponding to Expansion=-.\\n1. The overall entropy before splitting is ( 4.14):\\nEorig = −(4/7) log(4/7) − (3/7) log(3/7)\\n= 0.9852281 [bits/symbol]. (4.30)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is:0.9852281 bits\\nFIGURE 4.14: Entropy before splitting.\\n2. If we split on θ1, (4.6) the relative star expansion frequency is:\\nTotal θ1 = T θ1 = F\\n+ 3 1\\n- 0 3\\nTABLE 4.6: Splitting on θ1.\\nTherefore, the information gain after splitting on A is:\\nEθ1=T = −3\\n3 log 3\\n3 − 0\\n3 log 0\\n3 = 0.0,\\nEθ1=F = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.81127.\\n(4.31)\\n114'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 131, 'page_label': '132'}, page_content='Chapter 4 INFORMATION THEORY\\nNow we know that P (θ1 = T ) = 3/7 and P (θ1 = F ) = 4/7 , therefore:\\n∆ = Eorig − (3/7) Eθ1=T − (4/7) Eθ1=F\\n= 0.98522 − (3/7) ∗ 0.0 − (4/7) ∗ (0.81127)\\n= 0.52163 [bits/symbol].\\n(4.32)\\n3. If we split on θ2, (4.7) the relative star expansion frequency is:\\nTotal θ2 = T θ2 = F\\n+ 3 1\\n- 1 2\\nTABLE 4.7: Splitting on θ2.\\nThe information gain after splitting on B is:\\nEθ2=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.0.8112,\\nEθ2=F = −1\\n3 log 1\\n3 − 2\\n3 log 2\\n3 = 0.9182.\\n(4.33)\\nNow we know that P (θ2 = T ) = 4/7 and P (θ2 = F ) = 3/7 , therefore:\\n∆ = Eorig − (4/7) Eθ2=T − (3/7) Eθ2=F\\n= 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol].\\n∆ = 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol]. (4.34)\\n\\x04\\n115'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 132, 'page_label': '133'}, page_content='4.3. SOLUTIONS\\nSOL-91 \\uf14b CH.SOL- 4.25.\\n1.\\nH(γ) = −\\n( 2\\n6 log2\\n2\\n6 + 4\\n6 log2\\n4\\n6\\n)\\nH(γ) = −\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n≈ 0.92 [bits/symbol].\\n(4.35)\\n2.\\nH(γ|θ1) = −1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n−\\n1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n− 1\\n3 (1 log2 1) .\\nH(γ|θ1) = 1\\n3(1) + 1\\n3(1) + 1\\n3 (0).\\nH(γ|θ1) = 2\\n3 ≈ 0.66[bits/symbol].\\n(4.36)\\n3.\\nH(γ|θ2) = −1\\n2\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n− 1\\n2 (1 log2 1) .\\nH(γ|θ2) = 1\\n2\\n(\\nlog2 3 − 2\\n3\\n)\\n.\\nH(γ|θ2) = 1\\n2 log2 3 − 1\\n3 ≈ 0.46 [bits/symbol].\\n(4.37)\\n4. False.\\n\\x04\\n4.3.5 Mutual Information\\nSOL-92 \\uf14b CH.SOL- 4.26.\\n1. The diagram is depicted in Fig. 4.15.\\n116'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 133, 'page_label': '134'}, page_content='Chapter 4 INFORMATION THEORY\\nE N\\nH(S) H(D)\\nFIGURE 4.15: Mutual Information between H(S) & H(D).\\n2. Equivocation is annotated by E.\\n3. Noise is annotated by N .\\n4. The intersection (shaded area) in (4.15) corresponds to mutual information of the source\\nH(S) and of the destination H(D).\\n5. The formulae for mutual information is:\\nH(S; D) = H(S) − E = H(D) − N. (4.38)\\n\\x04\\nSOL-93 \\uf14b CH.SOL- 4.27.\\nThe relative entropy D(p||q) is the measure of difference between two distributions. It\\ncan also be expressed like a measure of the inefﬁciency of assuming that the distribution is q\\nwhen the true distribution is p. \\x04\\nSOL-94 \\uf14b CH.SOL- 4.28.\\nMutual information is a Shannon entropy-based measure of dependence between random\\nvariables. The mutual information between X and Z can be understood as the reduction of\\n117'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 134, 'page_label': '135'}, page_content=\"4.3. SOLUTIONS\\nthe uncertainty in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.39)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X. \\x04\\n4.3.6 Mechanical Statistics\\nSOL-95 \\uf14b CH.SOL- 4.29.\\nIs this question valuable? \\x04\\nSOL-96 \\uf14b CH.SOL- 4.30.\\nBoltzmann related the degree of disorder of the state of a physical system to the logarithm\\nof its probability. If, for example, the system has n non-interacting and identical particles,\\neach capable of existing in each of K equally likely states, the leading term in the logarithm of\\nthe probability of ﬁnding the system in a conﬁguration with n1 particles in state 1, n2 in state\\n2, etc, is given by the Boltzmann entropy Hπ = − ∑K\\n1 πi log(πi), where πi = ni/n. \\x04\\nSOL-97 \\uf14b CH.SOL- 4.31.\\nThere are 8 equiprobable events in each roll of the dice, therefore:\\nH = −\\n8∑\\ni=1\\n1\\n8 log2\\n1\\n8 = 3 [bits] . (4.40)\\n\\x04\\n4.3.7 Jensen's inequality\\nSOL-98 \\uf14b CH.SOL- 4.32.\\n1. A function f is concave in the range [a, b] if f φ2 is negative in the range [a, b].\\n2. A function f is convex in the range [a, b] if f φ2 is positive in the range [a, b].\\n118\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 135, 'page_label': '136'}, page_content=\"Chapter 4 INFORMATION THEORY\\n3. The following inequality was published by J.L. Jensen in 1906:\\n(Jensen’s Inequality)Let f be a function convex up on (a, b). Then for any n ≥ 2\\nnumbers xi ∈ (a, b):\\nf\\n( ∑n\\ni=1 xi\\nn\\n)\\n≤\\n∑n\\ni=1 f (xi)\\nn ,\\nand that the equality is attained if and only if f is linear or all xi are equal.\\nFor a convex down function, the sign of the inequality changes to ≥.\\nJensen’s inequality states that if f is convex in the range [a, b], then:\\nf (a) + f (b)\\n2 ≥ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b. Jensen’s inequality states that if f is concave in the\\nrange [a, b], then:\\nf (a) + f (b)\\n2 ≤ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b.\\n\\x04\\nSOL-99 \\uf14b CH.SOL- 4.33.\\nTrue The non-negativity of KLD can be proved using Jensen's inequality. \\x04\\nReferences\\n[1] S. Carnot. Reﬂections on the Motive Power of Fire: And Other Papers on the Second\\nLaw of Thermodynamics . Dover books on physics. Dover Publications, 2012 (cit.\\non p. 86).\\n[2] T. M. Cover and J. A. Thomas. Elements of Information Theory . John Wiley and\\nSons, Inc., 2006 (cit. on p. 86).\\n[3] B. J. Hiley. ‘From the Heisenberg Picture to Bohm: a New Perspective on Active\\nInformation and its relation to Shannon Information’. In: Proc. Conf. Quantum\\nTheory: reconsideration of foundations (2002), pp. 141–162 (cit. on p. 87).\\n119\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 136, 'page_label': '137'}, page_content='REFERENCES\\n[4] C. Shannon. ‘A mathematical theory of communication’. In: Bell System T echnical\\nJournal 27 (1948), pp. 379–423 (cit. on pp. 86, 90).\\n[5] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 96).\\n120'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 137, 'page_label': '138'}, page_content='CHAPTER\\n5\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 138, 'page_label': '139'}, page_content='5.1. INTRODUCTION\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 155\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n5.1 Introduction\\nC\\nALCULUS is the mathematics of change; the differentiation of a function is\\nkey to almost every domain in the scientiﬁc and engineering realms and\\ncalculus is also very much central to DL. A standard curriculum of ﬁrst year\\ncalculus includes topics such as limits, differentiation, the derivative, Taylor\\nseries, integration, and the integral. Many aspiring data scientists who lack a relevant\\nmathematical background and are shifting careers, hope to easily enter the ﬁeld but\\nfrequently encounter a mental barricade.\\n122'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 139, 'page_label': '140'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nf (x) f ′(x)\\nsin(x) cos(x)\\ncos(x) − sin(x)\\nlog(x) 1\\nx\\nex ex\\nThanks to the rapid advances in processing power and the proliferation of GPUs,\\nit is possible to lend the burden of computation to a computer with high efﬁciency\\nand precision. For instance, extremely fast implementations of backpropagation, the\\ngradient descent algorithm, and automatic differentiation (AD) [5] brought artiﬁcial in-\\ntelligence from a mere concept to reality .\\nCalculus is frequently taught in a way that is very burdensome to the student,\\ntherefore I tried incorporating the writing of Python code snippets into the learning\\nprocess and the usage of:\\nDAGs (Directed Acyclic Graphs). Gradient descent is the essence of optimization in\\ndeep learning, which requires efﬁcient access to ﬁrst and second order derivatives that\\nAD frameworks provide. While older AD frameworks were written in C++ ([ 4]), the\\nnewer ones are Python-based such as Autograd ([ 10]) and JAX ([ 3], [1]).\\nDerivatives are also crucial in graphics applications. For example, in a render-\\ning technique entitled global illumination, photons bounce in a synthetically generated\\nscene while their direction and colour has to be determined using derivatives based\\non the speciﬁc material each photon hits. In ray tracing algorithms, the colour of the\\npixels is determined by tracing the trajectory the photons travel from the eye of the\\nobserver through a synthetic 3D scene.\\nA function is usually represented by a DAG. For instance, one commonly used\\nform is to represent intermediate values as nodes and operations as arcs ( 5.2). One\\nother commonly used form is to represent not only the values but also the operations\\nas nodes ( 5.11).\\nThe ﬁrst representation of a function by a DAG goes back to [ 7].\\n123'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 140, 'page_label': '141'}, page_content='5.2. PROBLEMS\\nx\\ny\\nk\\nf (a)\\nf (b)\\na bc\\nFIGURE 5.1: Intermediate value theorem\\nManual differentiation is tedious and error-prone and practically unusable for real-\\ntime graphics applications wherein numerous successive derivatives have to be re-\\npeatedly calculated. Symbolic differentiation on the other hand, is a computer based\\nmethod that uses a collection of differentiation rules to analytically calculate an exact\\nderivative of a function resulting in a purely symbolic derivatives. Many symbolic\\ndifferentiation libraries utilize what is known as operator-overloading ([9]) for both the\\nforward and reverse forms of differentiation, albeit they are not quite as fast as AD.\\n5.2 Problems\\n5.2.1 AD, Gradient descent & Backpropagation\\nAD [5] is the application of the chain rule to functions by computers in order to auto-\\nmatically compute derivatives. AD plays a signiﬁcant role in training deep learning\\nalgorithms and in order to understand AD you need a solid grounding in Calculus. As\\nopposed to numerical differentiation, AD is a procedure for establishing exact deriv-\\natives without any truncation errors. AD breaks a computer program into a series of\\nfundamental mathematical operations, and the gradient or Hessian of the computer\\nprogram is found by successive application of the chain rule ( 5.1) to it’s elementary\\nconstituents.\\n124'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 141, 'page_label': '142'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nFor instance, in the C++ programming language, two techniques ([ 4]) are com-\\nmonly utilized in transforming a program that calculates numerical values of a func-\\ntion into a program which calculates numerical values for derivatives of that function;\\n(1) an operator overloading approach and (2) systematic source code transformation.\\n∂\\n∂t f (g(t))\\n⏐⏐⏐⏐⏐\\nt=t0\\n=\\n\\uf8eb\\n\\uf8ed ∂\\n∂s f (s)\\n⏐⏐⏐⏐⏐\\ns=g(t0)\\n\\uf8f6\\n\\uf8f8\\n(\\n∂\\n∂t g(t)\\n⏐⏐⏐⏐⏐\\nt=t0\\n)\\n(5.1)\\nOne notable feature of AD is that the values of the derivatives produced by apply-\\ning AD, as opposed to numerical differentiation (ﬁnite difference formulas), are exact\\nand accurate. Two variants of AD are widely adopted by the scientiﬁc community: the\\nforward mode or the reverse mode where the underlying distinction between them is\\nthe order in which the chain rule is being utilized. The forward mode, also entitled\\ntangent mode, propagates derivatives from the dependent towards the independent\\nvariables, whereas the reverse or adjoint mode does exactly the opposite. AD makes\\nheavy use of a concept known as dual numbers (DN) ﬁrst introduced by Clifford ([ 2]).\\nx1 v1 v2 f\\n(x)2\\nln(1 + v1)\\nexp(v1)\\nv2 + 1\\nFIGURE 5.2: A Computation graph with intermediate values as nodes and operations as\\narcs.\\n5.2.2 Numerical differentiation\\nPRB-100 \\uf059 CH.PRB- 5.1.\\n1. Write the formulae for the ﬁnite difference rule used in numerical differentiation.\\n2. What is the main problem with this formulae?\\n125'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 142, 'page_label': '143'}, page_content='5.2. PROBLEMS\\n3. Indicate one problem with software tools which utilize numerical differentiation and\\nsuccessive operations on ﬂoating point numbers.\\nPRB-101 \\uf059 CH.PRB- 5.2.\\n1. Given a function f (x) and a point a, deﬁne the instantaneous rate of change of\\nf (x) at a.\\n2. What other commonly used alternative name does the instantaneous rate of change\\nhave?\\n3. Given a function f (x) and a point a, deﬁne the tangent line of f (x) at a.\\n5.2.3 Directed Acyclic Graphs\\nThere are two possible ways to traverse a DAG (Directed Acyclic Graph). One\\nmethod is simple. Start at the bottom and go through all nodes to the top of the com-\\nputational tree. That is nothing else than passing the corresponding computation se-\\nquence top down. Based on this method, the so called forward mode or of AD was\\ndeveloped [ 8]. In contrast to this forward mode the reverse mode was ﬁrst used by\\nSpeelpenning [ 13] who passed the underlying graph top down and propagated the\\ngradient backwards.\\nPRB-102 \\uf059 CH.PRB- 5.3.\\n1. State the deﬁnition of the derivative f (c) of a function f (x) at x = c.\\n2. With respect to the DAG depicted in 5.3:\\n126'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 143, 'page_label': '144'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx √x\\n1\\n/\\ng(x)\\nFIGURE 5.3: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.3 and ﬁnd the function g(x) it represents.\\n(b) Using the deﬁnition of the derivative, ﬁnd g′(9).\\nPRB-103 \\uf059 CH.PRB- 5.4.\\n1. With respect to the expression graph depicted in 5.4, traverse the graph and ﬁnd the\\nfunction g(x) it represents.\\nx\\n**2\\n2\\n*\\n-\\n+\\n1\\ng(x)\\nFIGURE 5.4: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n2. Using the deﬁnition of the derivative ﬁnd the derivative of g(x).\\n5.2.4 The chain rule\\nPRB-104 \\uf059 CH.PRB- 5.5.\\n127'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 144, 'page_label': '145'}, page_content='5.2. PROBLEMS\\n1. The chain rule is key concept in differentiation. Deﬁne it.\\n2. Elaborate how the chain rule is utilized in the context of neural networks.\\n5.2.5 Taylor series expansion\\nThe idea behind a Taylor series is that if you know a function and all its derivatives\\nat one point x = a, you can approximate the function at other points near a. As an\\nexample, take f (x) = √x. You can use Taylor series to approximate\\n√\\n10 by knowing\\nf (9) and all the derivatives f ′(9), f ′′(9).\\nThe MacLaurin series ( 5.2) is a special case of Taylor series when f (0), f ′(0) are\\nknown:\\nf (x) = f (0) + xf ′(0) + x2\\n2! f ′′(0) + x3\\n3! f ′′′(0) + · · · =\\n∞∑\\np=0\\nxp\\np! f (p)(0) (5.2)\\nFor instance, the Maclaurin expansion of cos(x) is:\\nf (x) = cos x, f ′(x) = − sin x,\\nf ′′(x) = − cos x, f ′′′(x) = sin x (5.3)\\nWhen evaluated at 0 results in:\\ncos x = 1 − x2\\n2! + x4\\n4! − x6\\n6! + · · · (5.4)\\nPRB-105 \\uf059 CH.PRB- 5.6.\\nFind the T aylor series expansion for:\\n1.\\n1\\n1 − x (5.5)\\n128'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 145, 'page_label': '146'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2.\\nex (5.6)\\n3.\\nsin(x) (5.7)\\n4.\\ncos(x) (5.8)\\nPRB-106 \\uf059 CH.PRB- 5.7.\\nFind the T aylor series expansion for:\\nlog(x) (5.9)\\nPRB-107 \\uf059 CH.PRB- 5.8.\\nFind the T aylor series expansion centered at x = −3 for:\\nf (x) = 5 x2 − 11x + 1 (5.10)\\nPRB-108 \\uf059 CH.PRB- 5.9.\\nFind the 101th degree T aylor polynomial centered at x = 0 for:\\nf (x) = cos( x) (5.11)\\nPRB-109 \\uf059 CH.PRB- 5.10.\\nAt x = 1, compute the ﬁrst 7 terms of the T aylor series expansion of:\\nf (x) = ln 3 x. (5.12)\\n129'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 146, 'page_label': '147'}, page_content='5.2. PROBLEMS\\n5.2.6 Limits and continuity\\nTheorem 1 (L’Hopital’s rule) .\\n[limx→a\\nf (x)\\ng(x) = limx→a\\nf ′(x)\\ng′(x) ]. (5.13)\\nPRB-110 \\uf059 CH.PRB- 5.11.\\nFind the following limits:\\n1. lim\\nx→3\\nex3\\n− e27\\n3x − 9\\n2. lim\\nx→0\\nex2\\n− x − 1\\n3 cos x − x − 3\\n3. limx→∞\\nx − ln x\\n100√x + 4\\n5.2.7 Partial derivatives\\nPRB-111 \\uf059 CH.PRB- 5.12.\\n1. True or false: When applying a partial derivative, there are two variables considered\\nconstants - the dependent and independent variable.\\n2. Given g(x, y), ﬁnd its partial derivative with respect to x:\\ng(x, y) = x2y + yx + 8y. (5.14)\\nPRB-112 \\uf059 CH.PRB- 5.13.\\n130'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 147, 'page_label': '148'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe gradient of a two-dimensional function is given by\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j (5.15)\\n1. Find the gradient of the function:\\nf (x, y) = xy2 − y2 + x3 (5.16)\\n2. Given the function:\\ng(x, y) = x2y = xy2 − y − 1, (5.17)\\nevaluate it at (−1, 0), directed at (1, 1).\\nPRB-113 \\uf059 CH.PRB- 5.14.\\nFind the partial derivatives of:\\nf (x, y) = 3 sin 2(x − y) (5.18)\\nPRB-114 \\uf059 CH.PRB- 5.15.\\nFind the partial derivatives of:\\nz = 2 sin(x) sin(y) (5.19)\\n5.2.8 Optimization\\nPRB-115 \\uf059 CH.PRB- 5.16.\\nConsider f (x) = x2 + 1\\n(x + 2)2 .\\n1. Where is f (x) well deﬁned?\\n131'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 148, 'page_label': '149'}, page_content='5.2. PROBLEMS\\n2. Where is f (x) increasing and decreasing?\\n3. Where is f (x) reaching minimum and maximum values.\\nPRB-116 \\uf059 CH.PRB- 5.17.\\nConsider f (x) = 2 x3 − x.\\n1. Derive f (x) and conclude on its behavior.\\n2. Derive once again and discuss the concavity of the function f (x).\\nPRB-117 \\uf059 CH.PRB- 5.18.\\nConsider the function\\nf (x, y) = 2 x2 − xy + y2,\\nand ﬁnd maximum, minimum, and saddle points.\\n5.2.9 The Gradient descent algorithm\\nPRB-118 \\uf059 CH.PRB- 5.19.\\nThe gradient descent algorithm can be utilized for the minimization of convex functions.\\nStationary points are required in order to minimize a convex function. A very simple ap-\\nproach for ﬁnding stationary points is to start at an arbitrary point, and move along the\\ngradient at that point towards the next point, and repeat until converging to a stationary\\npoint.\\n1. What is the term used to describe the vector of all partial derivatives for a function\\nf (x)?\\n2. Complete the sentence: when searching for a minima, if the derivative is positive, the\\nfunction is increasing/decreasing.\\n132'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 149, 'page_label': '150'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n3. The function x2 as depicted in 5.5, has a derivative of f ′(x) = 2 x. Evaluated at x =\\n−1, the derivative equals f ′(x = −1) = −2. At x = −1, the function is decreasing\\nas x gets larger. We will happen if we wish to ﬁnd a minima using gradient descent,\\nand increase (decrease) x by the size of the gradient , and then again repeatedly keep\\njumping?\\n4. How this phenomena can be alleviated?\\n5. True or False: The gradient descent algorithm is guaranteed to ﬁnd a local minimum\\nif the learning rate is correctly decreased and a ﬁnite local minimum exists.\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−1,0\\n1,0\\n2,0\\n3,0\\n4,0\\nx = −1\\nx\\ny\\nx2\\nFIGURE 5.5: x2 Function\\nPRB-119 \\uf059 CH.PRB- 5.20.\\n1. Is the data linearly separable?\\nX1 X2 Y\\n1 1 +\\n12 12 −\\n4 5 −\\n12 12 +\\n(5.20)\\n133'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 150, 'page_label': '151'}, page_content='5.2. PROBLEMS\\n2. What is loss function for linear regression?\\n3. What is the gradient descent algorithm to minimize a function f (x)?\\n5.2.10 The Backpropagation algorithm\\nThe most important, expensive and hard to implement part of any hardware realiz-\\nation of ANNs is the non-linear activation function of a neuron. Commonly applied\\nactivation functions are the sigmoid and the hyperbolic tangent. In the most used\\nlearning algorithm in present day applications, back-propagation, the derivatives of\\nthe sigmoid function are needed when back propagating the errors.\\nThe backpropagation algorithm looks for the minimum of the error function in\\nweight space using the method of gradient descent.\\nPRB-120 \\uf059 CH.PRB- 5.21.\\n1. During the training of an ANN, a sigmoid layer applies the sigmoid function to every\\nelement in the forward pass, while in the backward pass the chain rule is being util-\\nized as part of the backpropagation algorithm. With respect to the backpropagation\\nalgorithm, given a sigmoid σ(x) = ex\\n1+ex activation function, and a J as the cost func-\\ntion, annotate each part of equation (5.21):\\ndZ = dJ\\ndσ(x)\\ndσ(x)\\ndx = dA · σ(x) ·\\n(\\n1 − σ(x)\\n)\\n(5.21)\\n2. Code snippet 5.6 provides a pure Python-based (e.g. not using Autograd) implement-\\nation of the forward pass for the sigmoid function. Complete the backward pass that\\ndirectly computes the analytical gradients.\\n134'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 151, 'page_label': '152'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5 def backward(self, grad):\\n6 grad_input = [???]\\n7 return grad_input\\nFIGURE 5.6: Forward pass for the sigmoid function.\\nPRB-121 \\uf059 CH.PRB- 5.22.\\nThis question deals with the effect of customized transfer functions. Consider a neural\\nnetwork with hidden units that use x3 and output units that use sin(2x) as transfer func-\\ntions. Using the chain rule, starting from ∂E/∂yk, derive the formulas for the weight updates\\n∆wjk and ∆wij. Notice - do not include partial derivatives in your ﬁnal answer.\\n5.2.11 Feed forward neural networks\\nUnderstanding the inner-workings of Feed Forward Neural Networks (FFNN) is\\ncrucial to the understanding of other, more advanced Neural Networks such as CNN’s.\\nA Neural Network (NN) is an interconnected assembly of simple processing\\nelements, units or nodes, whose functionality is loosely based on the animal\\nneuron. The processing ability of the network is stored in the inter-unit\\nconnection strengths, or weights, obtained by a process of adaptation to, or\\nlearning from, a set of training patterns. [ 6]\\nThe Backpropagation Algorithm is the most widely used learning algorithm for\\nFFNN. Backpropagation is a training method that uses the Generalized Delta Rule . Its\\nbasic idea is to perform a gradient descent on the total squared error of the network\\noutput, considered as a function of the weights. It was ﬁrst described by Werbos and\\nmade popular by Rumelhart’s, Hinton’s and Williams’ paper [ 12].\\n135'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 152, 'page_label': '153'}, page_content='5.2. PROBLEMS\\n5.2.12 Activation functions, Autograd/JAX\\nActivation functions, and most commonly the sigmoid activation function, are\\nheavily used for the construction of NNs. We utilize Autograd ([ 10]) and the recently\\npublished JAX ([ 1]) library to learn about the relationship between activation func-\\ntions and the Backpropagation algorithm.\\nUsing a logistic, or sigmoid, activation function has some beneﬁts in being able\\nto easily take derivatives and then interpret them using a logistic regression model.\\nAutograd is a core module in PyTorch ([ 11]) and adds inherit support for automatic\\ndifferentiation for all operations on tensors and functions. Moreover, one can imple-\\nment his own custom Autograd function by sub classing the autograd F unction and\\nimplementing the forward and backward passes which operate on PyTorch tensors.\\nPyTorch provides a simple syntax ( 5.7) which is transparent to both CPU/GPU sup-\\nport.\\nimport torch\\nfrom torch.autograd import Function\\nclass DLFunction(Function):\\n@staticmethod\\ndef forward(ctx, input):\\n...\\n@staticmethod\\ndef backward(ctx, grad_output):\\n...\\nFIGURE 5.7: PyTorch syntax for autograd.\\nPRB-122 \\uf059 CH.PRB- 5.23.\\n1. True or false:In Autograd, if any input tensor of an operation has requires_grad=T rue,\\nthe computation will be tracked. After computing the backward pass, a gradient w.r.t.\\nthis tensor is accumulated into .grad attribute\\n136'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 153, 'page_label': '154'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. True or false: In Autograd, multiple calls to backward will sum up previously com-\\nputed gradients if they are not zeroed.\\nPRB-123 \\uf059 CH.PRB- 5.24.\\nY our friend, a veteran of the DL community wants to use logistic regression and im-\\nplement custom activation functions using Autograd. Logistic regression is used when the\\nvariable y that we want to predict can only take on discrete values (i.e. classiﬁcation). Con-\\nsidering a binary classiﬁcation problem (y = 0 or y = 1) ( 5.8), the hypothesis function could\\nbe deﬁned so that it is bounded between [0, 1] in which we use some form of logistic function,\\nsuch as the sigmoid function. Other, more efﬁcient functions exist such as the ReLU (Rec-\\ntiﬁed Linear Unit) which we discussed later. Note: The weights in ( 5.8) are only meant for\\nillustration purposes and are not part of the solution.\\nxn\\nx2\\nx1\\n1\\n∑\\nwn\\nw2\\nw1\\nw0\\n0\\n1\\n0\\n1\\nSummation Activation\\nyk =f(netk)\\ninputs weights\\nFIGURE 5.8: A typical binary classiﬁcation problem.\\n1. Given the sigmoid function: g(x) = 1\\n1+e−z what is the expression for the corresponding\\nhypothesis in logistic regression?\\n2. What is the decision boundary?\\n3. What does hΘ(x) = 0 .8 mean?\\n4. Using an Autograd based Python program, implement both the forward and backward\\npass for the sigmoid activation function and evaluate it’s derivative at x = 1\\n137'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 154, 'page_label': '155'}, page_content='5.2. PROBLEMS\\n5. Using an Autograd based Python program, implement both the forward and backward\\npass for the ReLU activation function and evaluate it’s derivative at x = 1\\nPRB-124 \\uf059 CH.PRB- 5.25.\\nFor real values, −1 < x < 1 the hyperbolic tangent function is deﬁned as:\\ntanh−1 x = 1\\n2 [ln(1 + x) − ln(1 − x)] (5.22)\\nOn the other hand, the artanh function, which returns the inverse hyperbolic tangent of\\nits argument x, is implemented in numpy as arctanh().\\nIts derivative is given by:\\n(arctanh(x))′ = 1\\n1 − x2 (5.23)\\nY our friend, a veteran of the DL community wants to implement a custom activation\\nfunction for the arctanh function using Autograd. Help him in realize the method.\\n1. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n2. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the forward pass for the arctanh function in Python.\\n3. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the backward pass for the arctanh function in Python.\\n4. Name the class ArtanhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\n5.2.13 Dual numbers in AD\\nDual numbers (DN) are analogous to complex numbers and augment real numbers\\n138'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 155, 'page_label': '156'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nwith a dual element by adjoining an inﬁnitesimal element d, for which d2 = 0.\\nPRB-125 \\uf059 CH.PRB- 5.26.\\n1. Explain how AD uses ﬂoating point numerical rather than symbolic expressions.\\n2. Explain the notion of DN as introduced by ([ 2]).\\n3. What arithmetic operations are possible on DN?.\\n4. Explain the relationship between a T aylor series and DN.\\nPRB-126 \\uf059 CH.PRB- 5.27.\\n1. Expand the following function using DN:\\nsin(x + ˙xd) (5.24)\\n2. With respect to the expression graph depicted in 5.9:\\nx\\n3\\n* +\\n2\\ng(x)\\nFIGURE 5.9: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.9 and ﬁnd the function g(x) it represents.\\n(b) Expand the function g(x) using DN.\\n3. Show that the general identity :\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.25)\\n139'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 156, 'page_label': '157'}, page_content='5.2. PROBLEMS\\nholds in this particular case too.\\n4. Using the derived DN, evaluate the function g(x) at x = 2.\\n5. Using an Autograd based Python program implement the function and evaluate it’s\\nderivative at x = 2.\\nPRB-127 \\uf059 CH.PRB- 5.28.\\nWith respect to the expression graph depicted in 5.10:\\nx\\n**2\\n5\\n*\\n*\\n+\\n14\\ng(x)\\nFIGURE 5.10: An expression graph for g(x). Constants are shown in gray , crossed-out\\nsince derivatives should not be propagated to constant operands.\\n1. T raverse the graph5.10 and ﬁnd the function g(x) it represents.\\n2. Expand the function g(x) using DN.\\n3. Using the derived DN, evaluate the function g(x) at x = 5.\\n4. Using an AutoGrad based Python program implement the function and evaluate it’s\\nderivative at x = 5.\\n5.2.14 Forward mode AD\\nPRB-128 \\uf059 CH.PRB- 5.29.\\n140'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 157, 'page_label': '158'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nWhen differentiating a function using forward-mode AD, the computation of such an\\nexpression can be computed from its corresponding directed a-cyclical graph by propagating\\nthe numerical values.\\n1. Find the function, g(A, B, C) represented by the expression graph in 5.11.\\nA\\nB\\nC\\nln\\n+* g (A, B, C))\\nFIGURE 5.11: A computation graph for g(x)\\n2. Find the partial derivatives for the function g(x).\\nPRB-129 \\uf059 CH.PRB- 5.30.\\nAnswer the following given that a computational graph of a function has N inputs and\\nM outputs.\\n1. True or False?:\\n(a) Forward and reverse mode AD always yield the same result.\\n(b) In reverse mode AD there are fewer operations (time) and less space for interme-\\ndiates (memory).\\n(c) The cost for forward mode grows with N.\\n(d) The cost for reverse mode grows with M.\\nPRB-130 \\uf059 CH.PRB- 5.31.\\n141'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 158, 'page_label': '159'}, page_content='5.2. PROBLEMS\\n1. T ransform the source code in code snippet 5.1 into a function g(x1, x2).\\nCODE 5.1: A function, g(x1, x2) in the C programming language.\\n1 float g( float x1 , float x2) {\\n2 float v1, v2, v3 , v4 , v5;\\n3 v1=x1;\\n4 v2=x2;\\n5 v3 = v1 * v2;\\n6 v4 = ln (v1 );\\n7 v5 = v3 + v4;\\n8 return v5;\\n9 }\\n2. T ransform the functiong(x1, x2) into an expression graph.\\n3. Find the partial derivatives for the function g(x1, x2).\\n5.2.15 Forward mode AD table construction\\nPRB-131 \\uf059 CH.PRB- 5.32.\\n1. Given the function:\\nf (x1, x2) = x1x2 + ln (x1) (5.26)\\nand the graph 5.1, annotate each vertex (edge) of the graph with the partial derivatives\\nthat would be propagated in forward mode AD.\\n2. T ransform the graph into a table that computes the function:\\ng(x1, x2) evaluated at (x1; x2) = ( e2; π) using forward-mode AD.\\n3. Write and run a Python code snippet to prove your results are correct.\\n4. Describe the role of seed values in forward-mode AD.\\n142'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 159, 'page_label': '160'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n5. T ransform the graph into a table that computes the derivative of g(x1, x2) evalu-\\nated at (x1; x2) = ( e2; π) using forward-mode AD for x1 as the chosen independent\\nvariable.\\n6. Write and run a Python code snippet to prove your results are correct.\\n5.2.16 Symbolic differentiation\\nIn this section, we introduce the basic functionality of the SymPy (SYMbolic Python)\\nlibrary commonly used for symbolic mathematics as a means to deepen your under-\\nstanding in both Python and calculus. If you are using Sympy in a Jupyter notebook\\nin Google Colab (e.g. https://colab.research.google.com/) then rendering\\nsympy equations requires MathJax to be available within each cell output. The follow-\\ning is a hook function that will make this possible:\\nCODE 5.2: Sympy in Google Colab\\n1 from IPython.display import Math, HTML\\n2 def enable_sympy_in_cell():\\n3 display(HTML(\"<script\\nsrc=\\'https://cdnjs.cloudflare.com/ajax/libs/\"↪→\\n4 \"mathjax/2.7.3/latest.js?config=default\\'>\\n5 </script>\"))\\n6 get_ipython().events.register(\\'pre_run_cell\\' ,\\nenable_sympy_in_cell)↪→\\nAfter successfully registering this hook, SymPy rendering ( 5.3) will work correctly:\\nCODE 5.3: Rendering Sympy in Google Colab\\n1 import sympy\\n2 from sympy import *\\n3 init_printing()\\n4 x, y, z = symbols(\\'x y z\\' )\\n5 Integral(sqrt(1/x), (x, 0, oo))\\n143'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 160, 'page_label': '161'}, page_content='5.2. PROBLEMS\\nIt is also recommended to use the latest version of Sympy:\\nCODE 5.4: Updating Sympy\\n> pip install --upgrade sympy\\n5.2.17 Simple differentiation\\nPRB-132 \\uf059 CH.PRB- 5.33.\\nAnswer the following questions:\\n1. Which differentiation method is inherently prone to rounding errors?\\n2. Deﬁne the term symbolic differentiation.\\nPRB-133 \\uf059 CH.PRB- 5.34.\\nAnswer the following questions:\\n1. Implement the sigmoid function σ(x) = 1\\n1+e−x symbolically using a Python based\\nSymPy program.\\n2. Differentiate the sigmoid function using SymPy and compare it with the analytical\\nderivation σ′(x) = σ(x)(1 − σ(x)).\\n3. Using SymPy, evaluate the gradient of the sigmoid function at x = 0.\\n4. Using SymPy, plot the resulting gradient of the sigmoid function.\\n5.2.18 The Beta-Binomial model\\nPRB-134 \\uf059 CH.PRB- 5.35.\\n144'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 161, 'page_label': '162'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nY ou will most likely not be given such a long programming task during a face-to-face\\ninterview. Nevertheless, an extensive home programming assignment is typically given at\\nmany of the start-ups I am familiar with. Y ou should allocate around approximately four to\\nsix hours to completely answer all questions in this problem.\\nWe discussed the Beta-Binomial model extensively in chapter 3. Recall that the Beta-\\nBinomial distribution is frequently used in Bayesian statistics to model the number of suc-\\ncesses in n trials. We now employ SymPy to do the same; demonstrate computationally how\\na prior distribution is updated to develop into a posterior distribution after observing the\\ndata via the relationship of the Beta-Binomial distribution.\\nProvided the probability of success, the number of successes after n trials follows a bino-\\nmial distribution. Note that the beta distribution is a conjugate prior for the parameter of\\nthe binomial distribution. In this case, the likelihood function is binomial, and a beta prior\\ndistribution yields a beta posterior distribution.\\nRecall that for the Beta-Binomial distribution the following relationships exist:\\nPrior of θ Beta(a,b)\\nLikelihood binomial (n, θ)\\nPosterior of θ Beta (a + x, b + n − x)\\nPosterior Mean (a + x)/(a + b + n − x)\\n(5.27)\\n1. Likelihood: The starting point for our inference problem is the Likelihood, the prob-\\nability of the observed data. Find the Likelihood function symbolically using sympy.\\nConvert the SymPy representation to a purely Numpy based callable function with a\\nLambda expression. Evaluate the Likelihood function at θ = 0 .5 with 50 successful\\ntrials out of 100.\\n2. Prior: The Beta Distribution. Deﬁne the Beta distribution which will act as our prior\\ndistribution symbolically using sympy. Convert the SymPy representation to a purely\\nNumpy based callable function. Evaluate the Beta Distribution at θ : 0.5, a : 2, b : 7\\n3. Plot the Beta distribution, using the Numpy based function.\\n4. Posterior: Find the posterior distribution by multiplying our Beta prior by the Bi-\\nnomial Likelihood symbolically using sympy. Convert the SymPy representation to\\n145'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 162, 'page_label': '163'}, page_content='5.3. SOLUTIONS\\na purely Numpy based callable function. Evaluate the Posterior Distribution at θ :\\n0.5, a : 2, b : 7\\n5. Plot the posterior distribution, using the Numpy based function.\\n6. Show that the posterior distribution has the same functional dependence on θ as the\\nprior, and it is just another Beta distribution.\\n7. Given:\\nPrior : Beta(θ|a = 2, b = 7) = 56 θ (−θ + 1)6 and:\\nLikelihood : Bin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47 ﬁnd the resulting posterior\\ndistribution and plot it.\\n5.3 Solutions\\n5.3.1 Algorithmic differentiation, Gradient descent\\n5.3.2 Numerical differentiation\\nSOL-100 \\uf14b CH.SOL- 5.1.\\n1. The formulae is:\\nf ′(x) ≈ f (x + h) − f (x)\\nh . (5.28)\\n2. The main problem with this formulae is that it suffers from numerical instability for\\nsmall values of h.\\n3. In some numerical software systems, the number\\n√\\n2 may be represented as the a ﬂoat-\\ning point number ≈ 1.414213562. Therefore, the result of:\\nf loat\\n( √\\n(2)\\n)\\n∗ f loat\\n( √\\n(2)\\n)\\nmay equal ≈ 2.000000446.\\n\\x04\\nSOL-101 \\uf14b CH.SOL- 5.2.\\n146'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 163, 'page_label': '164'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The instantaneous rate of change equals:\\nlim\\nh→0\\nf (a + h) − f (a)\\na + h − a . (5.29)\\n2. The instantaneous rate of change of f (x) at a is also commonly known as the tangent\\nline of f (x) at a.\\n3. Given a function f (x) and a point a, the tangent (Fig. 5.12) line of f (x) at a is a line\\nthat touches f (a) but does not cross f (x) (sufﬁciently close to a).\\nFIGURE 5.12: A Tangent line\\n\\x04\\n5.3.3 Directed Acyclic Graphs\\nSOL-102 \\uf14b CH.SOL- 5.3.\\n147'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 164, 'page_label': '165'}, page_content='5.3. SOLUTIONS\\n1. The deﬁnition is:\\nf ′(c) = lim\\nh→0\\nf (c + h) − f (c)\\nh .\\n2. If we traverse the graph 5.3 from left to right we derive the following function:\\ng(x) = 1√x . (5.30)\\nf ′(9) = lim\\nh→0\\n1/\\n√\\n9 + h − 1/\\n√\\n9\\nh\\n= lim\\nh→0\\n√\\n9 −\\n√\\n9 + h√\\n9 ·\\n√\\n9 + h · h\\n= lim\\nh→0\\n(3 −\\n√\\n9 + h)(3 +\\n√\\n9 + h)\\n3\\n√\\n9 + h · (3 +\\n√\\n9 + h) · h\\n= lim\\nh→0\\n9 − (9 + h)\\n9\\n√\\n9 + h · h + 3 · (9 + h) · h\\n= − 1\\n9 · 3 + 3 · 9\\n= − 1\\n54\\n\\x04\\nSOL-103 \\uf14b CH.SOL- 5.4.\\n1. The function g(x) = 2 x2 − x + 1 represents the expression graph depicted in 5.4.\\n148'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 165, 'page_label': '166'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. By the deﬁnition:\\nf ′(x) = lim\\nh→0\\nf (x + h) − f (x)\\nx + h − x\\n= lim\\nh→0\\n2(x + h)2 − (x + h) + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2(x2 + 2xh + h2) − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2x2 + 4xh + 2h2 − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n4xh + 2h2 − h\\nh\\n= lim\\nh→0\\n4x + 2h − 1\\n= 4x − 1.\\n(5.31)\\nf (x) = 2 x2 − x + 1\\nf ′(x) = 4 x − 1\\n\\x04\\n5.3.4 The chain rule\\nSOL-104 \\uf14b CH.SOL- 5.5.\\n1. The chain rule states that the partial derivative of E = E(x, y) with respect to x can be\\ncalculated via another variable y = y(x), as follows:\\n∂E\\n∂x = ∂E\\n∂y · ∂y\\n∂x (5.32)\\n2. For instance, the chain rule [ 8] is applied in neural networks to calculate the change in\\n149'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 166, 'page_label': '167'}, page_content='5.3. SOLUTIONS\\nits weights resulting from tuning the cost function. This derivative is calculated via a\\nchain of partial derivatives (e.g. of the activation functions).\\n\\x04\\n5.3.5 Taylor series expansion\\nSOL-105 \\uf14b CH.SOL- 5.6.\\n1.\\n1\\n1 − x =\\n∞∑\\nn=0\\nxn = 1 + x + x2 + x3\\n(when −1 < x < 1) (5.33)\\n2.\\nex =\\n∞∑\\nn=0\\nxn\\nn! = 1 + x + x2\\n2! + x3\\n3! + · · · (5.34)\\n3.\\nsin x =\\n∞∑\\nn=0\\n(−1)n\\n(2n + 1)! x2n+1 = x − x3\\n3! + x5\\n5! − · · · (5.35)\\n4.\\ncos x =\\n∞∑\\nn=0\\n(−1)n\\n(2n)! x2n = 1 − x2\\n2! + x4\\n4! − · · · (5.36)\\n\\x04\\nSOL-106 \\uf14b CH.SOL- 5.7.\\n150'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 167, 'page_label': '168'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nlog x =\\n∞∑\\nn=1\\n(−1)n+1 (x − 1)n\\nn = (x − 1) − (x − 1)2\\n2 +\\n(x − 1)3\\n3 − (x − 1)4\\n4 + · · ·\\n(5.37)\\n\\x04\\nSOL-107 \\uf14b CH.SOL- 5.8.\\nIn this case, all derivatives can be computed:\\nf 0(x) = 5 x2 − 11x + 1,\\nf 0(−3) = 79 ,\\nf 1(x) = 10 x − 11,\\nf 1(−3) = −41,\\nf 2(x) = 10 ,\\nf 2(−3) = 10 ,\\nf n(x) = 0, ∀n ≥ 3.\\n(5.38)\\n\\x04\\nSOL-108 \\uf14b CH.SOL- 5.9.\\nThe immediate answer is 1. Refer to eq. 5.36 to verify this logical consequence. \\x04\\nSOL-109 \\uf14b CH.SOL- 5.10.\\nBy employing eq. 5.37, one can substitute x by 3 − x and generate the ﬁrst 7 terms of the\\nx-dependable outcome before assigning the point x = 1.\\n\\x04\\n5.3.6 Limits and continuity\\nSOL-110 \\uf14b CH.SOL- 5.11.\\n151'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 168, 'page_label': '169'}, page_content='5.3. SOLUTIONS\\n1. With an indeterminate form 0/0, L’Hopital’s rule holds. We look at\\nlim\\nx→3\\n3x2ex3\\n3 = 9e27,\\nwhich equals to the original limit.\\n2. Again, we yield 0/0 at interim, so we look at the ﬁrst order derivative\\nlim\\nx→0\\n2xex − 1\\n−3 sin x − 1 = 1.\\nThe original limit is also equal to 1.\\n3. This time, the intermediate form is of ∞/∞ and L’Hopital applies as well. The quotient\\nof the derivatives is\\n1 − 1\\nx\\n0.01x−99/100 = 100(x − 1)x1/99\\nAs x → ∞, this goes to ∞, so the original limit is equal to ∞ also.\\n\\x04\\n5.3.7 Partial derivatives\\nSOL-111 \\uf14b CH.SOL- 5.12.\\n1. T rue.\\n2. By treating y as constant, one can derive that\\n∂g\\n∂x = 2xy + y. (5.39)\\n\\x04\\nSOL-112 \\uf14b CH.SOL- 5.13.\\n152'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 169, 'page_label': '170'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1.\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j\\n=\\n(\\ny2 + 3x2\\n)\\ni + (2xy − 2y) j\\n(5.40)\\n2. It can be shown that ∇g(x, y) = (2 xy + y2) i + (x2 + 2xy − 1) j at (−1, 0) equals\\n(0, 0). According to the deﬁnition of directional derivative:\\n(0, 0) · (1, 1)\\n|(1, 1)| = 0 (5.41)\\n\\x04\\nSOL-113 \\uf14b CH.SOL- 5.14.\\n∂f\\n∂x = 6 sin(x − y) cos(x − y)\\n∂f\\n∂y = −6 sin(x − y) cos(x − y)\\n(5.42)\\n\\x04\\nSOL-114 \\uf14b CH.SOL- 5.15.\\n∂z\\n∂x = 2 cos x sin y\\n∂z\\n∂y = 2 sin x cos y\\n(5.43)\\n\\x04\\n5.3.8 Optimization\\nSOL-115 \\uf14b CH.SOL- 5.16.\\n153'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 170, 'page_label': '171'}, page_content='5.3. SOLUTIONS\\n1. The function is only deﬁned where x ̸= −2, in the domain of:\\n(−∞, −2) ∪ (−2, +∞).\\n2. By a simple quotient-based derivation:\\nf ′(x) = 2(x + 2)(2x − 1)\\n(x + 2)4 . (5.44)\\nNamely, expect for the ill-deﬁned x = −2, the critical point of x = 0 .5 should be\\nconsidered. For x > 0.5, the derivative is positive and the function increases, in contrast\\nto x < 0.5.\\n3. The requested coordinate is (0.5, 0.2).\\n\\x04\\nSOL-116 \\uf14b CH.SOL- 5.17.\\n1. f ′(x) = 6 x2 − 1, which entails the behavior of the function changes around the points\\nx = ± 1√\\n6. The derivative is negative between x = − 1√\\n6 and x = 1√\\n6, i.e., it decreases\\nin the domain, and increases otherwise.\\n2. The second derivative is f ′′(x) = 12 x, which means the function is concave for negative\\nx values and convex otherwise.\\n\\x04\\nSOL-117 \\uf14b CH.SOL- 5.18.\\nThe function should be derived according to each variable separately and be equated to 0,\\nas follows:\\nfx(x, y) = 4 x − y = 0 , f y(x, y) = −y + 2y = 0 .\\nSo, the solution to these equations yield the coordinate (0, 0), and f (0, 0) = 0 .\\nLet us derive the second order derivative, as follows:\\n∂2f\\n∂x2 (x, y) = 4 , ∂2f\\n∂y2 (x, y) = 2 , ∂2f\\n∂x∂y (x, y) = −1 ,\\n154'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 171, 'page_label': '172'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nAlso, the following relation exists:\\nD(x, y) = ∂2f\\n∂x2\\n∂2f\\n∂y2 −\\n(\\n∂2f\\n∂x∂y\\n) 2\\n= 7 ,\\nThus, the critical point (0, 0) is a minimum. \\x04\\n5.3.9 The Gradient descent algorithm\\nSOL-118 \\uf14b CH.SOL- 5.19.\\n1. It is the gradient of a function which is mathematically represented by:\\n∇f (x, y) =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\n∂f (x,y)\\n∂x\\n∂f (x,y)\\n∂y\\n\\uf8f6\\n\\uf8f7\\uf8f8 (5.45)\\n2. Increasing.\\n3. We will keep jumping between the same two points without ever reaching a minima.\\n4. This phenomena can be alleviated by using a learning rate or step size . For instance,\\nx+ = 2 ∗ η where η is a learning rate with small value such as η = 0.25.\\n5. T rue.\\n\\x04\\nSOL-119 \\uf14b CH.SOL- 5.20.\\n1. The point (12,12) has two classes, so the classes cannot be separated by any line.\\n2.\\nJ(θ) = 1\\n2m\\nm∑\\ni=1\\n(ˆyi − yi)2\\n(5.46)\\n155'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 172, 'page_label': '173'}, page_content='5.3. SOLUTIONS\\n3. Simple but fundamental algorithm for minimizing f . Just repeatedly move in the direc-\\ntion of the negative gradient\\n(a) Start with initial guess θ(0), step size η\\n(b) For k = 1, 2, 3, . . .:\\ni. Compute the gradient ∇f (θ(k−1))\\nii. Check if gradient is close to zero; is so stop, otherwise continue\\niii. Update θ(k) = θ(k−1) − η∇f (θ(k−1))\\n(c) Return ﬁnal θ(k) as approximate solution θ∗\\n\\x04\\n5.3.10 The Backpropagation algorithm\\nSOL-120 \\uf14b CH.SOL- 5.21.\\n1. The annotated parts of equation (5.21) appear in (5.47):\\nσ(x) = ex\\n1 + ex = The Sigmoid activation function\\nσ(x) ·\\n(\\n1 − σ(x)\\n)\\nThe deriviative of the Sigmoid activation function =\\n1Z = The input\\ndZ = The error introduced by input Z.\\nA = The output\\ndA = The error introduced by output A.\\n(5.47)\\n2. Code snippet 5.13 provides an implementation of both the forward and backward passes\\nfor the sigmoid function.\\n156'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 173, 'page_label': '174'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5\\n6 def backward(self, grad):\\n7 grad_input = self.x*(1-self.x) * grad\\n8 return grad_input\\nFIGURE 5.13: Forward and backward passes for the sigmoid activation function in pure\\nPython.\\n\\x04\\nSOL-121 \\uf14b CH.SOL- 5.22.\\nThe key concept in this question is merely understanding that the transfer function and\\nits derivatives are changing compared to traditional activation functions, namely:\\n∂E\\n∂yk\\n= (yk − dk) (5.48)\\n∂E\\n∂netk\\n= ∂E\\n∂yk\\n· ∂yk\\n∂netk\\n= (yk − dk) · 2 cos(2netk) (5.49)\\n∆wjk = −η ∂E\\n∂wjk\\n= −η ∂E\\n∂netk\\n· ∂netk\\n∂wjk\\n= −η · (yk − dk) · 2 cos(2netk) · yj (5.50)\\n∂E\\n∂yj\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\n· ∂netk\\n∂yj\\n)\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\nwjk\\n)\\n(5.51)\\n∂E\\n∂netj\\n= ∂E\\n∂yj\\n· ∂yj\\n∂netj\\n= ∂E\\n∂yj\\n· 3net2\\nj (5.52)\\n157'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 174, 'page_label': '175'}, page_content='5.3. SOLUTIONS\\n∆wij = −η ∂E\\n∂wij\\n= −η ∂E\\n∂netj\\n· ∂netj\\n∂wij\\n= −η · (∑\\nk [(yk − dk) · 2 cos(2netk) · wjk]) · 3net2\\nj · yi\\n(5.53)\\n\\x04\\n5.3.11 Feed forward neural networks\\n5.3.12 Activation functions, Autograd/JAX\\nSOL-122 \\uf14b CH.SOL- 5.23.\\n1. T rue.\\n2. T rue.\\n\\x04\\nSOL-123 \\uf14b CH.SOL- 5.24.\\nThe answers are as follows:\\n1. hΘ(x) = g(ΘT x) = 1\\n1+e−Θ\\nT\\nx\\n.\\n2. The decision boundary for the logistic sigmoid function is where hΘ(x) = 0 .5 (values\\nless than 0.5 mean false, values equal to or more than 0.5 mean true).\\n3. That there is a 80% chance that the instance is of the corresponding class, therefore:\\n• hΘ(x) = g(Θ0 + Θ1x1 + Θ2x2). We can predict y = 1 if x0 + x1 + x2 ≥ 0.\\n4. The code snippet in 5.14 implements the function using Autograd.\\n158'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 175, 'page_label': '176'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 from torch.autograd import Function\\n2 class Sigmoid(Function):\\n3 @staticmethod\\n4 def forward(ctx, x):\\n5 output = 1 / (1 + torch.exp(-x))\\n6 ctx.save_for_backward(output)\\n7 return output\\n8\\n9 @staticmethod\\n10 def backward(ctx, grad_output):\\n11 output, = ctx.saved_tensors\\n12 grad_x = output * (1 - output) * grad_output\\n13 return grad_x\\nFIGURE 5.14: Forward and backward for the sigmoid function in Autograd.\\n5. The code snippet in 5.15 implements the function using Autograd.\\n159'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 176, 'page_label': '177'}, page_content='5.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ReLU(torch.autograd.Function):\\n3 @staticmethod\\n4 def forward(ctx, input):\\n5 ctx.save_for_backward(input)\\n6 return input.clamp(min=0)\\n7\\n8 @staticmethod\\n9 def backward(ctx, grad_output):\\n10 input, = ctx.saved_tensors\\n11 grad_input = grad_output.clone()\\n12 grad_input[input < 0] = 0\\n13 return grad_input\\nFIGURE 5.15: Forward and backward for the ReLU function in Autograd.\\n\\x04\\nSOL-124 \\uf14b CH.SOL- 5.25. The answers are as follows:\\n1. Code snippet 5.16 implements the forward pass using pure Python.\\n160'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 177, 'page_label': '178'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n3 requires_grad=True)).type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 arctanh_values = np.arctanh(xT_np)\\n7 print (\"Numpy:\", arctanh_values)\\n8 > Numpy: [[ 0.38842311 0.1944129 0.64900533]]\\nFIGURE 5.16: Forward pass for equation ( 5.23) using pure Python.\\n2. Code snippet 5.17 implements the forward pass using Autograd.\\n1 import torch\\n2 from torch.autograd import Function\\n3 class ArtanhFunction(Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward(x)\\n7 r = (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5)\\n8 return r\\nFIGURE 5.17: Forward pass for equation ( 5.23).\\n3. Code snippet 5.18 implements the backward pass using Autograd.\\n161'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 178, 'page_label': '179'}, page_content='5.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ArtanhFunction(Function):\\n3 @staticmethod\\n4 input, = ctx.saved_tensors\\n5 out= grad_output / (1 - input ** 2)\\n6 print (\"backward:{}\".format(out))\\n7 return out\\nFIGURE 5.18: Backward pass for equation ( 5.23).\\n4. Code snippet 5.19 veriﬁes the correctness of the implementation using gradcheck.\\n1 import numpy as np\\n2\\n3 xT =\\ntorch.abs(torch.tensor([[0.11,0.19,0.57]],requires_grad=True))↪→\\n4 .type(torch.DoubleTensor)\\n5 arctanh_values_torch = arctanhPyTorch(xT)\\n6 print (\"Torch:\", arctanh_values_torch)\\n7 from torch.autograd import gradcheck, Variable\\n8 f = ArtanhFunction.apply\\n9 test=gradcheck(lambda t: f(t), xT)\\n10 print(test)\\n11\\n12 > PyTorch version: 1.7.0\\n13 > Torch: tensor([[ 0.3884, 0.1944, 0.6490]], dtype =torch.float64,\\n14 > grad_fn=<ArtanhFunctionBackward>)\\n15 > backward:tensor([[1.1586, 1.0383,1.4838]], dtype =torch.float64,\\n16 grad_fn=<CopyBackwards>)\\nFIGURE 5.19: Invoking arctanh using gradcheck\\n162'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 179, 'page_label': '180'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n\\x04\\n5.3.13 Dual numbers in AD\\nSOL-125 \\uf14b CH.SOL- 5.26.\\nThe answers are as follows:\\n1. The procedure of AD is to use verbatim text of a computer program which calculates\\na numerical value and to transform it into the text of a computer program called the\\ntransformed program which calculates the desired derivative values. The transformed\\ncomputer program carries out these derivative calculations by repeated use of the chain\\nrule however applied to actual ﬂoating point values rather than to a symbolic rep-\\nresentation.\\n2. Dual numbers extend all numbers by adding a second component x ↦→ x + ˙xd where\\nx + ˙x is the dual part.\\n3. The following arithmetic operations are possible on DN:\\n(a) d2 = 0\\n(b) (x + ˙xd) + (y + ˙yd) = x + y + ( ˙x + ˙y)d\\n(c) −(x + ˙xd) = −x − ˙xd\\n(d) 1\\nx+ ˙xd = 1\\nx − ˙x\\nx2 d\\n4. For f (x + ˙xd) the T aylor series expansion is:\\nf (x + ˙xd) = f (x) + f ′(x)\\n1! ˙xd + . . .0 (5.54)\\nThe immediate and important result is that all higher-order terms (n >= 2) disappear\\nwhich provides closed-form mathematical expression that represents a function and its\\nderivative.\\n\\x04\\nSOL-126 \\uf14b CH.SOL- 5.27.\\n163'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 180, 'page_label': '181'}, page_content='5.3. SOLUTIONS\\nThe answers are as follows:\\n1.\\nsin(x + ˙xd) = sin( x) + cos(x) ˙xd (5.55)\\n2. If we traverse the graph 5.9 from left to right we drive the following simple function:\\ng(x) = 3 ∗ x + 2 (5.56)\\n3. We know that:\\ng(x) = 3 ∗ x + 2 (5.57)\\ng′(x) = 3 (5.58)\\nNow if we expand the function using DN:\\ng(x + ˙xd) = 3 ∗ (x + ˙xd) + 2 = (5.59)\\n3 ∗ x + 3 ∗ ( ˙xd) + 2 (5.60)\\nRearranging:\\n3 ∗ x + 2 + 3 ∗ ( ˙xd) (5.61)\\nBut since g(x) = 3 ∗ x + 2 then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.62)\\n4. Evaluating the function g(x) at x = 2 using DN we get:\\ng(x = 2) = (3 ∗ 2 + 2) + (3) ˙xd = (5.63)\\n8 + (3) ˙xd (5.64)\\n5. The code snippet in 5.20 implements the function using Autograd.\\n164'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 181, 'page_label': '182'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([2.0], dtype =float)\\n4 def f1(x):\\n5 return 3*x + 2\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 8.0\\n8 print(grad_f1(x)) # > 3.0\\nFIGURE 5.20: Autograd\\n\\x04\\nSOL-127 \\uf14b CH.SOL- 5.28. The answers are as follows:\\n1. If we traverse the graph 5.9 from left to right we drive the following function:\\ng(x) = 5 ∗ x2 + 4 ∗ x + 1 (5.65)\\n2. We know that:\\ng(x1) = 5 ∗ x2 + 4 ∗ x + 1 (5.66)\\ng′(x1) = 10 ∗ x1 + 4 (5.67)\\nNow if we expand the function using DN we get:\\ng(x + ˙xd) = 5 ∗ (x + ˙xd)2 + 4 ∗ (x + ˙xd) + 1 = (5.68)\\n5 ∗ (x2 + 2 ∗ x + ˙xd + ( ˙xd)2) + 4 ∗ x + 4 ∗ ( ˙xd) + 1 (5.69)\\n165'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 182, 'page_label': '183'}, page_content='5.3. SOLUTIONS\\nHowever by deﬁnition (d2) = 0 and therefore that term vanishes. Rearranging the\\nterms:\\n(5 ∗ x2 + 4 ∗ x + 1) + (10 ∗ x + 4) ˙xd (5.70)\\nBut since g(x) = (5 ∗ x2 + 4 ∗ x + 1) then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.71)\\n3. Evaluating the function g(x) at x = 5 using DN we get:\\ng(x = 4) = (5 ∗ 52 + 4 ∗ 5 + 1) + (10 ∗ 5 + 4) ˙xd =\\n146 + (54) ˙xd (5.72)\\n4. The code snippet in 5.21 implements the function using Autograd.\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([5.0], dtype =float)\\n4 def f1(x):\\n5 return 5*x**2 + 4*x +1\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 146.0\\n8 print(grad_f1(x)) # > 54.0\\nFIGURE 5.21: Autograd\\n\\x04\\n5.3.14 Forward mode AD\\nSOL-128 \\uf14b CH.SOL- 5.29.\\nThe answers are as follows:\\n166'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 183, 'page_label': '184'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The function g(x) represented by the expression graph in 5.11 is:\\ng(x) = A + B ∗ ln(C) (5.73)\\n2. For a logarithmic function:\\nd\\ndx ln(x) = 1\\nx (5.74)\\nTherefore, the partial derivatives for the function g(x) are:\\n∂f\\n∂A = 1\\n∂f\\n∂B = ln(C)\\n∂f\\n∂C = B ∗ 1\\nC\\n(5.75)\\n\\x04\\nSOL-129 \\uf14b CH.SOL- 5.30. The answers are as follows:\\n1. T rue. Both directions yield the exact same results.\\n2. T rue. Reverse mode is more efﬁcient than forward mode AD (why?).\\n3. T rue.\\n4. T rue.\\n\\x04\\nSOL-130 \\uf14b CH.SOL- 5.31.\\nThe answers are as follows:\\n167'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 184, 'page_label': '185'}, page_content='5.3. SOLUTIONS\\n1. The function is\\nf (x1, x2) = x1x2 + ln (x1) (5.76)\\n2. The graph associated with the forward mode AD is as follows:\\nx1\\nx2\\n*\\n+\\nln\\nf (x1, x2)\\nFIGURE 5.22: A Computation graph for g(x1, x2) in 5.1\\n3. The partial derivatives are:\\n∂f\\n∂x1\\n= x2 − 1\\n(x1)\\n∂f\\n∂x2\\n= x1\\n(5.77)\\n\\x04\\n5.3.15 Forward mode AD table construction\\nSOL-131 \\uf14b CH.SOL- 5.32.\\nThe answers are as follows:\\n1. The graph with the intermediate values is depicted in ( 5.23)\\n168'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 185, 'page_label': '186'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx1\\nx2\\n*\\n+\\nln\\ng(x1, x2)\\nv1\\nv2\\nv1 v4\\nv3\\nv5\\nFIGURE 5.23: A derivative graph for g(x1, x2) in 5.1\\n2. Forward mode AD for g (x1, x2) = ln ( x1) + x1x2 evaluated at (x1, x2) = ( e2, π).\\nForward-mode function evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\nv1 = ln v−1 = ln (e2) = 2\\nv2 = v−1 × v0 = e2 × π = 23.2134\\nv3 = v1 + v2 2 + 23.2134 = 25 .2134\\nf = v3 =≈ 25.2134\\nTABLE 5.1: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n3. The following Python code ( 5.24) proves that the numerical results are correct:\\n169'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 186, 'page_label': '187'}, page_content='5.3. SOLUTIONS\\n1 import math\\n2 print (math.log(math.e*math.e) + math.e*math.e*math.pi)\\n3 > 25.2134^^I\\nFIGURE 5.24: Python code- AD of the function g(x1, x2)\\n4. Seed values indicate the values by which the dependent and independent variables are\\ninitialized to before being propagated in a computation graph. For instance:\\n˙v1 = ∂x1\\n∂x1\\n= 1\\n˙v2 = ∂x2\\n∂x1\\n= 0\\nTherefore we set ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n5. Here we construct a table for the forward-mode AD for the derivative of f (x1, x2) =\\nln (x1) + x1x2 evaluated at (x1, x2) = ( e2, π) while setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.. In\\nforward-mode AD a derivative is called a tangent.\\nIn the derivation that follows, note that mathematically using manual differentiation:\\nd\\ndx1\\n[ln(x) + x2x]\\n= d\\ndx1\\n[ln(x1)] + x2 · d\\ndx1\\n[x1]\\n= 1\\nx1\\n+ x2 · 1\\n= 1\\nx1\\n+ x2\\nand also since d\\ndx ln(x) = 1\\nx then ˙v1 = 1\\nv−1\\n∗ ˙v−1 = ˙v−1/v−1 = 1\\ne2 ∗ 1 = 1 /e2.\\n170'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 187, 'page_label': '188'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nForward-mode AD derivative evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\n˙v−1 = ˙x1 = 1\\n˙v0 = ˙x2 = 0\\n˙v1 = ˙v−1/v−1 = 1/e2\\n˙v2 = ˙v−1 × v0 + ˙v0 ×\\nv−1 = 1 × π + 0 ×\\ne2 = π\\n˙v4 = ˙v1 + ˙v2 = 1/e2 +\\nπ\\n˙f = ˙v4 = 1 /e2 +\\nπ =≈ 3.2769\\nTABLE 5.3: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute ∂y\\n∂x1\\n.\\n6. The following Python code ( 5.25) proves that the numerical results are correct:\\n171'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 188, 'page_label': '189'}, page_content='5.3. SOLUTIONS\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 import math\\n4\\n5 x1 = math.e* math.e\\n6 x2 = math.pi\\n7\\n8 def f1(x1,x2):\\n9 return (np.log(x1) + x1*x2)\\n10\\n11 grad_f1 = grad(f1)\\n12\\n13 print(f1(x1,x2)) # > 25.2134\\n14 print(grad_f1(x1,x2)) # > 3.2769\\nFIGURE 5.25: Python code- AD of the function g(x1, x2)\\n\\x04\\n5.3.16 Symbolic differentiation\\n5.3.17 Simple differentiation\\nSOL-132 \\uf14b CH.SOL- 5.33.\\nThe answers are as follows:\\n1. Approximate methods such as numerical differentiation suffer from numerical instabil-\\nity and truncation errors.\\n2. In symbolic differentiation, a symbolic expression for the derivative of a function is\\ncalculated. This approach is quite slow and requires symbols parsing and manipulation.\\nFor example, the number\\n√\\n2 is represented in SymPy as the object Pow(2,1/2). Since\\nSymPy employees exact representations Pow(2,1/2)*Pow(2,1/2) will always equal 2.\\n\\x04\\n172'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 189, 'page_label': '190'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nSOL-133 \\uf14b CH.SOL- 5.34.\\n1. First:\\n1 import sympy\\n2 sympy.init_printing()\\n3 from sympy import Symbol\\n4 from sympy import diff, exp, sin, sqrt\\n5 y = Symbol(\\'y\\' )\\n6 y = sympy.Symbol(\"y\")\\n7 sigmoid = 1/(1+sympy.exp(-y))^^I\\nFIGURE 5.26: Sigmoid in SymPy\\n2. Second:\\n1 sig_der=sym.diff(sigmoid, y)\\nFIGURE 5.27: Sigmoid gradient in SymPy\\n3. Third:\\n1 sig_der.evalf(subs={y:0})\\n2 > 0.25\\nFIGURE 5.28: Sigmoid gradient in SymPy\\n173'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 190, 'page_label': '191'}, page_content='5.3. SOLUTIONS\\n4. The plot is depicted in 5.29.\\n1 p = sym.plot(sig_der);\\n10.0\\n 7.5\\n 5.0\\n 2.5\\n 0.0 2.5 5.0 7.5 10.0\\ny\\n0.00\\n0.05\\n0.10\\n0.15\\n0.20\\n0.25f(y)\\nFIGURE 5.29: SymPy gradient of the Sigmoid() function\\n\\x04\\n5.3.18 The Beta-Binomial model\\nSOL-134 \\uf14b CH.SOL- 5.35.\\nT o correctly render the generated LaT eX in this problem, we import and conﬁgure several\\nlibraries as depicted in 5.30.\\n174'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 191, 'page_label': '192'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 import scipy.stats as st\\n3 import matplotlib.pyplot as plt\\n4 import sympy as sp\\n5 sp.interactive.printing.\\n6 init_printing(use_latex=True)\\n7 from IPython.display import display, Math, Latex\\n8 maths = lambda s: display(Math(s))\\n9 latex = lambda s: display(Latex(s)) ^^I\\nFIGURE 5.30: SymPy imports\\n1. The Likelihood function can be created as follows. Note the speciﬁc details of generating\\nthe Factorial function in SymPy.\\n175'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 192, 'page_label': '193'}, page_content='5.3. SOLUTIONS\\n1 n = sp.Symbol(\\'n\\' , integer =True, positive =True)\\n2 r = sp.Symbol(\\'r\\' , integer =True, positive =True)\\n3 theta = sp.Symbol(\\'theta\\' )\\n4 # Create the function symbolically\\n5 from sympy import factorial\\n6 cNkSym= (factorial(n))/ (factorial(r) *factorial(n-r))\\n7 cNkSym.evalf()\\n8 binomSym= cNkSym*((theta **r)*(1-theta)**(n-r))\\n9 binomSym.evalf()\\n10 #Convert it to a Numpy-callable function\\n11 binomLambda = sp.Lambda((theta,r,n), binomSym)\\n12 maths(r\"\\\\operatorname{Bin}(r|n,\\\\theta) = \" )\\n13 display (binomLambda .expr)\\n14 #Evaluating the SymPy version results in:\\n15 > binomSym.subs({theta:0.5,r:50,n:100})\\n16 #Evaluating the pure Numpy version results in:\\n17 > binomLambda(0.5,50,100)= 0.07958923\\nFIGURE 5.31: Likelihood function using SymPy\\nThe Symbolic representation results in the following LaT eX:\\nBin(r|n, θ) = θr (−θ + 1)n−r n!\\nr! (n − r)! (5.78)\\n2. The Beta distribution can be created as follows.\\n176'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 193, 'page_label': '194'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 #mu = sp.Symbol(\\'mu\\', integer=False, positive=True)\\n4 # Create the function symbolically\\n5 G = sp.gamma\\n6 # The normalisation factor\\n7 BetaNormSym = G(a + b)/(G(a)*G(b))\\n8 # The functional form\\n9 BetaFSym = theta**(a-1) * (1-theta)**(b-1)\\n10 BetaSym=BetaNormSym * BetaFSym\\n11 BetaSym.evalf() # this works\\n12 # Turn Beta into a function\\n13 BetaLambda = sp.Lambda((theta,a,b), BetaNormSym * BetaFSym)\\n14 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) = \" )\\n15 display(BetaSym)\\n16 #Evaluating the SymPy version results in:\\n17 > BetaLambda(0.5,2,7)=0.4375\\n18 #Evaluating the pure Numpy version results in:\\n19 > BetaSym.subs({theta:0.5,a:2,b:7})=0.4375\\nFIGURE 5.32: Beta distribution using SymPy\\nThe result is:\\nBeta(θ|a, b) = θa−1Γ(a + b)\\nΓ(a)Γ(b) (−θ + 1)b−1 (5.79)\\n3. The plot is depicted in 5.33.\\n177'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 194, 'page_label': '195'}, page_content='5.3. SOLUTIONS\\n1 %pylab inline\\n2 mus = arange(0,1,.01)\\n3 # Plot for various values of a and b\\n4 for ab in [(.1,.1),(.5,.5),(2,20),(2,3), ( 1,1)]:\\n5 plot(mus, vectorize(BetaLambda)(mus, *ab), label =\"a=%s b=%s\" % ab)\\n6 legend(loc=0)\\n7 xlabel(r\"$\\\\theta$\", size =22)\\nFIGURE 5.33: A plot of the Beta distribution\\n4. We can ﬁnd the posterior distribution by multiplying our Beta prior by the Binomial\\nLikelihood.\\n178'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 195, 'page_label': '196'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 BetaBinSym=BetaSym * binomSym\\n4 # Turn Beta-bin into a function\\n5 BetaBinLambda = sp.Lambda((theta,a,b,n,r), BetaBinSym)\\n6 BetaBinSym=BetaBinSym.powsimp()\\n7 display(BetaBinSym)\\n8 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) \\\\times\\n\\\\operatorname{Bin}(r|n,\\\\theta) \\\\propto %s\" %\\nsp.latex(BetaBinSym))\\n↪→\\n↪→\\n9 > BetaBinSym.subs({theta:0.5,a:2,b:7,n:10,r:3})= 0.051269\\n10 > BetaBinLambda ( 0.5,2,7, 10,3)= 0.051269\\nFIGURE 5.34: A plot of the Beta distribution\\nThe result is:\\nBeta(θ|a, b) × Bin(r|n, θ) ∝\\nθa+r−1 (−θ + 1)b+n−r−1 n!\\nr! (n − r)!Γ(a)Γ(b) Γ(a + b)\\nSo the posterior distribution has the same functional dependence on θ as the prior, it is\\njust another Beta distribution.\\n5. Mathematically, the relationship is as follows:\\n179'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 196, 'page_label': '197'}, page_content='5.3. SOLUTIONS\\nPrior :\\nBeta(θ|a = 2, b = 7)\\n= 56θ (−θ + 1)6\\nLikelihood :\\nBin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47\\nPosterior(normalised) :\\nBeta(θ|2, 7) × Bin(3|50, θ) = 1097600 θ4 (−θ + 1)53\\n(5.80)\\n180'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 197, 'page_label': '198'}, page_content='Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 prior = BetaLambda(theta,2,7)\\n2 maths(\"\\\\mathbf{Prior}:\\\\operatorname{Beta}(\\\\theta|a=2,b=7) = %s\" %\\nsp.latex(prior))↪→\\n3 likelihood = binomLambda(theta,3,50) # = binomLambda(0.5,3,10)\\n4 maths(\"\\\\mathbf{Likelihood}: \\\\operatorname{Bin}(r=3|n=6, \\\\theta) =\\n%s\" % sp.latex(likelihood))↪→\\n5 posterior = prior * likelihood\\n6 posterior=posterior.powsimp()\\n7 maths(r\"\\\\mathbf{Posterior\\n(normalised)}:\\\\operatorname{Beta}(\\\\theta|2,7) \\\\times\\n\\\\operatorname{Bin}(3|50,\\\\theta)=%s\"\\n↪→\\n↪→\\n8 posterior.subs({theta:0.5})\\n9 plt.plot(mus, (sp .lambdify(theta,posterior))(mus), \\'r\\' )\\n10 xlabel(\"$\\\\\\\\theta$\", size =22)\\nFIGURE 5.35: A plot of the Posterior with the provided data samples.\\n\\x04\\nReferences\\n[1] J. Bradbury et al. JAX: composable transformations of NumPy programs. 2018 (cit. on\\npp. 123, 136).\\n181'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 198, 'page_label': '199'}, page_content='REFERENCES\\n[2] W. K. Clifford. ‘Preliminary Sketch of Bi-quaternions’. In: Proceedings of the Lon-\\ndon Mathematical Society 4 (1873), pp. 381–95 (cit. on pp. 125, 139).\\n[3] R. Frostig et al. JAX: Autograd and XLA . 2018 (cit. on p. 123).\\n[4] A. Griewank, D. Juedes and J. Utke. ‘Algorithm 755; ADOL-C: a package for the\\nautomatic differentiation of algorithms written in C/C++’. In: ACM T ransactions\\non Mathematical Software 22.2 (June 1996), pp. 131–167 (cit. on pp. 123, 125).\\n[5] A. Griewank and A. Walther. Evaluating Derivatives: Principles and T echniques\\nof Algorithmic Differentiation . Second. USA: Society for Industrial and Applied\\nMathematics, 2008 (cit. on pp. 123, 124).\\n[6] K. Gurney. An Introduction to Neural Networks . 1 Gunpowder Square, London\\nEC4A 3DE, UK: UCL Press, 1998 (cit. on p. 135).\\n[7] L. V . Kantorovich. ‘On a mathematical symbolism convenient for performing\\nmachine calculations’. In: Dokl. Akad. Nauk SSSR . V ol. 113. 4. 1957, pp. 738–741\\n(cit. on p. 123).\\n[8] G. Kedem. ‘Automatic differentiation of computer programs’. In: ACM T ransac-\\ntions on Mathematical Software (TOMS) 6.2 (1980), pp. 150–165 (cit. on pp. 126,\\n149).\\n[9] S. Laue. On the Equivalence of Forward Mode Automatic Differentiation and Symbolic\\nDifferentiation. 2019. arXiv: 1904.02990 [cs.SC] (cit. on p. 124).\\n[10] D. Maclaurin, D. Duvenaud and R. P . Adams. ‘Autograd: Effortless gradients in\\nnumpy’. In: ICML 2015 AutoML Workshop . V ol. 238. 2015 (cit. on pp. 123, 136).\\n[11] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: (2017) (cit. on p. 136).\\n[12] D. Rumelhart, G. Hinton and R. Williams. ‘Learning representations by back\\npropagating errors’. In: Nature 323 (1986), pp. 533–536 (cit. on p. 135).\\n[13] B. Speelpenning. Compiling fast partial derivatives of functions given by algorithms .\\nTech. rep. Illinois Univ Urbana Dept of Computer Science, 1980 (cit. on p. 126).\\n182'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 199, 'page_label': '200'}, page_content='BACHELORS\\nPART IV'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 200, 'page_label': '201'}, page_content=''),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 201, 'page_label': '202'}, page_content='CHAPTER\\n6\\nDEEP LEARNING: NN ENSEMBLES\\nThe saddest aspect of life right now is that gathers knowledge faster than society\\ngathers wisdom.\\n— Isaac Asimov\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 202'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 202, 'page_label': '203'}, page_content='6.1. INTRODUCTION\\n6.1 Introduction\\nI\\nNtuition and practice demonstrate that a poor or an inferior choice may\\nbe altogether prevented merely by motivating a group (or an ensemble)\\nof people with diverse perspectives to make a mutually acceptable choice.\\nLikewise, in many cases, neural network ensembles signiﬁcantly improve\\nthe generalization ability of single-model based AI systems [ 5, 11]. Shortly follow-\\ning the foundation of Kaggle, research in the ﬁeld had started blooming; not only\\nbecause researchers are advocating and using advanced ensembling approaches in\\nalmost every competition, but also by the empirical success of the top winning mod-\\nels. Though the whole process of training ensembles typically involves the utilization\\nof dozens of GPUs and prolonged training periods, ensembling approaches enhance\\nthe predictive power of a single model. Though ensembling obviously has a signiﬁc-\\nant impact on the performance of AI systems in general, research shows its effect is\\nparticularly dramatic in the ﬁeld of neural networks [ Russakovsky_2015, 1, 4, 7, 13].\\nTherefore, while we could examine combinations of any type of learning algorithms,\\nthe focus of this chapter is the combination of neural networks.\\n6.2 Problems\\n6.2.1 Bagging, Boosting and Stacking\\nPRB-135 \\uf059 CH.PRB- 6.1.\\nMark all the approaches which can be utilized to boost a single model performance:\\n(i) Majority Voting\\n(ii) Using K-identical base-learning algorithms\\n(iii) Using K-different base-learning algorithms\\n(iv) Using K-different data-folds\\n(v) Using K-different random number seeds\\n(vi) A combination of all the above approaches\\n186'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 203, 'page_label': '204'}, page_content='Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nPRB-136 \\uf059 CH.PRB- 6.2.\\nAn argument erupts between two senior data-scientists regarding the choice of an ap-\\nproach for training of a very small medical corpus. One suggest that bagging is superior\\nwhile the other suggests stacking. Which technique, bagging or stacking, in your opinion is\\nsuperior? Explain in detail.\\n(i) Stacking since each classier is trained on all of the available data.\\n(ii) Bagging since we can combine as many classiﬁers as we want by training each on a\\ndifferent sub-set of the training corpus.\\nPRB-137 \\uf059 CH.PRB- 6.3.\\nComplete the sentence: A random forest is a type of a decision tree which utilizes [bag-\\nging/boosting]\\nPRB-138 \\uf059 CH.PRB- 6.4.\\nThe algorithm depicted in Fig. 6.1 was found in an old book about ensembling. Name the\\nalgorithm.\\n187'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 204, 'page_label': '205'}, page_content='6.2. PROBLEMS\\nAlgorithm 1: Algo 1\\nData: A set of training data, Q with N elements has been established\\nwhile K times do\\nCreate a random subset of N ′ data by sampling from Q containing the N\\nsamples;\\nN ′ < N ;\\nExecute algorithm Algo 2;\\nReturn all N ′ back to Q\\nAlgorithm 2: Algo 2\\nChoose a learner hm;\\nwhile K times do\\nPick a training set and train with hm;\\nFIGURE 6.1: A speciﬁc ensembling approach\\nPRB-139 \\uf059 CH.PRB- 6.5.\\nFig. 6.2 depicts a part of a speciﬁc ensembling approach applied to the models x1, x2...xk.\\nIn your opinion, which approach is being utilized?\\nGenerelizerx3\\nx2\\nx1\\n...\\nxk\\nBase Learners\\nf\\n?\\nFIGURE 6.2: A speciﬁc ensembling approach\\n(i) Bootstrap aggregation\\n(ii) Snapshot ensembling\\n(iii) Stacking\\n188'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 205, 'page_label': '206'}, page_content='Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n(iv) Classical committee machines\\nPRB-140 \\uf059 CH.PRB- 6.6.\\nConsider training corpus consisting of balls which are glued together as triangles, each\\nof which has either 1, 3, 6, 10, 15, 21, 28, 36, or 45 balls.\\n1. We draw several samples from this corpus as presented in Fig. 6.3 wherein each sample\\nis equiprobable. What type of sampling approach is being utilized here?\\nFIGURE 6.3: Sampling approaches\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n2. Two samples are drawn one after the other. In which of the following cases is the\\ncovariance between the two samples equals zero?\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n3. During training, the corpus sampled with replacement and is divided into several\\nfolds as presented in Fig. 6.4.\\nT1:\\nT2:\\nT3:\\nT4:\\nFIGURE 6.4: Sampling approaches\\n189'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 206, 'page_label': '207'}, page_content='6.2. PROBLEMS\\nIf 10 balls glued together is a sample event that we know is hard to correctly classify,\\nthen it is impossible that we are using:\\n(i) Bagging\\n(ii) Boosting\\n6.2.2 Approaches for Combining Predictors\\nPRB-141 \\uf059 CH.PRB- 6.7.\\nThere are several methods by which the outputs of base classiﬁers can be combined to\\nyield a single prediction. Fig. 6.5 depicts part of a speciﬁc ensembling approach applied to\\nseveral CNN model predictions for a labelled data-set. Which approach is being utilized?\\n(i) Majority voting for binary classiﬁcation\\n(ii) Weighted majority voting for binary classiﬁcation\\n(iii) Majority voting for class probabilities\\n(iv) Weighted majority class probabilities\\n(v) An algebraic weighted average for class probabilities\\n(vi) An adaptive weighted majority voting for combining multiple classiﬁers\\n190'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 207, 'page_label': '208'}, page_content=\"Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 l = []\\n2 for i,f in enumerate(filelist):\\n3 temp = pd.read_csv(f)\\n4 l.append(temp)\\n5 arr = np.stack(l,axis=-1)\\n6 avg_results = pd.DataFrame(arr[:,:-1,:].mean(axis=2))\\n7 avg_results['image' ] = l[0]['image' ]\\n8 avg_results.columns = l[0].columns\\nFIGURE 6.5: PyTorch code snippet for an ensemble\\nPRB-142 \\uf059 CH.PRB- 6.8.\\nRead the paper Neural Network Ensembles [3] and then complete the sentence: If the\\naverage error rate for a speciﬁc instance in the corpus is less than [...]% and the respective\\nclassiﬁers in the ensemble produce independent [...], then when the number of classiﬁers\\ncombined approaches inﬁnity, the expected error can be diminished to zero.\\nPRB-143 \\uf059 CH.PRB- 6.9.\\nTrue or false: A perfect ensemble comprises of highly correct classiﬁers that differ as\\nmuch as possible.\\nPRB-144 \\uf059 CH.PRB- 6.10.\\nTrue or false: In bagging, we re-sample the training corpus with replacement and there-\\nfore this may lead to some instances being represented numerous times while other instances\\nnot to be represented at all.\\n6.2.3 Monolithic and Heterogeneous Ensembling\\nPRB-145 \\uf059 CH.PRB- 6.11.\\n191\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 208, 'page_label': '209'}, page_content='6.2. PROBLEMS\\n1. True or false: T raining an ensemble of a single monolithic architecture results in\\nlower model diversity and possibly decreased model prediction accuracy.\\n2. True or false: The generalization accuracy of an ensemble increases with the number\\nof well-trained models it consists of.\\n3. True or false: Bootstrap aggregation (or bagging), refers to a process wherein a CNN\\nensemble is being trained using a random subset of the training corpus.\\n4. True or false: Bagging assumes that if the single predictors have independent errors,\\nthen a majority vote of their outputs should be better than the individual predictions.\\nPRB-146 \\uf059 CH.PRB- 6.12.\\nRefer to the papers: Dropout as a Bayesian Approximation [2] and Can Y ou Trust\\nY our Model’s Uncertainty? [12] and answer the following question: Do deep ensembles\\nachieve a better performance on out-of-distribution uncertainty benchmarks compared with\\nMonte-Carlo (MC)-dropout?\\nPRB-147 \\uf059 CH.PRB- 6.13.\\n1. In a transfer-learning experiment conducted by a researcher, a number of ImageNet-\\npretrained CNN classiﬁers, selected from T able 6.1 are trained on ﬁve different folds\\ndrawn from the same corpus. Their outputs are fused together producing a composite\\nmachine. Ensembles of these convolutional neural networks architectures have been\\nextensively studies an evaluated in various ensembling approaches [ 4, 9]. Is it likely\\nthat the composite machine will produce a prediction with higher accuracy than that\\nof any individual classiﬁer? Explain why.\\n192'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 209, 'page_label': '210'}, page_content='Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nCNN Model Classes Image Size Top-1 accuracy\\nResNet152 1000 224 78.428\\nDPN98 1000 224 79.224\\nSeNet154 1000 224 81.304\\nSeResneXT101 1000 224 80.236\\nDenseNet161 1000 224 77.560\\nInceptionV4 1000 299 80.062\\nTABLE 6.1: ImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches.\\n2. True or False: In a classiﬁcation task, the result of ensembling is always superior.\\n3. True or False: In an ensemble, we want differently trained models converge to differ-\\nent local minima.\\nPRB-148 \\uf059 CH.PRB- 6.14.\\nIn committee machines, mark all the combiners that do not make direct use of the input:\\n(i) A mixture of experts\\n(ii) Bagging\\n(iii) Ensemble averaging\\n(iv) Boosting\\nPRB-149 \\uf059 CH.PRB- 6.15.\\nTrue or False: Considering a binary classiﬁcation problem ( y = 0 or y = 1 ), ensemble\\naveraging, wherein the outputs of individual models are linearly combined to produce a fused\\noutput is a form of a static committee machine.\\n193'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 210, 'page_label': '211'}, page_content='6.2. PROBLEMS\\nMn\\nM2\\nM1\\n∑\\nwn\\nw2\\nw1\\n0\\n1\\n0\\n1\\nFIGURE 6.6: A typical binary classiﬁcation problem.\\nPRB-150 \\uf059 CH.PRB- 6.16.\\nTrue or false: When using a single model, the risk of overﬁtting the data increases when\\nthe number of adjustable parameters is large compared to cardinality (i.e., size of the set) of\\nthe training corpus.\\nPRB-151 \\uf059 CH.PRB- 6.17.\\nTrue or false:If we have a committee of K trained models and the errors are uncorrelated,\\nthen by averaging them the average error of a model is reduced by a factor of K.\\n6.2.4 Ensemble Learning\\nPRB-152 \\uf059 CH.PRB- 6.18.\\n1. Deﬁne ensemble learning in the context of machine learning.\\n2. Provide examples of ensemble methods in classical machine-learning.\\n3. True or false: Ensemble methods usually have stronger generalization ability.\\n4. Complete the sentence: Bagging is variance/bias reduction scheme while boosting\\nreduced variance/bias.\\n194'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 211, 'page_label': '212'}, page_content=\"Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n6.2.5 Snapshot Ensembling\\nPRB-153 \\uf059 CH.PRB- 6.19.\\nY our colleague, a well-known expert in ensembling methods, writes the following pseudo\\ncode in Python shown in Fig. 6.7 for the training of a neural network. This runs inside a\\nstandard loop in each training and validation step.\\n1 import torchvision.models as models\\n2 ...\\n3 models = ['resnext' ]\\n4 for m in models:\\n5 train ...\\n6 compute VAL loss ...\\n7 amend LR ...\\n8 if (val_acc > 90.0):\\n9 saveModel()\\nFIGURE 6.7: PyTorch code snippet for an ensemble\\n1. What type of ensembling can be used with this approach? Explain in detail.\\n2. What is the main advantage of snapshot ensembling? What are the disadvantages, if\\nany?\\nPRB-154 \\uf059 CH.PRB- 6.20.\\nAssume further that your colleague amends the code as follows in Fig. 6.8.\\n195\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 212, 'page_label': '213'}, page_content=\"6.2. PROBLEMS\\n1 import torchvision.models as models\\n2 import random\\n3 import np\\n4 ...\\n5 models = ['resnext' ]\\n6 for m in models:\\n7 train ...\\n8 compute loss ...\\n9 amend LR ...\\n10 manualSeed= draw a new random number\\n11 random.seed(manualSeed)\\n12 np.random.seed(manualSeed)\\n13 torch.manual_seed(manualSeed)\\n14 if (val_acc > 90.0):\\n15 saveModel()\\nFIGURE 6.8: PyTorch code snippet for an ensemble\\nExplain in detail what would be the possible effects of adding lines 10-13.\\n6.2.6 Multi-model Ensembling\\nPRB-155 \\uf059 CH.PRB- 6.21.\\n1. Assume your colleague, a veteran in DL and an expert in ensembling methods writes\\nthe following Pseudo code shown in Fig. 6.9 for the training of several neural networks.\\nThis code snippet is executed inside a standard loop in each and every training/valida-\\ntion epoch.\\n196\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 213, 'page_label': '214'}, page_content=\"Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 import torchvision.models as models\\n2 ...\\n3 models = ['resnext' ,'vgg' ,'dense' ]\\n4 for m in models:\\n5 train ...\\n6 compute loss /acc ...\\n7 if (val_acc > 90.0):\\n8 saveModel()\\nFIGURE 6.9: PyTorch code snippet for an ensemble\\nWhat type of ensembling is being utilized in this approach? Explain in detail.\\n2. Name one method by which NN models may be combined to yield a single prediction.\\n6.2.7 Learning-rate Schedules in Ensembling\\nPRB-156 \\uf059 CH.PRB- 6.22.\\n1. Referring to Fig. ( 6.10) which depicts a speciﬁc learning rate schedule, describe the\\nbasic notion behind its mechanism.\\n197\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 214, 'page_label': '215'}, page_content='6.3. SOLUTIONS\\n1\\n0,5\\n1\\nx\\ny\\nFIGURE 6.10: A learning rate schedule.\\n2. Explain how cyclic learning rates [10] can be effective for the training of convolutional\\nneural networks such as the ones in the code snippet of Fig. 6.10.\\n3. Explain how a cyclic cosine annealing schedule as proposed by Loshchilov [ 10] and\\n[13] is used to converge to multiple local minima.\\n6.3 Solutions\\n6.3.1 Bagging, Boosting and Stacking\\nSOL-135 \\uf14b CH.SOL- 6.1.\\nAll the presented options are correct. \\x04\\nSOL-136 \\uf14b CH.SOL- 6.2.\\nThe correct choice would be stacking. In cases where the given corpus is small, we would\\nmost likely prefer training our models on the full data-set. \\x04\\nSOL-137 \\uf14b CH.SOL- 6.3.\\nA random forest is a type of a decision tree which utilizes bagging. \\x04\\n198'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 215, 'page_label': '216'}, page_content='Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-138 \\uf14b CH.SOL- 6.4.\\nThe presented algorithm is a classic bagging. \\x04\\nSOL-139 \\uf14b CH.SOL- 6.5.\\nThe approach which is depicted is the ﬁrst phase of stacking. In stacking, we ﬁrst (phase\\n0) predict using several base learners and then use a generalizer (phase 1) that learns on top\\nof the base learners predictions. \\x04\\nSOL-140 \\uf14b CH.SOL- 6.6.\\n1. Sampling with replacement\\n2. Sampling without replacement\\n3. This may be mostly a result of bagging, since in boosting we would have expected miss-\\ncorrectly classiﬁed observations to repeatedly appear in subsequent samples.\\n\\x04\\n6.3.2 Approaches for Combining Predictors\\nSOL-141 \\uf14b CH.SOL- 6.7.\\nAn Algebraic weighted average for class probabilities. \\x04\\nSOL-142 \\uf14b CH.SOL- 6.8.\\nThis is true, [ 3] provides a mathematical proof. \\x04\\nSOL-143 \\uf14b CH.SOL- 6.9.\\nThis is true. For extension, see instance [ 8]. \\x04\\nSOL-144 \\uf14b CH.SOL- 6.10.\\nThis is true. In a bagging approach, we ﬁrst randomly draw (with replacement), K ex-\\n199'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 216, 'page_label': '217'}, page_content='6.3. SOLUTIONS\\namples where K is the size of the original training corpus therefore leading to an imbalanced\\nrepresentation of the instances. \\x04\\n6.3.3 Monolithic and Heterogeneous Ensembling\\nSOL-145 \\uf14b CH.SOL- 6.11.\\n1. True Due to their lack of diversity, an ensemble of monolithic architectures tends to\\nperform worse than an heterogeneous ensemble.\\n2. True This has be consistently demonstrated in [ 11, 5].\\n3. True In [6] there is a discussion about both using the whole corpus and a subset much\\nlike in bagging.\\n4. True The total error decreases with the addition of predictors to the ensemble.\\n\\x04\\nSOL-146 \\uf14b CH.SOL- 6.12.\\nY es, they do. \\x04\\nSOL-147 \\uf14b CH.SOL- 6.13.\\n1. Y es, it is very likely, especially if their errors are independent.\\n2. True It may be proven that ensembles of models perform at least as good as each of the\\nensemble members it consists of.\\n3. True Different local minima add to the diversiﬁcation of the models.\\n\\x04\\nSOL-148 \\uf14b CH.SOL- 6.14.\\nBoosting is the only one that does not. \\x04\\n200'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 217, 'page_label': '218'}, page_content='Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-149 \\uf14b CH.SOL- 6.15.\\nFalse By deﬁnition, static committee machines use only the output of the single predict-\\nors. \\x04\\nSOL-150 \\uf14b CH.SOL- 6.16.\\nTrue \\x04\\nSOL-151 \\uf14b CH.SOL- 6.17.\\nFalse Though this may be theoretically true, in practice the errors are rarely uncorrelated\\nand therefore the actual error can not be reduced by a factor of K. \\x04\\n6.3.4 Ensemble Learning\\nSOL-152 \\uf14b CH.SOL- 6.18.\\n1. Ensemble learning is an excellent machine learning idea which displays noticeable bene-\\nﬁts in many applications, one such notable example is the widespread use of ensembles\\nin Kaggle competitions. In an ensemble several individual models (for instance Res-\\nNet18 and VGG16) which were trained on the same corpus, work in tandem and during\\ninference, their predictions are fused by a pre-deﬁned strategy to yield a single predic-\\ntion.\\n2. In classical machine learning Ensemble methods usually refer to bagging, boosting and\\nthe linear combination of regression or classiﬁcation models.\\n3. True The stronger generalization ability stems from the voting power of diverse models\\nwhich are joined together.\\n4. Bagging is variance reduction scheme while boosting reduced bias.\\n\\x04\\n6.3.5 Snapshot Ensembling\\n201'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 218, 'page_label': '219'}, page_content='6.3. SOLUTIONS\\nSOL-153 \\uf14b CH.SOL- 6.19.\\n1. Since only a single model ie being utilized, this type of ensembling is known as snap-\\nshot ensembling. Using this approach, during the training of a neural network and\\nin each epoch, a snapshot, e.g. the weights of a trained instance of a model (a PTH\\nﬁle in PyT orch nomenclature) are persisted into permanent storage whenever a certain\\nperformance metrics, such as accuracy or loss is being surpassed. Therefore the name\\n“snapshot”; weights of the neural network are being snapshot at speciﬁc instances in\\ntime. After several such epochs the top-5 performing Snapshots which converged to\\nlocal minima [4] are combined as part of an ensemble to yield a single prediction.\\n2. Advantages: during a single training cycle, many model instances may be collected.\\nDisadvantages: inherent lack of diversity by virtue of the fact that the same models is\\nbeing repeatedly used.\\n\\x04\\nSOL-154 \\uf14b CH.SOL- 6.20.\\nChanging the random seed at each iteration/epoch, helps in introducing variation which\\nmay contribute to diversifying the trained neural network models. \\x04\\n6.3.6 Multi-model Ensembling\\nSOL-155 \\uf14b CH.SOL- 6.21.\\n1. Multi-model ensembling.\\n2. Both averaging and majority voting.\\n\\x04\\n6.3.7 Learning-rate Schedules in Ensembling\\nSOL-156 \\uf14b CH.SOL- 6.22.\\n202'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 219, 'page_label': '220'}, page_content='Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1. Capturing the best model of each training cycle allows to obtain multiple models settled\\non various local optima from cycle to cycle at the cost of training a single mode\\n2. The approach is based on the non-convex nature of neural networks and the ability to\\nconverge and escape from local minima using a speciﬁc schedule to adjust the learning\\nrate during training.\\n3. Instead of monotonically decreasing the learning rate, this method lets the learning rate\\ncyclically vary between reasonable boundary values.\\n\\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 186).\\n[2] Y . Gal and Z. Ghahramani. ‘Dropout as a Bayesian approximation’. In: arXiv\\npreprint arXiv:1506.02157 (2015) (cit. on p. 192).\\n[3] L. K. Hansen and P . Salamon. ‘Neural Network Ensembles’. In: IEEE T rans. Pat-\\ntern Anal. Mach. Intell. 12 (1990), pp. 993–1001 (cit. on pp. 191, 199).\\n[4] G. Huang et al. ‘Snapshot ensembles: Train 1, get M for free. arXiv 2017’. In:\\narXiv preprint arXiv:1704.00109 () (cit. on pp. 186, 192, 202).\\n[5] J. Huggins, T. Campbell and T. Broderick. ‘Coresets for scalable Bayesian logistic\\nregression’. In: Advances in Neural Information Processing Systems . 2016, pp. 4080–\\n4088 (cit. on pp. 186, 200).\\n[6] C. Ju, A. Bibaut and M. van der Laan. ‘The relative performance of ensemble\\nmethods with deep convolutional neural networks for image classiﬁcation’. In:\\nJournal of Applied Statistics 45.15 (2018), pp. 2800–2818 (cit. on p. 200).\\n[7] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on p. 186).\\n[8] A. Krogh and J. V edelsby. ‘Neural Network Ensembles, Cross Validation, and\\nActive Learning’. In: NIPS. 1994 (cit. on p. 199).\\n[9] S. Lee et al. ‘Stochastic multiple choice learning for training diverse deep en-\\nsembles’. In: Advances in Neural Information Processing Systems . 2016, pp. 2119–\\n2127 (cit. on p. 192).\\n203'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 220, 'page_label': '221'}, page_content='REFERENCES\\n[10] I. Loshchilov and F. Hutter. ‘Sgdr: Stochastic gradient descent with warm re-\\nstarts’. In: arXiv preprint arXiv:1608.03983 (2016) (cit. on p. 198).\\n[11] P . Oshiro et al.(2012)Oshiro and Baranauskas. ‘How many trees in a random\\nforest?’ In: International Workshop on Machine Learning and Data Mining in Pattern\\nRecognition. 2012 (cit. on pp. 186, 200).\\n[12] Y . Ovadia et al. ‘Can you trust your model’s uncertainty? Evaluating predict-\\nive uncertainty under dataset shift’. In: Advances in Neural Information Processing\\nSystems. 2019, p. 13991 (cit. on p. 192).\\n[13] L. N. Smith. ‘Cyclical learning rates for training neural networks’. In: 2017 IEEE\\nWinter Conference on Applications of Computer Vision (WACV). IEEE. 2017, pp. 464–\\n472 (cit. on pp. 186, 198).\\n204'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 221, 'page_label': '222'}, page_content='CHAPTER\\n7\\nDEEP LEARNING: CNN FEATURE EXTRACTION\\nWhat goes up must come down.\\n— Isaac Newton\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\\nNeural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\n7.1 Introduction\\nT\\nHE extraction of an n-dimensional feature vector (FV) or an embedding from\\none (or more) layers of a pre-trained CNN, is termed feature extraction (FE).\\nUsually , FE works by ﬁrst removing the last fully connected (FC) layer from\\na CNN and then treating the remaining layers of the CNN as a ﬁxed FE. As\\nexempliﬁed in Fig. ( 7.1) and Fig. ( 7.2), applying this method to the ResNet34 archi-\\ntecture, the resulting FV consists of 512 ﬂoating point values. Likewise, applying the\\nsame logic on the ResNet152 architecture, the resulting FV has 2048 ﬂoating point ele-\\nments.'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 222, 'page_label': '223'}, page_content='7.2. PROBLEMS\\n1 2 3 4 · · · k = 512\\nA ﬁxed k-element FV .\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nActual values of a normalized k-element FV .\\nFIGURE 7.1: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depicted is\\nthe ResNet CNN architecture with 34 layers.\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.2: PyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed).\\nThe premise behind FE is that CNNs which were originally trained on the Im-\\nageNet Large Scale Visual Recognition Competition [ 7], can be adapted and used (for\\ninstance in a classiﬁcation task) on a completely different (target) domain without any\\nadditional training of the CNN layers. The power of a CNN to do so lies in its ability\\nto generalize well beyond the original data-set it was trained on, therefore FE on a\\nnew target data-set involves no training and requires only inference.\\n7.2 Problems\\n7.2.1 CNN as Fixed Feature Extractor\\nBefore attempting the problems in this chapter you are highly encouraged to read the\\nfollowing papers [ 1, 3, 7]. In many DL job interviews, you will be presented with a\\npaper you have never seen before and subsequently be asked questions about it; so\\nreading these references would be an excellent simulation of this real-life task.\\n206'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 223, 'page_label': '224'}, page_content='Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-157 \\uf059 CH.PRB- 7.1.\\nTrue or False: While AlexNet [ 4] used 11 × 11 sized ﬁlters, the main novelty presented\\nin the VGG [ 8] architecture was utilizing ﬁlters with much smaller spatial extent, sized\\n3 × 3.\\nPRB-158 \\uf059 CH.PRB- 7.2.\\nTrue or False : Unlike CNN architectures such as AlexNet or VGG, ResNet does not\\nhave any hidden FC layers.\\nPRB-159 \\uf059 CH.PRB- 7.3.\\nAssuming the VGG-Net has 138, 357, 544 ﬂoating point parameters, what is the phys-\\nical size in Mega-Bytes (MB) required for persisting a trained instance of VGG-Net on\\npermanent storage?\\nPRB-160 \\uf059 CH.PRB- 7.4.\\nTrue or False : Most attempts at researching image representation using FE, focused\\nsolely on reusing the activations obtained from layers close to the output of the CNN, and\\nmore speciﬁcally the fully-connected layers.\\nPRB-161 \\uf059 CH.PRB- 7.5.\\nTrue or False: FE in the context of deep learning is particularly useful when the target\\nproblem does not include enough labeled data to successfully train CNN that generalizes\\nwell.\\nPRB-162 \\uf059 CH.PRB- 7.6.\\nWhy is a CNN trained on the ImageNet dataset [ 7] a good candidate for a source prob-\\nlem?\\nPRB-163 \\uf059 CH.PRB- 7.7.\\n207'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 224, 'page_label': '225'}, page_content='7.2. PROBLEMS\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of [...] layers.\\n2. It consists of [...] convolutional and 3 [...] layers.\\n3. The input image size is [...].\\n4. The number of input channels is [...].\\n5. Every image has it’s mean RGB value [subtracted / added].\\n6. Each convolutional layer has a [small/large] kernel sized [...].\\n7. The number of pixels for padding and stride is [...].\\n8. There are 5 [...] layers having a kernel size of [...] and a stride of [...] pixels.\\n9. For non-linearity a [rectiﬁed linear unit (ReLU [ 5])/sigmoid] is used.\\n10. The [...] FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of [...] features.\\n12. The last FC layer has only [...] features.\\n13. The last FC layer is terminated by a [...] activation layer.\\n14. Dropout [is / is not] being used between the FC layers.\\nPRB-164 \\uf059 CH.PRB- 7.8.\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture [ 8] for the classiﬁcation of pancreatic cancer. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with\\nit by utilizing the same logic. In Fig. ( 9.7) three different classes of pancreatic cancer are\\ndisplayed: A, B and C, curated from a dataset of 4K Whole Slide Images (WSI) labeled by\\na board certiﬁed pathologist. Y our task is to use FE to correctly classify the images in the\\ndataset.\\n208'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 225, 'page_label': '226'}, page_content='Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nFIGURE 7.3: A dataset of 4K histopathology WSI from three severity classes: A, B and C.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture [ 8]. As de-\\npicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters),\\nlearnable parameters (weights,biases), and FV size are presented.\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 7.1: Incomplete listing of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4K images from the dataset, how can\\nyou now classify the images into their respective categories?\\n209'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 226, 'page_label': '227'}, page_content='7.2. PROBLEMS\\nPRB-165 \\uf059 CH.PRB- 7.9.\\nStill referring to T able ( 9.3), a data scientist suggests using the output layer of the\\nVGG19 CNN as a ﬁxed FE. What is the main advantage of using this layer over using\\nfor instance, the f c7 layer? (Hint: think about an ensemble of feature extractors)\\nPRB-166 \\uf059 CH.PRB- 7.10.\\nStill referring to T able (9.3) and also to the code snippet in Fig. ( 7.4), which represents a\\nnew CNN derived from the VGG19 CNN:\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=[???])\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = [???]\\n11 self.classifier = torch.nn.Sequential([???])\\n12 self.num_feats = [???]\\n13\\n14 def forward(self, x):\\n15 f = self.features(x)\\n16 f = f.view(f.size(0), -1)\\n17 f = [???]\\n18 print (f.data.size())\\n19 return f\\nFIGURE 7.4: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n210'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 227, 'page_label': '228'}, page_content='Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. Complete line 6; what should be the value of pretrained ?\\n2. Complete line 10; what should be the value of self.features ?\\n3. Complete line 12; what should be the value of self.num_feats ?\\n4. Complete line 17; what should be the value of f ?\\nPRB-167 \\uf059 CH.PRB- 7.11.\\nWe are still referring to T able ( 9.3) and using the skeleton code provided in Fig. ( 7.5)\\nto derive a new CNN entitled ResNetBottom from the ResNet34 CNN, to extract a 512-\\ndimensional FV for a given input image. Complete the code as follows:\\n1. The value of self.features in line 7.\\n2. The forward method in line 11.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7\\n8 def forward(self, x):\\n9 x = [???]\\n10 x = x.view(x.size(0), -1)\\n11 return x\\nFIGURE 7.5: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\n211'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 228, 'page_label': '229'}, page_content='7.2. PROBLEMS\\nPRB-168 \\uf059 CH.PRB- 7.12.\\nStill referring to T able (9.3), the PyT orch based pseudo code snippet in Fig. (7.6) returns\\nthe 512-dimensional FV from the modiﬁed ResNet34 CNN, given a 3-channel RGB image\\nas an input.\\n1 import torchvision.models as models\\n2 from torchvision import transforms\\n3 ...\\n4\\n5 test_trans = transforms.Compose([\\n6 transforms.Resize(imgnet_size),\\n7 transforms.ToTensor(),\\n8 transforms.Normalize([0.485, 0.456, 0.406],\\n9 [0.229, 0.224, 0.225])])\\n10\\n11 def ResNet34FE(image, model):\\n12 f=None\\n13 image = test_trans(image)\\n14 image = Variable(image, requires_grad =False).cuda()\\n15 image= image.cuda()\\n16 f = model(image)\\n17 f = f.view(f.size(1), -1)\\n18 print (\"Size : {}\" .format(f.shape))\\n19 f = f.view(f.size(1),-1)\\n20 print (\"Size : {}\" .format(f.shape))\\n21 f =f.cpu().detach().numpy()[0]\\n22 print (\"Size : {}\" .format(f.shape))\\n23 return f\\nFIGURE 7.6: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\nAnswer the following questions regarding the code in Fig. ( 7.6):\\n212'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 229, 'page_label': '230'}, page_content='Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. What is the purpose of test_trans in line 5?\\n2. Why is the parameter requires_grad set to False in line 14?\\n3. What is the purpose of f.cpu() in line 23?\\n4. What is the purpose of detach() in line 23?\\n5. What is the purpose of numpy()[0] in line 23?\\n7.2.2 Fine-tuning CNNs\\nPRB-169 \\uf059 CH.PRB- 7.13.\\nDeﬁne the term ﬁne-tuning (FT) of an ImageNet pre-trained CNN .\\nPRB-170 \\uf059 CH.PRB- 7.14.\\nDescribe three different methods by which one can ﬁne-tune an ImageNet pre-trained\\nCNN.\\nPRB-171 \\uf059 CH.PRB- 7.15.\\nMelanoma is a lethal form of malignant skin cancer, frequently misdiagnosed as a benign\\nskin lesion or even left completely undiagnosed.\\nIn the United States alone, melanoma accounts for an estimated 6, 750 deaths per annum\\n[6]. With a 5-year survival rate of 98%, early diagnosis and treatment is now more likely\\nand possibly the most suitable means for melanoma related death reduction. Dermoscopy\\nimages, shown in Fig. ( 7.7) are widely used in the detection and diagnosis of skin lesions.\\nDermatologists, relying on personal experience, are involved in a laborious task of manually\\nsearching dermoscopy images for lesions.\\nTherefore, there is a very real need for automated analysis tools, providing assistance to\\nclinicians screening for skin metastases. In this question, you are tasked with addressing\\nsome of the fundamental issues DL researchers face when building deep learning pipelines.\\nAs suggested in [ 3], you are going to use ImageNet pre-trained CNN to resolve a classiﬁca-\\ntion task.\\n213'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 230, 'page_label': '231'}, page_content='7.2. PROBLEMS\\nFIGURE 7.7: Skin lesion categories. An exemplary visualization of melanoma.\\n1. Given that the skin lesions fall into seven distinct categories, and you are training us-\\ning cross-entropy loss, how should the classes be represented so that a typical PyT orch\\ntraining loop will successfully converge?\\n2. Suggest several data augmentation techniques to augment the data.\\n3. Write a code snippet in PyT orch to adapt the CNN so that it can predict 7 classes\\ninstead of the original source size of 1000.\\n4. In order to ﬁne tune our CNN, the (original) output layer with 1000 classes was\\nremoved and the CNN was adjusted so that the (new) classiﬁcation layer comprised\\nseven softmax neurons emitting posterior probabilities of class membership for each\\nlesion type.\\n7.2.3 Neural style transfer, NST\\nBefore attempting the problems in the section, you are strongly recommended to read\\nthe paper: “A Neural Algorithm of Artistic Style ” [2].\\nPRB-172 \\uf059 CH.PRB- 7.16.\\nBrieﬂy describe how neural style transfer (NST) [ 2] works.\\nPRB-173 \\uf059 CH.PRB- 7.17.\\nComplete the sentence : When using the VGG-19 CNN [ 8] for neural-style transfer,\\nthere different images are involved. Namely they are: [...], [...] and [...].\\n214'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 231, 'page_label': '232'}, page_content='Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-174 \\uf059 CH.PRB- 7.18.\\nRefer to Fig. 7.8 and answer the following questions:\\nFIGURE 7.8: Artistic style transfer using the style of Francis Picabia’s Udnie painting.\\n1. Which loss is being utilized during the training process?\\n2. Brieﬂy describe the use of activations in the training process.\\nPRB-175 \\uf059 CH.PRB- 7.19.\\nStill referring to Fig. 7.8:\\n1. How are the activations utilized in comparing the content of the content image to the\\ncontent of the combined image?.\\n2. How are the activations utilized in comparing the style of the content image to the\\n215'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 232, 'page_label': '233'}, page_content='7.3. SOLUTIONS\\nstyle of the combined image?.\\nPRB-176 \\uf059 CH.PRB- 7.20.\\nStill referring to Fig. 7.8. For a new style transfer algorithm, a data scientist extracts a\\nfeature vector from an image using a pre-trained ResNet34 CNN ( 7.9).\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.9: PyTorch declaration for a pre-trained ResNet34 CNN.\\nHe then deﬁnes the cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and :\\nv = {v1, v2, . . . , vN }\\nas:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures thecosine of the angle between\\nthe vectors irrespective of their magnitude. It is calculated as the dot product of two numeric\\nvectors, and is normalized by the product of the length of the vectors.\\nAnswer the following questions:\\n1. Deﬁne the term Gram matrix.\\n2. Explain in detail how vector similarity is utilised in the calculation of the Gram mat-\\nrix during the training of NST.\\n7.3 Solutions\\n7.3.1 CNN as Fixed Feature Extractor\\n216'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 233, 'page_label': '234'}, page_content='Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nSOL-157 \\uf14b CH.SOL- 7.1.\\nT rue. The increased depth in VGG-Net was made possible using smaller ﬁlters without\\nsubstantially increasing the number of learnable parameters. Albeit an unwanted side effect\\nof the usage of smaller ﬁlters is the increase in the number of ﬁlters per-layer. \\x04\\nSOL-158 \\uf14b CH.SOL- 7.2.\\nT rue. The ResNet architecture terminates with a global average pooling layer followed\\nby a K-way FC layer with a softmax activation function, where K is the number of classes\\n(ImageNet has 1000 classes). Therefore, the ResNet has no hidden FC layers. \\x04\\nSOL-159 \\uf14b CH.SOL- 7.3. Note that 1bit = 0.000000125 MB, therefore:\\n138, 357544 × 32 = 4427441408 bits = 553.430176 MB. (7.1)\\n\\x04\\nSOL-160 \\uf14b CH.SOL- 7.4.\\nT rue. There are dozens of published papers supporting this claim. Y ou are encouraged to\\nsearch them on Arxiv or Google Scholar. \\x04\\nSOL-161 \\uf14b CH.SOL- 7.5.\\nT rue. One of the major hurdles of training a medical AI system is the lack of annotated\\ndata. Therefore, extensive research is conducted to exploit ways for FE and transfer learning,\\ne.g., in the application of ImageNet trained CNNs, to target datasets in which labeled data is\\nscarce. \\x04\\nSOL-162 \\uf14b CH.SOL- 7.6.\\nThere are two main reasons why this is possible:\\n1. The huge number of images inside the ImageNet dataset ensures a CNN model that gen-\\neralizes to additional domains, like the histopathology domain, which is substantially\\ndifferent from the original domain the model was trained one (e.g., cats and dogs).\\n217'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 234, 'page_label': '235'}, page_content='7.3. SOLUTIONS\\n2. A massive array of disparate visual patterns is produced by an ImageNet trained CNN,\\nsince it consists of 1, 000 different groups.\\n\\x04\\nSOL-163 \\uf14b CH.SOL- 7.7.\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of 19 layers.\\n2. It consists of 5 convolutional and 3 FC layers.\\n3. The input image size is 244 , the default size most ImageNet trained CNNs work on.\\n4. The number of input channels is 3 .\\n5. Every image has its mean RGB value subtracted . (why?)\\n6. Each convolutional layer has a small kernel sized 3 × 3 . (why?)\\n7. The number of pixels for padding and stride is the same and equals 1 .\\n8. There are 5 convolutional layers having a kernel size of 2 × 2 and a stride of 2 pixels.\\n9. For non-linearity a rectiﬁed linear unit (ReLU [ 5]) is used.\\n10. The 3 FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of 4096 features.\\n12. The last FC layer has only 1000 features.\\n13. The last FC layer is terminated by a softmax activation layer.\\n14. Dropout is being used between the FC layers.\\n\\x04\\nSOL-164 \\uf14b CH.SOL- 7.8.\\n218'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 235, 'page_label': '236'}, page_content='Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. One or more layers of the VGG19 CNN are selected for extraction and a new CNN\\nis designed on top of it. Thus, during inference our target layers are extracted and\\nnot the original softmax layer. Subsequently, we iterate and run inference over all\\nthe images in our pancreatic cancer data-set, extract the features, and persist them to\\npermanent storage such as a solid-state drive (SSD) device. Ultimately, each image has\\na corresponding FV .\\n2. Regarding the VGG19 CNN, there are numerous ways of extracting and combining\\nfeatures from different layers. Of course, these different layers, e.g., the FC, conv4_3,\\nand fc7 layer may be combined together to form a larger feature vector. T o determine\\nwhich method works best, you shall have to experiment on your data-set; there is no way\\nof a-priory determining the optimal combination of layers. Here are several examples:\\n(a) Accessing the last FC layer resulting in a 1000-D FV . The output is the score for\\neach of the 1000 classes of the ImageNet data-set.\\n(b) Removing the last FC layer leaves the fc7 layer, resulting in a 4096-D FV .\\n(c) Directly accessing the conv4_3 layer results in a 512-D FV .\\n3. Once the FVs are extracted, we can train any linear classiﬁer such as an SVM or\\nsoftmax classiﬁer on the FV data-set, and not on the original images.\\n\\x04\\nSOL-165 \\uf14b CH.SOL- 7.9.\\nOne beneﬁt of using the FC layer is that other ImageNet CNNs can be used in tandem\\nwith the VGG19 to create an ensemble since they all produce the same 1000-D sized FV . \\x04\\nSOL-166 \\uf14b CH.SOL- 7.10. The full code is presented in Fig. ( 7.10).\\n219'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 236, 'page_label': '237'}, page_content='7.3. SOLUTIONS\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=True)\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = original_model.features\\n11 self.classifier = torch.nn.Sequential(\\n12 (*list(original_model.classifier.\\n13 children())[:-1]))\\n14 self.num_feats = 4096\\n15\\n16 def forward(self, x):\\n17 f = self.features(x)\\n18 f = f.view(f.size(0), -1) # (1, 4096) -> (4096,)\\n19 f = self.classifier(f)\\n20 print (f.data.size())\\n21 return f\\nFIGURE 7.10: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n1. The value of the parameter pretrained should be T rue in order to instruct PyT orch to\\nload an ImageNet trained weights.\\n2. The value of self.features should be original_model.features . This is because we like to\\nretain the layers of the original classiﬁer (original_model).\\n3. The value of self.num_feats should be 4096 . (Why?)\\n4. The value of f should be self.classiﬁer(f) since our newly created CNN has to be in-\\nvoked to generate the FV .\\n220'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 237, 'page_label': '238'}, page_content='Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n\\x04\\nSOL-167 \\uf14b CH.SOL- 7.11.\\n1. Line number 7 in Fig. ( 7.11) takes care of extracting the the correct 512-D FV .\\n2. Line number 11 in Fig. ( 7.11) extracts the correct 512-D FV by creating a sequential\\nmodule on top of the existing features.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7 def forward(self, x):\\n8 x = [???]\\n9 x = x.view(x.size(0), -1)\\n10 return x\\nFIGURE 7.11: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n\\x04\\nSOL-168 \\uf14b CH.SOL- 7.12.\\n1. T ransforms are incorporated into deep learning pipelines in order to apply one or more\\noperations on images which are represented as tensors. Different transforms are usu-\\nally utilized during training and inference. For instance, during training we can use a\\ntransform to augment our data-set, while during inference our transform may be lim-\\nited only to normalizing an image. PyT orch allows the use of transforms either during\\ntraining or inference. The purpose of test_trans in line 5 is to normalize the data.\\n221'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 238, 'page_label': '239'}, page_content='7.3. SOLUTIONS\\n2. The parameter requires_grad is set to False in line 14 since during inference the com-\\nputation of gradients is obsolete.\\n3. The purpose of f.cpu() in line 11 is to move a tensor that was allocated on the GPU\\nto the CPU. This may be required if we want to apply a CPU-based method from the\\nPython numpy package on a T ensor that does not live in the CPU.\\n4. detach() in line 23 returns a newly created tensor without affecting the current tensor.\\nIt also detaches the output from the current computational graph, hence no gradient is\\nbackpropagated for this speciﬁc variable.\\n5. The purpose of numpy()[0] in line 23 is to convert the variable (an array) to a numpy\\ncompatible variable and also to retrieve the ﬁrst element of the array.\\n\\x04\\n7.3.2 Fine-tuning CNNs\\nSOL-169 \\uf14b CH.SOL- 7.13.\\nThe term ﬁne-tuning (FT) of an ImageNet pre-trained CNN refers to the method by which\\none or more of the weights of the CNN are re-trained on a new target data-set, which may or\\nmay-not have similarities with the ImageNet data-set. \\x04\\nSOL-170 \\uf14b CH.SOL- 7.14. The three methods are as follows:\\n1. Replacing and re-training only the classiﬁer (usually the FC layer) of the ImageNet\\npre-trained CNN, on a target data-set.\\n2. FT all of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n3. FT part of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n\\x04\\nSOL-171 \\uf14b CH.SOL- 7.15.\\n222'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 239, 'page_label': '240'}, page_content=\"Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The categories have to be represented numerically. One such option is presented in Code\\n(7.1).\\n1 'MEL' : 0, 'NV' : 1, 'BCC' : 2, 'AKIEC' : 3, 'BKL' : 4, 'DF' : 5,\\n'VASC' : 6↪→\\nCODE 7.1: The seven categories of skin lesions.\\n2. Several possible augmentations are presented in Code ( 7.2). It is usually, that by trial\\nand error one ﬁnds the best possible augmentation for a target data-set. However, meth-\\nods such as AutoAugment may render the manual selection of augmentations obsolete.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\n6 if brightness != 0:\\n7 self.transforms.append(PILBrightness())\\n8 if contrast != 0:\\n9 self.transforms.append(PILContrast())\\n10 if colorbalance != 0:\\n11 self.transforms.append(PILColorBalance())\\n12 if sharpness != 0:\\n13 self.transforms.append(PILSharpness())\\nCODE 7.2: Pseudeo code for augmentations.\\n3. In contrast to the ResNet CNN which ends by an FC layer, the ImageNet pre-trained\\nDPN CNN family, in this case the pretrainedmodels.dpn107, terminated by a Conv2d\\n223\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 240, 'page_label': '241'}, page_content='7.3. SOLUTIONS\\nlayer and hence must be adapted accordingly if one wishes to change the number fo\\nclasses from the 1000 (ImageNet) classes to our skin lession classiﬁcation problem (7\\nclasses). Line 7 in Code ( 7.3) demonstrated this idiom.\\n1 import torch\\n2 class Dpn107Finetune(nn.Module):\\n3 def __init__(self, num_classes: int, net_kwards):\\n4 super().__init__()\\n5 self.net = pretrainedmodels.dpn107(**net_kwards)\\n6 self.net.__name__= str (self.net)\\n7 self.net.classifier = torch.nn.Conv2d(2688,\\nnum_classes,kernel_size=1)↪→\\n8 print(self.net)\\nCODE 7.3: Change between 1000 classes to 7 classes for the ImageNet pre-trained DPN\\nCNN family .\\n\\x04\\n7.3.3 Neural style transfer\\nSOL-172 \\uf14b CH.SOL- 7.16.\\nThe images are: a content image, a style image and lastly a combined image. \\x04\\nSOL-173 \\uf14b CH.SOL- 7.17.\\nThe algorithm presented in the paper suggests how to combine the content a ﬁrst image\\nwith the style of a second image to generate a third, stylized image using CNNs.\\n\\x04\\nSOL-174 \\uf14b CH.SOL- 7.18.\\nThe answers are as follows:\\n224'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 241, 'page_label': '242'}, page_content='Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The training pipeline uses a combined loss which consists of a weighted average of the\\nstyle loss and the content loss.\\n2. Different CNN layers at different levels are utilized to capture both ﬁne-grained styl-\\nistic details as well as larger stylistic features.\\n\\x04\\nSOL-175 \\uf14b CH.SOL- 7.19.\\n1. The content loss is the mean square error (MSE) calculated as the difference between\\nthe CNN activations of the last convolutional layer of both the content image and the\\nstyle images.\\n2. The style loss amalgamates the losses of several layers together. For each layer, the gram\\nmatrix (see 7.2) for the activations at that layer is obtained for both the style and the\\ncombined images. Then, just like in the content loss, the MSE of the Gram matrices is\\ncalculated.\\n\\x04\\nSOL-176 \\uf14b CH.SOL- 7.20.\\nFor each feature map, a feature vector is extracted. The gram matrix captures the correl-\\nation between these feature vectors which is then being used in the loss function. Provided a\\nlist of feature vectors extracted from the images, u1, . . . , uk ∈ Rn, the Gram matrix is deﬁned\\nas: \\uf8eb\\n\\uf8ec\\uf8ec\\uf8ec\\uf8ed\\nu1 · u1 . . . u 1 · uk\\n... . . . ...\\nuk · u1 . . . u k · uk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f7\\uf8f8 (7.2)\\nThe Gram matrix \\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 206).\\n225'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 242, 'page_label': '243'}, page_content='REFERENCES\\n[2] L. A. Gatys, A. S. Ecker and M. Bethge. A Neural Algorithm of Artistic Style . 2015.\\narXiv: 1508.06576 [cs.CV] (cit. on p. 214).\\n[3] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on pp. 206, 213).\\n[4] A. Krizhevsky. One weird trick for parallelizing convolutional neural networks . 2014.\\narXiv: 1404.5997 [cs.NE] (cit. on p. 207).\\n[5] V . Nair and G. E. Hinton. ‘Rectiﬁed Linear Units Improve Restricted Boltzmann\\nMachines’. In: ICML 10 . Madison, WI, USA: Omnipress, 2010, pp. 807–814 (cit.\\non pp. 208, 218).\\n[6] A. J. R. L. Siegel K. D. Miller. ‘Cancer statistics 2016’. In: CA: a cancer journal for\\nclinicians 66,1 (2016), pp. 7–30 (cit. on p. 213).\\n[7] Russakovsky. ‘ImageNet Large Scale Visual Recognition Challenge’. In: Journal\\nof Computer Vision 115.3 (Apr. 2015), pp. 211–252 (cit. on pp. 206, 207).\\n[8] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 207–209, 214).\\n226'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 243, 'page_label': '244'}, page_content='CHAPTER\\n8\\nDEEP LEARNING\\nIt is the weight, not numbers of experiments that is to be regarded.\\n— Isaac Newton.\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 234\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 235\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 236\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 239\\nConvolution and correlation in python . . . . . . . . . . . . . . 240\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 241\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 244\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 246'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 244, 'page_label': '245'}, page_content='The Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 247\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 248\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 249\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 251\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 251\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 253\\nSigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 260\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 268\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 273\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 274\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 276\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 280\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 283\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 284\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\n228'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 245, 'page_label': '246'}, page_content='Chapter 8 DEEP LEARNING\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 286\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 291\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 291\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 292\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 293\\nConvolution and correlation in python . . . . . . . . . . . . . . 294\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 295\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 297\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 299\\nThe Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 300\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 301\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 301\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 304\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 305\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 306\\n229'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 246, 'page_label': '247'}, page_content='Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 318\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 324\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 324\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 326\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 326\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 327\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 328\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 329\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 331\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333\\n230'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 247, 'page_label': '248'}, page_content='Chapter 8 DEEP LEARNING\\n8.1 Introduction\\nI\\nT was Alex Krizhevsky who ﬁrst demonstrated that a convolutional neural\\nnetwork (CNN) can be effectively trained on the ImageNet large scale visual\\nrecognition challenge. A CNN automatically provides some degree of trans-\\nlation and assumes that we wish to learn ﬁlters, in a data-driven fashion, as\\na means to extract features describing the inputs. CNNs are applied to numerous com-\\nputer vision, imaging, and computer graphics tasks as in [ 24], [ 23], [ 15], [ 5]. Further-\\nmore, they have become extremely popular, and novel architectures and algorithms\\nare continually popping up overnight.\\n8.2 Problems\\n8.2.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nPRB-177 \\uf059 CH.PRB- 8.1.\\nFig (8.1) depicts two different cross-validation approaches. Name them.\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\nTRAIN VAL\\nFIGURE 8.1: Two CV approaches\\n231'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 248, 'page_label': '249'}, page_content='8.2. PROBLEMS\\nPRB-178 \\uf059 CH.PRB- 8.2.\\n1. What is the purpose of the following Python code snippet 8.2 ?\\n1 skf = StratifiedKFold(y, n_folds =5, random_state =989,\\nshuffle=True)↪→\\nFIGURE 8.2: Stratiﬁed K-fold\\n2. Explain the beneﬁts of using the K-fold cross validation approach.\\n3. Explain the beneﬁts of using the Stratiﬁed K-fold cross validation approach.\\n4. State the difference between K-fold cross validation and stratiﬁed cross validation.\\n5. Explain in your own words what is meant by “We adopted a 5-fold cross-validation\\napproach to estimate the testing error of the model”.\\nK-Fold CV\\nPRB-179 \\uf059 CH.PRB- 8.3.\\nT rue or False: In a K-fold CV approach, the testing set is completely excluded from the\\nprocess and only the training and validation sets are involved in this approach.\\nPRB-180 \\uf059 CH.PRB- 8.4.\\nT rue or False: In a K-fold CV approach, the ﬁnal test error is:\\nCV (k) = 1\\nk\\nk∑\\ni=1\\nMSEi (8.1)\\n232'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 249, 'page_label': '250'}, page_content='Chapter 8 DEEP LEARNING\\nPRB-181 \\uf059 CH.PRB- 8.5.\\nMark all the correct choices regarding a cross-validation approach:\\n(i) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted.\\n(ii) A 5-fold cross-validation approach results in 1 model instance being ﬁtted over and\\nover again 5 times.\\n(iii) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted\\nover and over again 5 times.\\n(iv) Uses K-different data-folds.\\nPRB-182 \\uf059 CH.PRB- 8.6.\\nMark all the correct choices regarding the approach that should be taken to compute the\\nperformance of K-fold cross-validation:\\n(i) We compute the cross-validation performance as the arithmetic mean over the K per-\\nformance estimates from the validation sets.\\n(ii) We compute the cross-validation performance as the best one over the K performance\\nestimates from the validation sets.\\nStratification\\nPRB-183 \\uf059 CH.PRB- 8.7.\\nA data-scientist who is interested in classifying cross sections of histopathology image\\nslices (8.3) decides to adopt a cross-validation approach he once read about in a book. Name\\nthe approach from the following options:\\n233'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 250, 'page_label': '251'}, page_content='8.2. PROBLEMS\\n1st\\n2nd\\n3rd\\nK-fold CV\\nVAL FOLD TRAIN FOLD\\nFIGURE 8.3: A speciﬁc CV approach\\n(i) 3-fold CV\\n(ii) 3-fold CV with stratiﬁcation\\n(iii) A (repeated) 3-fold CV\\nLOOCV\\nPRB-184 \\uf059 CH.PRB- 8.8.\\n1. T rue or false: The leave-one-out cross-validation (LOOCV) approach is a sub-case of\\nk-fold cross-validation wherein K equals N , the sample size.\\n2. T rue or false: It is always possible to ﬁnd an optimal value n, K = n in K-fold\\ncross-validation.\\n8.2.2 Convolution and correlation\\nThe convolution operator\\nPRB-185 \\uf059 CH.PRB- 8.9.\\nEquation 8.2 is commonly used in image processing:\\n(f ∗ g)(t) =\\n∫ ∞\\n−∞\\nf (τ )g(t − τ )dτ (8.2)\\n234'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 251, 'page_label': '252'}, page_content='Chapter 8 DEEP LEARNING\\n1. What does equation 8.2 represent?\\n2. What does g(t) represent?\\nPRB-186 \\uf059 CH.PRB- 8.10.\\nA data-scientist assumes that:\\ni A convolution operation is both linear and shift invariant.\\nii A convolution operation is just like correlation, except that we ﬂip over the ﬁlter before\\napplying the correlation operator.\\niii The convolution operation reaches a maximum, only in cases where the ﬁlter is mostly\\nsimilar to a speciﬁc section of the input signal.\\nIs he right in assuming so? Explain in detail the meaning of these statements.\\nThe correlation operator\\nPRB-187 \\uf059 CH.PRB- 8.11.\\nMark the correct choice(s):\\n1. The cross-correlation operator is used to ﬁnd the location where two different signals\\nare most similar.\\n2. The autocorrelation operator is used to ﬁnd when a signal is similar to a delayed ver-\\nsion of itself.\\nPRB-188 \\uf059 CH.PRB- 8.12.\\nA data-scientist provides you with a formulae for a discrete 2D convolution operation\\n(8.3):\\nf (x, y) ∗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf (m, n)h(x − m, y − n) (8.3)\\n235'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 252, 'page_label': '253'}, page_content='8.2. PROBLEMS\\nUsing only (8.3), write the equivalent 2D correlation operation.\\nPadding and stride\\nRecommended reading : “A guide to convolution arithmetic for deep learning ” by Vincent\\nDumoulin and Francesco Visin (2016) [ 22].\\nPRB-189 \\uf059 CH.PRB- 8.13.\\nWhen designing a convolutional neural network layer, one must also deﬁne how the ﬁlter\\nor kernel slides through the input signal. This is controlled by what is known as the stride\\nand padding parameters or modes. The two most commonly used padding approached in\\nconvolutions are the V ALIDand the SAME modes. Given an input stride of 1:\\n1. Deﬁne SAME\\n2. Deﬁne V ALID\\nPRB-190 \\uf059 CH.PRB- 8.14.\\nTrue or False: A valid convolution is a type of convolution operation that does not use\\nany padding on the input.\\nPRB-191 \\uf059 CH.PRB- 8.15.\\nY ou are provided with aK × K input signal and a θ × θ ﬁlter. The signal is subjected to\\nthe valid padding mode convolution. What are the resulting dimensions?\\narr = [\\n0 ... 0\\n0 ... 0\\n0 ... 0\\n] (8.4)\\nPRB-192 \\uf059 CH.PRB- 8.16.\\nAs depicted in ( 8.4), a ﬁlter is applied to a ×3 input signal. Identify the correct choice\\ngiven a stride of 1 and Same padding mode.\\n236'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 253, 'page_label': '254'}, page_content='Chapter 8 DEEP LEARNING\\nFIGURE 8.4: A padding approach\\nPRB-193 \\uf059 CH.PRB- 8.17.\\nAs depicted in in ( 8.5), a ﬁlter is applied to a 3 × 3 input signal, mark the correct choices\\ngiven a stride of 1.\\n(i) A represents a V ALID convolution and B represents a SAME convolution\\n(ii) A represents a SAME convolution and B represents a V ALID convolution\\n(iii) Both A and B represent a V ALID convolution\\n(iv) Both A and B represent a SAME convolution\\n237'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 254, 'page_label': '255'}, page_content='8.2. PROBLEMS\\nFIGURE 8.5: A padding approach\\nPRB-194 \\uf059 CH.PRB- 8.18.\\nIn this question we discuss the two most commonly used padding approaches in convo-\\nlutions; V ALIDand SAME . Fig.8.6 presents python code for generating an input signal\\narr001 and a convolution kernel f ilter001. The input signal, arr001 is ﬁrst initialized to\\nall zeros as follows:\\narr001 = [\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n] (8.5)\\n1. Without actually executing the code, determine what would be the resulting shape of\\nthe convolve2d() operation.\\n2. Manually compute the result of convolving the input signal with the provided ﬁlter.\\n3. Elaborate why the size of the resulting convolutions is smaller than the size of the\\ninput signal.\\n238'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 255, 'page_label': '256'}, page_content=\"Chapter 8 DEEP LEARNING\\n1 import numpy\\n2 import scipy.signal\\n3\\n4 arr01 = numpy.zeros((6, 6),dtype=float)\\n5 print (arr01)\\n6 arr01[:,:3] = 3.0\\n7 arr01[:,3:] = 1.0\\n8\\n9 filter001 = numpy.zeros((3, 3), dtype =float)\\n10 filter001[:,0] = 2.0\\n11 filter001[:,2] = -2.0\\n12\\n13 output = scipy.signal.convolve2d(arr01, filter, mode ='valid' )\\nFIGURE 8.6: Convolution and correlation in python\\nKernels and filters\\nPRB-195 \\uf059 CH.PRB- 8.19.\\nEquation 8.6 is the discrete equivalent of equation 8.2 which is frequently used in image\\nprocessing:\\n(y ∗ k)[i, j] =\\n∑\\nn\\n∑\\nm\\ny[i − n, j − m]k[n, m] (8.6)\\n1. Given the following discrete kernel in the X direction, what would be the equivalent Y\\ndirection?\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 1\\n−1 1\\n\\uf8f9\\n\\uf8fb (8.7)\\n2. Identify the discrete convolution kernel presented in ( 8.7).\\n239\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 256, 'page_label': '257'}, page_content='8.2. PROBLEMS\\nFIGURE 8.7: A 3 by 3 convolution kernel\\nPRB-196 \\uf059 CH.PRB- 8.20.\\nGiven an image of size w × h, and a kernel with width K, how many multiplications and\\nadditions are required to convolve the image?\\nConvolution and correlation in python\\nPRB-197 \\uf059 CH.PRB- 8.21.\\nFig.8.8 presents two built-in Python functions for the convolution and correlation oper-\\nators.\\n1 import nympy as np\\n2 np.convolve(A,B,\"full\") # for convolution\\n3 np.correlate(A,B,\"full\") # for cross correlation\\nFIGURE 8.8: Convolution and correlation in python\\n1. Implement the convolution operation from scratch in Python. Compare it with the\\n240'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 257, 'page_label': '258'}, page_content='Chapter 8 DEEP LEARNING\\nbuilt-in numpy equivalent.\\n2. Implement the correlation operation using the implementation of the convolution op-\\neration. Compare it with the built-in numpy equivalent.\\nSeparable convolutions\\nPRB-198 \\uf059 CH.PRB- 8.22.\\nThe Gaussian distribution in the 1D and 2D is shown in Equations 8.8 and 8.9.\\nG(x) = 1√\\n2πσ e− x2\\n2σ2 (8.8)\\nG(x, y) = 1\\n2πσ 2 e− x2+y2\\n2σ2 (8.9)\\nThe Gaussian ﬁlter, is an operator that is used to blur images and remove detail and\\nnoise while acting like a low-pass ﬁlter. This is similar to the way a mean ﬁlter works, but\\nthe Gaussian ﬁlter uses a different kernel. This kernel is represented with a Gaussian bell\\nshaped bump.\\nAnswer the following questions:\\n1. Can 8.8 be used directly on a 2D image?\\n2. Can 8.9 be used directly on a 2D image?\\n3. Is the Gaussian ﬁlter separable? if so, what are the advantages of separable ﬁlters.\\n8.2.3 Similarity measures\\nImage, text similarity\\nPRB-199 \\uf059 CH.PRB- 8.23.\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n241'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 258, 'page_label': '259'}, page_content='8.2. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 8.9: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\n1 void xxx(std::vector<float>& arr) {\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nAn unknown algorithm in C++11\\nFIGURE 8.10: listing\\nWhich results in this vector ( 8.11):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 8.11: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n242'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 259, 'page_label': '260'}, page_content='Chapter 8 DEEP LEARNING\\nPRB-200 \\uf059 CH.PRB- 8.24.\\nFurther to the above, the scientist then applies the following algorithm:\\nAlgorithm 3: Algo 1\\nData: Two vectors v1 and v2 are provided\\nApply algorithm xxx on the two vectors\\nRun algorithm 2\\nAlgorithm 4: Algo 2\\n1 float algo2(const std::vector<float>& v1, const\\nstd::vector<float>& v2){↪→\\n2 double mul = 0;\\n3 for (size_t i = 0; i < v1.size(); ++i){\\n4 mul += v1[i] * v2[i];\\n5 }\\n6 if (mul < 0) {\\n7 return 0;\\n8 }\\n9 return mul;\\n10 }\\nFIGURE 8.12: An unknown algorithm\\n1. Name the algorithm algo2 that he used and explain in detail what he used it for.\\n2. Write the mathematical formulae behind it.\\n3. What are the minimum and maximum values it can return?\\n4. An alternative similarity measures between two vectors is:\\nsimeuc(v1, v2) = −||v1 − v2||. (8.10)\\nName the measure.\\n243'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 260, 'page_label': '261'}, page_content='8.2. PROBLEMS\\nJacard similarity\\nPRB-201 \\uf059 CH.PRB- 8.25.\\n1. What is the formulae for the Jaccard similarity [ 12] of two sets?:\\n2. Explain the formulae in plain words.\\n3. Find the Jacard similarity given the sets depicted in ( 8.13)\\nFIGURE 8.13: Jaccard similarity .\\n4. Compute the Jaccard similarity of each pair of the following sets:\\ni 12, 14, 16, 18.\\nii 11, 12, 13, 14, 15.\\niii 11, 16, 17.\\nThe Kullback-Leibler Distance\\nPRB-202 \\uf059 CH.PRB- 8.26.\\nIn this problem, you have to actually read 4 different papers, so you will probably not\\nencounter such a question during an interview, however reading academic papers is an ex-\\ncellent skill to master for becoming a DL researcher.\\nRead the following papers which discuss aspects of the Kullback-Leibler divergence:\\ni Bennet [2]\\n244'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 261, 'page_label': '262'}, page_content='Chapter 8 DEEP LEARNING\\nii Ziv [29]\\niii Bigi [3]\\niv Jensen [1]\\nThe Kullback-Leibler divergence, which was discussed thoroughly in chap 4 is a meas-\\nure of how different two probability distribution are. As noted, the KL divergence of the\\nprobability distributions P , Q on a set X is deﬁned as shown in Equation 8.11.\\nDKL(P ||Q) =\\n∑\\nx∈X\\nP (x)log P (x)\\nQ(x) (8.11)\\nNote however that since KL divergence is a non-symmetric information theoretical meas-\\nure of distance of P from Q, then it is not strictly a distance metric. During the past years,\\nvarious KL based distance measures (rather than divergence based) have been introduced in\\nthe literature generalizing this measure.\\nName each of the following KL based distances:\\nDKLD 1(P ||Q) = DKL(P ||Q) + DKL(Q||P ) (8.12)\\nDKLD 2(P ||Q) =\\n∑\\nx∈X\\n(P (x) − Q(x))log P (x)\\nQ(x) (8.13)\\nDKLD 3(P ||Q) = 1\\n2\\n[\\nDKL\\n(\\nP ||P + Q\\n2\\n)\\n+ DKL\\n(\\nQ||P + Q\\n2\\n)]\\n(8.14)\\nDKLD 4(P ||Q) = max (DKL(P ||Q) + DKL(Q||P )) (8.15)\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nPRB-203 \\uf059 CH.PRB- 8.27.\\nWhat is the goal of hashing? Draw a simple HashMap of keys and values. Explain what\\nis a collision and the notion of buckets. Explain what is the goal of MinHash.\\n245'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 262, 'page_label': '263'}, page_content='8.2. PROBLEMS\\nPRB-204 \\uf059 CH.PRB- 8.28.\\nWhat is Locality Sensitive Hashing or LSH?\\nPRB-205 \\uf059 CH.PRB- 8.29.\\nComplete the sentence : LSH main goal is to [...] the probability of a colliding, for\\nsimilar items in a corpus.\\n8.2.4 Perceptrons\\nThe Single Layer Perceptron\\nPRB-206 \\uf059 CH.PRB- 8.30.\\n1. complete the sentence : In a single-layer feed-forward NN, there are [...] input(s)\\nand [...]. output layer(s) and no [...] connections at all.\\nPRB-207 \\uf059 CH.PRB- 8.31.\\nIn its simplest form, a perceptron (8.16) accepts only a binary input and emits a binary\\noutput. The output, can be evaluated as follows:\\noutput =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0, if ∑\\nj wjxj + b ≤ 0,\\n1, if\\n∑\\nj wjxj + b > 0\\n. (8.16)\\nWhere weights are denoted by wj and biases are denoted by b. Answer the following ques-\\ntions:\\n1. T rue or False: If such a perceptron is trained using a labelled corpus, for each parti-\\ncipating neuron the values wj and b are learned automatically.\\n2. T rue or False: If we instead use a new perceptron (sigmoidial) deﬁned as follows:\\nσ(wx + b) (8.17)\\n246'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 263, 'page_label': '264'}, page_content='Chapter 8 DEEP LEARNING\\nwhere σ is the sigmoid function:\\nσ(z) = 1\\n1 + e−z . (8.18)\\nThen the new perceptron can process inputs ranging between 0 and 1 and emit output\\nranging between 0 and 1.\\n3. Write the cost function associated with the sigmoidial neuron.\\n4. If we want to train the perceptron in order to obtain the best possible weights and\\nbiases, which mathematical equation do we have to solve?\\n5. Complete the sentence: T o solve this mathematical equation, we have to apply [...]\\n6. What does the following equation stands for?\\n∇C = 1\\nn\\n∑\\nx\\n∇Cx (8.19)\\nWhere:\\nCx = 1\\n2∥y(x) − a(x, w, b)∥2 (8.20)\\n7. Complete the sentence: Due to the time-consuming nature of computing gradients for\\neach entry in the training corpus, modern DL libraries utilize a technique that gauges\\nthe gradient by ﬁrst randomly sampling a subset from the training corpus, and then\\naveraging only this subset in every epoch. This approach is known as [...]. The actual\\nnumber of randomly chosen samples in each epoch is termed [...]. The gradient itself\\nis obtained by an algorithm known as [...].\\nThe Multi Layer Perceptron\\nPRB-208 \\uf059 CH.PRB- 8.32.\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\n247'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 264, 'page_label': '265'}, page_content='8.2. PROBLEMS\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 8.14: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the value resulting from the application the sum operator?\\n3. Verify the correctness of your results using PyT orch.\\nActivation functions in perceptrons\\nPRB-209 \\uf059 CH.PRB- 8.33.\\nThe following questions refer to the MLP depicted in ( 8.15).\\n1. Further to the above, the ReLU non-linear activation function g(z) = max {0, z} is\\napplied ( 8.15) to the output of the linear transformation. What is the value of the\\noutput (out2) now?\\nx1\\nH1\\nx2\\ng(x1, x2)\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1 out2\\n0.001\\nInputs Hidden ActivationSum\\nFIGURE 8.15: Several nodes in a MLP .\\n248'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 265, 'page_label': '266'}, page_content='Chapter 8 DEEP LEARNING\\n2. Conﬁrm your manual calculation using PyT orch tensors.\\nBack-propagation in perceptrons\\nPRB-210 \\uf059 CH.PRB- 8.34.\\nY our co-worker, an postgraduate student at M.I.T, suggests using the following activa-\\ntion functions in a MLP . Which ones can never be back-propagated and why?\\ni\\nf (x) = |x| (8.21)\\nii\\nf (x) = x (8.22)\\niii\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx sin(1/x) if x ̸= 0\\n0 if x = 0\\n(8.23)\\niv\\nf (x) =\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f3\\nx2 x > 0\\n−x x < 0\\n0 x = 0\\n(8.24)\\nPRB-211 \\uf059 CH.PRB- 8.35.\\nY ou are provided with the following MLP as depicted in 8.16.\\n249'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 266, 'page_label': '267'}, page_content='8.2. PROBLEMS\\nθ0\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nγ2\\nFIGURE 8.16: A basic MLP\\nThe ReLU non-linear activation function g(z) = max {0, z} is applied to the hidden\\nlayers H1...H3 and the bias term equals 0.001.\\nAt a certain point in time it has the following values 8.17 all of which are belong to the\\ntype torch.F loatT ensor:\\n1 import torch\\n2 x= torch.tensor([0.9,0.7]) # Input\\n3 w= torch.tensor([\\n4 [-0.3,0.15],\\n5 [0.32,-0.91],\\n6 [0.37,0.47],\\n7 ]) # Weights\\n8 B= torch.tensor([0.002]) # Bias\\nFIGURE 8.17: MLP operations.\\n1. Using Python, calculate the output of the MLP at the hidden layers H1...H3.\\n2. Further to the above, you discover that at a certain point in time that the weights\\nbetween the hidden layers and the output layers γ1 have the following values:\\n1 w1= torch.tensor([\\n2 [0.15,-0.46,0.59],\\n3 [0.10,0.32,-0.79],\\n4 )\\n250'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 267, 'page_label': '268'}, page_content='Chapter 8 DEEP LEARNING\\nWhat is the value observed at the output nodes γ1..γ2?\\n3. Assume now that a Softmax activation is applied to the output. What are the resulting\\nvalues?\\n4. Assume now that a cross-entropy loss is applied to the output of the Softmax.\\nL = −\\n∑\\ni\\nˆyi log (yi) (8.25)\\nWhat are the resulting values?\\nThe theory of perceptrons\\nPRB-212 \\uf059 CH.PRB- 8.36. If someone is quoted saying:\\nMLP networks are universal function approximators.\\nWhat does he mean?\\nPRB-213 \\uf059 CH.PRB- 8.37.\\nT rue or False: the output of a perceptron is 0 or 1.\\nPRB-214 \\uf059 CH.PRB- 8.38.\\nT rue or False: A multi-layer perceptron falls under the category of supervised machine\\nlearning.\\nPRB-215 \\uf059 CH.PRB- 8.39.\\nT rue or False: The accuracy of a perceptron is calculated as the number of correctly\\nclassiﬁed samples divided by the total number of incorrectly classiﬁed samples.\\nLearning logical gates\\n251'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 268, 'page_label': '269'}, page_content='8.2. PROBLEMS\\nPRB-216 \\uf059 CH.PRB- 8.40.\\nThe following questions refer to the SLP depicted in ( 8.18). The weights in the SLP are\\nw1 = 1 and w2 = 1 respectively. There is a single hidden node, H1. The bias term, B1 equals\\n−2.5.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1 =\\n1\\nw2 =\\n1\\nout1\\n−2.5\\nInputs\\nHidden\\nSum\\nFIGURE 8.18: A single layer perceptron.\\n1. Assuming the inputs to the SLP in ( 8.18) are\\ni x1 = 0.0 and x2 = 0.0\\nii x1 = 0.0 and x2 = 1.0\\niii x1 = 1.0 and x2 = 0.0\\niv x1 = 1.0 and x2 = 1.0\\nWhat is the value resulting from the application the sum operator?\\n2. Repeat the above, assuming now that the bias term B1 was amended and equals −0.25.\\n3. Deﬁne what is the perceptron learning rule.\\n4. What was the most crucial difference between Rosenblatt’s original algorithm and\\nHinton’s fundamental papers of 1986:\\n“Learning representations by back-propagating errors ” [22]\\nand 2012:\\n“ImageNet Classiﬁcation with Deep Convolutional Neural Networks ” [18]?\\n5. The AND logic gate [ 7] is deﬁned by the following table ( 8.19):\\n252'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 269, 'page_label': '270'}, page_content='Chapter 8 DEEP LEARNING\\nx1 x2 y\\n1 1 1\\n1 0 0\\n0 1 0\\n0 0 0\\nFIGURE 8.19: Logical AND gate\\nCan a perceptron with only two inputs and a single output function as an AND logic\\ngate? If so, ﬁnd the weights and the threshold and demonstrate the correctness of your\\nanswer using a truth table.\\n8.2.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\nPRB-217 \\uf059 CH.PRB- 8.41.\\nThe Sigmoid sc(x) = 1\\n1+e−cx , also commonly known as the logistic function (Fig. 8.20),\\nis widely used in binary classiﬁcation and as a neuron activation function in artiﬁcial neural\\nnetworks. Typically, during the training of an ANN, a Sigmoid layer applies the Sigmoid\\nfunction to elements in the forward pass, while in the backward pass the chain rule is be-\\ning utilized as part of the backpropagation algorithm. In 8.20 the constant c was selected\\narbitrarily as 2 and 5 respectively.\\n253'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 270, 'page_label': '271'}, page_content='8.2. PROBLEMS\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−2x\\nσ(x) = 1\\n1+e−5x\\nσ(x) = 1\\n1+2−1.5x\\nFIGURE 8.20: Examples of two sigmoid functions and an approximation.\\nDigital hardware implementations of the sigmoid function do exist but they are expens-\\nive to compute and therefore several approximation methods were introduced by the research\\ncommunity. The method by [ 10] uses the following formulas to approximate the exponential\\nfunction:\\nex ≈ Ex(x) ≈ 21.44x (8.26)\\nBased on this formulation, one can calculate the sigmoid function as:\\nSigmoid (x) ≈ 1\\n1 + 2−1.44x ≈ 1\\n1 + 2−1.5x (8.27)\\n1. Code snippet 8.21 provides a pure C++ based (e.g. not using Autograd) implementa-\\ntion of the forward pass for the Sigmoid function. Implement the backward pass that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19] style tensors.\\n254'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 271, 'page_label': '272'}, page_content='Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001( const torch::Tensor & x ){\\n5 torch::Tensor sig = 1.0 / (1.0 + torch::exp(( -x)));\\n6 return sig;\\n7 }\\nFIGURE 8.21: Forward pass for the Sigmoid function using Libtorch\\n2. Code snippet 8.22 provides a skeleton for printing the values of the sigmoid and its\\nderivative for a range of values contained in the vector v. Complete the code (lines 7-8)\\nso that the values are printed.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 ...\\n8 ...\\n9 }\\n10 }\\n.\\nFIGURE 8.22: Evaluation of the sigmoid and its derivative using Libtorch\\n3. Manually derive the derivative of eq. 8.27, e.g:\\nd\\ndx\\n[ 1\\n1 + 2−1.5x\\n]\\n(8.28)\\n255'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 272, 'page_label': '273'}, page_content='8.2. PROBLEMS\\n4. Implement both the forward pass for the Sigmoid function approximation eq. 8.27 that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19].\\n5. Print the values of the Sigmoid function and the Sigmoid function approximation eq.\\n8.27 for the following vector:\\nv = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] (8.29)\\nTanh\\nPRB-218 \\uf059 CH.PRB- 8.42.\\nThe Hyperbolic tangent nonlinearity, or the tanh function (Fig. 8.23), is a widely used\\nneuron activation function in artiﬁcial neural networks:\\nftanh (x) = sinh(x)\\ncosh(x) = ex − e−x\\nex + e−x (8.30)\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−4,0\\n−2,0\\n2,0\\n4,0\\nx\\nyσ(x) = 4 ∗ tanh x\\n4\\nσ(x) = tanh x\\n4\\nFIGURE 8.23: Examples of two tanh functions.\\n1. Manually derive the derivative of the tanh function.\\n256'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 273, 'page_label': '274'}, page_content='Chapter 8 DEEP LEARNING\\n2. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n3. Use the PyT orch based torch.autograd.F unction class to write a custom Function\\nthat implements the forward and backward passes for the tanh function in Python.\\n4. Name the class T anhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\nPRB-219 \\uf059 CH.PRB- 8.43.\\nThe code snippet in 8.24 makes use of the tanh function.\\n1 import torch\\n2\\n3 nn001 = nn.Sequential(\\n4 nn.Linear(200, 512),\\n5 nn.Tanh(),\\n6 nn.Linear(512, 512),\\n7 nn.Tanh(),\\n8 nn.Linear(512, 10),\\n9 nn.LogSoftmax(dim=1)\\n10 )\\nFIGURE 8.24: A simple NN based on tanh in PyTorch.\\n1. What type of a neural network does nn001 in 8.24 represent?\\n2. How many hidden layers does the layer entitles nn001 have?\\nPRB-220 \\uf059 CH.PRB- 8.44.\\n257'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 274, 'page_label': '275'}, page_content='8.2. PROBLEMS\\nY our friend, a veteran of the DL community claims that MLPs based on tanh activation\\nfunction, have a symmetry around 0 and consequently cannot be saturated. Saturation, so\\nhe claims is a phenomenon typical of the top hidden layers in sigmoid based MLPs. Is he\\nright or wrong?\\nPRB-221 \\uf059 CH.PRB- 8.45.\\nIf we initialize the weights of a tanh based NN, which of the following approaches will\\nlead to the vanishing gradients problem?.\\ni Using the normal distribution, with parameter initialization method as suggested by\\nKaiming [14].\\nii Using the uniform distribution, with parameter initialization method as suggested by\\nXavier Glorot [9].\\niii Initialize all parameters to a constant zero value.\\nPRB-222 \\uf059 CH.PRB- 8.46.\\nY ou friend, who is experimenting with the tanh activation function designed a small\\nCNN with only one hidden layer and a linear output ( 8.25):\\nFIGURE 8.25: A small CNN composed of tanh blocks.\\nHe initialized all the weights and biases (biases not shown for brevity) to zero. What is\\nthe most signiﬁcant design ﬂaw in his architecture?\\nHint: think about back-propagation.\\nReLU\\nPRB-223 \\uf059 CH.PRB- 8.47.\\n258'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 275, 'page_label': '276'}, page_content='Chapter 8 DEEP LEARNING\\nThe rectiﬁed linear unit, or ReLU g(z) = max {0, z} is the default for many CNN archi-\\ntectures. It is deﬁned by the following function:\\nfReLU(x) = max(0 , x) (8.31)\\nOr:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.32)\\n1. In what sense is the ReLU better than traditional sigmoidal activation functions?\\nPRB-224 \\uf059 CH.PRB- 8.48.\\nY ou are experimenting with the ReLU activation function, and you design a small CNN\\n(8.26) which accepts an RGB image as an input. Each CNN kernel is denoted by w.\\nFIGURE 8.26: A small CNN composed of ReLU blocks.\\nWhat is the shape of the resulting tensor W ?\\nPRB-225 \\uf059 CH.PRB- 8.49.\\nName the following activation function where a ∈ (0, 1):\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx if x > 0\\nax otherwise\\n(8.33)\\nSwish\\n259'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 276, 'page_label': '277'}, page_content='8.2. PROBLEMS\\nPRB-226 \\uf059 CH.PRB- 8.50.\\nIn many interviews, you will be given a paper that you have never encountered before,\\nand be required to read and subsequently discuss it. Please read Searching for Activation\\nFunctions [21] before attempting the questions in this question.\\n1. In [21], researchers employed an automatic pipeline for searching what exactly?\\n2. What types of functions did the researchers include in their search space?\\n3. What were the main ﬁndings of their research and why were the results surprising?\\n4. Write the formulae for the Swish activation function.\\n5. Plot the Swish activation function.\\n8.2.6 Performance Metrics\\nComparing different machine learning models, tuning hyper parameters and learn-\\ning rates, ﬁnding optimal augmentations, are all important steps in ML research. Typ-\\nically our goal is to ﬁnd the best model with the lowest errors on both the training\\nand validation sets. To do so we need to be able to measure the performance of each\\napproach/model/parameter setting etc. and compare those measures. For valuable\\nreference, read: “Evaluating Learning Algorithms: A Classiﬁcation Perspective ” [22]\\nConfusion matrix, precision, recall\\nPRB-227 \\uf059 CH.PRB- 8.51.\\nY ou design a binary classiﬁer for detecting the presence of malfunctioning temperature\\nsensors. Non-malfunctioning (N) devices are the majority class in the training corpus. While\\nrunning inference on an unseen test-set, you discover that the Confusion Metrics (CM) has\\nthe following values 8.27:\\n260'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 277, 'page_label': '278'}, page_content='Chapter 8 DEEP LEARNING\\nPredicted\\nP N\\nActual P 12 7\\nN 24 1009\\nFIGURE 8.27: A confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices.\\n1. Find: TP , TN, FP , FN and correctly label the numbers in table 8.27.\\n2. What is the accuracy of the model?\\n3. What is the precision of the model?\\n4. What is the recall of the model?\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\nFIGURE 8.28: Receiver Operating Characteristic curve.\\n261'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 278, 'page_label': '279'}, page_content='8.2. PROBLEMS\\nPRB-228 \\uf059 CH.PRB- 8.52.\\nComplete the following sentences:\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween [...] and [...].\\n2. It is a plot of [...] vs. the [...]. In place of [...], one could also use [...] which are essen-\\ntially {1 - ‘true negatives’ }.\\n3. A typical ROC curve has a concave shape with [...] as the beginning and [...] as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely con-\\nfused and cannot at all distinguish between the two classes, has an AUC of [...] which\\nis the [...] line in an ROC curve plot.\\nPRB-229 \\uf059 CH.PRB- 8.53.\\nThe code 8.30 and Figure 8.29 are the output from running XGBOOST for a binary\\nclassiﬁcation task.\\nFIGURE 8.29: RUC AUC\\n262'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 279, 'page_label': '280'}, page_content=\"Chapter 8 DEEP LEARNING\\n1 XGBClassifier(base_score=0.5, colsample_bylevel =1,\\ncolsample_bytree=0.5,↪→\\n2 gamma=0.017, learning_rate =0.15, max_delta_step =0, max_depth =9,\\n3 min_child_weight=3, missing =None, n_estimators =1000, nthread =-1,\\n4 objective='binary:logistic' , reg_alpha =0, reg_lambda =1,\\n5 scale_pos_weight=1, seed =0, silent =1,\\nsubsample=0.9)shape:(316200, 6)↪→\\n6\\n7 >ROC AUC: 0.984439608912\\n8 >LOG LOSS: 0.0421598347226\\nFIGURE 8.30: XGBOOST for binary classiﬁcation.\\nHow would you describe the results of the classiﬁcation?.\\n8.2.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nPRB-230 \\uf059 CH.PRB- 8.54.\\nGiven an input of size of n × n, ﬁlters of size f × f and a stride of s with padding of p,\\nwhat is the output dimension?\\nPRB-231 \\uf059 CH.PRB- 8.55.\\nReferring the code snippet in Fig. ( 8.31), answer the following questions regarding the\\nVGG11 architecture [25]:\\n263\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 280, 'page_label': '281'}, page_content='8.2. PROBLEMS\\n1 import torchvision\\n2 import torch\\n3 def main():\\n4 vgg11 = torchvision.models.vgg11(pretrained=True)\\n5 vgg_layers = vgg11.features\\n6 for param in vgg_layers.parameters():\\n7 param.requires_grad = False\\n8\\n9 example = [torch.rand(1, 3, 224, 224),\\n10 torch.rand(1, 3, 512, 512),\\n11 torch.rand(1, 3, 704, 1024)]\\n12 vgg11.eval()\\n13 for e in example:\\n14 out=vgg_layers(e)\\n15 print(out.shape)\\n16 if __name__ == \"__main__\":\\n17 main()^^I^^I\\nFIGURE 8.31: CNN arithmetics on the VGG11 CNN model.\\n1. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the VGG11 CNN to the respective input.\\n2. Choose the correct option. The last layer of the VGG11 architecture is:\\ni Conv2d\\nii MaxPool2d\\niii ReLU\\nPRB-232 \\uf059 CH.PRB- 8.56.\\nStill referring the code snippet in Fig. ( 8.31), and speciﬁcally to line 7, the code is\\namended so that the line is replaced by the line:\\nvgg_layers=vgg11.features[:3] .\\n264'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 281, 'page_label': '282'}, page_content='Chapter 8 DEEP LEARNING\\n1. What type of block is now represented by the new line? Print it using PyT orch.\\n2. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the block:\\nvgg_layers=vgg11.features[:3] to the respective input.\\nPRB-233 \\uf059 CH.PRB- 8.57.\\nT able (8.1) presents an incomplete listing of the of the VGG11 architecture [ 25]. As\\ndepicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters) are\\npresented.\\nLayer #Filters\\nconv4_3 512\\nfc6 4,096\\nfc7 4,096\\noutput 1,000\\nTABLE 8.1: Incomplete listing of the VGG11 architecture.\\nComplete the missing parts regarding the dimensions and arithmetics of the VGG11\\nCNN architecture:\\n1. The VGG11 architecture consists of [...] convolutional layers.\\n2. Each convolutional layer is followed by a [...] activation function, and ﬁve [...] opera-\\ntions thus reducing the preceding feature map size by a factor of [...].\\n3. All convolutional layers have a [...] kernel.\\n4. The ﬁrst convolutional layer produces [...] channels.\\n5. Subsequently as the network deepens, the number of channels [...] after each [...] oper-\\nation until it reaches [...].\\n265'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 282, 'page_label': '283'}, page_content='8.2. PROBLEMS\\nDropout\\nPRB-234 \\uf059 CH.PRB- 8.58.\\nA Dropout layer [26] (Fig. 8.32) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 8.32: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [20], a Dropout layer is declared as follows ( 8.2):\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 8.2: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 8.2) indicates that the probability of zeroing an\\nelement is 0.2.\\n266'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 283, 'page_label': '284'}, page_content='Chapter 8 DEEP LEARNING\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 8.33: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 8.32). Here, for illustration purposes, all four\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\n1. Y ou are interested in the proportionθ of dropped-out neurons. Assume that the chance\\nof drop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the\\nposterior of θ.\\n2. Describe the similarities of dropout to bagging.\\nPRB-235 \\uf059 CH.PRB- 8.59.\\nA co-worker claims he discovered an equivalence theorem where, two consecutive Dro-\\npout layers [26] can be replaced and represented by a single Dropout layer 8.34.\\nFIGURE 8.34: Two consecutive Dropout layers\\nHi realized two consecutive layers in PyT orch [20], declared as follows ( 8.3):\\n267'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 284, 'page_label': '285'}, page_content='8.2. PROBLEMS\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Sequential(\\n4 nn.Conv2d(1024, 32),\\n5 nn.ReLU(),\\n6 nn.Dropout(p=P, inplace =True),\\n7 nn.Dropout(p=Q, inplace =True)\\n8 )\\nCODE 8.3: Consequtive dropout in PyTorch\\nWhere nn.Dropout(0.1) (Line #6 in 8.3) indicates that the probability of zeroing an\\nelement is 0.1.\\n1. What do you think about his idea, is he right or wrong?\\n2. Either prove that he is right or provide a single example that refutes his theorem.\\nConvolutional Layer\\nThe convolution layer is probably one of the most important layers in the theory and\\npractice of modern deep learning and computer vision in particular.\\nTo study the optimal number of convolutional layers for the classiﬁcation of two\\ndifferent types of the Ebola virus, a researcher designs a binary classiﬁcation pipeline\\nusing a small CNN with only a few layers ( 8.35):\\n268'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 285, 'page_label': '286'}, page_content='Chapter 8 DEEP LEARNING\\nFIGURE 8.35: A CNN based classiﬁcation system.\\nAnswer the following questions while referring to ( 8.35):\\nPRB-236 \\uf059 CH.PRB- 8.60.\\nIf he uses the following ﬁlter for the convolutional operation, what would be the resulting\\ntensor after the application of the convolutional layer?\\nFIGURE 8.36: A small ﬁlter for a CNN\\nPRB-237 \\uf059 CH.PRB- 8.61.\\nWhat would be the resulting tensor after the application of the ReLU layer ( 8.37)?\\n269'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 286, 'page_label': '287'}, page_content='8.2. PROBLEMS\\nFIGURE 8.37: The result of applying the ﬁlter.\\nPRB-238 \\uf059 CH.PRB- 8.62.\\nWhat would be the resulting tensor after the application of the MaxPool layer ( 8.78)?\\nPooling Layers\\nA pooling layer transforms the output of a convolutional layer, and neurons in a pool-\\ning layer accept the outputs of a number of adjacent feature maps and merge their\\noutputs into a single number.\\nMaxPooling\\nPRB-239 \\uf059 CH.PRB- 8.63.\\nThe following input 8.38 is subjected to a MaxPool2D(2,2) operation having 2 × 2 max-\\npooling ﬁlter with a stride of 2 and no padding at all.\\n270'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 287, 'page_label': '288'}, page_content='Chapter 8 DEEP LEARNING\\nFIGURE 8.38: Input to MaxPool2d operation.\\nAnswer the following questions:\\n1. What is the most common use of max-pooling layers?\\n2. What is the result of applying the MaxPool2d operation on the input?\\nPRB-240 \\uf059 CH.PRB- 8.64.\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and evaluate its behaviour during inference:\\n271'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 288, 'page_label': '289'}, page_content='8.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 8.4: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n272'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 289, 'page_label': '290'}, page_content='Chapter 8 DEEP LEARNING\\nFIGURE 8.39: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet a second MaxPool2D(2,2).\\nWhat is the resulting tensor shape after running line 9? and line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\nBatch normalization, Gaussian PDF\\nRecommended readings for this topic are “ Batch Normalization: Accelerating Deep Net-\\nwork T raining by Reducing Internal Covariate Shift ” [16] and “ Delving deep into rectiﬁers:\\nSurpassing human-level performance on imagenet classiﬁcation ” [14].\\nA discussion of batch normalization (BN) would not be complete without a discus-\\nsion of the Gaussian normal distribution. Though it would be instructive to develop\\nthe forward and backwards functions for a BN operation from scratch, it would also\\nbe quite complex. As an alternative we discuss several aspects of the BN operation\\nwhile expanding on the Gaussian distribution.\\n273'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 290, 'page_label': '291'}, page_content='8.2. PROBLEMS\\nThe Gaussian distribution\\nPRB-241 \\uf059 CH.PRB- 8.65.\\n1. What is batch normalization?\\n2. The normal distribution is deﬁned as follows:\\nP (x) = 1\\nσ\\n√\\n2π e−(x−µ)2/2σ2\\n(8.34)\\nGenerally i.i.d. X ∼ N (µ, σ2) however BN uses the standard normal distribution.\\nWhat mean and variance does the standard normal distribution have?\\n3. What is the mathematical process of normalization?\\n4. Describe, how normalization works in BN.\\nPRB-242 \\uf059 CH.PRB- 8.66.\\nIn python, the probability density function for a normal distribution is given by 8.40:\\n1 import scipy\\n2 scipy.stats.norm.pdf(x, mu, sigma)\\nFIGURE 8.40: Normal distribution in Python.\\n1. Without using Scipy, implement the normal distribution from scratch in Python.\\n2. Assume, you want to back propagate on the normal distribution, and therefore you\\nneed the derivative. Using Scipy write a function for the derivative.\\nBN\\nPRB-243 \\uf059 CH.PRB- 8.67.\\n274'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 291, 'page_label': '292'}, page_content='Chapter 8 DEEP LEARNING\\nY our friend, a novice data scientist, uses an RGB image ( 8.41) which he then subjects to\\nBN as part of training a CNN.\\nFIGURE 8.41: A convolution and BN applied to an RGB image.\\n1. Help him understand, during BN, is the normalization applied pixel-wise or per colour\\nchannel?\\n2. In the PyT orch implementation, he made a silly mistake 8.42, help him identify it:\\n275'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 292, 'page_label': '293'}, page_content='8.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class BNl001(nn.Module):\\n4 def __init__(self):\\n5 super(BNl001, self).__init__()\\n6 self.cnn = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 64, kernel_size =3, padding =2),\\n8 )\\n9 self.math= torch.nn.Sequential(\\n10 torch.nn.BatchNorm2d(32),\\n11 torch.nn.PReLU(),\\n12 torch.nn.Dropout2d(0.05)\\n13 )\\n14 def forward(self, x):\\n15 ...\\nFIGURE 8.42: A mistake in a CNN\\nTheory of CNN design\\nPRB-244 \\uf059 CH.PRB- 8.68.\\nTrue or false: An activation function applied after a Dropout, is equivalent to an activ-\\nation function applied before a dropout.\\nPRB-245 \\uf059 CH.PRB- 8.69.\\nWhich of the following core building blocks may be used to construct CNNs? Choose all\\nthe options that apply:\\ni Pooling layers\\nii Convolutional layers\\niii Normalization layers\\niv Non-linear activation function\\n276'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 293, 'page_label': '294'}, page_content='Chapter 8 DEEP LEARNING\\nv Linear activation function\\nPRB-246 \\uf059 CH.PRB- 8.70.\\nY ou are designing a CNN which has a single BN layer. Which of the following core CNN\\ndesigns are valid? Choose all the options that apply:\\ni CONV → act → BN → Dropout → . . .\\nii CONV → act → Dropout → BN → . . .\\niii CONV → BN → act → Dropout → . . .\\niv BN → CONV → act → Dropout → . . .\\nv CONV → Dropout → BN → act → . . .\\nvi Dropout → CONV → BN → act → . . .\\nPRB-247 \\uf059 CH.PRB- 8.71.\\nThe following operator is known as the Hadamard product:\\nOUT = A ⊙ B (8.35)\\nWhere:\\n(A ⊙ B)i,j := (A)i,j(B)i,j (8.36)\\nA scientist, constructs a Dropout layer using the following algorithm:\\ni Assign a probability of p for zeroing the output of any neuron.\\nii Accept an input tensor T , having a shape S\\niii Generate a new tensor T ‘∈ {0, 1}S\\niv Assign each element in T ‘a randomly and independently sampled value from a Bernoulli\\ndistribution:\\nT ‘i ∼ B(1, p) (8.37)\\n277'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 294, 'page_label': '295'}, page_content='8.2. PROBLEMS\\nv Calculate the OU T tensor as follows:\\nOUT = T ‘⊙ T (8.38)\\nY ou are surprised to ﬁnd out that his last step is to multiply the output of a dropout layer\\nwith:\\n1\\n1 − p (8.39)\\nExplain what is the purpose of multiplying by the term 1\\n1−p .\\nPRB-248 \\uf059 CH.PRB- 8.72.\\nVisualized in (8.43) from a high-level view, is an MLP which implements a well-known\\nidiom in DL.\\nFIGURE 8.43: A CNN block\\n1. Name the idiom.\\n2. What can this type of layer learn?\\n3. A fellow data scientist suggests amending the architecture as follows ( 8.44)\\n278'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 295, 'page_label': '296'}, page_content='Chapter 8 DEEP LEARNING\\nFIGURE 8.44: A CNN block\\nName one disadvantage of this new architecture.\\n4. Name one CNN architecture where the input equals the output.\\nCNN residual blocks\\nPRB-249 \\uf059 CH.PRB- 8.73.\\nAnswer the following questions regarding residual networks ([ 13]).\\n1. Mathematically, the residual block may be represented by:\\ny = x + F(x) (8.40)\\nWhat is the function F?\\n2. In one sentence, what was the main idea behind deep residual networks (ResNets) as\\nintroduced in the original paper ([ 13])?\\nPRB-250 \\uf059 CH.PRB- 8.74.\\nY our friend was thinking about ResNet blocks, and tried to visualize them in ( 8.45).\\n279'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 296, 'page_label': '297'}, page_content='8.2. PROBLEMS\\nFIGURE 8.45: A resnet CNN block\\n1. Assuming a residual of the form y = x + F(x), complete the missing parts in Fig.\\n(8.45).\\n2. What does the symbol ⊕ denotes?\\n3. A fellow data scientist, who had coffee with you said that residual blocks may compute\\nthe identity function. Explain what he meant by that.\\n8.2.8 Training, hyperparameters\\nHyperparameter optimization\\nPRB-251 \\uf059 CH.PRB- 8.75.\\nA certain training pipeline for the classiﬁcation of large images (1024 x 1024) uses the\\nfollowing Hyperparameters (8.46):\\n280'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 297, 'page_label': '298'}, page_content=\"Chapter 8 DEEP LEARNING\\nHyperparameter Value\\nInitial learning rate 0.1\\nWeight decay 0.0001\\nMomentum 0.9\\nBatch size 1024\\n1 optimizer = optim.SGD(model.parameters(), lr =0.1,\\n2 momentum=0.9,\\n3 weight_decay=0.0001)\\n4 ...\\n5 trainLoader = torch.utils.data.DataLoader(\\n6 datasets.LARGE('../data' , train =True, download =True,\\n7 transform=transforms.Compose([\\n8 transforms.ToTensor(),\\n9 ])),\\n10 batch\\\\_size=1024, shuffle =True)\\nFIGURE 8.46: Hyperparameters.\\nIn your opinion, what could possibly go wrong with this training pipeline?\\nPRB-252 \\uf059 CH.PRB- 8.76.\\nA junior data scientist in your team who is interested in Hyperparameter tuning, wrote\\nthe following code ( 8.5) for spiting his corpus into two distinct sets and ﬁtting an LR model:\\n281\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 298, 'page_label': '299'}, page_content=\"8.2. PROBLEMS\\n1 from sklearn.model_selection import train_test_split\\n2 dataset = datasets.load_iris()\\n3 X_train, X_test, y_train, y_test =\\n4 train_test_split(dataset.data, dataset .target, test_size =0.2)\\n5 clf = LogisticRegression(data_norm=12)\\n6 clf.fit(X_train, y_train)\\nCODE 8.5: Train and Validation split.\\nHe then evaluated the performance of the trained model on the Xtest set.\\n1. Explain why his methodology is far from perfect.\\n2. Help him resolve the problem by utilizing a difference splitting methodology.\\n3. Y our friend now amends the code an uses:\\n1 clf = GridSearchCV(method, params, scoring ='roc_auc' , cv =5)\\n2 clf.fit(train_X, train_y)\\nExplain why his new approach may work better.\\nPRB-253 \\uf059 CH.PRB- 8.77.\\nIn the context of Hyperparameter optimization, explain the difference between grid search\\nand random search.\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nPRB-254 \\uf059 CH.PRB- 8.78.\\n282\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 299, 'page_label': '300'}, page_content='Chapter 8 DEEP LEARNING\\nNon-invasive methods that forecast the existence of lung nodules ( 8.47), is a precursor\\nto lung cancer. Y et, in spite of acquisition standardization attempts, the manual detection of\\nlung nodules still remains predisposed to inter mechanical and observer variability. What is\\nmore, it is a highly laborious task.\\nFIGURE 8.47: Pulmonary nodules.\\nIn the majority of cases, the training data is manually labelled by radiologists who make\\nmistakes. Imagine you are working on a classiﬁcation problem and hire two radiologists for\\nlung cancer screening based on low-dose CT (LDCT). Y ou ask them to label the data, the\\nﬁrst radiologist labels only the training set and the second the validation set. Then you hire\\na third radiologist to label the test set.\\n1. Do you think there is a design ﬂow in the curation of the data sets?\\n2. A friend suggests that all there radiologists read all the scans and label them independ-\\nently thus creating a majority vote. What do you think about this idea?\\nValidation curve ACC\\nPRB-255 \\uf059 CH.PRB- 8.79.\\nAnswer the following questions regarding the validation curve visualized in ( 8.48):\\n283'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 300, 'page_label': '301'}, page_content='8.2. PROBLEMS\\n20 40 60 80 100\\n0,2\\n0,4\\n0,6\\n0,8\\nEPOCH\\nERR V ALID\\nTRAIN\\nFIGURE 8.48: A validation curve.\\n1. Describe in one sentence, what is a validation curve.\\n2. Which hyperparameter is being used in the curve?\\n3. Which well-known metric is being used in the curve? Which other metric is commonly\\nused?\\n4. Which positive phenomena happens when we train a NN longer?\\n5. Which negative phenomena happens when we train a NN longer than we should?\\n6. How this negative phenomena is reﬂected in 8.48?\\nValidation curve Loss\\nPRB-256 \\uf059 CH.PRB- 8.80.\\nRefer to the validation log-loss curve visualized in ( 8.49) and answer the following ques-\\ntions:\\n284'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 301, 'page_label': '302'}, page_content='Chapter 8 DEEP LEARNING\\nFIGURE 8.49: Log-loss function curve.\\n1. Name the phenomena that starts happening right after the marking by the letter E and\\ndescribe why it is happening.\\n2. Name three different weight initialization methods.\\n3. What is the main idea behind these methods?\\n4. Describe several ways how this phenomena can be alleviated.\\n5. Y our friend, a fellow data-scientist, inspects the code and sees the following Hyper-\\nparameters are being used:\\nHyperparameter Value\\nInitial LR 0.00001\\nMomentum 0.9\\nBatch size 1024\\nHe then tells you that the learning rate (LR) is constant and suggests amending the\\ntraining pipeline by adding the following code ( 8.50):\\n285'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 302, 'page_label': '303'}, page_content='8.2. PROBLEMS\\n1 scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt)\\nFIGURE 8.50: A problem with the log-loss curve.\\nWhat do you think about his idea?\\n6. Provide one reason against the use of the log-loss curve.\\nInference\\nPRB-257 \\uf059 CH.PRB- 8.81.\\nY ou ﬁnished training a face recognition algorithm, which uses a feature vector of 128\\nelements. During inference, you notice that the performance is not that good. A friend tells\\nyou that in computer vision faces are gathered in various poses and perspectives. He there-\\nfore suggests that during inference you would augment the incoming face ﬁve times, run\\ninference on each augmented image and then fuse the output probability distributions by\\naveraging.\\n1. Name the method he is suggesting.\\n2. Provide several examples of augmentation that you might use during inference.\\nPRB-258 \\uf059 CH.PRB- 8.82.\\nComplete the sentence: If the training loss is insigniﬁcant while the test loss is signiﬁc-\\nantly higher, the network has almost certainly learned features which are not present in an\\n[...] set. This phenomena is referred to as [...]\\n8.2.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nPRB-259 \\uf059 CH.PRB- 8.83.\\nWhat does the term stochastic in SGD actually mean? Does it use any random number\\n286'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 303, 'page_label': '304'}, page_content='Chapter 8 DEEP LEARNING\\ngenerator?\\nPRB-260 \\uf059 CH.PRB- 8.84.\\nExplain why in SGD, the number of epochs required to surpass a certain loss threshold\\nincreases as the batch size decreases?\\nMomentum\\nPRB-261 \\uf059 CH.PRB- 8.85.\\nHow does momentum work? Explain the role of exponential decay in the gradient descent\\nupdate rule.\\nPRB-262 \\uf059 CH.PRB- 8.86.\\nIn your training loop, you are using SGD and a logistic activation function which is\\nknown to suffer from the phenomenon of saturated units.\\n1. Explain the phenomenon.\\n2. Y ou switch to using the tanh activation instead of the logistic activation, in your\\nopinion does the phenomenon still exists?\\n3. In your opinion, is using the tanh function makes the SGD operation to converge\\nbetter?\\nPRB-263 \\uf059 CH.PRB- 8.87.\\nWhich of the following statements holds true?\\ni In stochastic gradient descent we ﬁrst calculate the gradient and only then adjust weights\\nfor each data point in the training set.\\nii In stochastic gradient descent, the gradient for a single sample is not so different from\\nthe actual gradient, so this gives a more stable value, and converges faster.\\niii SGD usually avoids the trap of poor local minima.\\n287'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 304, 'page_label': '305'}, page_content='8.2. PROBLEMS\\niv SGD usually requires more memory.\\nNorms, L1, L2\\nPRB-264 \\uf059 CH.PRB- 8.88.\\nAnswer the following questions regarding norms.\\n1. Which norm does the following equation represent?\\n|x1 − x2| + |y1 − y2| (8.41)\\n2. Which formulae does the following equation represent?\\n\\ued6a\\ued6b\\ued6b√\\nn∑\\ni=1\\n(xi − yi)2 (8.42)\\n3. When your read that someone penalized the L2 norm, was the euclidean or the Man-\\nhattan distance involved?\\n4. Compute both the Euclidean and Manhattan distance of the vectors:\\nx1 = [6 , 1, 4, 5] and x2 = [2 , 8, 3, −1].\\nPRB-265 \\uf059 CH.PRB- 8.89.\\nY ou are provided with a pure Python code implementation of the Manhattan distance\\nfunction (8.51):\\n1 from scipy import spatial\\n2 x1=[6,1,4,5]\\n3 x2=[2,8,3,-1]\\n4 cityblock = spatial.distance.cityblock(x1, x2)\\n5 print(\"Manhattan:\", cityblock)\\nFIGURE 8.51: Manhattan distance function.\\n288'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 305, 'page_label': '306'}, page_content='Chapter 8 DEEP LEARNING\\nIn many cases, and for large vectors in particular, it is better to use a GPU for imple-\\nmenting numerical computations. PyT orch has full support for GPU’s (and its my favourite\\nDL library ... ), use it to implement the Manhattan distance function on a GPU.\\nPRB-266 \\uf059 CH.PRB- 8.90.\\nY our friend is training a logistic regression model for a binary classiﬁcation problem\\nusing the L2 loss for optimization. Explain to him why this is a bad choice and which loss he\\nshould be using instead.\\n8.3 Solutions\\n8.3.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nSOL-177 \\uf14b CH.SOL- 8.1.\\nThe ﬁrst approach is a leave-one-out CV (LOOCV) and the second is a K-fold cross-\\nvalidation approach. \\x04\\nSOL-178 \\uf14b CH.SOL- 8.2.\\nCross Validation is a cornerstone in machine learning, allowing data scientists to take\\nfull gain of restricted training data. In classiﬁcation, effective cross validation is essential to\\nmaking the learning task efﬁcient and more accurate. A frequently used form of the technique\\nis identiﬁed as K-fold cross validation. Using this approach, the full data set is divided into K\\nrandomly selected folds, occasionally stratiﬁed, meaning that each fold has roughly the\\nsame class distribution as the overall data set . Subsequently, for each fold, all the other\\n(K − 1) folds are used for training, while the present fold is used for testing. This process\\nguarantees that sets used for testing, are not used by a classiﬁer that also saw it during\\ntraining.\\n\\x04\\nK-Fold CV\\n289'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 306, 'page_label': '307'}, page_content='8.3. SOLUTIONS\\nSOL-179 \\uf14b CH.SOL- 8.3.\\nT rue. We never utilize the test set during a K-fold CV process. \\x04\\nSOL-180 \\uf14b CH.SOL- 8.4.\\nT rue. This is the average of the individual errors of K estimates of the test error:\\nMSE1, . . . ,MSEk (8.43)\\n\\x04\\nSOL-181 \\uf14b CH.SOL- 8.5.\\nThe correct answer is: A 5-fold cross-validation approach results in 5-different model in-\\nstances being ﬁtted. It is a common misconception to think that in a K-fold approach the same\\nmodel instance is repeatedly used. We must create a new model instance in each fold. \\x04\\nSOL-182 \\uf14b CH.SOL- 8.6.\\nThe correct answer is: we compute the cross-validation performance as the arithmetic\\nmean over the K performance estimates from the validation sets. \\x04\\nStratification\\nSOL-183 \\uf14b CH.SOL- 8.7.\\nThe correct answer is: 3-fold CV . A k-fold cross-validation is a special case of cross-\\nvalidation where we iterate over a dataset set k times. In each round, we split the dataset\\ninto k parts: one part is used for validation, and the remaining k − 1 parts are merged into\\na training subset for model evaluation. Stratiﬁcation is used to balance the classes in the\\ntraining and validation splits in cases where the corpus is imbalanced. \\x04\\nLOOCV\\nSOL-184 \\uf14b CH.SOL- 8.8.\\n1. T rue: In (LOOCV) K = N the full sample size.\\n2. False: There is no way of a-priori ﬁnding an optimal value for K, and the relationship\\n290'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 307, 'page_label': '308'}, page_content='Chapter 8 DEEP LEARNING\\nbetween the actual sample size and the resulting accuracy is unknown.\\n\\x04\\n8.3.2 Convolution and correlation\\nThe convolution operator\\nSOL-185 \\uf14b CH.SOL- 8.9.\\n1. This is the deﬁnition of a convolution operation on the two signals f and g.\\n2. In image processing, the term g(t) represents a ﬁltering kernel.\\n\\x04\\nSOL-186 \\uf14b CH.SOL- 8.10.\\n1. T rue. These operations have two key features: they are shift invariant, and they are\\nlinear. Shift invariance means that we perform the same operation at every point in the\\nimage. Linearity means that this operation is linear, that is, we replace every pixel with\\na linear combination of its neighbours\\n2. T rue. See for instance Eq. (8.3).\\n3. T rue.\\n\\x04\\nThe correlation operator\\nSOL-187 \\uf14b CH.SOL- 8.11.\\n1. T rue.\\n2. T rue.\\n\\x04\\n291'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 308, 'page_label': '309'}, page_content='8.3. SOLUTIONS\\nSOL-188 \\uf14b CH.SOL- 8.12.\\nA convolution operation is just like correlation, except that we ﬂip over the ﬁlter both\\nhorizontally and vertically before correlating.\\nf (x, y) ⊗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf ∗(m, n)h(x + m, y + n) (8.44)\\n\\x04\\nPadding and stride\\nRecommended reading : “ A guide to convolution arithmetic for deep learning by Vincent\\nDumoulin and Francesco Visin (2016) ” [22].\\nSOL-189 \\uf14b CH.SOL- 8.13.\\n1. The Valid padding only uses values from the original input; however, when the data\\nresolution is not a multiple of the stride, some boundary values are ignored entirely in\\nthe feature calculation.\\n2. The Same padding ensures that every input value is included, but also adds zeros near\\nthe boundary which are not in the original input.\\n\\x04\\nSOL-190 \\uf14b CH.SOL- 8.14.\\nT rue. Contrast this with the two other types of convolution operations. \\x04\\nSOL-191 \\uf14b CH.SOL- 8.15.\\n⌊\\nK − θ\\nθ\\n⌋\\n+ 1 ×\\n⌊\\nn − θ\\nθ\\n⌋\\n+ 1 (8.45)\\n\\x04\\nSOL-192 \\uf14b CH.SOL- 8.16.\\n292'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 309, 'page_label': '310'}, page_content='Chapter 8 DEEP LEARNING\\nA is the correct choice. \\x04\\nSOL-193 \\uf14b CH.SOL- 8.17.\\nA represents the V ALID mode while B represents the SAME mode. \\x04\\nSOL-194 \\uf14b CH.SOL- 8.18.\\n1. The resulting output has a shape of 4 × 4.\\n2. Convolution operation\\n[[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]]\\n[[ 2. 0. -2.]\\n[ 2. 0. -2.]\\n[ 2. 0. -2.]]\\n3. By deﬁnition, convolutions in the valid mode, reduce the size of the resulting input\\ntensor.\\n[[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]]\\n\\x04\\nKernels and filters\\nSOL-195 \\uf14b CH.SOL- 8.19.\\n293'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 310, 'page_label': '311'}, page_content='8.3. SOLUTIONS\\n1. Flipping by 180 degrees we get:\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 −1\\n1 1\\n\\uf8f9\\n\\uf8fb (8.46)\\n2. The Sobel ﬁlter which is being frequently used for edge detection in classical computer\\nvision.\\n\\x04\\nSOL-196 \\uf14b CH.SOL- 8.20.\\nThe resulting complexity is given by:\\nK 2wh (8.47)\\n\\x04\\nConvolution and correlation in python\\nSOL-197 \\uf14b CH.SOL- 8.21.\\n1. Convolution operation:\\n294'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 311, 'page_label': '312'}, page_content='Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 def convolution(A,B):\\n3 l_A = np.size(A)\\n4 l_B = np.size(B)\\n5 C = np.zeros(l_A + l_B -1)\\n6\\n7 for m in np.arange(l_A):\\n8 for n in np.arange(l_B):\\n9 C[m+n] = C[m+n] + A[m]*B[n]\\n10\\n11 return C\\nFIGURE 8.52: Convolution and correlation in python\\n2. Correlation operation:\\n1 def crosscorrelation(A,B):\\n2 return convolution(np.conj(A),B[::-1])\\nFIGURE 8.53: Convolution and correlation in python\\n\\x04\\nSeparable convolutions\\nSOL-198 \\uf14b CH.SOL- 8.22.\\n1. No.Since images are usually stored as discrete pixel values one would have to use a\\ndiscrete approximation of the Gaussian function on the ﬁltering mask before performing\\nthe convolution.\\n2. No.\\n295'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 312, 'page_label': '313'}, page_content='8.3. SOLUTIONS\\n3. Y es it is separable, a factor that has great implications. For instance, separability means\\nthat a 2D convolution can be reduced to two consequent 1D convolutions reducing the\\ncomputational runtime from O (n2 m2) to O (n2 m).\\n\\x04\\n8.3.3 Similarity measures\\nImage, text similarity\\nSOL-199 \\uf14b CH.SOL- 8.23.\\nThe algorithm presented in ( 8.12) normalizes the input vector. This is usually done prior\\nto applying any other method to the vector or before persisting a vector to a database of FVs.\\n\\x04\\nSOL-200 \\uf14b CH.SOL- 8.24.\\n1. The algorithm presented in ( 8.1) is one of the most commonly used image similarity\\nmeasures and is entitled cosine similarity. It can be applied to any pair of images.\\n2. The mathematical formulae behind it is:\\nThe cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and v = {v1, v2, . . . , vN } is deﬁned as:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures the cosine of the angle\\nbetween the vectors irrespective of their magnitude. It is calculated as the dot product\\nof two numeric vectors, and is normalized by the product of the length of the vectors.\\n3. The minimum and maximum values it can return are 0 and 1 respectively. Thus, a\\ncosine similarity value which is close to 1 indicated a very high similarity while that\\nclose to 0 indicates a very low similarity.\\n4. It represents the negative distance in Euclidean space between the vectors.\\n296'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 313, 'page_label': '314'}, page_content='Chapter 8 DEEP LEARNING\\n\\x04\\nJacard similarity\\nSOL-201 \\uf14b CH.SOL- 8.25.\\n1. The general formulae for the Jaccard similarity of two sets is given as follows:\\nJ(A, B) = |A ∩ B|\\n|A ∪ B|\\n2. That is, the ratio of the size of the intersection of A and B to the size of their union.\\n3. The Jaccard similarity equals:\\n2\\n7\\n4. Given (8.13)\\nFor the three combinations of pairs above, we have\\nJ({11, 16, 17}, {12, 14, 16, 18}) = 1\\n6\\nJ({11, 12, 13, 14, 15}, {11, 16, 17}) = 1\\n7\\nJ({11, 12, 13, 14, 15}, {12, 14, 16, 18}) = 2\\n7\\n\\x04\\nThe Kullback-Leibler Distance\\nSOL-202 \\uf14b CH.SOL- 8.26.\\nEach KLD corresponds to the deﬁnition of:\\ni Jensen [1]\\n297'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 314, 'page_label': '315'}, page_content='8.3. SOLUTIONS\\nii Bennet [2]\\niii Bigi [3]\\niv Ziv [29]\\n\\x04\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nSOL-203 \\uf14b CH.SOL- 8.27.\\nA Hashing function ( 8.54) maps a value into a constant length string that can be com-\\npared with other hashed values.\\nFIGURE 8.54: The idea of hashing\\nThe idea behind hashing is that items are hashed into buckets, such that similar items\\nwill have a higher probability of hashing into the same buckets.\\nThe goal of MinHash is to compute the Jaccard similarity without actually computing the\\nintersection and union of the sets, which would be slower. The main idea behind MinHash\\nis to devise a signature scheme such that the probability that there is a match between the\\nsignatures of two sets, S1 and S2, is equal to the Jaccard measure [ 12].\\n\\x04\\n298'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 315, 'page_label': '316'}, page_content='Chapter 8 DEEP LEARNING\\nSOL-204 \\uf14b CH.SOL- 8.28.\\nLocality-Sensitive Hashing (LSH) is a method which is used for determining which items\\nin a given set are similar. Rather than using the naive approach of comparing all pairs of items\\nwithin a set, items are hashed into buckets, such that similar items will be more likely to hash\\ninto the same buckets.\\n\\x04\\nSOL-205 \\uf14b CH.SOL- 8.29.\\nMaximise.\\n\\x04\\n8.3.4 Perceptrons\\nThe Single Layer Perceptron\\nSOL-206 \\uf14b CH.SOL- 8.30.\\nAnswer: one, one, feedback.\\n\\x04\\nSOL-207 \\uf14b CH.SOL- 8.31.\\n1. T rue.\\n2. T rue.\\n3.\\nC(w, b) = 1\\n2n\\n∑\\nx\\n∥y(x) − a(x, w, b)∥2 (8.48)\\nwhere w denotes the collection of all weights in the network, b all the biases, n is the\\ntotal number of training inputs and a(x, w, b) is the vector of outputs from the network\\nwhich has weights w, biases b and the input x.\\n4.\\narg min\\nw,b\\nC(w, b). (8.49)\\n5. Gradient descent.\\n299'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 316, 'page_label': '317'}, page_content='8.3. SOLUTIONS\\n6. The gradient.\\n7. Stochastic gradient descent. Batch size. Back-propagation.\\n\\x04\\nThe Multi Layer Perceptron\\nSOL-208 \\uf14b CH.SOL- 8.32.\\n1. This operation is a dot product with the given weights. Therefore:\\nout = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 = −0.164 (8.50)\\n2. This operation (sum) is a dot product with the given weights and with the given bias\\nadded. Therefore:\\nout1 = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 + 0.001 = −0.165 (8.51)\\n3. Code snippet 8.55 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 # .type(torch.FloatTensor)\\n3 x= torch.tensor([0.9,0.7])\\n4 w= torch.tensor([-0.3,0.15])\\n5 B= torch.tensor([0.001])\\n6 print (torch.sum(x*w))\\n7 print (torch.sum(x*w) + B)\\nFIGURE 8.55: MLP operations.\\n\\x04\\n300'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 317, 'page_label': '318'}, page_content='Chapter 8 DEEP LEARNING\\nActivation functions in perceptrons\\nSOL-209 \\uf14b CH.SOL- 8.33.\\n1. Since by deﬁnition:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.52)\\nAnd the output of the linear sum operation was −0.164 then, the output out2 = 0 .\\n2. Code snippet 8.56 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 x= torch.tensor([0.9,0.7])\\n3 w= torch.tensor([-0.3,0.15])\\n4 B= torch.tensor([0.001])\\n5 print (torch.sum(x*w))\\n6 print (torch.sum(x*w) + B)\\n7 print (torch.relu(torch.sum(x*w + B)))\\nFIGURE 8.56: MLP operations.\\n\\x04\\nBack-propagation in perceptrons\\nSOL-210 \\uf14b CH.SOL- 8.34. The answers are as follows:\\n1. Non-differentiable at 0.\\n2. Non-differentiable at 0.\\n301'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 318, 'page_label': '319'}, page_content='8.3. SOLUTIONS\\n3. Even though for x ̸= 0:\\nf ′(x) = sin 1\\nx − 1\\nx cos 1\\nx, (8.53)\\nthe function is still non-differentiable at 0.\\n4. Non-differentiable at 0.\\n\\x04\\nSOL-211 \\uf14b CH.SOL- 8.35.\\n1. Fig 8.57 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 for i in range(0,w.size(0)):\\n2 print (torch.relu(torch.sum(x*w[i]) + B))\\n3 > tensor([0.])\\n4 > tensor([0.])\\n5 > tensor([0.6630])\\nFIGURE 8.57: MLP operations- values.\\n2. The values at each hidden layer are depicted in 8.58\\n302'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 319, 'page_label': '320'}, page_content='Chapter 8 DEEP LEARNING\\n0.0\\n0.0\\n0.6630\\nOutput\\nFIGURE 8.58: Hidden layer values, simple MLP .\\n3. Fig 8.59 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 x1= torch.tensor([0.0,0.0,0.6630])# Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 for i in range(0,w1.size(0)):\\n7 print (torch.sum(x1*w1[i]))\\n8 > tensor(0.3912)\\n9 > tensor(-0.5238)\\nFIGURE 8.59: MLP operations- values at the output.\\n4. We can apply the Softmax function like so 8.60:\\n303'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 320, 'page_label': '321'}, page_content='8.3. SOLUTIONS\\n1 x1= torch.tensor([0.0,0.0,0.6630]) # Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 out1 = torch.tensor([[torch.sum(x1*w1[0]).item()],\\n7 [torch.sum(x1*w1[1]).item()]])\\n8 print (out1)\\n9 yhat = torch.softmax(out1, dim =0)\\n10 print (yhat)\\n11 > tensor([[ 0.3912],\\n12 [-0.5238]])\\n13 > tensor([[0.7140],\\n14 [0.2860]])\\nFIGURE 8.60: MLP operations- Softmax.\\n5. For the cross-entropy loss, we use the Softmax values and calculate the result as follows:\\n−1.0 ∗ log(0.7140) − 0.0 ∗ log(0.2860) = 1 .31 (8.54)\\n\\x04\\nThe theory of perceptrons\\nSOL-212 \\uf14b CH.SOL- 8.36.\\nHe means that theoretically [ 6], a non-linear layer followed by a linear layer, can ap-\\nproximate any non-linear function with arbitrary accuracy, provided that there are enough\\nnon-linear neurons\\n\\x04\\nSOL-213 \\uf14b CH.SOL- 8.37. T rue \\x04\\nSOL-214 \\uf14b CH.SOL- 8.38. T rue \\x04\\n304'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 321, 'page_label': '322'}, page_content='Chapter 8 DEEP LEARNING\\nSOL-215 \\uf14b CH.SOL- 8.39.\\nFalse. Divided by the training samples, not the number of incorrectly classiﬁed samples. \\x04\\nLearning logical gates\\nSOL-216 \\uf14b CH.SOL- 8.40.\\n1. The values are presented in the following table ( 8.61):\\nBias = −2.5\\nInput Weighted sum Output\\n(0,0) -2.5 0\\n(0,1) -1.5 0\\n(1,0) -1.5 0\\n(1,1) -0.5 0\\nFIGURE 8.61: Logical AND: B=-2.5\\n2. The values are presented in the following table ( 8.62):\\nBias = −0.25\\nInput Weighted sum Output\\n(0,0) -0.25 0\\n(0,1) -0.75 0\\n(1,0) -0.75 0\\n(1,1) 1.75 1\\nFIGURE 8.62: Logical AND: B=-0.25\\n3. The perceptron learning rule is an algorithm that can automatically compute optimal\\nweights for the perceptron.\\n305'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 322, 'page_label': '323'}, page_content='8.3. SOLUTIONS\\n4. The main addition by [ 22] and [ 18] was the introduction of a differentiable activation\\nfunction.\\n5. if we select w1 = 1;w2 = 1 and threshold=1. We get:\\nx1 = 1, x2 = 1 :\\nn = 1 × 1 + 1 × 1 = 2 ,thus,y = 1\\nx1 = 1, x2 = −1 :\\nn = 1 × 1 + 1 × (−1) = 0 ,thus,y = −1\\nx1 = −1, x2 = 1 :\\nn = 1 × (−1) + 1 × 1 = 0 ,thus,y = −1\\nx1 = −1, x2 = −1 :\\nn = 1 × (−1) + 1 × (−1) = −2,thus,y = −1\\n(8.55)\\nOr summarized in a table ( 8.63):\\nAND gate\\nin1 in2 out\\n0 0 0\\n0 1 0\\n1 0 0\\n1 1 1\\nFIGURE 8.63: Logical AND gate\\n\\x04\\n8.3.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\n306'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 323, 'page_label': '324'}, page_content='Chapter 8 DEEP LEARNING\\nSOL-217 \\uf14b CH.SOL- 8.41.\\n1. Remember that the analytical derivative is of the sigmoid:\\nd\\ndxs(x) = d\\ndx((1 + e−x)−1) (8.56)\\nd\\ndxs(x) = −1((1 + e−x)(−1−1)) d\\ndx(1 + e−x) (8.57)\\nd\\ndxs(x) = −1((1 + e−x)(−2))( d\\ndx (1) + d\\ndx(e−x)) (8.58)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(0 + e−x( d\\ndx(−x))) (8.59)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(e−x)(−1) (8.60)\\nd\\ndx s(x) = ((1 + e−x)(−2))(e−x) (8.61)\\nd\\ndxs(x) = 1\\n(1 + e−x)2 (e−x) (8.62)\\nd\\ndxs(x) = (e−x)\\n(1 + e−x)2 (8.63)\\nCode snippet 8.64 provides a pure C++ based implementation of the backward pass that\\ndirectly computes the analytical gradients in C++.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001_d(torch ::Tensor & x) {\\n5 torch::Tensor s = sigmoid001(x);\\n6 return (1 - s) * s;\\n7 }\\nFIGURE 8.64: Backward pass for the Sigmoid function using Libtorch.\\n307'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 324, 'page_label': '325'}, page_content='8.3. SOLUTIONS\\n2. Code snippet 8.65 depicts one way of printing the values.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"\\n9 << sigmoid001_d (t0).data().detach().item().toFloat()\\n10 << \\'\\\\n\\' ;\\n11 }\\n12 }\\nFIGURE 8.65: Evaluation of the sigmoid and its derivative in C++ using Libtorch.\\n3. The manual derivative of eq. 8.27 is:\\n3 ln(2)×\\n[\\n2−1.5x\\n(2−1.5x + 1)2\\n]\\n(8.64)\\n4. The forward pass for the Sigmoid function approximation eq. 8.27 is presented in code\\nsnippet 8.66:\\n308'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 325, 'page_label': '326'}, page_content='Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 torch::Tensor sig_approx( const torch::Tensor & x ){\\n4 torch::Tensor sig = 1.0 / (1.0 + torch::pow(2,( -1.5*x)));\\n5 return sig;\\n6 }\\nFIGURE 8.66: Forward pass for the Sigmoid function approximation in C++ using Libtorch.\\n5. The values are 8.67: :\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"<< sig_approx (t0).data().detach().item().\\n9 toFloat()<<\\'\\\\n\\' ;\\n10 }\\nFIGURE 8.67: Printing the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch.\\nAn the values are presented in T able 8.2:\\n309'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 326, 'page_label': '327'}, page_content='8.3. SOLUTIONS\\nValue Sig Approx\\n0 0.5 0.5\\n0.1 0.524979 0.52597\\n0.2 0.549834 0.5518\\n0.3 0.574443 0.577353\\n0.4 0.598688 0.602499\\n0.5 0.622459 0.627115\\n0.6 0.645656 0.65109\\n0.7 0.668188 0.674323\\n0.8 0.689974 0.69673\\n0.9 0.710949 0.71824\\n0.99 0.729088 0.736785\\nTABLE 8.2: Computed values for the Sigmoid and the Sigmoid approximation.\\n\\x04\\nTanh\\nSOL-218 \\uf14b CH.SOL- 8.42.\\nThe answers are as follows:\\n1. The derivative is:\\nftanh(x) = 1 − ftanh(x)2 (8.65)\\n2. Code snippet 8.68 implements the forward pass using pure Python.\\n310'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 327, 'page_label': '328'}, page_content='Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 xT =\\ntorch.abs(torch.tensor([[0.37,0.192,0.571]],requires_grad=True))↪→\\n3 .type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 tanh_values = np.tanh(xT_np)\\n7 print (\"Numpy:\", tanh_values)\\n8 > Numpy: [[ 0.35399172 0.18967498 0.51609329]]\\nFIGURE 8.68: Forward pass for tanh using pure Python.\\n3. In order to implement a PyT orch based torch.autograd.F unction function such as\\ntanh, we must provide both the forward and backward passes implementation. The\\nmechanism behind this idiom in PyT orch is via the use of a context, abbreviated ctx\\nwhich is like a state manager for automatic differentiation. The implementation is de-\\npicted in 8.69:\\n311'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 328, 'page_label': '329'}, page_content='8.3. SOLUTIONS\\n1 import torch\\n2\\n3 class TanhFunction(torch.autograd.Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward( x )\\n7 y = x.tanh()\\n8 return y\\n9\\n10 @staticmethod\\n11 def backward(ctx, grad_output):\\n12 input, = ctx.saved_tensors\\n13 dy_dx = 1 / (input.cosh() ** 2)\\n14 out = grad_output * dy_dx\\n15 print (\"backward:{}\".format(out))\\n16 return out\\nFIGURE 8.69: Tanh in PyTorch.\\n4. Code snippet 8.70 veriﬁes the correctness of the implementation using gradcheck.\\n312'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 329, 'page_label': '330'}, page_content='Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 import numpy as np\\n3 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n4 requires_grad=True))\\n5 .type(torch.DoubleTensor)\\n6 xT_np=xT.detach().cpu().numpy()\\n7 tanh_values = np.tanh(xT_np)\\n8 tanh_values_torch = tanhPyTorch(xT)\\n9 print (\"Torch:\", tanh_values_torch)\\n10 from torch.autograd import gradcheck, Variable\\n11 f = TanhFunction.apply\\n12 test=gradcheck(lambda t: f(t), xT)\\n13 print(test)\\n14 > PyTorch version: 1.7.0\\n15 > Torch: tensor([[ 0.3540, 0.1897, 0.5161]], dtype =torch.float64)\\n16 > backward:tensor([[0.8747, 0.9640, 0.7336]],dtype=torch.float64)\\nFIGURE 8.70: Invoking gradcheck on tanh.\\n\\x04\\nSOL-219 \\uf14b CH.SOL- 8.43.\\n1. The type of NN is a MultiLayer Perceptron or MLP .\\n2. There are two hidden layers.\\n\\x04\\nSOL-220 \\uf14b CH.SOL- 8.44.\\nHe is partially correct , see for example Understanding the difﬁculty of training deep\\nfeedforward neural networks [9]. \\x04\\n313'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 330, 'page_label': '331'}, page_content='8.3. SOLUTIONS\\nSOL-221 \\uf14b CH.SOL- 8.45.\\nInitialize all parameters to a constant zero value. When we apply the tanh function to an\\ninput which is very large, the output which is almost zero, will be propagated to the remaining\\npartial derivatives leading to the well known phenomenon.\\n\\x04\\nSOL-222 \\uf14b CH.SOL- 8.46.\\nDuring the back-propagation process, derivatives are calculated with respect to (W (1))\\nand also (W (2)). The design ﬂaw:\\ni Y our friend initialized all weights and biases to zero.\\nii Therefore any gradient with respect to (W (2)) would also be zero.\\niii Subsequently, (W (2)) will never be updated.\\niv This would inadvertently cause the derivative with respect to (W (1)) to be always zero.\\nv Finally, would also never be updated (W (1)).\\n\\x04\\nReLU\\nSOL-223 \\uf14b CH.SOL- 8.47.\\nThe ReLU function has the beneﬁt of not saturating for positive inputs since its derivative\\nis one for any positive value.\\n\\x04\\nSOL-224 \\uf14b CH.SOL- 8.48.\\nThe shape is:\\n3 × 3 × 3 × 16\\n\\x04\\nSOL-225 \\uf14b CH.SOL- 8.49.\\nThe activation function is a leaky ReLU which in some occasions may outperform the\\n314'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 331, 'page_label': '332'}, page_content='Chapter 8 DEEP LEARNING\\nReLU activation function. \\x04\\nSwish\\nSOL-226 \\uf14b CH.SOL- 8.50.\\n1. They intended to ﬁnd new better-performing activation functions.\\n2. They had a list of basic mathematical functions to choose from, for instance the expo-\\nnential families exp(), sin(), min and max.\\n3. Previous research found several activation function properties which were considered\\nvery useful. For instance, gradient preservation and non-monotonicity. However the\\nsurprising discovery was that the swish function violates both of these previously deemed\\nuseful properties.\\n4. The equation is:\\nf (x) = x · σ(x) (8.66)\\n5. The plot is 8.71\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n−1,0\\n−0,5\\n0,5\\n1,0\\nx\\nyx ∗ σ(x) = x ∗ 1\\n1+e−4x\\nFIGURE 8.71: A plot of the Swish activation function.\\n\\x04\\n315'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 332, 'page_label': '333'}, page_content='8.3. SOLUTIONS\\n8.3.6 Performance Metrics\\nConfusion matrix, precision, recall\\nSOL-227 \\uf14b CH.SOL- 8.51.\\n1. The values are labelled inside 8.27:\\nPredicted\\nP N\\nTruth P TP=12 FN=7\\nN FP=24 TN=1009\\nFIGURE 8.72: TP , TN, FP , FN.\\n2.\\nacc = 12 + 1009\\n12 + 7 + 24 + 1009 = 0.97 (8.67)\\n3.\\nprec = 12\\n12 + 24 = 0.333 (8.68)\\n4.\\nrecall = 12\\n12 + 7 = 0.631 (8.69)\\n\\x04\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\n316'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 333, 'page_label': '334'}, page_content='Chapter 8 DEEP LEARNING\\nFIGURE 8.73: Receiver Operating Characteristic curve.\\nSOL-228 \\uf14b CH.SOL- 8.52.\\nROC allows to attest the relationship between sensitivity and speciﬁcity of a binary clas-\\nsiﬁer. Sensitivity or true positive rate measures the proportion of positives correctly classiﬁed;\\nspeciﬁcity or true negative rate measures the proportion of negatives correctly classiﬁed. Con-\\nventionally, the true positive rate tpr is plotted against the false positive rate fpr, which is one\\nminus true negative rate.\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween selectivity and sensitivity.\\n2. It is a plot of ‘true positives’ vs. the ‘true negatives’ . In place of ‘true negatives’ ,\\none could also use ‘false positives’ which are essentially 1 - ‘true negatives’ .\\n3. A typical ROC curve has a concave shape with (0,0) as the beginning and (1,1) as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely confused\\nand cannot at all distinguish between the two classes, has an AUC of 0.5, the ‘x = y’\\nline in an ROC curve plot.\\n317'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 334, 'page_label': '335'}, page_content='8.3. SOLUTIONS\\n\\x04\\nSOL-229 \\uf14b CH.SOL- 8.53.\\nThe ROC curve of an ideal classiﬁer (100% accuracy) has an AUC of 1, with 0.0 ‘false\\npositives’ and 1.0 ‘true positives’ . The ROC curve in our case, is almost ideal, which may\\nindicate over-ﬁtting of the XGBOOST classiﬁer to the training corpus. \\x04\\n8.3.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nSOL-230 \\uf14b CH.SOL- 8.54.\\nOutput dimension: L × L × M where L = n−f +2p\\ns + 1 \\x04\\nSOL-231 \\uf14b CH.SOL- 8.55.\\nThe answers are as follows:\\n1. Output dimensions:\\ni torch.Size([1, 512, 7, 7])\\nii torch.Size([1, 512, 16, 16])\\niii torch.Size([1, 512, 22, 40])\\n2. The layer is MaxPool2d.\\n\\x04\\nSOL-232 \\uf14b CH.SOL- 8.56.\\nThe answers are as follows:\\n1. A convolutional block 8.74.\\n318'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 335, 'page_label': '336'}, page_content='Chapter 8 DEEP LEARNING\\n1 Sequential(\\n2 (0): Conv2d( 3, 64, kernel_size =(3, 3), stride =(1, 1), padding =(1,\\n1))↪→\\n3 (1): ReLU(inplace =True)\\n4 (2): MaxPool2d(kernel_size =2, stride =2, padding =0, dilation =1,\\nceil_mode=False↪→\\n5 )\\nFIGURE 8.74: Convolutional block from the VGG11 architecture.\\n2. The shapes are as follows:\\ni torch.Size([1, 64, 112, 112])\\nii torch.Size([1, 64, 256, 256])\\niii torch.Size([1, 64, 352, 512])\\n\\x04\\nSOL-233 \\uf14b CH.SOL- 8.57.\\nThe VGG11 architecture contains seven convolutional layers, each followed by a ReLU\\nactivation function, and ﬁve max-polling operations, each reducing the respective feature\\nmap by a factor of 2. All convolutional layers have a 3 × 3 kernel. The ﬁrst convolutional\\nlayer produces 64 channels and subsequently, as the network deepens, the number of channels\\ndoubles after each max-pooling operation until it reaches 512. \\x04\\nDropout\\nSOL-234 \\uf14b CH.SOL- 8.58.\\n1. The observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (8.70)\\n319'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 336, 'page_label': '337'}, page_content='8.3. SOLUTIONS\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (8.71)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (8.72)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (8.73)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(8.74)\\n2. In dropout, in every training epoch, neurons are randomly pruned with probability\\nP = p sampled from a Bernoulli distribution. During inference, all the neurons are used\\nbut their output is multiplied by the a-priory probability P . This approach resembles to\\nsome degree the model averaging approach of bagging.\\n\\x04\\nSOL-235 \\uf14b CH.SOL- 8.59.\\nThe answers are as follows:\\n1. The idea is true and a solid one.\\n2. The idiom may be exempliﬁed as follows 8.75:\\n320'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 337, 'page_label': '338'}, page_content='Chapter 8 DEEP LEARNING\\nFIGURE 8.75: Equivalence of two consecutive dropout layers\\nThe probabilities add up by multiplication at each layer, resulting in a single dropout\\nlayer with probability:\\n1 − (1 − p)(1 − q) (8.75)\\n\\x04\\nConvolutional Layer\\nSOL-236 \\uf14b CH.SOL- 8.60.\\nThe result is ( 8.76):\\nFIGURE 8.76: The result of applying the ﬁlter.\\n\\x04\\n321'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 338, 'page_label': '339'}, page_content='8.3. SOLUTIONS\\nSOL-237 \\uf14b CH.SOL- 8.61.\\nThe result is ( 8.77):\\nFIGURE 8.77: The result of applying a ReLU activation.\\n\\x04\\nSOL-238 \\uf14b CH.SOL- 8.62.\\nThe result is ( 8.78):\\nFIGURE 8.78: The result of applying a MaxPool layer.\\n\\x04\\nPooling Layers\\nMaxPooling\\n322'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 339, 'page_label': '340'}, page_content='Chapter 8 DEEP LEARNING\\nSOL-239 \\uf14b CH.SOL- 8.63.\\nThe answers are as follows:\\n1. A max-pooling layer is most commonly used after a convolutional layer in order to\\nreduce the spatial size of CNN feature maps.\\n2. The result is 8.79:\\nFIGURE 8.79: Output of the MaxPool2d operation.\\n\\x04\\nSOL-240 \\uf14b CH.SOL- 8.64.\\n1. In MaxPool2D(2,2), the ﬁrst parameter is the size of the pooling operation and the\\nsecond is the stride of the pooling operation.\\n2. The BatchNorm2D operation does not change the shape of the tensor from the previous\\nlayer and therefore it is:\\ntorch.Size ([1, 32, 222, 222]).\\n3. During the training of a CNN we use model.train() so that Dropout layers are ﬁred.\\nHowever, in order to run inference, we would like to turn this ﬁring mechanism off,\\nand this is accomplished by model.eval() instructing the PyT orch computation graph\\nnot to activate dropout layers.\\n4. The resulting tensor shape is:\\ntorch.Size ([1, 32, 55, 55])\\nIf we reshape the tensor like in line 17 using:\\nx = x.view(x.size(0), −1)\\n323'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 340, 'page_label': '341'}, page_content='8.3. SOLUTIONS\\nThen the tensor shape becomes:\\ntorch.Size ([1, 96800])\\n5. Y es, you should agree with him, as depicted by the following plot 8.80:\\nFIGURE 8.80: A single MaxPool layer.\\n\\x04\\nBatch normalization, Gaussian PDF\\nThe Gaussian distribution\\nSOL-241 \\uf14b CH.SOL- 8.65.\\nThe answers are as follows:\\n1. BN is a method that normalizes the mean and variance of each of the elements during\\ntraining.\\n2. X ∼ N (0, 1) a mean of zero and a variance of one. The standard normal distribution\\noccurs when (σ)2 = 1 and µ = 0.\\n3. In order to normalize we:\\ni Step one is to subtract the mean to shift the distribution.\\nii Divide all the shifted values by their standard deviation (the square root of the\\nvariance).\\n4. In BN, the normalization is applied on an element by element basis. During training at\\neach epoch, every element in the batch has to be shifted and scaled so that it has a zero\\nmean and unit variance within the batch.\\n\\x04\\n324'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 341, 'page_label': '342'}, page_content='Chapter 8 DEEP LEARNING\\nSOL-242 \\uf14b CH.SOL- 8.66.\\n1. One possible realization is as follows 8.81:\\n1 from math import sqrt\\n2 import math\\n3 def normDist(x, mu, sigSqrt):\\n4 return (1 / sqrt(2 * math.pi * sigSqrt)) * math.e ** ((-0.5) *\\n(x - mu) ** 2 / sigSqrt)↪→\\nFIGURE 8.81: Normal distribution in Python: from scratch.\\n2. The derivative is given by 8.82:\\n1 scipy.stats.norm.pdf(x, mu, sigma) *(mu - x)/sigma**2\\nFIGURE 8.82: The derivative of a Normal distribution in Python.\\n\\x04\\nBN\\nSOL-243 \\uf14b CH.SOL- 8.67.\\n1. During training of a CNN, when a convolution is being followed by a BN layer, for\\neach of the three RGB channels a single separate mean and variance is being computed.\\n2. The mistake he made is using a BN with a batch size of 32, while the output from the\\nconvolutional layer is 64.\\n\\x04\\n325'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 342, 'page_label': '343'}, page_content='8.3. SOLUTIONS\\nTheory of CNN design\\nSOL-244 \\uf14b CH.SOL- 8.68.\\nT rue.\\n\\x04\\nSOL-245 \\uf14b CH.SOL- 8.69.\\nAll the options may be used to build a CNN. \\x04\\nSOL-246 \\uf14b CH.SOL- 8.70. While the original paper ([ 16]) suggests that BN layers be\\nused before an activation function, it is also possible to use BN after the activation function.\\nIn some cases, it actually leads to better results ([ 4]).\\n\\x04\\nSOL-247 \\uf14b CH.SOL- 8.71.\\nWhen dropout is enabled during the training process, in order to keep the expected output\\nat the same value, the output of a dropout layer must be multiplied with this term. Of course,\\nduring inference no dropout is taking place at all. \\x04\\nSOL-248 \\uf14b CH.SOL- 8.72.\\n1. The idiom is a bottleneck layer ([ 27]), which may act much like an autoencoder.\\n2. Reducing and then increasing the activations, may force the MLP to learn a more com-\\npressed representation.\\n3. The new architecture has far more connections and therefore it would be prone to over-\\nﬁtting.\\n4. Once such architecture is an autoencoder ([ 28]).\\n\\x04\\nCNN residual blocks\\nSOL-249 \\uf14b CH.SOL- 8.73.\\n326'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 343, 'page_label': '344'}, page_content='Chapter 8 DEEP LEARNING\\n1. The function F is the residual function.\\n2. The main idea was to add an identity connection which skips two layers all together.\\n\\x04\\nSOL-250 \\uf14b CH.SOL- 8.74.\\n1. The missing parts are visualized in ( 8.83).\\nFIGURE 8.83: A resnet CNN block\\n2. The symbol represents the addition operator.\\n3. Whenever F returns a zero, then the input X will reach the output without being\\nmodiﬁed. Therefore, the term identity function.\\n\\x04\\n8.3.8 Training, hyperparameters\\nHyperparameter optimization\\nSOL-251 \\uf14b CH.SOL- 8.75.\\nThe question states that image size is quite large, and the batch size is 1024, therefore it\\nmay fail to allocate memory on the GPU with an Out Of Memory (OOM) error message. This\\n327'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 344, 'page_label': '345'}, page_content='8.3. SOLUTIONS\\nis one of the most commonly faced errors when junior data-scientist start training models.\\n\\x04\\nSOL-252 \\uf14b CH.SOL- 8.76.\\n1. Since hs is tuning his Hyperparameters on the validation set, he would most probably\\noverﬁt to the validation set which he also used for evaluating the performance of the\\nmodel.\\n2. One way would be to amend the splitting, is by ﬁrst keeping a fraction of the training set\\naside, for instance 0.1, and then split the remaining .90 into a training and a validation\\nset, for instance 0.8 and 0.1.\\n3. His new approach uses GridSearchCV with 5-fold cross-validation to tune his Hyper-\\nparameters. Since he is using cross validation with ﬁve folds, his local CV metrics would\\nbetter reﬂect the performance on an unseen data set.\\n\\x04\\nSOL-253 \\uf14b CH.SOL- 8.77.\\nIn grid search, a set of pre-determined values is selected by a user for each dimension in\\nhis search space, and then thoroughly attempting each and every combination. Naturally, with\\nsuch a large search space the number of the required combinations that need to be evaluated\\nscale exponentially in the number of dimensions in the grid search.\\nIn random search the main difference is that the algorithm samples completely random\\npoints for each of the dimensions in the search space. Random search is usually faster and may\\neven produce better results.\\n\\x04\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nSOL-254 \\uf14b CH.SOL- 8.78.\\nThere is a potential for bias in certain settings such as this. If the whole training set\\nis labelled only by a single radiologist, it may be possible that his professional history would\\n328'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 345, 'page_label': '346'}, page_content='Chapter 8 DEEP LEARNING\\ninadvertently generate bias into the corpus. Even if we use the form of radiology report reading\\nknown as double reading it would not be necessarily true that the annotated scans would be\\ndevoid of bias or that the quality would be better [ 8].\\n\\x04\\nValidation curve ACC\\nSOL-255 \\uf14b CH.SOL- 8.79.\\nThe answers are as follows:\\n1. A validation curve displays on a single graph a chosen hyperparameter on the hori-\\nzontal axis and a chosen metric on the vertical axis.\\n2. The hyperparameter is the number of epochs\\n3. The quality metric is the error (1 -accuracy). Accuracy, error = (1`accuracy) or loss are\\ntypical quality metrics.\\n4. The longer the network is trained, the better it gets on the training set.\\n5. At some point the network is ﬁt too well to the training data and loses its capability to\\ngeneralize. While the classiﬁer is still improving on the training set, it gets worse on\\nthe validation and the test set.\\n6. At this point the quality curve of the training set and the validation set diverge.\\n\\x04\\nValidation curve Loss\\nSOL-256 \\uf14b CH.SOL- 8.80.\\nThe answers are as follows:\\n1. What we are witnessing is phenomena entitled a plateau. This may happen when the\\noptimization protocol can not improve the loss for several epochs.\\n2. There possible methods are:\\ni Constant\\nii Xavier/Glorot uniform\\n329'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 346, 'page_label': '347'}, page_content='8.3. SOLUTIONS\\niii Xavier/Glorot normal\\n3. Good initialization would optimally generate activations that produce initial gradients\\nthat are larger than zero. One idea is that the training process would converge faster if\\nunit variance is achieved ([ 16]). Moreover, weights should be selected carefully so that:\\ni They are large enough thus preventing gradients from decaying to zero.\\nii They are not too large causing activation functions to over saturate.\\n4. There are several ways to reduce the problem of plateaus:\\ni Add some type of regularization.\\nii In cases wherein the plateau happens right at the beginning, amend the way weights\\nare initialized.\\niii Amending the optimization algorithm altogether, for instance using SGD instead\\nof Adam and vice versa.\\n5. Since the initial LR is already very low, his suggestion may worsen the situation since\\nthe optimiser would not be able to jump off and escape the plateau.\\n6. In contrast to accuracy, Log loss has no upper bounds and therefore at times may be\\nmore difﬁcult to understand and to explain.\\n\\x04\\nInference\\nSOL-257 \\uf14b CH.SOL- 8.81.\\n1. Usually data augmentation, is a technique that is heavily used during training, espe-\\ncially for increasing the number of instances of minority classes. In this case, augment-\\nations are using during inference and this method is entitled T est Time Augmentation\\n(TTA).\\n2. Here are several image augmentation methods for TTA, with two augmentations shown\\nalso in PyT orch.\\n330'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 347, 'page_label': '348'}, page_content='Chapter 8 DEEP LEARNING\\nHorizontal ﬂip\\nV ertical ﬂip\\nRotation\\nScaling\\nCrops\\n1 transforms.HorizolntalFlip(p=1)(image)\\n2 transforms.VerticalFlip(p=1)(image)\\nFIGURE 8.84: Several image augmentation methods for TTA.\\n\\x04\\nSOL-258 \\uf14b CH.SOL- 8.82.\\ni Unseen\\nii Overﬁtting\\n\\x04\\n8.3.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nSOL-259 \\uf14b CH.SOL- 8.83.\\nThere is no relation to random number generation, the true meaning is the use of batches\\nduring the training process.\\n\\x04\\nSOL-260 \\uf14b CH.SOL- 8.84.\\nA larger batch size decreases the variance of the gradient estimation of SGD. Therefore, if\\nyour training loop uses larger batches, the model will converge faster. On the other hand, smal-\\n331'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 348, 'page_label': '349'}, page_content='8.3. SOLUTIONS\\nler batch sizes increase the variance, leading to the opposite phenomena; longer convergence\\ntimes.\\n\\x04\\nMomentum\\nSOL-261 \\uf14b CH.SOL- 8.85.\\nMomentum introduces an extra term which comprises a moving average which is used\\nin gradient descent update rule to exponentially decay the historical gradients Using such\\nterm has been demonstrated to accelerate the training process ([ 11]) requiring less epochs to\\nconverge.\\n\\x04\\nSOL-262 \\uf14b CH.SOL- 8.86.\\nThe answers are as follows:\\n1. The derivative of the logistic activation function is extremely small for either negtive or\\npositive large inputs.\\n2. The use of the tanh function does not alleviate the problem since we can scale and\\ntranslate the sigmoid function to represent the tanh function:\\ntanh(z) = 2 σ(2z) − 1 (8.76)\\nWhile the sigmoid function is centred around 0.5, the tanh activation is centred around\\nzero. Similar to the application of BN, centring the activations may aid the optimizer con-\\nverge faster. Note: there is no relation to SGD; the issue exists when using other optimization\\nfunctions as well. \\x04\\nSOL-263 \\uf14b CH.SOL- 8.87.\\nThe answers are as follows:\\ni T rue.\\nii False. In stochastic gradient descent, the gradient for a single sample is quite different\\n332'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 349, 'page_label': '350'}, page_content='Chapter 8 DEEP LEARNING\\nfrom the actual gradient, so this gives a more noisy value, and converges slower\\niii T rue.\\niv False. SGD requires less memory.\\n\\x04\\nNorms, L1, L2\\nSOL-264 \\uf14b CH.SOL- 8.88.\\n1. The L2 norm.\\n2. The Euclidean distance which is calculated as the square root of the sum of differences\\nbetween each point in a set of two points.\\n3. The Manhattan distance is an L1 norm (introduced by Hermann Minkowski) while the\\nEuclidean distance is an L2 norm.\\n4. The Manhattan distance is:\\n|6 − 2| + |1 − 8| + |4 − 3| + |5 − (−1)|\\n= 4 + 7 + 1 + 6 = 18 (8.77)\\n5. The Euclidean distance is:\\n√\\n(6 − 2)2 + (1 − 8)2 + (4 − 3)2 + (5 − (−1))2\\n=\\n√\\n102\\n(8.78)\\n\\x04\\nSOL-265 \\uf14b CH.SOL- 8.89.\\nThe PyT orch implementation is in ( 8.85). Note that we are allocating tensors on a GPU\\nbut ﬁrst they are created on a CPU using numpy. This is also always the interplay between\\nthe CPU and the GPU when training NN models. Note that this only work if you have GPU\\navailable; in case there is no GPU detected, the code has a fallback to the CPU.\\n333'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 350, 'page_label': '351'}, page_content='REFERENCES\\n1 %reset -f\\n2 import torch\\n3 import numpy\\n4\\n5 use_cuda = torch.cuda.is_available()\\n6 device = torch.device(\"cuda\" if use_cuda else \"cpu\")\\n7 print (device)\\n8 x1np=numpy.array([6,1,4,5])\\n9 x2np=numpy.array([2,8,3,-1])\\n10 x1t=torch.FloatTensor(x1np).to(device) # Move to GPU if available\\n11 x2t=torch.FloatTensor(x2np).to(device)\\n12 dist = torch.sqrt (torch .pow(x1t - x2t, 2).sum())\\n13 dist\\n14 >cuda\\n15 >tensor(10.0995, device =\\'cuda:0\\' )\\nFIGURE 8.85: Manhattan distance function in PyTorch.\\n\\x04\\nSOL-266 \\uf14b CH.SOL- 8.90.\\nThe L2 loss is suitable for a target, or a response variable that is continuous. On the other\\nhand, in a binary classiﬁcation problem using LR we would like the output to match either\\nzero or one and a natural candidate for a loss function is the binary cross-entropy loss. \\x04\\nReferences\\n[1] F. T. B. Fuglede. ‘Jensen-Shannon Divergence and Hilbert space embedding’. In:\\nIEEE Int Sym. Information Theory (2004) (cit. on pp. 245, 297).\\n[2] C. Bennett. ‘Information Distance’. In: IEEE T rans. Pattern Anal. Inform. Theory.\\n44:4 (1998), pp. 1407–1423 (cit. on pp. 244, 298).\\n[3] B. Bigi. ‘Using Kullback-Leibler Distance for Text Categorization’. In: In Pro-\\nceedings of the ECIR-2003, Lecture Notes in Computer Science, Springer-Verlag 2633\\n(2003), pp. 305–319 (cit. on pp. 245, 298).\\n334'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 351, 'page_label': '352'}, page_content='Chapter 8 DEEP LEARNING\\n[4] G. Chen. Rethinking the Usage of Batch Normalization and Dropout in the T raining of\\nDeep Neural Networks. 2019. arXiv: 1905.05928 [cs.LG] (cit. on p. 326).\\n[5] Y . S. Chen et al. ‘Deep photo enhancer: Unpaired learning for image enhance-\\nment from photographs with gans’. In: IEEE Conference on Computer Vision and\\nPattern Recognition. 2018, p. 6306 (cit. on p. 231).\\n[6] I. Ciuca and J. A. Ware. ‘Layered neural networks as universal approximators’.\\nIn: Computational Intelligence Theory and Applications . Ed. by B. Reusch. Berlin,\\nHeidelberg: Springer Berlin Heidelberg, 1997, pp. 411–415 (cit. on p. 304).\\n[7] T. Floyd. Digital Fundamentals. Prentice Hall, 2003 (cit. on p. 252).\\n[8] H. Geijer and M. Geijer. ‘Added value of double reading in diagnostic radi-\\nology ,a systematic review’. In: Insights into Imaging 9 (Mar. 2018). DOI : 10.1007/\\ns13244-018-0599-0 (cit. on pp. 282, 328, 329).\\n[9] X. Glorot and Y . Bengio. ‘Understanding the difﬁculty of training deep feedfor-\\nward neural networks’. In: Journal of Machine Learning Research - Proceedings T rack\\n9 (Jan. 2010), pp. 249–256 (cit. on pp. 258, 313).\\n[10] S. Gomar, M. Mirhassani and M. Ahmadi. ‘Precise digital implementations of\\nhyperbolic tanh and sigmoid function’. In: 2016 50th Asilomar Conference on Sig-\\nnals, Systems and Computers (2016) (cit. on p. 254).\\n[11] I. Goodfellow, Y . Bengio and A. Courville. Adaptive computation and machine\\nlearning. MIT Press, 2016 (cit. on p. 332).\\n[12] J. Gurmeet Singh Manku. ‘Detecting near-duplicates for web crawling’. In: Pro-\\nceedings of the 16th International Conference on World Wide Web (2007), p. 141 (cit.\\non pp. 244, 245, 298).\\n[13] K. He. Deep Residual Learning for Image Recognition . 2015. arXiv: 1512 . 03385\\n(cit. on p. 279).\\n[14] K. He et al. Delving Deep into Rectiﬁers: Surpassing Human-Level Performance on\\nImageNet Classiﬁcation. 2015. arXiv: 1502.01852 [cs.CV] (cit. on pp. 258, 273).\\n[15] A. Ignatov et al. ‘Dslr-quality photos on mobile devices with deep convolu-\\ntional networks’. In: IEEE International Conference on Computer Vision (ICCV) .\\n2017, pp. 3297–3305 (cit. on p. 231).\\n[16] S. Ioffe and C. Szegedy. ‘Batch Normalization’. In: CoRR abs/1502.03167 (2015).\\narXiv: 1502.03167 (cit. on pp. 273, 326, 330).\\n335'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 352, 'page_label': '353'}, page_content='REFERENCES\\n[17] R. Kohavi. ‘A Study of Cross-Validation and Bootstrap for Accuracy Estima-\\ntion and Model Selection’. In: Morgan Kaufmann, 1995, pp. 1137–1143 (cit. on\\npp. 231, 289).\\n[18] A. Krizhevsky , I. Sutskever and G. E. Hinton. ‘ImageNet Classiﬁcation with\\nDeep Convolutional Neural Networks’. In: Advances in Neural Information Pro-\\ncessing Systems . Ed. by F. Pereira et al. V ol. 25. Curran Associates, Inc., 2012,\\npp. 1097–1105 (cit. on pp. 252, 306).\\n[19] Libtorch: The PyT orch C++ frontend is a C++14 library for CPU and GPU tensor com-\\nputation. 2020 (cit. on pp. 254, 256).\\n[20] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on pp. 266, 267).\\n[21] P . Ramachandran.Searching for Activation Functions . 2017. arXiv: 1710.05941\\n[cs.NE] (cit. on p. 260).\\n[22] D. E. Rumelhart and G. E. Hinton. ‘Learning Representations by Back Propagat-\\ning Errors’. In: Neurocomputing: Foundations of Research . Cambridge, MA, USA:\\nMIT Press, 1988, pp. 696–699 (cit. on pp. 236, 252, 260, 292, 306).\\n[23] S. Sengupta et al. ‘Sfsnet: Learning shape, reﬂectance and illuminance of faces\\nin the wild’. In: Computer Vision and Pattern Regognition (CVPR) . 2018 (cit. on\\np. 231).\\n[24] Z. Shu, E. Yumer and S. Hadap. ‘Neural face editing with intrinsic image dis-\\nentangling’. In: Computer Vision and Pattern Recognition (CVPR) IEEE Conference .\\n2017, pp. 5444–5453 (cit. on p. 231).\\n[25] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 263, 265).\\n[26] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on pp. 266, 267).\\n[27] C. Szegedy et al. ‘Inception v4, Inception-ResNet and the Impact of Residual\\nConnections on Learning’. In: ICLR 2016 Workshop. 2016 (cit. on p. 326).\\n[28] P . Vincent et al. ‘Extracting and composing robust features with denoising au-\\ntoencoders’. In: Proceedings of the 25th international conference on Machine learning .\\n2008, pp. 1096–1103 (cit. on p. 326).\\n336'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 353, 'page_label': '354'}, page_content='Chapter 8 DEEP LEARNING\\n[29] J. Ziv and N. Merhav . ‘A measure of relative entropy between individual se-\\nquences with application to universal classiﬁcation’. In: IEEE T ransactions on In-\\nformation Theory 39(4) (1993), pp. 1270–1279 (cit. on pp. 245, 298).\\n337'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 354, 'page_label': '355'}, page_content='REFERENCES\\n338'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 355, 'page_label': '356'}, page_content='PRACTICE EXAM\\nPART V'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 356, 'page_label': '357'}, page_content=''),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 357, 'page_label': '358'}, page_content='CHAPTER\\n9\\nJOB INTER VIEW MOCK EXAM\\nA man who dares to waste one hour of time has not discovered the value of life.\\n— Charles Darwin\\nContents\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nClassiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nStressful events, such as a job interview, prompt concern and anxiety (as they do for\\nvirtually every person), but it’s the lack of preparation that fuels unnecessary nervous-\\nness. Many perceive the interview as a potentially threatening event. Testing your\\nknowledge in AI using a mock exam, is an effective way to not only identifying your\\nweaknesses and to pinpointing the concepts and topics that need brushing up, but\\nalso to becoming more relaxed in similar situations. Remember that at the heart of job\\ninterview conﬁdence is feeling relaxed.\\nDoing this test early enough, gives you a head-start before the actual interview, so\\nthat you can target areas that require perfection. The exam includes questions from\\na wide variety of topics in AI, so that these areas are recognised and it would then\\nbe a case of solving all the problems in this book over a period of few months to be\\nproperly prepared. Do not worry even if you can not solve any of the problems in the\\nexam as some of them are quite difﬁcult.'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 358, 'page_label': '359'}, page_content='DEEP LEARNING JOB INTER VIEW MOCK EXAM\\nEXAM INSTRUCTIONS :\\nYOU SHOULD NOT SEARCH FOR SOLUTIONS ON THE WEB . M ORE GENERALLY , YOU\\nARE URGED TO TRY AND SOLVE THE PROBLEMS WITHOUT CONSULTING ANY REFER -\\nENCE MATERIAL , AS WOULD BE THE CASE IN A REAL JOB INTERVIEW .\\n9.0.1 Rules\\nREMARK: In order to receive credits, you must:\\ni Show all work neatly .\\nii A sheet of formulas and calculators are permitted but not notes or texts.\\niii Read the problems CAREFULLY\\niv Do not get STUCK at any problem (or in local minima ...) for too much time!\\nv After completing all problems, a double check is STRONGLY advised.\\nvi You have three hours to complete all questions.\\n342'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 359, 'page_label': '360'}, page_content='Chapter 9 JOB INTER VIEW MOCK EXAM\\n9.1 Problems\\n9.1.1 Perceptrons\\nPRB-267 \\uf059 CH.PRB- 9.1. [PERCEPTRONS]\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 9.1: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the resulting value from the application of the sum operator?\\n3. Using PyT orch tensors, verify the correctness of your answers.\\n9.1.2 CNN layers\\nPRB-268 \\uf059 CH.PRB- 9.2. [CNN LAYERS]\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and examine its behaviour during inference:\\n343'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 360, 'page_label': '361'}, page_content='9.1. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 9.1: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n344'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 361, 'page_label': '362'}, page_content='Chapter 9 JOB INTER VIEW MOCK EXAM\\nFIGURE 9.2: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet\\na second MaxPool2D(2,2). What is the resulting tensor shape after running line 9?\\nand line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\n9.1.3 Classification, Logistic regression\\nPRB-269 \\uf059 CH.PRB- 9.3. [CLASSIFICATION, LR]\\nT o study factors that affect the survivability of humans infected with COVID19 using\\nlogistic regression, a researcher considers the link between lung cancer and COVID19 as a\\n345'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 362, 'page_label': '363'}, page_content='9.1. PROBLEMS\\nplausible risk factor. The predictor variable is a count of removed pulmonary nodules (Fig.\\n9.3) in the lungs.\\nFIGURE 9.3: Pulmonary nodules.\\nThe response variable Y measures whether the patient shows any remission (as in the\\nmanifestations of a disease, e. g. yes=1, no=0) when the pulmonary nodules count shifts up\\nor down. The output from training a logistic regression classiﬁer is as follows:\\nStandard\\nParameter DF Estimate Error\\nIntercept 1 -4.8792 1.0732\\nPulmonary nodules 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of removed pulmonary nod-\\nules of a patient is 33.\\n2. Find out the removed pulmonary nodules count at which the estimated probability of\\nimprovement is 0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1, in the total\\nremoved pulmonary nodule count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total removed pulmonary nodule count. Remember that The most common\\nconﬁdence levels are 90%, 95%, 99%, and 99.9%.\\n346'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 363, 'page_label': '364'}, page_content='Chapter 9 JOB INTER VIEW MOCK EXAM\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 9.1: Common conﬁdence levels\\nT able9.1 lists the z values for these levels.\\n9.1.4 Information theory\\nPRB-270 \\uf059 CH.PRB- 9.4. [INFORMATION THEORY]\\nThis question discusses the link between binary classiﬁcation, information gain and\\ndecision trees. Recent research suggests that the co-existence of inﬂuenza (Fig. 9.4) and\\nCOVID19 virus may decrease the survivability of humans infected with the COVID 19\\nvirus. The data (T able 9.2) comprises a training set of feature vectors with corresponding\\nclass labels which a researcher intents classifying using a decision tree.\\nT o study factors affecting COVID19 eradication, the deep-learning researcher collects\\ndata regrading two independent binary variables; θ1 (T/F) indicating whether the patient is\\na female, and θ2 (T/F) indicating whether the human tested positive for the inﬂuenza virus.\\nThe binary response variable, γ, indicates whether eradication was observed (e.g. eradica-\\ntion=+, no eradication=-).\\n347'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 364, 'page_label': '365'}, page_content='9.1. PROBLEMS\\nFIGURE 9.4: The inﬂuenza virus.\\nReferring to T able ( 9.2), each row indicates the observed values, columns ( θi) denote\\nfeatures and rows (< θ i, γi >) denote labelled instances while class label ( γ) denotes whether\\neradication was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 9.2: Decision trees and the COVID19 virus.\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\n348'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 365, 'page_label': '366'}, page_content='Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-271 \\uf059 CH.PRB- 9.5.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh) + p(xt) = 1 , what is the\\nformula for the average surprise?\\n6. What is the value of the average surprise in bits?\\nPRB-272 \\uf059 CH.PRB- 9.6.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\n9.1.5 Feature extraction\\nPRB-273 \\uf059 CH.PRB- 9.7. [FEATURE EXTRACTION]\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n349'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 366, 'page_label': '367'}, page_content='9.1. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 9.5: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\nCODE 9.2: An unknown algorithm in C++11\\n1 void xxx(std::vector<float>& arr){\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nWhich results in this vector ( 9.6):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 9.6: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n350'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 367, 'page_label': '368'}, page_content='Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-274 \\uf059 CH.PRB- 9.8.\\n[FEATURE EXTRACTION]\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture for the classiﬁcation of the COVID19 pathogen. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with it\\nby utilizing the same logic.\\nIn (Fig. 9.7), 2 different classes of human cells are displayed; infected and not-infected,\\nwhich were curated from a dataset of 4K images labelled by a majority vote of two expert\\nvirologists. Y our task is to use FE to correctly classify the images in the dataset.\\nFIGURE 9.7: A dataset of human cells infected by the COVID19 pathogen.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture. As depicted,\\nfor each layer the number of ﬁlters (i. e. neurons with unique set of parameters), learnable\\nparameters (e. g. weights and biases), and FV size are presented.\\n351'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 368, 'page_label': '369'}, page_content='9.1. PROBLEMS\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 9.3: Incomplete listing of the of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4k images from the dataset, how can\\nyou now classify the images into their respective categories?\\n9.1.6 Bayesian deep learning\\nPRB-275 \\uf059 CH.PRB- 9.9. [BAYESIAN DEEP LEARNING]\\nA recently published paper presents a new layer for Bayesian neural networks (BNNs).\\nThe layer behaves as follows. During the feed-forward operation, each of the hidden neurons\\nHn , n ∈ { 1, 2, } in the neural network in (Fig. 9.8) may, or may not ﬁre, independently\\nof each other, according to a known prior distribution.\\n352'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 369, 'page_label': '370'}, page_content='Chapter 9 JOB INTER VIEW MOCK EXAM\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 9.8: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ B(n, γ ) random variable and ﬁres\\nwith a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U (0, γ) random variable and ﬁres\\nwith a probability of γ.\\nPRB-276 \\uf059 CH.PRB- 9.10.\\nDuring pregnancy, the Placenta Chorion T est is commonly used for the diagnosis of\\nhereditary diseases (Fig. 9.9).\\nFIGURE 9.9: Foetal surface of the placenta\\nAssume, that a new test entitled the Placenta COVID19 T est has the exact same proper-\\nties as the Placenta Chorion T est. The test has a probability of 0.95 of being correct whether\\nor not a COVID19 pathogen is present. It is known that 1/100 of pregnancies result in\\n353'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 370, 'page_label': '371'}, page_content='9.1. PROBLEMS\\nCOVID19 virus being passed to foetal cells. Calculate the probability of a test indicating\\nthat a COVID19 virus is present.\\nPRB-277 \\uf059 CH.PRB- 9.11.\\nA person who was unknowingly infected with the COVID19 pathogen takes a walk in\\na park crowded with people. Let y be the number of successful infections in 5 independent\\nsocial interactions or infection attempts (trials), where the probability of “success\" (infecting\\nsomeone else) is θ in each trial. Suppose your prior distribution for θ is as follows: P (θ =\\n1/2) = 0 .25, P (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y).\\n2. Derive the prior predictive distribution for y.\\nPRB-278 \\uf059 CH.PRB- 9.12.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history with a death tool far exceeding all past\\noutbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976 in\\nSudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 9.10: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the centre for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\n354'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 371, 'page_label': '372'}, page_content='Chapter 9 JOB INTER VIEW MOCK EXAM\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y,\\nγ ∈ [0, 1], y = 1, 2, . . . , n ,\\n(9.1)\\nwhere: \\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 = n!\\n(n − y)!y!. (9.2)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ, the\\nproportion of infected humans in the entire population.\\nThe expectation and variance of the binomial are:\\nE(y|γ, n) = nγ, , V (y|γ, n) = nγ(1 − γ). (9.3)\\nAnswer the following:\\n1. For the likelihood function of the form lx(γ) = log Lx(γ) what is the log-likelihood\\nfunction?\\n2. Find the log-likelihood function ln (L(γ))\\n3. Find the gradient vector g(γ)\\n4. Find the Hessian matrix H(γ)\\n5. Find the Fisher information I(γ)\\n6. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\n355'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 372, 'page_label': '373'}, page_content='9.1. PROBLEMS\\n356'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 373, 'page_label': '374'}, page_content='VOLUME TWO\\nPART VI'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 374, 'page_label': '375'}, page_content=''),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 375, 'page_label': '376'}, page_content='CHAPTER\\n10\\nVOLUME TWO - PLAN\\nNothing exists until it is measured.\\n— Niels Bohr, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nV ariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . 361'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 376, 'page_label': '377'}, page_content='10.1. INTRODUCTION\\nT ext to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\n10.1 Introduction\\nI\\nT is important at the outset to understand we could not possibly include\\neverything we wanted to include in the ﬁrst VOLUME of this series. While\\nthe ﬁrst volume is meant to introduce many of the core subjects in AI, the\\nsecond volume takes another step down that road and includes numerous,\\nmore advanced subjects. This is a short glimpse into the plan for VOLUME-2 of this\\nseries. This second volume focuses on more advanced topics in AI\\n10.2 AI system design\\n10.3 Advanced CNN topologies\\n10.4 1D CNN’s\\n10.5 3D CNN’s\\n10.6 Data augmentations\\n10.7 Object detection\\n10.8 Object segmentation\\n10.9 Semantic segmentation\\n10.10 Instance segmentation\\n10.11 Image classification\\n10.12 Image captioning\\n10.13 NLP\\n360'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 377, 'page_label': '378'}, page_content='Chapter 10 VOLUME TWO - PLAN\\n10.14 RNN\\n10.15 LSTM\\n10.16 GANs\\n10.17 Adversarial attacks and defences\\n10.18 Variational auto encoders\\n10.19 FCN\\n10.20 Seq2Seq\\n10.21 Monte carlo, ELBO, Re-parametrization\\n10.22 Text to speech\\n10.23 Speech to text\\n10.24 CRF\\n10.25 Quantum computing\\n10.26 RL\\n361'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 378, 'page_label': '379'}, page_content='10.26. RL\\n362'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 379, 'page_label': '380'}, page_content='List of Tables\\nTumour eradication statistics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\nCommon conﬁdence levels. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nTumour shrinkage in rats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nProbability values of hereditary-disease detection. . . . . . . . . . . . . . . . . 67\\nDecision trees and frogs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\\nDecision trees and Cannabinoids administration . . . . . . . . . . . . . . . . . 96\\nDecision trees and star expansion. . . . . . . . . . . . . . . . . . . . . . . . . . 97\\nDecision trees and radiation therapy . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nSplitting on θ2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . 169\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute\\n∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\\nImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches. . . 193\\nIncomplete listing of the VGG19 architecture . . . . . . . . . . . . . . . . . . . 209\\nIncomplete listing of the VGG11 architecture. . . . . . . . . . . . . . . . . . . . 265\\nComputed values for the Sigmoid and the Sigmoid approximation. . . . . . . 310\\nCommon conﬁdence levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nDecision trees and the COVID19 virus. . . . . . . . . . . . . . . . . . . . . . . . 348\\nIncomplete listing of the of the VGG19 architecture . . . . . . . . . . . . . . . . 352'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 380, 'page_label': '381'}, page_content='LIST OF TABLES\\n364'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 381, 'page_label': '382'}, page_content='List of Figures\\nExamples of two sigmoid functions. . . . . . . . . . . . . . . . . . . . . . . . . 15\\nPulmonary nodules (left) and breast cancer (right). . . . . . . . . . . . . . . . . 16\\nA multi-detector positron scanner used to locate tumours. . . . . . . . . . . . 18\\nA dental amalgam. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nA chain of spherical bacteria. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nCannabis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nLogistic regression in CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nA linear model in PyTorch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 25\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 26\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds vs. probability values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\nBinary entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nLogistic regression in C++ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nHistopathology for pancreatic cancer cells. . . . . . . . . . . . . . . . . . . . . 44\\nBosons and fermions: particles with half-integer spin are fermions. . . . . . . 46\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe Dercum disease . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe New York Stock Exchange. . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\nHedge funds and monkeys. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nDialect detection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nThe Morse telegraph code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nOnOffLayer in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 57\\nThe Maxwell-Boltzmann distribution. . . . . . . . . . . . . . . . . . . . . . . . 58\\nA QuantumDrop layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nThe binomial distribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nZ-score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 382, 'page_label': '383'}, page_content=\"LIST OF FIGURES\\nConditional probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\nV enn diagram of the intersected events A and B in probability space H . . . . 63\\nAnnotated components of the Bayes formula (eq. 3.23) . . . . . . . . . . . . . . 64\\nMutual information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nReﬂection on the motive power of ﬁre. . . . . . . . . . . . . . . . . . . . . . . . 87\\nNatural (ln), binary (log2) and common ( log10) logarithms. . . . . . . . . . . . . 88\\nA Frog in its natural habitat. Photo taken by my son. . . . . . . . . . . . . . . . 95\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\\nShannon's ﬁve element communications system. . . . . . . . . . . . . . . . . . 99\\nAn octahedral dice. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in information theory . . . . . . . . . . . . . . . . . . . . . . . . . . 102\\nH vs. Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\nShannon information gain for a biased coin toss. . . . . . . . . . . . . . . . . . 107\\nAverage surprise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nFirst split. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nMutual Information between H(S) & H(D). . . . . . . . . . . . . . . . . . . . . 117\\nIntermediate value theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nA Computation graph with intermediate values as nodes and operations as\\narcs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nx2 Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\\nForward pass for the sigmoid function. . . . . . . . . . . . . . . . . . . . . . . . 135\\nPyTorch syntax for autograd. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 137\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 139\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 140\\nA computation graph for g(x) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nA Tangent line . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\n366\"),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 383, 'page_label': '384'}, page_content='Chapter 10 LIST OF FIGURES\\nForward and backward passes for the sigmoid activation function in pure\\nPython. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\\nForward and backward for the sigmoid function in Autograd. . . . . . . . . . 159\\nForward and backward for the ReLU function in Autograd. . . . . . . . . . . . 160\\nForward pass for equation ( 5.23) using pure Python. . . . . . . . . . . . . . . . 161\\nForward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . . 161\\nBackward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nInvoking arctanh using gradcheck . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nA Computation graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . 168\\nA derivative graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . . . 169\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 170\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 172\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSymPy gradient of the Sigmoid() function . . . . . . . . . . . . . . . . . . . . . 174\\nSymPy imports . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\\nLikelihood function using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . 176\\nBeta distribution using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\nA plot of the Posterior with the provided data samples. . . . . . . . . . . . . . 181\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 191\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 194\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 195\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 196\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 197\\nA learning rate schedule. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\n367'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 384, 'page_label': '385'}, page_content='LIST OF FIGURES\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depic-\\nted is the ResNet CNN architecture with 34 layers. . . . . . . . . . . . . . 206\\nPyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 206\\nA dataset of 4K histopathology WSI from three severity classes: A, B and C. . 209\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\\nSkin lesion categories. An exemplary visualization of melanoma. . . . . . . . 214\\nArtistic style transfer using the style of Francis Picabia’s Udnie painting. . . . 215\\nPyTorch declaration for a pre-trained ResNet34 CNN. . . . . . . . . . . . . . . 216\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\\nTwo CV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nStratiﬁed K-fold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nA speciﬁc CV approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 239\\nA 3 by 3 convolution kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 240\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 242\\nlisting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nAn unknown algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\\nJaccard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nA basic MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\n368'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 385, 'page_label': '386'}, page_content='Chapter 10 LIST OF FIGURES\\nA single layer perceptron. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nExamples of two sigmoid functions and an approximation. . . . . . . . . . . . 254\\nForward pass for the Sigmoid function using Libtorch . . . . . . . . . . . . . . 255\\nEvaluation of the sigmoid and its derivative using Libtorch . . . . . . . . . . . 255\\nExamples of two tanh functions. . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nA simple NN based on tanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 257\\nA small CNN composed of tanh blocks. . . . . . . . . . . . . . . . . . . . . . . 258\\nA small CNN composed of ReLU blocks. . . . . . . . . . . . . . . . . . . . . . 259\\nA confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 261\\nRUC AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\\nXGBOOST for binary classiﬁcation. . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics on the VGG11 CNN model. . . . . . . . . . . . . . . . . . . . 264\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nTwo consecutive Dropout layers . . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nA CNN based classiﬁcation system. . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nA small ﬁlter for a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nInput to MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . . . . 271\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 273\\nNormal distribution in Python. . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nA convolution and BN applied to an RGB image. . . . . . . . . . . . . . . . . . 275\\nA mistake in a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\\nA validation curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog-loss function curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\\nA problem with the log-loss curve. . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nManhattan distance function. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\n369'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 386, 'page_label': '387'}, page_content='LIST OF FIGURES\\nThe idea of hashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301\\nMLP operations- values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\\nHidden layer values, simple MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- values at the output. . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- Softmax. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\\nLogical AND: B=-2.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND: B=-0.25 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nBackward pass for the Sigmoid function using Libtorch. . . . . . . . . . . . . . 307\\nEvaluation of the sigmoid and its derivative in C++ using Libtorch. . . . . . . 308\\nForward pass for the Sigmoid function approximation in C++ using Libtorch. 309\\nPrinting the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\\nForward pass for tanh using pure Python. . . . . . . . . . . . . . . . . . . . . . 311\\nTanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\\nInvoking gradcheck on tanh. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313\\nA plot of the Swish activation function. . . . . . . . . . . . . . . . . . . . . . . 315\\nTP , TN, FP , FN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 317\\nConvolutional block from the VGG11 architecture. . . . . . . . . . . . . . . . . 319\\nEquivalence of two consecutive dropout layers . . . . . . . . . . . . . . . . . . 321\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nThe result of applying a ReLU activation. . . . . . . . . . . . . . . . . . . . . . 322\\nThe result of applying a MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . 322\\nOutput of the MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . 323\\nA single MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324\\nNormal distribution in Python: from scratch. . . . . . . . . . . . . . . . . . . . 325\\nThe derivative of a Normal distribution in Python. . . . . . . . . . . . . . . . . 325\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nSeveral image augmentation methods for TTA. . . . . . . . . . . . . . . . . . . 331\\nManhattan distance function in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 334\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 345\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346\\n370'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 387, 'page_label': '388'}, page_content='Chapter 10 LIST OF FIGURES\\nThe inﬂuenza virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 350\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\\nA dataset of human cells infected by the COVID19 pathogen. . . . . . . . . . . 351\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354\\n371'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 388, 'page_label': '389'}, page_content='LIST OF FIGURES\\n372'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 389, 'page_label': '390'}, page_content='Alphabetical Index\\nA\\nA 2D convolution . . . . . . . . . . . . . . . . . .235\\nA 512 dimension embedding . . . . . . . 206\\nA mathematical theory of\\ncommunication . . . . . . . . . . . . . 90\\nA random forest . . . . . . . . . . . . . . . . . . . 187\\nACC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .329\\nAccuracy . . . . . . . . . . . . . . . . .251, 283, 329\\nActivation functions . 125, 135 ff., 139 ff.,\\n157 f., 160, 163, 165, 168, 248,\\n256, 301, 306\\nActivation layer . . . . . . . . . . . . . . .253, 306\\nAD . . . . . . . . . . . . . . . . .123 f., 137, 140, 166\\nAdam . . . . . . . . . . . . . . . . . . . . . . . . . . . . .330\\nAdditivity property . . . . . . . . . . . . . . . .103\\nAlexNet . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nAlgorithmic differentiation . . . .125, 135,\\n137, 139 ff., 146, 157 f., 160, 163,\\n165, 168\\nAlzheimer’s disease . . . . . . . . . . . . . . . . . 20\\nAmalgam ﬁllings . . . . . . . . . . . . . . . . . . . 18\\nAnalytical gradients . . . . . . . . . . . . . . . 134\\nAnalyze a paper . . . . . . . . . . . . . . . . . . . 260\\nAND logic gate . . . . . . . . . . . . . . . . . . . . 252\\nANN . . . . . . . . . . . . . . . . . . . . . . . . . . .15, 135\\nAnnotated probabilities . . . . . . . . . . . . .62\\nAnnotations . . . . . . . . . . . . . . . . . . . . . . .282\\nANNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\\nANOV A . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nApproaches for combining predictors\\n190, 199\\nArithmetic operations . . . . . . . . . 138, 163\\nArithmetical methods . . . . . . . . . . . . . . .41\\nArtiﬁcial neural networks . . . . . . . 12, 15\\nAUC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nAugmentation . . . . . . . . . . . . . . . . . . . . .222\\nAugmentations . . . . . . . . . . . . . . . . . . . . . . 8\\nAuto correlation . . . . . . . . . . . . . . .235, 291\\nAutoAugment . . . . . . . . . . . . . . . . . . . . .223\\nAutoencoder . . . . . . . . . . . . . . . . . .279, 326\\nAutoGrad . . . . . . . . . . . . . . . . . . . . .158, 173\\nAutograd124 f., 135–141, 157 f., 160, 163,\\n165, 168, 310\\nAutomatic differentiation . . . .123 f., 173\\nAveraging and majority voting . . . . .202\\nB\\nBack-propagation in perceptrons . . 249,\\n301\\nBack-propogation . . . . . . . . . . . . . . . . . .247\\nBackprop learning . . . . . . . . . . . . . . . . .134\\nBackprop learning rule . . . . . . . . . . . . 134\\nBackpropagation . . . . . . . . . 123, 134, 158\\nBackpropagation algorithm . . . 135, 156\\nBackward pass125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nBagging . . . . . . . . . . . . . .186, 189, 193, 198\\nBasic laws of logarithms . . . . . . . . . . . . 88\\nBatch normalization . . . . . . . . . . .273, 324\\nBatchNorm2D . . . . . . . . . . . . . . . . 271, 343\\nBayes formulae . . . . . . . . . . . . . . . . . .45, 64\\nBayes rule . . . . . . . . . . . . . 45, 47, 66, 353 f.'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 390, 'page_label': '391'}, page_content='ALPHABETICAL INDEX\\nBayes theorem . . . . 42, 46–50, 65 f., 68 ff.\\nBayesian . . . . . . . . . . . . . . . . . . . . . . . . . . . .77\\nBayesian analysis . . . . . . . . . . . . . . . .65, 77\\nBayesian approximation . . . . . . . . . . . 192\\nBayesian deep learning . . . . . 55, 77, 352\\nBayesian dropout . . . . . . . . . . . . . . . . . .352\\nBayesian inference . . . . . . . . . . . . . . .42, 45\\nBayesian machine learning . . . . . . . . . .54\\nBayesian neural networks . . . . . .55 f., 79\\nBayesian paradigm . . . . . . . . . . . . . . . . . 42\\nBayesian statistical conclusions . . . . . 65\\nBayesian statistics . . . . . . . . . . . . . . . 42, 65\\nBernoulli . . . . . . . . . . . . . . . . . . . . . . .75, 277\\nBernoulli distribution . . . . . . . . . . . . . . .53\\nBernoulli random variable . . . . . . . . . . 18\\nBernoulli trial . . . . . . . . . . . . . . 42 f., 59, 62\\nBeta binomial . . . . . . . . . . . . . . . . . . . . . .146\\nBeta binomial distribution . . . . . . . . .54 f.\\nBeta distribution . . . . . . . 42, 55, 146, 176\\nBeta prior . . . . . . . . . . . . . . . . . . . . . . . . . . .55\\nBias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .282\\nBiased coin . . . . . . . . . . . . . . . . . . . . .92, 349\\nBiased coin toss . . . . . . . . . . . . . . . . . 64, 92\\nBiases . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nBinary class . . . . . . . . . . . . . . . . . . . . . . . . .38\\nBinary classiﬁcation 12, 15, 96, 137, 190,\\n193 f., 246\\nBinary code . . . . . . . . . . . . . . . . . . . . . . . . .90\\nBinary logistic regression . . . . . . . . 14, 31\\nBinary options . . . . . . . . . . . . . . . . . . . . 48 f.\\nBinary response . . . . . . . . . . . . . . . . . . . . .14\\nBinary response variable . . . . . 19, 94, 97\\nBinomial . . . . . . . . . . . . . . . . . . . .43, 53, 354\\nBinomial distribution31, 43, 52 f., 55, 59,\\n78\\nBinomial likelihood . . . . . . . . . . . . 54, 178\\nBinomial random variable . . . . . 43, 59 f.\\nBlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .318\\nBN . . . . . . . . . . . . . . . . . . .273 f., 277, 324 ff.\\nBNN . . . . . . . . . . . . . . . . . . . . . . . . . . 55 f., 79\\nBNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nBohm and Hiley . . . . . . . . . . . . . . . . . . . . 87\\nBoltzmann . . . . . . . . . . . .58, 86, 100 f., 118\\nBoltzmann entropy . . . . . . . . . . . . . . . . 118\\nBoltzmann’s constant . . . . . . . . . . . . . . 100\\nBoltzmanns entropy . . . . . . . . . . . . . . . 101\\nBoosting . . . . . . . . .186, 189, 193, 198, 200\\nBootstrap aggregation . . . . . . . . .189, 192\\nBosons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nBosons and fermions . . . . . . . . . . . . . . . .46\\nBottleneck . . . . . . . . . . . . . . . . . . . . 279, 326\\nBrazilian rain forest . . . . . . . . . . . . . . . . .94\\nBreast cancer . . . . . . . . . . . . . . . . . . . . . . . 17\\nC\\nCalculus . . . . . . . . . . . . . . . . .80, 122 f., 143\\nCalculus in deep learning . . . . . . . . . . 123\\nCancer . . . . . . . . . . . . . . . . . . . . . .16, 43, 208\\nCannabinoids . . . . . . . . . . . . . . . . . . . . . . .96\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . .96\\nCDC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354\\nCE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nChain of spherical bacteria . . . . . . . . . . 20\\nChain rule . . . . . . . . . . . . . . . . . . . . . . . . .163\\nChaotic distribution . . . . . . . . . . . . . . . . 38\\nCI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .35\\nClass probabilities . . . . . . . . . . . . .190, 199\\nClassic bagging . . . . . . . . . . . . . . . . . . . .199\\nClassic logistic regression . . . . . . . . . . . 35\\nClassic normalization . . . . . . . . . . . . . . .29\\nClassical committee machines . . . . . .189\\nClassical machine learning . . . . . . . . . 201\\nClassical probability . . . . . . . . . . . . . . . . 42\\n374'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 391, 'page_label': '392'}, page_content='Chapter 10 ALPHABETICAL INDEX\\nClassiﬁcation . . . . . 32, 206, 208, 289, 345\\nClassiﬁcation and information gain . 94,\\n110\\nClaud Shannon . . . . . . . . . . . . . . . . . . . . .90\\nCM . . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nCNN . . . 8, 190, 192, 205 f., 216, 272, 274,\\n318, 326, 344, 349\\nCNN arithmetics . . . . . . . . . . . . . . . . . . 318\\nCNN as Fixed Feature Extractor . . . 206,\\n216\\nCNN classiﬁers . . . . . . . . . . . . . . . . . . . .192\\nCNN feature extraction . . . . . . . . . . . . 206\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . .343\\nCNN model predictions . . . . . . . . . . . 190\\nCNN parameters . . . . . . . . . . . . . . . . . . 207\\nCNN residual blocks . . . . . . . . . . . . . . .326\\nCoefﬁcients . . . . . . . . . . . . . . . . . . 12, 16, 27\\nCoffee consumption . . . . . . . . . . . . . . . . 36\\nCoin toss . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nCoin toss probabillity . . . . . . . . . . . . . . . 93\\nCommon conﬁdence levels . . . . . . . . . .21\\nComplementary probability . . . . . . . . .63\\nComputational graph . . . . . . . . . . . . . .140\\nComputational graphs . . 127, 140 f., 165,\\n168\\nConcave . . . . . . . . . . . . . . . . . . . . . . 154, 202\\nConcave and Convex functions . . . . 101\\nConcavity . . . . . . . . . . . . . . . . . . . . .106, 154\\nConcavity of the logarithm . . . . . . . . 106\\nConditional entropy . . . . . . . . . . . . . . . 118\\nConditional independence . . . . . . . . . . 66\\nConditional probability42, 44–50, 62, 69\\nConﬁdence intervals . . . . . . . . . . . . . . . . 37\\nConfusion matrics . . . . . . . . . . . . .261, 316\\nConfusion matrix . . . . . . . . . . . . . . . . . .316\\nConjugate prior . . . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . .54 f., 77\\nContent loss . . . . . . . . . . . . 214, 216, 224 f.\\nConv2D . . . . . . . . . . . . . . . . . . . . . . .271, 343\\nConv2d layer . . . . . . . . . . . . . . . . . . . . . .223\\nConv4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nConvex . . . . . . . . . . . . . . . . . . . . . . . 132, 202\\nConvex down function . . . . . . . . . . . . 119\\nConvex functions . . . . . . . . . . . . . . . . . .132\\nConvNet’s as ﬁxed feature extractors\\n206\\nConvolution . . . . . . . . . . . . . .234, 277, 291\\nConvolution and correlation in python\\n294\\nConvolution complexity . . . . . . . . . . . 240\\nConvolution layer . . . . . . . . . . . . .268, 321\\nConvolutional layer . . . . . . . . . 268, 321 f.\\nConvolutional neural network . . . . . . . 8\\nConvolutional neural networks192, 198\\nCorrelation . . . . . . . . . . . . . . . . . .234 f., 291\\nCost . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nCost function . . . . . . . . . . . . . . . . . . . . . .247\\nCovariance . . . . . . . . . . . . . . . . . . . . . . . .189\\nCovariates . . . . . . . . . . . . . . . . . . . . . . . . . .17\\nCOVID19 . . . . . . . . . . . . . . . . . . . . .345, 351\\nCPP 23 f., 38 f., 142 f., 168 f., 242 f., 254 f.,\\n307 ff.\\nCPP hypothesis . . . . . . . . . . . . . . . . . . . . .23\\nCPU . . . . . . . . . . . . . . . . . . . . . . . . . .222, 289\\nCPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\nCross correlation . . . . . . . . . . . . . .235, 291\\nCross entropy . . . . . . . . . . . . . . . . 25 f., 251\\nCross entropy loss . . . . . . . . . . . . .214, 251\\nCross validation . . . . . . . . . . 231, 289, 328\\nCross validation approaches . . .231, 289\\nCUDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . .289\\nCV . . . . . . . . . . . . . . . . . . . . . . . . . . . .231, 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . 289\\n375'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 392, 'page_label': '393'}, page_content='ALPHABETICAL INDEX\\nD\\nDAG . . . . . . . . . . . . . . . . .123, 126, 141, 168\\nData Science . . . . . . . . . . . . . . . . . . . . . . . . .4\\nDecision boundary . . . . . . . . . . . . . . . . . .14\\nDecision tree . . . 94 f., 97 f., 111, 187, 198\\nDecision trees . . . . . . . . . . . . . 94, 96 f., 348\\nDecision trees and cannabinoids\\nadministration . . . . . . . . . . . . . . 96\\nDeep Learning . . . . . . . . . . . . . . . . . . . . . . .4\\nDeep learning . . . . . 22, 77, 123, 196, 352\\nDeep Learning Job Interviews . . . . . . . . 6\\nDeep learning pipelines . . . . . . . . . . . .221\\nDental amalgam . . . . . . . . . . . . . . . . . . . .19\\nDercum disease . . . . . . . . . . . . . . . . . . . . .47\\nDifferentiation . . . . . . . . . .122, 143 f., 150\\nDifferentiation in deep learning . . . . 123\\nDirect derivation . . . . . . . . . . . . . . . . . . . .32\\nDirected Acyclic Graph . . . . . . . . . . . . 168\\nDirected acyclic graph . . . . . . . . . . . . . 141\\nDirected acyclic graphs . . . . . . . .126, 147\\nDirectional derivative . . . . . . . . . . . . . .131\\nDirectional derivatives . . . . . . . . . . . . .125\\nDistribution . . . . . . . . . . . . . . . . . . . . . . . . 45\\nDL . . . . . . . . . . . . . . 123, 196, 206, 221, 352\\nDL classiﬁcation pipeline . . . . . . . . . . . 91\\nDL job interviews . . . . . . . . . . . . . . . . . .206\\nDN . . . . . . . . . . . . . . . . . . . . . . . . . .138 f., 163\\nDouble reading . . . . . . . . . . . . . .282 f., 329\\nDPN CNN . . . . . . . . . . . . . . . . . . . . . . . . .223\\nDropout8, 57, 267 f., 277, 319 f., 326, 352\\nDropout as a bayesian approximation\\n192\\nDropout in PyTorch . . . . . . . . . . . . . . . . .56\\nDropout layer . . . . . . . . . . 57, 267 f., 319 f.\\nDropped out neurons . . . . . . . . . . . . . . . 57\\nDual numbers . . . . . . . . . .138 ff., 163, 165\\nDual numbers in AD . . . . . . . . . . 138, 163\\nE\\nEbola . . . . . . . . . . . . . . . . . . . . . . . . .53, 354 f.\\nEmbedding . . . . . . . . . . . . . . . . . . . . . . . .206\\nEncoded messages . . . . . . . . . . . . . . . . . .51\\nEncrypted communications . . . . . . . . . 50\\nEnigma machine . . . . . . . . . . . . . . . . . . . .50\\nEnsemble averaging . . . . . . . . . . . . . . . 193\\nEnsemble learning . . . . . . . .186, 194, 201\\nEnsemble methods . . . . . . . . . . . . 190, 195\\nEnsembling . . . . . .186 ff., 190, 194 f., 197\\nEntropy 22, 38, 86 f., 89, 93, 95, 97 f., 106,\\n108, 214, 349\\nEntry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .186\\nEpidemic . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nEquiprobable events . 90 f., 103, 105, 118\\nEquiprobable sample . . . . . . . . . . . . . . 189\\nEquivocation . . . . . . . . . . . . . . . . . . . . . . . 99\\nEradication . . . . . . . . . . . . . . . . . . . . . . . .347\\nEradication probabillity . . . . . . . . . . . . .18\\nEuclidean . . . . . . . . . . . . . . . . . . . . .288, 333\\nExpansion of stars . . . . . . . . . . . . . . . . . . 97\\nExpectation . . . . . . . . . . . . . . . . . . . . . . . . .62\\nExpectation and variance . . . . . . . . 42, 59\\nExplanatory variable . . . . . . . . . . . . . . . .17\\nExponential family . . . . . . . . . . . . . . . . . .78\\nF\\nFc7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nFeature extraction 214 f., 224 f., 349, 351\\nFeature vector . . . . . . . . . . . . . . . . .205, 350\\nFeature vectors . . . . . . . . . . . . . . . . . . . . . 96\\nFeed forward neural networks 135, 158\\nFermions . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nFFNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\n376'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 393, 'page_label': '394'}, page_content='Chapter 10 ALPHABETICAL INDEX\\nFiltering . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nFiltering kernel . . . . . . . . . . . . . . . . . . . . 234\\nFilters . . . . . . . . . . . . . . . . . . . . . . . . .239, 293\\nFinancial mathematics . . . . . . . . . . . . . . 42\\nFine tuning CNNs . . . . . . . . . . . . 213, 222\\nFinite difference rule . . . . . . . . . . 125, 147\\nFisher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nFisher information . . . . . . . . . 51, 53, 73 f.\\nFisher score . . . . . . . . . . . . . . . . . . . . . . . . .73\\nFliping . . . . . . . . . . . . . . . . . . . . . . . . . . . .294\\nForward mode . . . . . . . . . .131, 140 f., 168\\nForward mode AD . 140 f., 163, 166, 168\\nForward mode AD table construction\\n142, 168\\nForward pass . 125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nG\\nGausiian distribution . . . . . . . . . .241, 295\\nGaussian . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nGaussian bell . . . . . . . . . . . . . . . . . . . . . .241\\nGaussian distribution . . . . . . . . . 274, 324\\nGaussian PDF . . . . . . . . . . . . . . . . . . . . . 324\\nGeneral concepts . . . . . . . . . . . . . . . . 12, 27\\nGeneralization . . . . . . . . . . . . . . . . 186, 206\\nGeneralized delta rule . . . . . . . . . . . . . 135\\ngeneralized linear models . . . . . . . . . . .14\\nGLM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\\nGLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\nGPU . . . . . . . . . . . . . . . . .222, 281, 289, 327\\nGPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\ngradcheck . . . . . . . . . . . . . . . . . . . . . . . . .310\\nGradient . . . . . . . . . . . . . . . . . . . . . .130, 247\\nGradient descent 123, 130, 146, 158, 247\\nGradient descent algorithm . . . . . . . . 132\\nGradient descent and backpropagation\\n124\\nGradients . . . . . . . . . . . . . . . . . . . . . . . . . .222\\nGram matrix . . . . . . . . . . . . . . . . . . . . . . .225\\nGrid search . . . . . . . . . . . . . . . . . . . 282, 328\\nGum bacteria . . . . . . . . . . . . . . . . . . . . . . .20\\nGUR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\nH\\nHereditary disease . . . . . . . . . . . . . . . . . .66\\nHereditary diseases . . . . . . . . . . . . . . . . .47\\nHessian . . . . . . . . . . . . . . . . . . . . . . . . . . . . .74\\nHessian matrix . . . . . . . . . . . . . . . . . . . . . 52\\nHeterogeneous ensembling . . . .191, 200\\nHidden layer . . . . . . . . . . . . . . . . . . .78, 248\\nHidden layers . . . . . . . . . . . . . . . . . . . . . 250\\nHidden node . . . . . . . . . . . . . 248, 252, 343\\nHinton . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nHistopathology . . . . . . . . . . . .43, 217, 351\\nHuang1704snapshot . . . . . . . . . . . . . . .202\\nHuman voice activity . . . . . . . . . . . . . . . 31\\nHyperbolic tangent . . . . . . . . . . . . . . . . 134\\nHyperbolig tangent . . . . . . . . . . . . . . . .138\\nHyperparameter optimization . . . . . 282,\\n327 f.\\nHyperparameters . . . . . . . . . . . . . . . . . .328\\nHypotheis . . . . . . . . . . . . . . . . . . . . . . . . . .16\\nI\\nIdeal classiﬁer . . . . . . . . . . . . . . . . .262, 317\\nIdentity connection . . . . . . . . . . . . . . . . 326\\nImage analysis . . . . . . . . . . . . . . . . . . . . .110\\nImage and text similarity . . . . . . . . . . 296\\nImage processing . . . . . . . . . . . . . . . . . .234\\nImageNet . . . . . . . . . . . . . . . . . .206 f., 222 f.\\nImageNet pre trained CNNs . . . . . . . 213\\n377'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 394, 'page_label': '395'}, page_content='ALPHABETICAL INDEX\\nImageNet pretrained CNN classiﬁers\\n192\\nImproper prior . . . . . . . . . . . . . . . . . . . . . 54\\nIndependent binary co variates . . . . . 94\\nIndependent events . . . . . . . . . . . . . . . . .45\\nIndependent variables . . . . . . . . . . .19, 97\\nIndividual predictions . . . . . . . . . . . . . 192\\nInductive inference . . . . . . . . . . . . . . . . . 86\\nInference . . . . . . . . . . . . . . . . . . . . . .286, 330\\nInformation gain . . . . . . . . . . 94–98, 106 f.\\nInformation gain values . . . . . . . . . . . . .95\\nInformation matrix . . . . . . . . . . . . . . . . . 53\\nInformation theory . . . . . . . 58, 86, 88–93,\\n98–101, 106, 347\\nInteractions . . . . . . . . . . . . . . . . . . . . . . . . .13\\nIntermediate value theorem . . . . . . . .124\\nIntersected events . . . . . . . . . . . . . . . . . . .63\\nIntroduction . . . .12, 42, 86, 122, 186, 205\\nJ\\nJacard similarity . . . . . . . . . . . . . . . . . . .297\\nJAX . . . . . . . . . . . . . . . . . . . . . . . . . . .136, 158\\nJensen . . . . . . . . . . . . . . . . . . . . . . . . 101, 119\\nJensen’s inequality . . . . . . . . . . . . 101, 118\\nJob Interview . . . . . . . . . . . . . . . . . . . . . . . . 4\\nJohn von Neumann . . . . . . . . . . . . . . . . . 41\\nJoint distribution . . . . . . . . . . . . . . . . . . 110\\nJupyter notebook . . . . . . . . . . . . . . . . . . 143\\nK\\nK Fold cross validation . . . . . . . . . . . . 289\\nK way FC layer . . . . . . . . . . . . . . . . . . . . 217\\nK-Fold cross validation . . . . . . . . . . . . 232\\nKaggle . . . . . . . . . . . . . . . . . . . . . . . .186, 201\\nKaggle competitions . . . . . . . . . . . . . . .201\\nKaiming . . . . . . . . . . . . . . . . . . . . . . . . . . .258\\nKernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nKernels . . . . . . . . . . . . . . . . . . . . . . . 239, 293\\nKL divergence . . . . . . . .53, 93, 100 f., 109\\nKLD . . . . . . . . . . . . . . . . . . . . . . .93, 119, 297\\nKullback Leibler . . . . . . . . . . . . . . . . . . .297\\nKullback Leibler divergence 87, 93, 108\\nL\\nL1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288, 333\\nL2 . . . . . . . . . . . . . . . . . . . . . . . . . . .288, 333 f.\\nLabelling and bias . . . . . . . . . . . . . . . . . 328\\nLaTeX . . . . . . . . . . . . . . . . . . . . . . . . .174, 176\\nLaw of total probability42, 46–50, 66–70\\nLaws of data compression . . . . . . . . . . 86\\nLDCT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nLeaky ReLU . . . . . . . . . . . . . . . . . . . . . . .259\\nLearning logical gates . . . . . . . . . . . . . .305\\nLearning rate schedules in ensembling\\n197, 202\\nLeave one out CV . . . . . . . . . . . . . . . . . .290\\nLeave-one-out CV . . . . . . . . . . . . . . . . . 234\\nLibtorch . . . . . . . . . . . . . .254 f., 257, 307 ff.\\nLikelihood . . . . . . . . . . . . . . . . . . . .44 f., 353\\nLikelihood function . . . 51, 53, 56, 73, 79\\nLikelihood parameter . . . . . . . . . . . . . . .45\\nLimits and continuity . . . . . . . . . 130, 151\\nLinear classiﬁers . . . . . . . . . . . . . . . . . . .219\\nLinear combination of regression . . 201\\nLinear decision boundary . . . . . . . . . . . 14\\nLinear logistic regression model . . . . . 33\\nLinear model in PyTorch . . . . . . . . . . . .24\\nLinear regression . . . . . . . . . . . . . . . . . . 133\\nLinear transformation . . . . . . . . . . . . . 343\\nLinearity . . . . . . . . . . . . . . . . . . . . . . . . . . 235\\nLink function . . . . . . . . . . . . . . . . . . . . . . .31\\nLocal minima . . . . . . . . . . . . . . . . . 198, 202\\n378'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 395, 'page_label': '396'}, page_content='Chapter 10 ALPHABETICAL INDEX\\nLog likelihood . . . . . . . . . . . . . . . . . . . . . .13\\nLog likelihood function . . 51, 53, 73, 355\\nLog loss . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog odds . . . . . . . . . . . . 13 f., 17 f., 20 f., 29\\nLogarithm . . . . . . . . . . . . . . . . . . . 35, 53, 72\\nLogarithmic function . . . . . . . . . . . . . . 166\\nLogarithms . . . . . . . . . . . .88 f., 101 ff., 172\\nLogarithms in information theory . . . 87\\nLogic gate . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical gates . . . . . . . . . . . . . . . . . .251, 305\\nLogistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogistic inverse . . . . . . . . . . . . . . . . . . . . .14\\nLogistic regression 12–16, 24 ff., 28 f., 31,\\n36, 137, 345\\n• Sigmoid . . . . . . . . . . . . . . . . . . . . . .253\\nLogistic regression classiﬁer . . . . . . . . .19\\nLogistic regression coefﬁcients . . . . . . 16\\nLogistic regression implementation23 f.\\nLogistic regression in C++ . . . . . . . . . . 39\\nLogistic regression in Python . . . . . . . 26\\nLogistic regression model . . . . . . . .27, 35\\nLogistic regression predictor variable12\\nLogistic regression threashold . . . . . . .39\\nLogistic response function . . . . . . . . . . 33\\nLogit . . . . . . . . . . . . . . . . . . . . . . . . . . . .14, 32\\nLogit equation . . . . . . . . . . . . . . . . . . . . . .16\\nLogit function . . . . . . . . . . . . . . . .14, 22, 31\\nLogit inverse . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogit transformation . . . . . . . . . . . . . . . .14\\nLogit value . . . . . . . . . . . . . . . . . . . . . . . . . 33\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . .234, 290\\nLoss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .334\\nLoss function . . . . . . . . . . . . . . . . . . . . . .133\\nLow model generalization . . . . . . . . . 109\\nLow standard error . . . . . . . . . . . . . . . . . 75\\nLower entropy . . . . . . . . . . . . . . . . . . . . . .38\\nLR . . . . . . . . . . . . . 16, 27, 33, 133, 137, 345\\nLR coefﬁcients . . . . . . . . . . . . . . . . . . . . . .16\\nLung cancer . . . . . . . . . . . . . . . . . . . .17, 282\\nM\\nM.Sc in Artiﬁcial Intelligence . . . . . . . . . 4\\nMachine learning . . . . . . 13 f., 25, 28, 316\\nMachine learning terminology . . . . . . 13\\nMacLaurin expansion . . . . . . . . . . . . . .128\\nMacLaurin series . . . . . . . . . . . . . . . . .128 f.\\nMagna Carta . . . . . . . . . . . . . . . . . . . . . . . .90\\nMajority voting . . . . . . . . . . .186, 190, 202\\nMalignant tumour . . . . . . . . . . . . . . . . . . 17\\nMalignant tumours . . . . . . . . . . . . . . . . . 96\\nManhattan . . . . . . . . . . . . . . . . . . . .288, 333\\nManual differentiation . . . . . . . . 124, 170\\nMaster’s programme in Artiﬁcial\\nIntelligence . . . . . . . . . . . . . . . . . . .4\\nMasters programme . . . . . . . . . . . . . . . . . 4\\nMathJax . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nMaximum likelihood estimatator . . . .73\\nMaximum likelihood estimation . 51, 71\\nMaxpool2D . . . . . . . . . . . . . . . . . . .271, 343\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxwell Boltzmann distribution . . . . 57\\nMaxwell distribution . . . . . . . . . . . . . . . 58\\nMean ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .241\\nMean square error . . . . . . . . . . . . . . . . . 225\\nMeasurement vector . . . . . . . . . . . . . . . . 16\\nMechanical statistics . . . . . . . 42, 100, 118\\nMedical AI . . . . . . . . . . . . . . . . . . . . . . . . 217\\nMelanoma . . . . . . . . . . . . . . . . . . . . . . . . .213\\nMigraine probabillity . . . . . . . . . . . . . . . 20\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . .298\\nML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .316\\nMLE . . . . . . . . . . . . . . . . . . .51, 53, 72 f., 355\\nMLP . . . . . . . . . . . . . . .246 ff., 252, 299, 343\\n379'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 396, 'page_label': '397'}, page_content='ALPHABETICAL INDEX\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . .332\\nMonolithic and heterogeneous\\nensembling . . . . . . . . . . . .191, 200\\nMonolithic architectures . . . . . . . . . . . 200\\nMonolithic ensembling . . . . . . . . . . . . 191\\nMonotonically increasing function . . 72\\nMonte Carlo dropout . . . . . . . . . . . . . . 192\\nMSE . . . . . . . . . . . . . . . . . . . . . .225, 288, 333\\nMulti class responses . . . . . . . . . . . . . . . 29\\nMulti Layer Perceptrons . . . . . . . . . . . 246\\nMulti layer perceptrons . . . . . . . . . . . . 299\\nMulti model ensembling . . . . . . 196, 202\\nMulticlass classiﬁcation . . . . . . . . . . . . . 12\\nMulticlass classiﬁcation problems . . . 12\\nMultivariable . . . . . . . . . . . . . . . . . . . . . . .12\\nMultivariable methods . . . . . . . . . . . . . .12\\nMutual information . . .86, 94, 98 ff., 110,\\n116\\nMutual information formulae . . . . . . 117\\nN\\nN dimensional feature vector . . . . . . 205\\nNatural logistic function . . . . . . . . . . . . 14\\nNatural logistic sigmoid . . . . . . . . . . . . 14\\nNegative log likelihood . . . . . . . . . . . . . 13\\nNeural network . . . . . . . . . . . . . . .195, 202\\nNeural network ensembles . . . . 186, 191\\nNeural networks . . 55, 57, 127, 135, 158,\\n186\\nNeural style transfer . . . . . . . . . . . . . 214 f.\\nNeuron activation function . . . . . . . . . 15\\nNew York stock exchange . . . . . . . . . . .48\\nNLL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .13\\nNN . . . . . . . . . . 55, 127, 135, 158, 186, 202\\nNN Layers . . . . . . . . . . . . . . . . . . . . . . . . 318\\nNoise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99\\nNon convex neural networks . . . . . . 203\\nNon informative prior . . . . . . . . . . . . . . 54\\nNon informative priors . . . . . . . . . . . . . 77\\nNon interacting identical particles . 118\\nNon linearity . . . . . . . . . . . . . . . . . . . . . .301\\nNon-differentiable . . . . . . . . . . . . . . . . .301\\nNon-linearity . . . . . . . . . . . . . . . . . . . . . .248\\nNonlinear layer . . . . . . . . . . . . . . . 253, 306\\nNormal distribution . . . . . . . . . . .274, 324\\nNormalization constant . . . . . . . . . . . . .64\\nNST . . . . . . . . . . . . . . . . . . . . . . . . . . . . .214 f.\\nNumerical Differentiation . . . . . . . . . .147\\nNumerical differentiation . . .124 ff., 146,\\n173\\nNumerical instability . . . . . . . . . . . . . . 146\\nNumpy . . . . . . . . . . . . . . . . . . . . . . . . . . . .221\\nO\\nOctahedral dice . . . . . . . . . . . . . . . . . . . .101\\nOdds . . . . . . . . . . . . . . . . . . . . . . . . . .12 f., 29\\nOdds of success in a binary response 14\\nOnOffLayer . . . . . . . . . . . . . . . . . . . . .56, 78\\nOOM . . . . . . . . . . . . . . . . . . . . . . . . .281, 327\\nOptimization . . . . . . . . . . . . . . . . . .131, 153\\nOptimization loss . . . . . . . . . . . . . . . . . .331\\nOrdinary predictors . . . . . . . . . . . . . . . . .28\\nOut of memory . . . . . . . . . . . . . . . 281, 327\\nOverﬁtting . . . . . . . . . . . . . . . . . .12, 27, 194\\nP\\nP value . . . . . . . . . . . . . . . . . . . . . . . . . . . . .36\\nPadding . . . . . . . . . . . . . . . . . . . . . . 236, 292\\nPancreactic cancer . . . . . . . . . . . . . . . . . . 43\\nPancreatic cancer classiﬁcation . . . . . 208\\nPartial derivative . . . . . . . . . . . . . . . . . . . 53\\nPartial derivatives . . . . . .130 ff., 142, 152\\n380'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 397, 'page_label': '398'}, page_content='Chapter 10 ALPHABETICAL INDEX\\nParticle physics . . . . . . . . . . . . . . . . . . . . .45\\nPDF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nPerceptron . . . . . . . . . . . . . . . . . . . .246, 299\\nPerceptron learning rule . . . . . . . . . . . 252\\nPerceptrons . . . . . . . . . .299, 301, 304, 343\\nPerformance metrics . . . . . . . . . . . . . . .316\\nPhysical constants . . . . . . . . . . . . . . . . . 100\\nPlacenta Chorion Test . . . . . . . . . . . . . .353\\nPlacenta chorion test . . . . . . . . . . . . . . 46 f.\\nPlanck’s constant . . . . . . . . . . . . . . . . . . 100\\nPlateau . . . . . . . . . . . . . . . . . . . . . . . . . . . .284\\nPMF . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43, 59\\nPoisson . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75\\nPoisson distribution . . . . . . . . . . . . . . . . 53\\nPooling Layer . . . . . . . . . . . . . . . . . . . . . 270\\nPooling layer . . . . . . . . . . . . . . . . . . . . . . 322\\nPosterior . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPosterior and prior predictive\\ndistributions . . . . . . . . . . . . . . . . 54\\nPosterior distribution . 54, 146, 180, 354\\nPosterior predictive distributions . . . 76\\nPre trained CNN . . . . . . . . . . . . . . . . . . 349\\nPre trained CNNs . . . . . . . . . . . . . . . . . .205\\nPre trained VGG19 CNN model . . . . 220\\nPrecision . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nPredictor variables . . . . . . . . . . . . . . . . . .28\\nPrior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPrior distribution . . . . . . . . . . . . . . . . . . . 45\\nPrior distributions . . . . . . . . . . . . . . . . . . 77\\nPrior predictive distribution . . . . 54, 354\\nProbabilistic programming . . . . . . . . . .42\\nProbability distribution . . . . . . . . . .13, 94\\nProbability mass function . . . . . . . .43, 60\\nProbability of failure . . . . . . . . . . . . . . . .28\\nProbability space . . . . . . . . . . . . . . . . . . . 44\\nProbability statements . . . . . . . . . . . . . . 65\\nProblems . . . . . . . . . . . . . . . . . .12, 186, 206\\nProton theraphy . . . . . . . . . . . . . . . . . . . . 43\\nProton therapy . . . . . . . . . . . . . . . . . . 16, 43\\nPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .16, 43\\nPulmonary nodules . . . . . . . . . . . 282, 345\\nPyMc3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nPython . 7, 23–27, 38 ff., 42, 56 f., 88, 102,\\n107 f., 112, 114, 123, 134, 136,\\n138, 140, 143 f., 157, 159 f., 163,\\n165 f., 170, 172 f., 175 ff., 179,\\n181, 191, 195–198, 202, 206,\\n210 f., 218, 221, 223 f., 232,\\n239 ff., 250 f., 256 f., 263 f., 266 ff.,\\n272, 282, 288, 294 f., 300–304,\\n312, 319 f., 330, 343 f., 349\\nPython coin toss . . . . . . . . . . . . . . . . . . . 108\\nPython interpreter . . . . . . . . . . . . . . . . . . 88\\nPyTorch . 7, 23–26, 38, 40, 56 f., 123, 134,\\n136, 138, 140, 143, 157, 159 f.,\\n163, 165 f., 170, 173, 176 f., 181,\\n191, 195 ff., 202, 206, 210 f., 218,\\n221, 223 f., 254–257, 267 f., 272,\\n288, 307 ff., 319 f., 343 f., 349\\nPytorch . . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nPyTorch code snippet for an ensemble\\n191\\nPyTorch sequential . . . . . . . . . . . . . . . . 257\\nPyTorch tanh . . . . . . . . . . . . . . . . . . . . . .257\\nQ\\nQuadratic equation . . . . . . . . . . . . . . . . . 80\\nQuantum drop . . . . . . . . . . . . . . . . . . . . . .57\\nQuantum physics . . . . . . . . . . . . . . . . . .100\\nQuantum states . . . . . . . . . . . . . . . . . . . . .45\\nQuantum term speed . . . . . . . . . . . . . . . 79\\n381'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 398, 'page_label': '399'}, page_content='ALPHABETICAL INDEX\\nR\\nRadiation therapy . . . . . . . . . . . . . . . 17, 98\\nRadiation therapy planning . . . . . . . . . 17\\nRadiology . . . . . . . . . . . . . . . . . . . . . . . . .282\\nRandom guess classiﬁer . . . . . . . 262, 317\\nRandom number seeds . . . . . . . . . . . . 186\\nRandom search . . . . . . . . . . . . . . . 282, 328\\nRecall . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic . . 261\\nReceiver operating characteristic . . . 316\\nRectiﬁcation . . . . . . . . . . . . . . . . . . . . . . .306\\nRelative entropy . . . . .98 f., 109, 117, 349\\nRelative maxima and minima . . . . . . 132\\nRelative risk . . . . . . . . . . . . . . . . . . . . . . . .34\\nRelative shrinkage frequency . . . . . . 112\\nRelative star expansion frequency . . 115\\nReLU . . . .248 f., 253, 258 f., 301, 306, 314\\nRendering sympy in Google colab . 143\\nResNet . . . . . . . . . . 205, 207, 211, 217, 223\\nResNet152 . . . . . . . . . . . . . . . . . . . . . . . . .205\\nResNet18 . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nResNet34 . . . . . . . . . . . . . . . . .205, 211, 349\\nResNet34 CNN . . . . . . . . . . . . . . . . . . . .211\\nResNetBottom . . . . . . . . . . . . . . . . . . . . .211\\nResNets . . . . . . . . . . . . . . . . . . . . . . . . . . .326\\nResponse variable . . . . . . . . . . 12 f., 17, 29\\nReversing probabilities . . . . . . . . . . . . . 47\\nROC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nROC AUC . . . . . . . . . . . . . . . . . . . . . . . . .316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . .261\\nRosenblatt . . . . . . . . . . . . . . . . . . . . . . . . .252\\nRR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34\\nRussakovsky . . . . . . . . . . . . . . . . . . . . . . 206\\nRussakovsky 2015 . . . . . . . . . . . . . . . . . 206\\nS\\nSaddle points . . . . . . . . . . . . . . . . . . . . . .155\\nSame padding . . . . . . . . . . . . 236, 238, 292\\nSample odds ratio . . . . . . . . . . . . . . . . . . 37\\nSampling approaches . . . . . . . . . . . . . .189\\nSampling with replacement . . . 189, 199\\nSampling without replacement 189, 199\\nSearch space . . . . . . . . . . . . . . . . . . 282, 328\\nSecond derivative test . . . . . . . . . . . . . 132\\nSeed values in AD . . . . . . . . . . . . .142, 170\\nSequential . . . . . . . . . . . . . . . . . . . . . . . . .221\\nSGD . . . . . . . . . . . . . . . . . . . . . .286 f., 330 ff.\\nShannon . . . . . . . 86 f., 89, 100, 103 f., 117\\nShannon bit . . . . . . . . . . . . . . . . . . . . . . . . .90\\nShannon’s famous general formulae\\n103\\nShannon’s general formulae . . . . . . . . 89\\nShift-invariance . . . . . . . . . . . . . . . . . . . .235\\nSigmoid . . . 15, 23, 32, 134, 137, 144, 160,\\n253, 306\\nSigmoid activation function . . . . 33, 137,\\n157 f., 160\\nSigmoid derivative . . . . . . . . . . . . . . . . . 15\\nSigmoid function . . . . . . . . . . . . . . . . . . 157\\nSigmoid gradient . . . . . . . . . . . . . .144, 173\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . 173\\nSigmoidal neuron . . . . . . . . . . . . . . . . . .247\\nSigmoidal perceptron . . . . . . . . . . . . . .246\\nSimilarity measures . . . . . . . . . . . . . . . .296\\nSimple differentiation . . . . . . . . . 144, 172\\nSingle Layer Perceptrons . . . . . . . . . . .246\\nSingle layer perceptrons . . . . . . . . . . . 299\\nSingle model based AI systems . . . . 186\\nSingle predictors . . . . . . . . . . . . . . . . . . .201\\nSkip connection . . . . . . . . . . . . . . . . . . . .326\\nSnapshot ensembling . . . 189 f., 195, 201\\n382'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 399, 'page_label': '400'}, page_content='Chapter 10 ALPHABETICAL INDEX\\nSobel ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .294\\nSoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nsoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . . .217\\nSoftmax activation . . . . . . . . . . . . . . . . .251\\nSoftmax activation function . . . . . . . . . 32\\nSoftmax derivation . . . . . . . . . . . . . . . . . 32\\nSoftmax function . . . . . . . . . . . . . . . . 32, 40\\nSoftmax layers . . . . . . . . . . . . . . . . . . . . . .29\\nSoftmax neurons . . . . . . . . . . . . . . . . . . .214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . .198\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . .49\\nSpeed of light in vacum . . . . . . . . . . . . 100\\nSperable convolutions . . . . . . . . .241, 295\\nSplitting criterion . . . . . . . . . . . . . . . . . .111\\nStacking . . . . . . . . . . . . . . . . . .186, 189, 198\\nStacking and bagging . . . . . . . . . . . . . .187\\nStan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nStandard deviation . . . . . . . . . . . . . . . . . 61\\nStar density . . . . . . . . . . . . . . . . . . . . . . . . .97\\nStar expansion . . . . . . . . . . . . . . . . . . . . .115\\nStatic committee machines . . . . . . . . . 201\\nStatistical distribution . . . . . . . . . . . . . . .44\\nStatistical independence . . . . . . . . . . . . 45\\nStatistical mechanics . . . . . . . . . . . . .11, 86\\nStochastic . . . . . . . . . . . . . . . . . . . . . . . . . .287\\nStochastic gradient descent . . . . 247, 331\\nStochastic gradient descent, SGD . . 286\\nStock markets . . . . . . . . . . . . . . . . . . . . . . .48\\nStocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .48\\nStratiﬁcation . . . . . . . . . . . . . . . . . . 233, 290\\nStratiﬁed K fold . . . . . . . . . . . . . . . . . . . 290\\nStratiﬁed K-Fold . . . . . . . . . . . . . . . . . . .233\\nStride . . . . . . . . . . . . . . . . . . . . 236, 292, 323\\nSTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\nStyle loss . . . . . . . . . . . . . . . 214, 216, 224 f.\\nStyle transfer . . . . . . . . . . . . . . 214 f., 224 f.\\nSupervised learning . . . . . . . . . . . . . . . . 28\\nSupervised machine learning . . . . . . . 12\\nSurprise . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . .260, 315\\nSymbolic differentiation . . . 123 f., 143 f.,\\n172 f.\\nSymPy . . . . . . . . .124, 143 f., 146, 173, 177\\nT\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310\\ntanh . . . . . . . . . . . . . . . . . . . . 253, 256 f., 306\\nTaylor series . . . . . . . . . . . . . . . . .122, 128 f.\\nTaylor series and dual numbers . . . . 163\\nTaylor series expansion . . . . . . 128 f., 150\\nTest set . . . . . . . . . . . . . . . . . . . . . . . . . . . .328\\nThe backpropagation algorithm . . . . 134\\nThe bayesian school of thought . . . . . 42\\nThe beta binomial model . . . . . . 144, 174\\nThe chain rule . . . . . . . . . . . . . . . . .127, 149\\nThe convolution operator . . . . . 234, 291\\nThe correlation operator . . . . . . .234, 291\\nThe gaussian distribution . . . . . . . . . . 324\\nThe gradient descent algorithm . . . . 155\\nThe gram matrix . . . . . . . . . . . . . . . . . . .225\\nThe hyperplane . . . . . . . . . . . . . . . . . 14, 31\\nThe Kullback Leibler distance . . . . . . 297\\nThe Likelihood function . . . . . . . . . . . 174\\nThe logit function and entropy . . . . . . 38\\nThe multi layer perceptron . . . . . . . . . 300\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . .32\\nThe sigmoid . . . . . . . . . . . . . . . . . . . . . . . . 15\\nThe sigmoid function . . . . . . . . . . . . . . . 29\\nThe theory of perceptrons . . . . . . . . . .304\\nTheory of CNN design . . . . . . . . . . . . .326\\nThermodynamics . . . . . . . . . . 86, 100, 103\\nTopologies . . . . . . . . . . . . . . . . . . . . . . . . .318\\nToxic mercury fumes . . . . . . . . . . . . . .18 f.\\n383'),\n",
              " Document(metadata={'producer': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creator': 'Adobe Acrobat Pro DC (32-bit) 21.7.20099', 'creationdate': '2022-01-04T07:43:45+02:00', 'moddate': '2022-01-04T07:43:45+02:00', 'title': '', 'source': '/content/dl intervie.pdf', 'total_pages': 401, 'page': 400, 'page_label': '401'}, page_content='ALPHABETICAL INDEX\\nTrain validation split . . . . . . . . . . . . . . .281\\nTraining corpus . . . . . . . . . . . . . . . 189, 200\\nTraining curve curve . . . . . . . . . . 283, 329\\nTraining hyperparameters . . . . . . . . . 327\\nTraining validation epoch . . . . . . . . . .196\\nTransformation . . . . . . . . . . . . . . . . . . . .222\\nTriangle inequality . . . . . . . . . . . . . . . . .109\\nTrue probability distribution . . . . . . . . 93\\nTruly understanding LR . . . . . . . . . 16, 33\\nTTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .69\\nTumors . . . . . . . . . . . . . . . . . . . . . . . . . . . . .98\\nTumour eradication . . . . . . . . . . . . . 17, 34\\nTumour shrinkage . . . . . . . . . . . . . . . . . .96\\nTumour shrinkage in rats . . . . . . . . . . . 22\\nTwo dimensional matrix . . . . . . . . . . . . 24\\nU\\nUncertainty . . . . . . . . . . . . . . . . . . . . . . .89 f.\\nUniversal function approximators . 251\\nV\\nValid padding . . . . . . . . . . . . 236, 238, 292\\nValidation curve . . . . . . . . . . . . . . 283, 329\\nValidation curve ACC . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . .329\\nValidation set . . . . . . . . . . . . . . . . . . . . . .328\\nVanilla linear regression . . . . . . . . . . . . .14\\nVanishing gradients . . . . . . . . . . . . . . . .258\\nVariance . . . . . . . . . . . .42 f., 59, 62, 74, 201\\nV enn diagram . . . . . . . . . . . . . . . . .44 f., 99\\nVGG . . . . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nVGG conv43 layer . . . . . . . . . . . . . . . . . 209\\nVGG fc7 layer . . . . . . . . . . . . . . . . . . . . . 209\\nVGG Net . . . . . . . . . . . . . . . . . . . . . .205, 216\\nVGG16 . . . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nVGG19 . . . . . . . . . . . . . . . . . . . 209, 221, 351\\nVGG19 architecture . . . . . . . . . . . . . . . .208\\nVGG19 CNN . . . . . . . . . . . . . 208, 218, 351\\nV oting power . . . . . . . . . . . . . . . . . . . . . .201\\nVumulative distribution . . . . . . . . . . . . .62\\nW\\nWald chi squared test . . . . . . . . . . . . . . . 28\\nWeight initialization247, 253, 258, 299 f.,\\n314\\nWest African ebola . . . . . . . . . . . . . . . . . .52\\nWSI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .208\\nWW2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .50\\nX\\nXavier . . . . . . . . . . . . . . . . . . . . . . . . 258, 330\\n384')]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OyXx6VEvp9Ml"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UECxIgwS-71i",
        "outputId": "ac0bac73-cf7c-4af1-f66b-f4370b3befb4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "401"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_gen=\"\"\n",
        "for page in data:\n",
        "  question_gen+=page.page_content"
      ],
      "metadata": {
        "id": "rlom9Wkb-9Ue"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "1kz_N6Yo_Kvi",
        "outputId": "077855e0-cc61-4c34-d2ce-18d19cacc949"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SHLOMO KASHANI\\nDeep Learning Interviews is home to hundreds of fully-solved problems, \\nfrom a wide range of key topics in AI. It is designed to both rehearse \\ninterview or exam-specific topics and provide machine learning M.Sc./Ph.D. \\nstudents, and those awaiting an interview a well-organized overview of the \\nfield. The problems it poses are tough enough to cut your teeth on and to \\ndramatically improve your skills-but they’re framed within thought-\\nprovoking questions and engaging stories.\\nThat is what makes the volume so specifically valuable to students and job \\nseekers: it provides them with the ability to speak confidently and quickly on \\nany relevant topic, to answer technical questions clearly and correctly, and to \\nfully understand the purpose and meaning \\nof interview questions and \\nanswers. These are powerful, indispensable advantages to have when walking \\ninto the interview room.\\nThe book’s contents is a large inventory of numerous topics relevant to DL \\njob interviews and graduate-level exams. That places \\nthis work at the \\nforefront \\nof the growing trend in science to teach a core set of practical \\nmathematical and computational \\nskills. It is widely accepted that the \\ntraining of every computer scientist must include the fundamental theorems \\nof ML, and AI appears in the curriculum of \\nnearly every \\nuniversity. This \\nvolume is designed as an excellent reference for graduates of \\nsuch programs.\\nShlomo Kashani, Author. \\nwww.interviews.ai\\nDEEP LEARNING INTERVIEWS\\nDEEP LEARNING \\nINTERVIEWS\\nSHLOMO KASHANI deep learning interviews\\nAmir Ivry, Chief Editor.\\n    REAL-WORLD DEEP LEARNING INTERVIEW \\nPROBLEMS & SOLUTIONS\\n• Logistic Regression\\n• Information Theory\\n• Calculus\\n• Algorithmic Differentiation\\n• Bayesian Deep Learning\\n• Probabilistic Programming\\n• Ensemble Learning\\n• CNN Feature Extraction\\n• Deep Learning: Expanded Chapter\\nsecond editionSHLOMO KASHANI\\nDEEP LEARNING INTERVIEWS\\nBy Shlomo Kashani, M.Sc, QMUL, UK.\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nPublished by Shlomo Kashani, Tel-Aviv , ISRAEL.\\nVisit: http://www.interviews.ai\\nCopyright, 2020\\nThis book is protected by copyright.\\nNo part may be reproduced in any manner without written permission from the publisher.\\nPrinting version: VER . 26 TH OCTOBER 2021\\nPrinted in the United States of America.\\nLibrary of Congress Cataloging-in-Publication Data\\nA catalog record for this book is available from the Library of CongressCOPYRIGHT.\\n© 2016-2020 Shlomo Kashani, entropy@interviews.ai\\nA\\nLL RIGHTS RESERVED .The content contained within this book may not be\\nreproduced, duplicated or transmitted without direct written permission\\nfrom the author or the publisher. Under no circumstances will any blame\\nor legal responsibility be held against the publisher, or author, for any dam-\\nages, reparation, or monetary loss due to the information contained within this book.\\nEither directly or indirectly . This book is copyright protected. This book is only for\\npersonal use. You cannot amend, distribute, sell, use, quote or paraphrase any part, or\\nthe content within this book, without the consent of the author or publisher.\\nPlease note the information contained within this document is for educational and\\nentertainment purposes only . All effort has been executed to present accurate, up to\\ndate, and reliable, complete information. No warranties of any kind are declared or\\nimplied. Readers acknowledge that the author is not engaging in the rendering of\\nlegal, ﬁnancial, medical or professional advice. The content within this book has been\\nderived from various sources. Please consult a licensed professional before attempt-\\ning any techniques outlined in this book. By reading this document, the reader agrees\\nthat under no circumstances is the author responsible for any losses, direct or indirect,\\nwhich are incurred as a result of the use of information contained within this docu-\\nment, including, but not limited to errors, omissions, or inaccuracies.\\nNo part of this publication may be reproduced, stored in a retrieval system, or trans-\\nmitted in any form or by any means, electronic, mechanical, photocopying, record-\\ning, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976\\nUnited States Copyright Act, without the prior written permission of the Publisher.\\nLimit of Liability/Disclaimer of Warranty . While the publisher and author have used\\ntheir best efforts in preparing this book, they make no representations or warranties\\nwith respect to the accuracy or completeness of the contents of this book and spe-\\nciﬁcally disclaim any implied warranties of merchantability or ﬁtness for a particular\\npurpose. No warranty may be created or extended by sales representatives or writ-\\nten sales materials. The advice and strategies contained herein may not be suitable\\nfor your situation. You should consult with a professional where appropriate. Neitherthe publisher nor author shall be liable for any loss of proﬁt or any other commer-\\ncial damages, including but not limited to special, incidental, consequential, or other\\ndamages.\\nNotices. Knowledge and best practice in this ﬁeld are constantly changing. As new\\nresearch and experience broaden our understanding, changes in research methods,\\nprofessional practices, or medical treatment may become necessary . Practitioners and\\nresearchers must always rely on their own experience and knowledge in evaluating\\nand using any information, methods, compounds, or experiments described herein.\\nIn using such information or methods they should be mindful of their own safety and\\nthe safety of others, including parties for whom they have a professional responsibil-\\nity . To the fullest extent of the law, neither the Publisher nor the authors, contributors,\\nor editors, assume any liability for any injury and/or damage to persons or property\\nas a matter of products liability , negligence or otherwise, or from any use or operation\\nof any methods, products, instructions, or ideas contained in the material herein.FOREWORD.\\nWe will build a machine that will ﬂy.\\n— Joseph Michael Montgolﬁer, French Inventor/Aeronaut (1740-1810)\\nD\\nEEP learning interviews are technical, dense, and thanks to the ﬁelds com-\\npetitiveness, often high-stakes. The prospect of preparing for one can be\\ndaunting, and the fear of failure can be paralyzing and many interviewees\\nﬁnd their ideas slipping away alongside their conﬁdence.\\nThis book was written for you: an aspiring data scientist with a quantitative back-\\nground, facing down the gauntlet of the interview process in an increasingly competit-\\nive ﬁeld. For most of you, the interview process is the most signiﬁcant hurdle between\\nyou and a dream job. Even though you have the ability , the background, and the mo-\\ntivation to excel in your target position, you might need some guidance on how to get\\nyour foot in the door.\\nThough this book is highly technical it is not too dense to work through quickly . It\\naims to be comprehensive, including many of the terms and topics involved in modern\\ndata science and deep learning. That thoroughness makes it unique; no other single\\nwork offers such breadth of learning targeted so speciﬁcally at the demands of the\\ninterview.\\nMost comparable information is available in a variety of formats, locations, struc-\\ntures, and resourcesblog posts, tech articles, and short books scattered across the inter-\\nnet. Those resources are simply not adequate to the demands of deep learning inter-\\nview or exam preparation and were not assembled with this explicit purpose in mind.\\nIt is hoped that this book does not suffer the same shortcomings.\\nT\\nHIS books creation was guided by a few key principles: clarity and depth,\\nthoroughness and precision, interest and accuracy . The volume was de-\\nsigned for use by job seekers in the ﬁelds of machine learning and deep\\nlearning whose abilities and background locate them ﬁrmly within STEM\\n(science, technology , engineering, and mathematics). The book will still be of use to\\nother readers, such as those still undergoing their initial education in a STEM ﬁeld.\\nHowever, it is tailored most directly to the needs of active job seekers and stu-\\ndents attending M.Sc/Ph.D programmes in AI . It is, in any case, a book for engineers,\\nmathematicians, and computer scientists: nowhere does it include the kind of very\\nbasic background material that would allow it to be read by someone with no priorknowledge of quantitative and mathematical processes.\\nThe books contents are a large inventory of numerous topics relevant to deep learn-\\ning job interviews and graduate level exams. Ideas that are interesting or pertinent\\nhave been excluded if they are not valuable in that context. That places this work at\\nthe forefront of the growing trend in education and in business to emphasize a core\\nset of practical mathematical and computational skills. It is now widely understood\\nthat the training of every computer scientist must include a course dealing with the\\nfundamental theorems of machine learning in a rigorous manner; Deep Learning ap-\\npears in the curriculum of nearly every university; and this volume is designed as a\\nconvenient ongoing reference for graduates of such courses and programs.\\nThe book is grounded in both academic expertise and on-the-job experience and\\nthus has two goals. First, it compresses all of the necessary information into a coher-\\nent package. And second, it renders that information accessible and makes it easy to\\nnavigate. As a result, the book helps the reader develop a thorough understanding of\\nthe principles and concepts underlying practical data science. None of the textbooks I\\nread met all of those needs, which are:\\n1. Appropriate presentation level. I wanted a friendly introductory text accessible\\nto graduate students who have not had extensive applied experience as data\\nscientists.\\n2. A text that is rigorous and builds a solid understanding of the subject without\\ngetting bogged down in too many technicalities.\\n3. Logical and notational consistency among topics . There are intimate connec-\\ntions between calculus, logistic regression, entropy , and deep learning theory ,\\nwhich I feel need to be emphasized and elucidated if the reader is to fully under-\\nstand the ﬁeld. Differences in notation and presentation style in existing sources\\nmake it very difﬁcult for students to appreciate these kinds of connections.\\n4. Manageable size. It is very useful to have a text compact enough that all of the\\nmaterial in it can be covered in few weeks or months of intensive review. Most\\ncandidates will have only that much time to prepare for an interview, so a longer\\ntext is of no use to them.\\nThe text that follows is an attempt to meet all of the above challenges. It will\\ninevitably prove more successful at handling some of them than others, but it\\nhas at least made a sincere and devoted effort.A note about Bibliography\\nThe book provides a carefully curated bibliography to guide further study , whether\\nfor interview preparation or simply as a matter of interest or job-relevant research. A\\ncomprehensive bibliography would be far too long to include here, and would be of\\nlittle immediate use, so the selections have been made with deliberate attention to the\\nvalue of each included text.\\nOnly the most important books and articles on each topic have been included, and\\nonly those written in English that I personally consulted. Each is given a brief annota-\\ntion to indicate its scope and applicability . Many of the works cited will be found to\\ninclude very full bibliographies of the particular subject treated, and I recommend\\nturning there if you wish to dive deeper into a speciﬁc topic, method, or process.\\nWe have a web page for this book, where we list errata, examples, and any ad-\\nditional information. You can access this page at: http://www.interviews.ai.\\nTo comment or ask technical questions about this book, send email to: entropy@\\ninterviews.ai.\\nI would also like to solicit corrections, criticisms, and suggestions from students\\nand other readers. Although I have tried to eliminate errors over the multi year\\nprocess of writing and revising this text, a few undoubtedly remain. In particular,\\nsome typographical infelicities will no doubt ﬁnd their way into the ﬁnal version. I\\nhope you will forgive them .\\nTHE AUTHOR .\\nTEL AVIV ISRAEL, D ECEMBER , 2020. F IRST PRINTING , D ECEMBER 2020.ACKNOWLEDGEMENTS.\\nThe thanks and acknowledgements of the publisher are due to the following:\\nMy dear son, Amir Ivry , Matthew Isaac Harvey , Sandy Noymer, Steve foot and V elimir\\nGayevskiy .AUTHOR ’S BIOGRAPHY .\\nWhen Shlomo typed his book in LATEX, he wanted it to\\nreﬂect some of his passions: AI, design, typography , and\\nmost notably coding. On a typical day , his two halves - the\\nscientist and the artist - spend hours meticulously design-\\ning AI systems, from epilepsy prediction and pulmonary\\nnodule detection, to training a computer-vision model on\\na cluster.\\nShlomo spends whole days in a lab full of GPUs work-\\ning on his many interesting research projects. Though re-\\nsearch satisﬁes his itch for discovery , his most important\\nscientiﬁc contribution, he says, is helping other researchers.\\nAnd the results are evident in his publications. But, al-\\nthough theoretical studies are important, practical experi-\\nence has many great virtues. As the Head of AI at DeepOncology , he developed uses\\nof Deep Learning for precise tumour detection, expanding and reﬁning what human\\nexperts are capable of. The work, which relies on CNN’s, marks the culmination of a\\ncareer spent applying AI techniques to problems in medical AI. Shlomo holds an MSc\\nin Digital Signal Processing (Distinction) from the University of London.\\nA PERSONAL NOTE : In this ﬁrst volume, I purposely present a coherent, cumu-\\nlative, and content-speciﬁc core curriculum of the data science ﬁeld, including topics\\nsuch as information theory , Bayesian statistics, algorithmic differentiation, logistic re-\\ngression, perceptrons, and convolutional neural networks.\\nI hope you will ﬁnd this book stimulating. It is my belief that you the postgradu-\\nate students and job-seekers for whom the book is primarily meant will beneﬁt from\\nreading it; however, it is my hope that even the most experienced researchers will ﬁnd\\nit fascinating as well.\\nSHLOMO KASHANI ,T EL-AVIV,ISRAEL.ABOUT\\nTHE CHIEF\\nEDITOR .\\nAmir Ivry has been an applied research scientist in the ﬁelds\\nof deep learning and speech signal processing since 2015. A direct\\nPhD candidate in the Electrical and Computer Engineering Fac-\\nulty in the Technion - Israel Institute of Technology , Amir is the\\nauthor of over a dozen academic papers in leading IEEE journ-\\nals and top-tier conferences. For his contribution to the ﬁeld of\\nhands-free speech communication using deep neural networks,\\nAmir has received more than a dozen awards and honors, in-\\ncluding back-to-back Jacobs citations for research excellence, and\\nmost recently the international speech communication associ-\\nation grant. Being only 28 years old, he has been cemented as a popular lecturer in the\\nmachine learning community , and delivered technological sessions for MIT, Google\\nfor startups, Alibaba, and more. Amir is currently holding a position as an applied\\nresearch intern in Microsoft Advanced Technology Labs.Contents\\nI Rusty Nail 1\\nHOW-TO USE THIS BOOK 3\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\nII Kindergarten 9\\nLOGISTIC REGRESSION 11\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38PROBABILISTIC PROGRAMMING & BA YESIAN DL 41\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nIII High School 83\\nINFORMATION THEORY 85\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 87\\nShannon\\'s Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen\\'s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 101\\nShannon\\'s Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103Kullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen\\'s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION 121\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 155The Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\nIV Bachelors 183\\nDEEP LEARNING: NN ENSEMBLES 185\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 202\\nDEEP LEARNING: CNN FEATURE EXTRACTION 205\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213Neural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\nDEEP LEARNING 227\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 253\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 306\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nV Practice Exam 339\\nJOB INTERVIEW MOCK EXAM 341\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343Classiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nVI V olume two 357\\nVOLUME TWO - PLAN 359\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nVariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . . . 361\\nText to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nxviRUSTY NAIL\\nPART ICHAPTER\\n1\\nHOW-TO USE THIS BOOK\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nStarting Your Career . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nAdvancing Your Career . . . . . . . . . . . . . . . . . . . . . . . 5\\nDiving Into Deep Learning . . . . . . . . . . . . . . . . . . . . . 5\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.1 Introduction\\nFirst of all, welcome to world of Deep Learning Interviews.\\n1.1.1 What makes this book so valuable\\nT\\nARGETED advertising. Deciphering dead languages. Detecting malignant\\ntumours. Predicting natural disasters. Every year we see dozens of new\\nuses for deep learning emerge from corporate R&R, academia, and plucky\\nentrepreneurs. Increasingly , deep learning and artiﬁcial intelligence are in-\\ngrained in our cultural consciousness. Leading universities are dedicating programs\\nto teaching them, and they make the headlines every few days.\\nThat means jobs. It means intense demand and intense competition. It means a\\ngeneration of data scientists and machine learning engineers making their way into1.1. INTRODUCTION\\nthe workforce and using deep learning to change how things work. This book is for\\nthem, and for you. It is aimed at current or aspiring experts and students in the ﬁeld\\npossessed of a strong grounding in mathematics, an active imagination, engaged cre-\\nativity , and an appreciation for data. It is hand-tailored to give you the best possible\\npreparation for deep learning job interviews by guiding you through hundreds of\\nfully solved questions.\\nThat is what makes the volume so speciﬁcally valuable to students and job seekers:\\nit provides them with the ability to speak conﬁdently and quickly on any relevant\\ntopic, to answer technical questions clearly and correctly , and to fully understand the\\npurpose and meaning of interview questions and answers.\\nThose are powerful, indispensable advantages to have when walking into the in-\\nterview room.\\nThe questions and problems the book poses are tough enough to cut your teeth\\non-and to dramatically improve your skills but theyre framed within thought provok-\\ning questions, powerful and engaging stories, and cutting edge scientiﬁc information.\\nWhat are bosons and fermions? What is choriionic villus? Where did the Ebola virus\\nﬁrst appear, and how does it spread? Why is binary options trading so dangerous?\\nYour curiosity will pull you through the book’s problem sets, formulas, and in-\\nstructions, and as you progress, you’ll deepen your understanding of deep learning.\\nThere are intricate connections between calculus, logistic regression, entropy , and deep\\nlearning theory; work through the book, and those connections will feel intuitive.\\n1.1.2 What will I learn\\nStarting Your Career\\nAre you actively pursuing a career in deep learning and data science, or hoping to do\\nso? If so, you’re in luck everything from deep learning to artiﬁcial intelligence is in\\nextremely high demand in the contemporary workforce. Deep learning professionals\\nare highly sought after and also ﬁnd themselves among the highest-paid employee\\ngroups in companies around the world.\\nSo your career choice is spot on, and the ﬁnancial and intellectual beneﬁts of land-\\ning a solid job are tremendous. But those positions have a high barrier to entry: the\\ndeep learning interview. These interviews have become their own tiny industry , with\\nHR employees having to specialize in the relevant topics so as to distinguish well-\\nprepared job candidates from those who simply have a loose working knowledge of\\nthe material. Outside the interview itself, the difference doesn’t always feel import-\\n4Chapter 1 HOW-TO USE THIS BOOK\\nant. Deep learning libraries are so good that a machine learning pipeline can often be\\nassembled with little high-skill input from the researcher themselves. But that level\\nof ability won’t cut it in the interview. You’ll be asked practical questions, technical\\nquestions, and theoretical questions, and expected to answer them all conﬁdently and\\nﬂuently .\\nFor unprepared candidates, that’s the end of the road. Many give up after repeated\\npost-interview rejections.\\nAdvancing Your Career\\nSome of you will be more conﬁdent. Those of you with years on the job will be highly\\nmotivated, exceptionally numerate, and prepared to take an active, hands-on role in\\ndeep learning projects. You probably already have extensive knowledge in applied\\nmathematics, computer science, statistics, and economics. Those are all formidable\\nadvantages.\\nBut at the same time, it’s unlikely that you will have prepared for the interview\\nitself. Deep learning interviews especially those for the most interesting, autonom-\\nous, and challenging positions demand that you not only know how to do your job\\nbut that you display that knowledge clearly , eloquently , and without hesitation. Some\\nquestions will be straightforward and familiar, but others might be farther aﬁeld or\\ndraw on areas you haven’t encountered since college.\\nThere is simply no reason to leave that kind of thing to chance. Make sure you’re\\nprepared. Conﬁrm that you are up-to-date on terms, concepts, and algorithms. Refresh\\nyour memory of fundamentals, and how they inform contemporary research practices.\\nAnd when the interview comes, walk into the room knowing that you’re ready for\\nwhat’s coming your way .\\nDiving Into Deep Learning\\n\"Deep Learning Job Interviews\" is organized into chapters that each consist of an Intro-\\nduction to a topic, Problems illustrating core aspects of the topic, and complete Solu-\\ntions. You can expect each question and problem in this volume to be clear, practical,\\nand relevant to the subject. Problems fall into two groups, conceptual and application-\\nbased. Conceptual problems are aimed at testing and improving your knowledge of\\nbasic underlying concepts, while applications are targeted at practicing or applying\\nwhat you’ve learned (most of these are relevant to Python and PyTorch). The chapters\\nare followed by a reference list of relevant formulas and a selective bibliography for\\nguide further reading.\\n51.1. INTRODUCTION\\n1.1.3 How to Work Problems\\nIn real life, like in exams, you will encounter problems of varying difﬁculty . A good\\nskill to practice is recognizing the level of difﬁculty a problem poses. Job interviews\\nwill have some easy problems, some standard problems, and some much harder prob-\\nlems.\\nEach chapter of this book is usually organized into three sections: Introduction,\\nProblems, and Solutions. As you are attempting to tackle problems, resist the tempta-\\ntion to prematurely peek at the solution; It is vital to allow yourself to struggle for\\na time with the material. Even professional data scientists do not always know right\\naway how to resolve a problem. The art is in gathering your thoughts and ﬁguring\\nout a strategy to use what you know to ﬁnd out what you don’t.\\nPRB-1 \\uf059 CH.PRB- 1.1.\\nProblems outlined in grey make up the representative question set . This set of prob-\\nlems is intended to cover the most essential ideas in each section. These problems are usually\\nhighly typical of what you’d see on an interview, although some of them are atypical but\\ncarry an important moral. If you ﬁnd yourself unconﬁdent with the idea behind one of these,\\nit’s probably a good idea to practice similar problems. This representative question set is our\\nsuggestion for a minimal selection of problems to work on. Y ou are highly encouraged to\\nwork on more.\\nSOL-1 \\uf14b CH.SOL- 1.1. I am a solution. \\x04\\nIf you ﬁnd yourself at a real stand-off, go ahead and look for a clue in one of the\\nrecommended theory books. Think about it for a while, and don’t be afraid to read\\nback in the notes to look for a key idea that will help you proceed. If you still can’t\\nsolve the problem, well, we included the Solutions section for a reason! As you’re\\nreading the solutions, try hard to understand why we took the steps we did, instead\\nof memorizing step-by-step how to solve that one particular problem.\\nIf you struggled with a question quite a lot, it’s probably a good idea to return to it\\nin a few days. That might have been enough time for you to internalize the necessary\\nideas, and you might ﬁnd it easily conquerable. If you’re still having troubles, read\\nover the solution again, with an emphasis on understanding why each step makes\\nsense. One of the reasons so many job candidates are required to demonstrate their\\nability to resolves data science problems on the board, is that it hiring managers as-\\nsume it reﬂects their true problem-solving skills.\\n6Chapter 1 HOW-TO USE THIS BOOK\\nIn this volume, you will learn lots of concepts, and be asked to apply them in\\na variety of situations. Often, this will involve answering one really big problem by\\nbreaking it up into manageable chunks, solving those chunks, then putting the pieces\\nback together. When you see a particularly long question, remain calm and look for a\\nway to break it into pieces you can handle.\\n1.1.4 Types of Problems\\nTwo main types of problems are presented in this book.\\nCONCEPTUAL : The ﬁrst category is meant to test and improve your understanding\\nof basic underlying concepts. These often involve many mathematical calculations.\\nThey range in difﬁculty from very basic reviews of deﬁnitions to problems that require\\nyou to be thoughtful about the concepts covered in the section.\\nAn example in Information Theory follows.\\nPRB-2 \\uf059 CH.PRB- 1.2.\\nWhat is the distribution of maximum entropy, that is, the distribution which has the\\nmaximum entropy among all distributions on the bounded interval [a, b],(−∞, +∞)\\nSOL-2 \\uf14b CH.SOL- 1.2.\\nThe uniform distribution has the maximum entropy among all distributions on the\\nbounded interval: [a, b],(−∞, +∞).\\nThe variance of U (a, b) is σ2 = 1/12(b − a)2.\\nTherefore the entropy is:\\n1/2 log 12 + log σ. (1.1)\\n\\x04\\nAPPLICATION : Problems in this category are for practicing skills. It’s not enough to\\nunderstand the philosophical grounding of an idea: you have to be able to apply it in\\nappropriate situations. This takes practice! mostly in Python or in one of the available\\nDeep Learning Libraries such as PyTorch.\\nAn example in PyTorch follows.\\n71.1. INTRODUCTION\\nPRB-3 \\uf059 CH.PRB- 1.3.\\nDescribe in your own words, what is the purpose of the following code in the context of\\ntraining a Convolutional Neural Network.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\nSOL-3 \\uf14b CH.SOL- 1.3.\\nDuring the training of a Convolutional Neural Network, data augmentation, and to some\\nextent dropout are used as core methods to decrease overﬁtting. Data augmentation is a regu-\\nlarization scheme that synthetically expands the data-set by utilizing label-preserving trans-\\nformations to add more invariant examples of the same data samples. It is most commonly\\nperformed in real time on the CPU during the training phase whilst the actual training mode\\ntakes place on the GPU. This may consist for instance, random rotations, random ﬂips, zoom-\\ning, spatial translations etc. \\x04\\n8KINDERGARTEN\\nPART IICHAPTER\\n2\\nLOGISTIC REGRESSION\\nY ou should call it entropy for two reasons. In the ﬁrst place, your uncertainty\\nfunction has been used in statistical mechanics under that name. In the second\\nplace, and more importantly, no one knows what entropy really is, so in a debate\\nyou will always have the advantage.\\n— John von Neumann to Claude Shannon\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382.1. INTRODUCTION\\n2.1 Introduction\\nM\\nUltivariable methods are routinely utilized in statistical analyses across a\\nwide range of domains. Logistic regression is the most frequently used\\nmethod for modelling binary response data and binary classiﬁcation.\\nWhen the response variable is binary , it characteristically takes the form of 1/0,\\nwith 1 normally indicating a success and 0 a failure. Multivariable methods usually\\nassume a relationship between two or more independent, predictor variables, and\\none dependent, response variable. The predicted value of a response variable may be\\nexpressed as a sum of products, wherein each product is formed by multiplying the\\nvalue of the variable and its coefﬁcient. How the coefﬁcients are computed? from a\\nrespective data set. Logistic regression is heavily used in supervised machine learning\\nand has become the workhorse for both binary and multiclass classiﬁcation problems.\\nMany of the questions introduced in this chapter are crucial for truly understanding\\nthe inner-workings of artiﬁcial neural networks.\\n2.2 Problems\\n2.2.1 General Concepts\\nPRB-4 \\uf059 CH.PRB- 2.1.\\nTrue or False: For a ﬁxed number of observations in a data set, introducing more vari-\\nables normally generates a model that has a better ﬁt to the data. What may be the drawback\\nof such a model ﬁtting strategy?\\nPRB-5 \\uf059 CH.PRB- 2.2.\\nDeﬁne the term “odds of success” both qualitatively and formally. Give a numerical\\nexample that stresses the relation between probability and odds of an event occurring.\\nPRB-6 \\uf059 CH.PRB- 2.3.\\n1. Deﬁne what is meant by the term \"interaction\", in the context of a logistic regression\\npredictor variable.\\n12Chapter 2 LOGISTIC REGRESSION\\n2. What is the simplest form of an interaction? Write its formulae.\\n3. What statistical tests can be used to attest the signiﬁcance of an interaction term?\\nPRB-7 \\uf059 CH.PRB- 2.4.\\nTrue or False: In machine learning terminology, unsupervised learning refers to the\\nmapping of input covariates to a target response variable that is attempted at being predicted\\nwhen the labels are known.\\nPRB-8 \\uf059 CH.PRB- 2.5.\\nComplete the following sentence: In the case of logistic regression, the response vari-\\nable is the log of the odds of being classiﬁed in [...].\\nPRB-9 \\uf059 CH.PRB- 2.6.\\nDescribe how in a logistic regression model, a transformation to the response variable is\\napplied to yield a probability distribution. Why is it considered a more informative repres-\\nentation of the response?\\nPRB-10 \\uf059 CH.PRB- 2.7.\\nComplete the following sentence: Minimizing the negative log likelihood also means\\nmaximizing the [...] of selecting the [...] class.\\n2.2.2 Odds, Log-odds\\nPRB-11 \\uf059 CH.PRB- 2.8.\\nAssume the probability of an event occurring is p = 0.1.\\n1. What are the odds of the event occurring?.\\n2. What are the log-odds of the event occurring?.\\n132.2. PROBLEMS\\n3. Construct the probability of the event as a ratio that equals 0.1.\\nPRB-12 \\uf059 CH.PRB- 2.9.\\nTrue or False: If the odds of success in a binary response is 4, the corresponding probab-\\nility of success is 0.8.\\nPRB-13 \\uf059 CH.PRB- 2.10.\\nDraw a graph of odds to probabilities , mapping the entire range of probabilities to\\ntheir respective odds.\\nPRB-14 \\uf059 CH.PRB- 2.11.\\nThe logistic regression model is a subset of a broader range of machine learning models\\nknown as generalized linear models (GLMs), which also include analysis of variance (AN-\\nOV A), vanilla linear regression, etc. There are three components to a GLM; identify these\\nthree components for binary logistic regression.\\nPRB-15 \\uf059 CH.PRB- 2.12.\\nLet us consider the logit transformation, i.e., log-odds. Assume a scenario in which the\\nlogit forms the linear decision boundary:\\nlog\\n(\\nPr(Y = 1|X)\\nPr(Y = 0|X)\\n)\\n= θ0 + θT X, (2.1)\\nfor a given vector of systematic components X and predictor variables θ. Write the mathem-\\natical expression for the hyperplane that describes the decision boundary.\\nPRB-16 \\uf059 CH.PRB- 2.13.\\nTrue or False: The logit function and the natural logistic (sigmoid) function are inverses\\nof each other.\\n14Chapter 2 LOGISTIC REGRESSION\\n2.2.3 The Sigmoid\\nThe sigmoid (Fig. 2.1) also known as the logistic function, is widely used in binary\\nclassiﬁcation and as a neuron activation function in artiﬁcial neural networks.\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−4x\\nσ(x) = 1\\n1+e−15x\\nFIGURE 2.1: Examples of two sigmoid functions.\\nPRB-17 \\uf059 CH.PRB- 2.14.\\nCompute the derivative of the natural sigmoid function:\\nσ(x) = 1\\n1 + e−x ∈ (0, 1). (2.2)\\nPRB-18 \\uf059 CH.PRB- 2.15.\\nRemember that in logistic regression, the hypothesis function for some parameter vector\\nβ and measurement vector x is deﬁned as:\\nhβ(x) = g(βT x) = 1\\n1 + e−βT x\\n= P (y = 1|x; β), (2.3)\\n152.2. PROBLEMS\\nwhere y holds the hypothesis value.\\nSuppose the coefﬁcients of a logistic regression model with independent variables are as\\nfollows: β0 = −1.5, β1 = 3, β2 = −0.5.\\nAssume additionally, that we have an observation with the following values for the dependent\\nvariables: x1 = 1, x2 = 5. As a result, the logit equation becomes:\\nlogit = β0 + β1x1 + β2x2. (2.4)\\n1. What is the value of the logit for this observation?\\n2. What is the value of the odds for this observation?\\n3. What is the value of P (y = 1) for this observation?\\n2.2.4 Truly Understanding Logistic Regression\\nPRB-19 \\uf059 CH.PRB- 2.16.\\nProton therapy (PT) [ 2] is a widely adopted form of treatment for many types of cancer\\nincluding breast and lung cancer (Fig. 2.2).\\nFIGURE 2.2: Pulmonary nodules (left) and breast cancer (right).\\nA PT device which was not properly calibrated is used to simulate the treatment of\\ncancer. As a result, the PT beam does not behave normally. A data scientist collects inform-\\nation relating to this simulation. The covariates presented in T able 2.1 are collected during\\n16Chapter 2 LOGISTIC REGRESSION\\nthe experiment. The columns Yes and No indicate if the tumour was eradicated or not, re-\\nspectively.\\nTumour eradication\\nCancer Type Yes No\\nBreast 560 260\\nLung 69 36\\nTABLE 2.1: Tumour eradication statistics.\\nReferring to T able2.1:\\n1. What is the explanatory variable and what is the response variable?\\n2. Explain the use of relative risk and odds ratio for measuring association.\\n3. Are the two variables positively or negatively associated?\\nFind the direction and strength of the association using both relative risk and odds\\nratio.\\n4. Compute a 95% conﬁdence interval (CI) for the measure of association.\\n5. Interpret the results and explain their signiﬁcance.\\nPRB-20 \\uf059 CH.PRB- 2.17.\\nConsider a system for radiation therapy planning (Fig. 2.3). Given a patient with a ma-\\nlignant tumour, the problem is to select the optimal radiation exposure time for that patient.\\nA key element in this problem is estimating the probability that a given tumour will be erad-\\nicated given certain covariates. A data scientist collects information relating to this radiation\\ntherapy system.\\n172.2. PROBLEMS\\nFIGURE 2.3: A multi-detector positron scanner used to locate tumours.\\nThe following covariates are collected; X1 denotes time in milliseconds that a patient is\\nirradiated with, X2 = holds the size of the tumour in centimeters, and Y notates a binary re-\\nsponse variable indicating if the tumour was eradicated. Assume that each response’ variable\\nYi is a Bernoulli random variable with success parameter pi, which holds:\\npi = eβ0+β1x1+β2x2\\n1 + eβ0+β1x1+β2x2\\n. (2.5)\\nThe data scientist ﬁts a logistic regression model to the dependent measurements and pro-\\nduces these estimated coefﬁcients:\\nˆβ0 = −6,\\nˆβ1 = 0.05,\\nˆβ2 = 1.\\n(2.6)\\n1. Estimate the probability that, given a patient who undergoes the treatment for 40\\nmilliseconds and who is presented with a tumour sized 3.5 centimetres, the system\\neradicates the tumour.\\n2. How many milliseconds the patient in part (a) would need to be radiated with to have\\nexactly a 50% chance of eradicating the tumour?\\n18Chapter 2 LOGISTIC REGRESSION\\nPRB-21 \\uf059 CH.PRB- 2.18.\\nRecent research [ 3] suggests that heating mercury containing dental amalgams may\\ncause the release of toxic mercury fumes into the human airways. It is also presumed that\\ndrinking hot coffee, stimulates the release of mercury vapour from amalgam ﬁllings (Fig.\\n2.4).\\nFIGURE 2.4: A dental amalgam.\\nT o study factors that affect migraines, and in particular, patients who have at least four\\ndental amalgams in their mouth, a data scientist collects data from 200K users with and\\nwithout dental amalgams. The data scientist then ﬁts a logistic regression model with an\\nindicator of a second migraine within a time frame of one hour after the onset of the ﬁrst mi-\\ngraine, as the binary response variable (e.g., migraine=1, no migraine=0). The data scientist\\nbelieves that the frequency of migraines may be related to the release of toxic mercury fumes.\\nThere are two independent variables:\\n1. X1 = 1 if the patient has at least four amalgams; 0 otherwise.\\n2. X2 = coffee consumption (0 to 100 hot cups per month).\\nThe output from training a logistic regression classiﬁer is as follows:\\nAnalysis of LR Parameter Estimates\\nParameter Estimate Std.Err Z-val Pr>|Z|\\nIntercept -6.36347 3.21362 -1.980 0.0477\\n$X_1$ -1.02411 1.17101 -0.875 0.3818\\n$X_2$ 0.11904 0.05497 2.165 0.0304\\n192.2. PROBLEMS\\n1. Using X1 and X2, express the odds of a patient having a migraine for a second time.\\n2. Calculate the probability of a second migraine for a patient that has at least four\\namalgams and drank 100 cups per month?\\n3. For users that have at least four amalgams, is high coffee intake associated with an\\nincreased probability of a second migraine?\\n4. Is there statistical evidence that having more than four amalgams is directly associ-\\nated with a reduction in the probability of a second migraine?\\nPRB-22 \\uf059 CH.PRB- 2.19.\\nT o study factors that affect Alzheimer’s disease using logistic regression, a researcher\\nconsiders the link between gum (periodontal) disease and Alzheimer as a plausible risk factor\\n[1]. The predictor variable is a count of gum bacteria (Fig. 2.5) in the mouth.\\nFIGURE 2.5: A chain of spherical bacteria.\\nThe response variable, Y , measures whether the patient shows any remission (e.g. yes=1).\\nThe output from training a logistic regression classiﬁer is as follows:\\nParameter DF Estimate Std\\nIntercept 1 -4.8792 1.2197\\ngum bacteria 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of gum bacteria of a patient\\nis 33.\\n20Chapter 2 LOGISTIC REGRESSION\\n2. Find out the gum bacteria count at which the estimated probability of improvement is\\n0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1 in the total gum\\nbacteria count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total gum bacteria count. Remember that the most common conﬁdence levels\\nare 90%, 95%, 99%, and 99.9%. T able9.1 lists the z values for these levels.\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 2.2: Common conﬁdence levels.\\nPRB-23 \\uf059 CH.PRB- 2.20.\\nRecent research [ 4] suggests that cannabis (Fig. 2.6) and cannabinoids administration\\nin particular, may reduce the size of malignant tumours in rats.\\nFIGURE 2.6: Cannabis.\\n212.2. PROBLEMS\\nT o study factors affecting tumour shrinkage, a deep learning researcher collects data from\\ntwo groups; one group is administered with placebo (a substance that is not medicine) and\\nthe other with cannabinoids. His main research revolves around studying the relationship\\n(T able2.3) between the anticancer properties of cannabinoids and tumour shrinkage:\\nTumour Shrinkage In Rats\\nGroup Yes No Sum\\nCannabinoids 60 6833 6893\\nPlacebo 130 6778 6909\\nSum 190 13611 13801\\nTABLE 2.3: Tumour shrinkage in rats.\\nFor the true odds ratio:\\n1. Find the sample odds ratio.\\n2. Find the sample log-odds ratio.\\n3. Compute a 95% conﬁdence interval ( z0.95 = 1.645; z0.975 = 1.96) for the true log odds\\nratio and true odds ratio.\\n2.2.5 The Logit Function and Entropy\\nPRB-24 \\uf059 CH.PRB- 2.21.\\nThe entropy (see Chapter 4) of a single binary outcome with probability p to receive 1 is\\ndeﬁned as:\\nH(p) ≡ −p log p − (1 − p) log(1 − p). (2.7)\\n1. At what p does H(p) attain its maximum value?\\n2. What is the relationship between the entropy H(p) and the logit function, given p?\\n22Chapter 2 LOGISTIC REGRESSION\\n2.2.6 Python/PyTorch/CPP\\nPRB-25 \\uf059 CH.PRB- 2.22.\\nThe following C++ code (Fig. 2.7) is part of a (very basic) logistic regression implement-\\nation module. For a theoretical discussion underlying this question, refer to problem 2.17.\\n1 #include ...\\n2 std::vector<double> theta { -6,0.05,1.0};\\n3 double sigmoid(double x) {\\n4 double tmp =1.0 / (1.0 + exp(-x));\\n5 std::cout << \"prob=\" << tmp<<std::endl;\\n6 return tmp;\\n7 }\\n8 double hypothesis(std::vector<double> x){\\n9 double z;\\n10 z=std::inner_product(std::begin(x), std ::end(x),\\nstd::begin(theta), 0.0);↪→\\n11 std::cout << \"inner_product=\" << z<<std::endl;\\n12 return sigmoid(z);\\n13 }\\n14 int classify(std::vector<double> x){\\n15 int hypo=hypothesis(x) > 0.5f;\\n16 std::cout << \"hypo=\" << hypo<<std::endl;\\n17 return hypo;\\n18 }\\n19 int main() {\\n20 std::vector<double> x1 { 1,40,3.5};\\n21 classify(x1);\\n22 }\\nFIGURE 2.7: Logistic regression in CPP\\n1. Explain the purpose of line 10, i.e., inner_product.\\n2. Explain the purpose of line 15, i.e., hypo(x) > 0.5f.\\n232.2. PROBLEMS\\n3. What does θ (theta) stand for in line 2?\\n4. Compile and run the code, you can use:\\nhttps://repl.it/languages/cpp11 to evaluate the code.\\nWhat is the output?\\nPRB-26 \\uf059 CH.PRB- 2.23.\\nThe following Python code (Fig. 2.8) runs a very simple linear model on a two-dimensional\\nmatrix.\\n1 import torch\\n2 import torch.nn as nn\\n3\\n4 lin = nn.Linear(5, 7)\\n5 data = (torch.randn(3, 5))\\n6\\n7 print(lin(data).shape)\\n8 >?\\nFIGURE 2.8: A linear model in PyTorch\\nWithout actually running the code, determine what is the size of the matrix printed as a\\nresult of applying the linear model on the matrix.\\nPRB-27 \\uf059 CH.PRB- 2.24.\\nThe following Python code snippet (Fig. 2.9) is part of a logistic regression implementa-\\ntion module in Python.\\n24Chapter 2 LOGISTIC REGRESSION\\n1 from scipy.special import expit\\n2 import numpy as np\\n3 import math\\n4\\n5 def Func001(x):\\n6 e_x = np.exp(x - np.max(x))\\n7 return e_x / e_x.sum()\\n8\\n9 def Func002(x):\\n10 return 1 / (1 + math.exp(-x))\\n11\\n12 def Func003(x):\\n13 return x * (1-x)\\nFIGURE 2.9: Logistic regression methods in Python.\\nAnalyse the methods Func001 , Func002 and Func003 presented in Fig. 2.9, ﬁnd their\\npurposes and name them.\\nPRB-28 \\uf059 CH.PRB- 2.25.\\nThe following Python code snippet (Fig. 2.10) is part of a machine learning module in\\nPython.\\n252.2. PROBLEMS\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5 ^^I^^I\\n6 def Func006(y_hat, y):\\n7 if y == 1:\\n8 return -np.log(y_hat)\\n9 else:\\n10 return -np.log(1 - y_hat)^^I\\nFIGURE 2.10: Logistic regression methods in Python.\\nAnalyse the method Func006 presented in Fig. 2.10. What important concept in machine-\\nlearning does it implement?\\nPRB-29 \\uf059 CH.PRB- 2.26.\\nThe following Python code snippet (Fig. 2.11) presents several different variations of the\\nsame function.\\n26Chapter 2 LOGISTIC REGRESSION\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5\\n6 def Ver001(x):\\n7 return 1 / (1 + math.exp(-x))\\n8\\n9 def Ver002(x):\\n10 return 1 / (1 + (np.exp(-x)))\\n11\\n12 WHO_AM_I = 709\\n13\\n14 def Ver003(x):\\n15 return 1 / (1 + np.exp(-(np.clip(x, -WHO_AM_I, None))))\\nFIGURE 2.11: Logistic regression methods in Python.\\n1. Which mathematical function do these methods implement?\\n2. What is signiﬁcant about the number 709 in line 11?\\n3. Given a choice, which method would you use?\\n2.3 Solutions\\n2.3.1 General Concepts\\nSOL-4 \\uf14b CH.SOL- 2.1.\\nTrue. However, when an excessive and unnecessary number of variables is used in a lo-\\ngistic regression model, peculiarities (e.g., speciﬁc attributes) of the underlying data set dis-\\nproportionately affect the coefﬁcients in the model, a phenomena commonly referred to as\\n“overﬁtting”. Therefore, it is important that a logistic regression model does not start training\\nwith more variables than is justiﬁed for the given number of observations. \\x04\\n272.3. SOLUTIONS\\nSOL-5 \\uf14b CH.SOL- 2.2.\\nThe odds of success are deﬁned as the ratio between the probability of success p ∈ [0, 1]\\nand the probability of failure 1 − p. Formally:\\nOdds(p) ≡\\n(\\np\\n1 − p\\n)\\n. (2.8)\\nFor instance, assuming the probability of success of an event is p = 0 .7. Then, in our\\nexample, the odds of success are 7/3, or 2.333 to 1. Naturally, in the case of equal probabilities\\nwhere p = 0.5, the odds of success is 1 to 1.\\n\\x04\\nSOL-6 \\uf14b CH.SOL- 2.3.\\n1. An interaction is the product of two single predictor variables implying a non-additive\\neffect.\\n2. The simplest interaction model includes a predictor variable formed by multiplying two\\nordinary predictors. Let us assume two variables X and Z. Then, the logistic regression\\nmodel that employs the simplest form of interaction follows:\\nβ0 + β1X + β2Z + β3XZ, (2.9)\\nwhere the coefﬁcient for the interaction term XZ is represented by predictor β3.\\n3. For testing the contribution of an interaction, two principal methods are commonly\\nemployed; the Wald chi-squared test or a likelihood ratio test between the model with\\nand without the interaction term. Note: How does interaction relates to information\\ntheory? What added value does it employ to enhance model performance?\\n\\x04\\nSOL-7 \\uf14b CH.SOL- 2.4.\\nFalse. This is exactly the deﬁnition of supervised learning; when labels are known then\\nsupervision guides the learning process. \\x04\\n28Chapter 2 LOGISTIC REGRESSION\\nSOL-8 \\uf14b CH.SOL- 2.5.\\nIn the case of logistic regression, the response variable is the log of the odds of being clas-\\nsiﬁed in a group of binary or multi-class responses. This deﬁnition essentially demonstrates\\nthat odds can take the form of a vector. \\x04\\nSOL-9 \\uf14b CH.SOL- 2.6.\\nWhen a transformation to the response variable is applied, it yields a probability distribu-\\ntion over the output classes, which is bounded between 0 and 1; this transformation can be\\nemployed in several ways, e.g., a softmax layer, the sigmoid function or classic normalization.\\nThis representation facilitates a soft-decision by the logistic regression model, which permits\\nconstruction of probability-based processes over the predictions of the model. Note: What are\\nthe pros and cons of each of the three aforementioned transformations? \\x04\\nSOL-10 \\uf14b CH.SOL- 2.7.\\nMinimizing the negative log likelihood also means maximizing the likelihood of selecting\\nthe correct class. \\x04\\n2.3.2 Odds, Log-odds\\nSOL-11 \\uf14b CH.SOL- 2.8.\\n1. The odds of the event occurring are, by deﬁnition:\\nodds = ( 0.1\\n0.9 ) = 0 .11. (2.10)\\n2. The log-odds of the event occurring are simply taken as the log of the odds:\\nlog-odds = ln(0.1/0.9) = −2.19685. (2.11)\\n3. The probability may be constructed by the following representation:\\nprobability = odds\\nodds + 1 = 0.11\\n1.11 = 0.1, (2.12)\\n292.3. SOLUTIONS\\nor, alternatively:\\np = exp (ln odds)\\nexp (ln odds) + 1 = 0.11\\n1.11 = 0.1. (2.13)\\nNote: What is the intuition behind this representation?\\n\\x04\\nSOL-12 \\uf14b CH.SOL- 2.9.\\nTrue. By deﬁnition of odds, it is easy to notice that p = 0.8 satisﬁes the following relation:\\nodds = ( 0.8\\n0.2) = 4 (2.14)\\n\\x04\\nSOL-13 \\uf14b CH.SOL- 2.10.\\nThe graph of odds to probabilities is depicted in Figure 2.12.\\n0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 0,9\\n2,0\\n4,0\\n6,0\\n8,0\\n10,0\\nProbability\\nOdds odds(p) = p\\n1−p\\nFIGURE 2.12: Odds vs. probability values.\\n\\x04\\n30Chapter 2 LOGISTIC REGRESSION\\nSOL-14 \\uf14b CH.SOL- 2.11.\\nA binary logistic regression GLM consists of there components:\\n1. Random component: refers to the probability distribution of the response variable (Y ),\\ne.g., binomial distribution for Y in the binary logistic regression, which takes on the\\nvalues Y = 0 or Y = 1.\\n2. Systematic component: describes the explanatory variables:\\n(X1, X2, ...) as a combination of linear predictors. The binary case does not constrain\\nthese variables to any degree.\\n3. Link function: speciﬁes the link between random and systematic components. It says\\nhow the expected value of the response relates to the linear predictor of explanatory\\nvariables.\\nNote: Assume that Y denotes whether a human voice activity was detected ( Y = 1 )\\nor not ( Y = 0 ) in a give time frame. Propose two systematic components and a link\\nfunction adjusted for this task.\\n\\x04\\nSOL-15 \\uf14b CH.SOL- 2.12.\\nThe hyperplane is simply deﬁned by:\\nθ0 + θT X = 0. (2.15)\\nNote: Recall the use of the logit function and derive this decision boundary rigorously. \\x04\\nSOL-16 \\uf14b CH.SOL- 2.13.\\nTrue. The logit function is deﬁned as:\\nz(p) = logit(p) = log\\n(\\np\\n1 − p\\n)\\n, (2.16)\\n312.3. SOLUTIONS\\nfor any p ∈ [0, 1]. A simple set of algebraic equations yields the inverse relation:\\np(z) = exp z\\n1 + exp z , (2.17)\\nwhich exactly describes the relation between the output and input of the logistic function, also\\nknown as the sigmoid. \\x04\\n2.3.3 The Sigmoid\\nSOL-17 \\uf14b CH.SOL- 2.14.\\nThere are various approaches to solve this problem, here we provide two; direct derivation\\nor derivation via the softmax function.\\n1. Direct derivation:\\nd\\ndx σ(x) = d\\ndx ((1 + e−x)−1) = −((1 + e−x)(−2)) d\\ndx (1 + e−x) = e−x\\n(1+e−x)2 .\\n2. Softmax derivation:\\nIn a classiﬁcation problem with mutually exclusive classes, where all of the values are\\npositive and sum to one, a softmax activation function may be used. By deﬁnition, the\\nsoftmax activation function consists of n terms, such that ∀i ∈ [1, n]:\\nf (θi) = eθi\\n∑\\nk evk\\n= 1\\n1 + e−θi\\n∑\\nk̸=i eθk\\n. (2.18)\\nT o compute the partial derivative of 2.18, we treat all θk where k ̸= i as constants and\\nthen differentiate θi using regular differentiation rules. For a given θi, let us deﬁne:\\nβ =\\n∑\\nk̸=i\\neθk, (2.19)\\nand\\nf (θi) = 1\\n1 + βe−θi\\n= (1 + βe−θi)−1. (2.20)\\nIt can now be shown that the derivative with respect to θi holds:\\nf ′(θi) =\\n(\\n1 + βe−θi\\n) −2\\nβe−θi, (2.21)\\n32Chapter 2 LOGISTIC REGRESSION\\nwhich can take on the informative form of:\\nf ′(θi) = f (θi)(1 − f (θi)). (2.22)\\nIt should be noted that 2.21 holds for any constant β, and for β = 1 it clearly reduces\\nto the sigmoid activation function.\\nNote: Characterize the sigmoid function when its argument approaches 0, ∞ and −∞.\\nWhat undesired properties of the sigmoid function do this values entail when considered as an\\nactivation function?\\n\\x04\\nSOL-18 \\uf14b CH.SOL- 2.15.\\n1. The logit value is simply obtained by substituting the values of the dependent variables\\nand model coefﬁcients into the linear logistic regression model, as follows:\\nlogit = β0 + β1x1 + β2x2 = −1.5 + 3 · 1 + −0.5 · 5 = −1. (2.23)\\n2. According to the natural relation between the logit and the odds, the following holds:\\nodds = elogit = eβ0+β1x1+β2x2 = e−1 = 0.3678794. (2.24)\\n3. The odds ratio is, by deﬁnition:\\nodds = P (y = 1)\\nP (y = 0) , (2.25)\\nso the logistic response function is:\\nP (y = 1) = 1\\n1 + e−logit = 1\\n1 + e1 = 0.2689414. (2.26)\\n\\x04\\n2.3.4 Truly Understanding Logistic Regression\\n332.3. SOLUTIONS\\nSOL-19 \\uf14b CH.SOL- 2.16.\\n1. T umour eradication (Y ) is the response variable and cancer type ( X) is the explanatory\\nvariable.\\n2. Relative risk (RR) is the ratio of risk of an event in one group (e.g., exposed group)\\nversus the risk of the event in the other group (e.g., non-exposed group). The odds ratio\\n(OR) is the ratio of odds of an event in one group versus the odds of the event in the\\nother group.\\n3. If we calculate odds ratio as a measure of association:\\nˆθ = 560 × 36\\n69 × 260 = 1.23745. (2.27)\\nAnd the log-odds ratio is (log(1.23745)) = 0 .213052:\\nThe odds ratio is larger than one, indicating that the odds for a breast cancer is more\\nthan the odds for a lung cancer to be eradicated. Notice however, that this result is too\\nclose to one, which prevents conclusive decision regarding the odds relation.\\nAdditionally, if we calculate relative risk as a measure of association:\\nRR =\\n560\\n560+260\\n69\\n69+36\\n= 1.0392. (2.28)\\n4. The 95% conﬁdence interval for the odds-ratio, θ is computed from the sample conﬁd-\\nence interval for log odds ratio:\\nˆσ\\n(\\nlog(ˆθ)\\n)\\n=\\n√\\n1\\n560 + 1\\n260 + 1\\n69 + 1\\n36 = 0.21886. (2.29)\\nTherefore, the 95% CI for log (θ) is:\\n0.213052 ± 1.95 × 0.21886 = (0 .6398298, −0.2137241). (2.30)\\n34Chapter 2 LOGISTIC REGRESSION\\nTherefore, the 95% CI for θ is:\\n(e−0.210, e0.647) = (0 .810, 1.909). (2.31)\\n5. The CI (0.810, 1.909) contains 1, which indicates that the true odds ratio is not signi-\\nﬁcantly different from 1 and there is not enough evidence that tumour eradication is\\ndependent on cancer type.\\n\\x04\\nSOL-20 \\uf14b CH.SOL- 2.17.\\n1. By using the deﬁned values for X1 and X2, and the known logistic regression model,\\nsubstitution yields:\\nˆp(X) = e−6+0.05X1+X2\\n(1 + e−6+0.05X1+X2) = 0.3775. (2.32)\\n2. The equation for the predicted probability tells us that:\\ne−6+0.05X1+3.5\\n(1 + e−6+0.05X1+3.5) = 0.5, (2.33)\\nwhich is equivalent to constraining:\\ne−6+0.05X1+3.5 = 1. (2.34)\\nBy taking the logarithm of both sides, we get that the number of milliseconds needed is:\\nX1 = 2.5\\n0.05 = 50. (2.35)\\n\\x04\\nSOL-21 \\uf14b CH.SOL- 2.18.\\n352.3. SOLUTIONS\\nFor the purpose of this exercise, it is instructive to pre-deﬁne z as:\\nz (X1, X2) = −6.36 − 1.02 × X1 + 0.12 × X2. (2.36)\\n1. By employing the classic logistic regression model:\\nodds = exp(z (X1, X2)). (2.37)\\n2. By substituting the given values of X1, X2 into z (X1, X2), the probability holds:\\np = exp(z (1, 100))/(1 + exp(z (1, 100))) = 0 .99. (2.38)\\n3. Y es. The coefﬁcient for coffee consumption is positive ( 0.119) and the p-value is less\\nthan 0.05 (0.0304).\\nNote: Can you describe the relation between these numerical relations and the positive\\nconclusion?\\n4. No. The p-value for this predictor is 0.3818 > 0.05.\\nNote: Can you explain why this inequality implicates a lack of statistical evidence?\\n\\x04\\nSOL-22 \\uf14b CH.SOL- 2.19.\\n1. The estimated probability of improvement is:\\nˆπ(gum bacteria) =\\nexp(−4.8792 + 0.0258 × gum bacteria)\\n1 + exp(−4.8792 + 0.0258 × gum bacteria).\\nHence, ˆπ(33) = 0 .01748.\\n36Chapter 2 LOGISTIC REGRESSION\\n2. For ˆπ(gum bacteria) = 0 .5 we know that:\\nˆπ(gum) = exp( ˆα + ˆβx)\\n1 + exp( ˆα + ˆβx)\\n= 0.5 (2.39)\\ngum bacteria = −ˆα/ ˆβ = 4.8792/0.0258 = 189 .116. (2.40)\\n3. The estimated odds ratio are given by:\\nexp( ˆβ) = exp(0 .0258) = 1 .0504. (2.41)\\n4. A 99% conﬁdence interval for β is calculated as follows:\\nˆβ ± z0.005 × ASE( ˆβ) = (2.42)\\n0.0258 ± 2.576 × 0.0194 (2.43)\\n= (−0.00077, 0.9917). (2.44)\\nTherefore, a 99% conﬁdence interval for the true odds ratio exp(β) is given by:\\n(exp(−0.00077), exp(0.9917)) = (0 .99923, 2.6958). (2.45)\\n\\x04\\nSOL-23 \\uf14b CH.SOL- 2.20.\\n1. The sample odds ratio is:\\nˆθ = 130 × 6833\\n60 × 6778 = 2.1842. (2.46)\\n372.3. SOLUTIONS\\n2. The estimated standard error for log\\n(\\nˆθ\\n)\\nis:\\nˆσ\\n(\\nlog ˆθ\\n)\\n=\\n√\\n1\\n60 + 1\\n6833 + 1\\n130 + 1\\n6778 = 0.1570. (2.47)\\n3. According to previous sections, the 95% CI for the true log odds ratio is:\\n0.7812 ± 1.96 × 0.1570 = (0 .4734, 1.0889). (2.48)\\nCorrespondingly, the 95% CI for the true odds ratio is:\\n(e0.4734, e1.0889) = (1 .6060, 2.9710). (2.49)\\n\\x04\\n2.3.5 The Logit Function and Entropy\\nSOL-24 \\uf14b CH.SOL- 2.21.\\n1. The entropy (Fig. 2.13) has a maximum value of log2(2) for probability p = 1/2, which\\nis the most chaotic distribution. A lower entropy is a more predictable outcome, with\\nzero providing full certainty.\\n2. The derivative of the entropy with respect to p yields the negative of the logit func-\\ntion:\\ndH(p)\\ndp = −logit(p). (2.50)\\nNote: The curious reader is encouraged to rigorously prove this claim.\\n\\x04\\n2.3.6 Python, PyTorch, CPP\\nSOL-25 \\uf14b CH.SOL- 2.22.\\n38Chapter 2 LOGISTIC REGRESSION\\nFIGURE 2.13: Binary entropy .\\n1. During inference, the purpose of inner_product is to multiply the vector of logistic re-\\ngression coefﬁcients with the vector of the input which we like to evaluate, e.g., calculate\\nthe probability and binary class.\\n2. The line hypo(x) > 0.5f is commonly used for the evaluation of binary classiﬁcation\\nwherein probability values above 0.5 (i.e., a threshold) are regarded as TRUE whereas\\nvalues below 0.5 are regarded as F ALSE.\\n3. The term θ (theta) stands for the logistic regression coefﬁcients which were evaluated\\nduring training.\\n4. The output is as follows:\\n1 > inner_product=-0.5\\n2 > prob=0.377541\\n3 > hypo=0\\nFIGURE 2.14: Logistic regression in C++\\n\\x04\\nSOL-26 \\uf14b CH.SOL- 2.23.\\n392.3. SOLUTIONS\\nBecause the second dimension of lin is 7, and the ﬁrst dimension of data is 3, the result-\\ning matrix has a shape of torch.Size([3, 7]) .\\n\\x04\\nSOL-27 \\uf14b CH.SOL- 2.24.\\nIdeally, you should be able to recognize these functions immediately upon a request from\\nthe interviewer.\\n1. A softmax function.\\n2. A sigmoid function.\\n3. A derivative of a sigmoid function.\\n\\x04\\nSOL-28 \\uf14b CH.SOL- 2.25.\\nThe function implemented in Fig. 2.10 is the binary cross-entropy function. \\x04\\nSOL-29 \\uf14b CH.SOL- 2.26.\\n1. All the methods are variations of the sigmoid function.\\n2. In Python, approximately 1.797e + 308 holds the largest possible valve for a ﬂoating\\npoint variable. The logarithm of which is evaluated at 709.78. If you try to execute the\\nfollowing expression in Python, it will result in inf : np.log(1.8e + 308).\\n3. I would use Ver003 because of its stability. Note: Can you entail why is this method\\nmore stable than the others?\\n\\x04\\n40CHAPTER\\n3\\nPROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAnyone who considers arithmetical methods of producing random digits is, of\\ncourse, in a state of sin.\\n— John von Neumann (1903-1957)\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nThe Beta-Binomial distribution . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 773.1. INTRODUCTION\\n3.1 Introduction\\nT\\nHE Bayesian school of thought has permeated ﬁelds such as mechanical\\nstatistics, classical probability , and ﬁnancial mathematics [ 13]. In tandem,\\nthe subject matter itself has gained attraction, particularly in the ﬁeld of\\nBML. It is not surprising then, that several new Python based probabilistic\\nprogramming libraries such as PyMc3 and Stan [ 11] have emerged and have become\\nwidely adopted by the machine learning community .\\nThis chapter aims to introduce the Bayesian paradigm and apply Bayesian infer-\\nences in a variety of problems. In particular, the reader will be introduced with real-\\nlife examples of conditional probability and also discover one of the most important\\nresults in Bayesian statistics: that the family of beta distributions is conjugate to a bi-\\nnomial likelihood . It should be stressed that Bayesian inference is a subject matter\\nthat students evidently ﬁnd hard to grasp, since it heavily relies on rigorous probab-\\nilistic interpretations of data. Speciﬁcally , several obstacles hamper with the prospect\\nof learning Bayesian statistics:\\n1. Students typically undergo merely basic introduction to classical probability and\\nstatistics. Nonetheless, what follows requires a very solid grounding in these\\nﬁelds.\\n2. Many courses and resources that address Bayesian learning do not cover essen-\\ntial concepts.\\n3. A strong comprehension of Bayesian methods involves numerical training and\\nsophistication levels that go beyond ﬁrst year calculus.\\nConclusively , this chapter may be much harder to understand than other chapters.\\nThus, we strongly urge the readers to thoroughly solve the following questions and\\nverify their grasp of the mathematical concepts in the basis of the solutions [ 8].\\n3.2 Problems\\n3.2.1 Expectation and Variance\\nPRB-30 \\uf059 CH.PRB- 3.1.\\nDeﬁne what is meant by a Bernoulli trial.\\n42Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPRB-31 \\uf059 CH.PRB- 3.2.\\nThe binomial distribution is often used to model the probability that k out of a group of n\\nobjects bare a speciﬁc characteristic. Deﬁne what is meant by a binomial random variable\\nX.\\nPRB-32 \\uf059 CH.PRB- 3.3.\\nWhat does the following shorthand stand for?\\nX ∼ Binomial(n, p ) (3.1)\\nPRB-33 \\uf059 CH.PRB- 3.4.\\nFind the probability mass function (PMF) of the following random variable:\\nX ∼ Binomial(n, p ) (3.2)\\nPRB-34 \\uf059 CH.PRB- 3.5.\\nAnswer the following questions:\\n1. Deﬁne what is meant by (mathematical) expectation.\\n2. Deﬁne what is meant by variance.\\n3. Derive the expectation and variance of a the binomial random variable X ∼ Binomial(n, p )\\nin terms of p and n.\\nPRB-35 \\uf059 CH.PRB- 3.6.\\nProton therapy (PT) is a widely adopted form of treatment for many types of cancer [ 6].\\nA PT device which was not properly calibrated is used to treat a patient with pancreatic\\ncancer (Fig. 3.1). As a result, a PT beam randomly shoots 200 particles independently and\\ncorrectly hits cancerous cells with a probability of 0.1.\\n433.2. PROBLEMS\\nFIGURE 3.1: Histopathology for pancreatic cancer cells.\\n1. Find the statistical distribution of the number of correct hits on cancerous cells in\\nthe described experiment. What are the expectation and variance of the corresponding\\nrandom variable?\\n2. A radiologist using the device claims he was able to hit exactly 60 cancerous cells.\\nHow likely is it that he is wrong?\\n3.2.2 Conditional Probability\\nPRB-36 \\uf059 CH.PRB- 3.7.\\nGiven two events A and B in probability space H, which occur with probabilities P (A)\\nand P (B), respectively:\\n1. Deﬁne the conditional probability of A given B. Mind singular cases.\\n2. Annotate each part of the conditional probability formulae.\\n3. Draw an instance of Venn diagram, depicting the intersection of the events A and B.\\nAssume that A ⋃ B = H.\\nPRB-37 \\uf059 CH.PRB- 3.8.\\nBayesian inference amalgamates data information in the likelihood function with known\\nprior information. This is done by conditioning the prior on the likelihood using the Bayes\\nformulae. Assume two events A and B in probability space H, which occur with probabilities\\n44Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nP (A) and P (B), respectively. Given that A ⋃ B = H, state the Bayes formulae for this case,\\ninterpret its components and annotate them.\\nPRB-38 \\uf059 CH.PRB- 3.9.\\nDeﬁne the terms likelihood and log-likelihood of a discrete random variable X given\\na ﬁxed parameter of interest γ. Give a practical example of such scenario and derive its\\nlikelihood and log-likelihood.\\nPRB-39 \\uf059 CH.PRB- 3.10.\\nDeﬁne the term prior distribution of a likelihood parameter γ in the continuous case.\\nPRB-40 \\uf059 CH.PRB- 3.11.\\nShow the relationship between the prior, posterior and likelihood probabilities.\\nPRB-41 \\uf059 CH.PRB- 3.12.\\nIn a Bayesian context, if a ﬁrst experiment is conducted, and then another experiment is\\nfollowed, what does the posterior become for the next experiment?\\nPRB-42 \\uf059 CH.PRB- 3.13.\\nWhat is the condition under which two events A and B are said to be statistically\\nindependent?\\n3.2.3 Bayes Rule\\nPRB-43 \\uf059 CH.PRB- 3.14.\\nIn an experiment conducted in the ﬁeld of particle physics (Fig. 3.2), a certain particle\\nmay be in two distinct equally probable quantum states: integer spin or half-integer spin.\\nIt is well-known that particles with integer spin are bosons, while particles with half-integer\\nspin are fermions [ 4].\\n453.2. PROBLEMS\\nFIGURE 3.2: Bosons and fermions: particles with half-integer spin are fermions.\\nA physicist is observing two such particles, while at least one of which is in a half-integer\\nstate. What is the probability that both particles are fermions?\\nPRB-44 \\uf059 CH.PRB- 3.15.\\nDuring pregnancy, the Placenta Chorion T est [1] is commonly used for the diagnosis of\\nhereditary diseases (Fig. 3.3). The test has a probability of 0.95 of being correct whether or\\nnot a hereditary disease is present.\\n46Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.3: Foetal surface of the placenta\\nIt is known that 1% of pregnancies result in hereditary diseases. Calculate the probability\\nof a test indicating that a hereditary disease is present.\\nPRB-45 \\uf059 CH.PRB- 3.16.\\nThe Dercum disease [ 3] is an extremely rare disorder of multiple painful tissue growths.\\nIn a population in which the ratio of females to males is equal, 5% of females and 0.25% of\\nmales have the Dercum disease (Fig. 3.4).\\nFIGURE 3.4: The Dercum disease\\nA person is chosen at random and that person has the Dercum disease. Calculate the\\nprobability that the person is female.\\nPRB-46 \\uf059 CH.PRB- 3.17.\\nThere are numerous fraudulent binary options websites scattered around the Internet,\\nand for every site that shuts down, new ones are sprouted like mushrooms. A fraudulent AI\\n473.2. PROBLEMS\\nbased stock-market prediction algorithm utilized at the New Y ork Stock Exchange, (Fig. 3.6)\\ncan correctly predict if a certain binary option [ 7] shifts states from 0 to 1 or the other way\\naround, with 85% certainty.\\nFIGURE 3.5: The New York Stock Exchange.\\nA ﬁnancial engineer has created a portfolio consisting twice as many state-1 options then\\nstate-0 options. A stock option is selected at random and is determined by said algorithm to\\nbe in the state of 1. What is the probability that the prediction made by the AI is correct?\\nPRB-47 \\uf059 CH.PRB- 3.18.\\nIn an experiment conducted by a hedge fund to determine if monkeys (Fig. 3.6) can\\noutperform humans in selecting better stock market portfolios, 0.05 of humans and 1 out of\\n15 monkeys could correctly predict stock market trends correctly.\\n48Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.6: Hedge funds and monkeys.\\nFrom an equally probable pool of humans and monkeys an “expert” is chosen at ran-\\ndom. When tested, that expert was correct in predicting the stock market shift. What is the\\nprobability that the expert is a human?\\nPRB-48 \\uf059 CH.PRB- 3.19.\\nDuring the cold war, the U.S.A developed a speech to text (STT) algorithm that could\\ntheoretically detect the hidden dialects of Russian sleeper agents. These agents (Fig. 3.7),\\nwere trained to speak English in Russia and subsequently sent to the US to gather intelli-\\ngence. The FBI was able to apprehend ten such hidden Russian spies [ 9] and accused them\\nof being \"sleeper\" agents.\\nFIGURE 3.7: Dialect detection.\\n493.2. PROBLEMS\\nThe Algorithm relied on the acoustic properties of Russian pronunciation of the word\\n(v-o-k-s-a-l) which was borrowed from English V-a-u-x-h-a-l-l. It was alleged that it is im-\\npossible for Russians to completely hide their accent and hence when a Russian would\\nsay V-a-u-x-h-a-l-l, the algorithm would yield the text \"v-o-k-s-a-l\". T o test the algorithm\\nat a diplomatic gathering where 20% of participants are Sleeper agents and the rest Americ-\\nans, a data scientist randomly chooses a person and asks him to say V-a-u-x-h-a-l-l. A single\\nletter is then chosen randomly from the word that was generated by the algorithm, which\\nis observed to be an \"l\". What is the probability that the person is indeed a Russian sleeper\\nagent?\\nPRB-49 \\uf059 CH.PRB- 3.20.\\nDuring World War II, forces on both sides of the war relied on encrypted communica-\\ntions. The main encryption scheme used by the German military was an Enigma machine\\n[5], which was employed extensively by Nazi Germany. Statistically, the Enigma machine\\nsent the symbols X and Z Fig. ( 3.8) according to the following probabilities:\\nP (X) = 2\\n9 (3.3)\\nP (Z) = 7\\n9 (3.4)\\nFIGURE 3.8: The Morse telegraph code.\\nIn one incident, the German military sent encoded messages while the British army used\\ncountermeasures to deliberately tamper with the transmission. Assume that as a result of the\\nBritish countermeasures, an X is erroneously received as a Z (and mutatis mutandis) with a\\n50Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nprobability 1\\n7. If a recipient in the German military received a Z, what is the probability that\\na Z was actually transmitted by the sender?\\n3.2.4 Maximum Likelihood Estimation\\nPRB-50 \\uf059 CH.PRB- 3.21.\\nWhat is likelihood function of the independent identically distributed (i.i.d) random\\nvariables:\\nX1, · · · , Xn where Xi ∼ binomial(n, p ), ∀i ∈ [1, n],\\nand where p is the parameter of interest?\\nPRB-51 \\uf059 CH.PRB- 3.22.\\nHow can we derive the maximum likelihood estimator (MLE) of the i.i.d samples\\nX1, · · · , Xn introduced in Q. 3.21?\\nPRB-52 \\uf059 CH.PRB- 3.23.\\nWhat is the relationship between the likelihood function and the log-likelihood function?\\nPRB-53 \\uf059 CH.PRB- 3.24.\\nDescribe how to analytically ﬁnd the MLE of a likelihood function?\\nPRB-54 \\uf059 CH.PRB- 3.25.\\nWhat is the term used to describe the ﬁrst derivative of the log-likelihood function?\\nPRB-55 \\uf059 CH.PRB- 3.26.\\nDeﬁne the term Fisher information.\\n3.2.5 Fisher Information\\n513.2. PROBLEMS\\nPRB-56 \\uf059 CH.PRB- 3.27.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history [ 2] with a death tool far exceeding all\\npast outbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976\\nin Sudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 3.9: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the center for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ | y) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y, γ ∈ [0, 1], y = 1, 2, . . . , n (3.5)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ,\\nthe proportion of infected humans in the entire population. The expectation and variance of\\nthe binomial distribution are:\\nE(y|γ, n) = nγ, V (y|γ, n) = nγ(1 − γ) (3.6)\\nAnswer the following; for the likelihood function of the form Lx(γ):\\n1. Find the log-likelihood function lx(γ) = ln Lx(γ).\\n52Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. Find the gradient of lx(γ).\\n3. Find the Hessian matrix H(γ).\\n4. Find the Fisher information I(γ).\\n5. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\nPRB-57 \\uf059 CH.PRB- 3.28.\\nIn this question, you are going to derive the Fisher information function for several\\ndistributions. Given a probability density function (PDF) f (X|γ), you are provided with\\nthe following deﬁnitions:\\n1. The natural logarithm of the PDF ln f (X|γ) = Φ(X|γ).\\n2. The ﬁrst partial derivative Φ′(X|γ).\\n3. The second partial derivative Φ′′(X|γ).\\n4. The Fisher Information for a continuous random variable:\\nI(γ) = −Eγ\\n[\\nΦ′(X|γ)2\\n]\\n. (3.7)\\nFind the Fisher Information I(γ) for the following distributions:\\n1. The Bernoulli Distribution X ∼ B(1, γ).\\n2. The Poisson Distribution X ∼ P oiss(θ).\\nPRB-58 \\uf059 CH.PRB- 3.29.\\n1. True or False: The Fisher Information is used to compute the Cramer-Rao bound on\\nthe variance of any unbiased maximum likelihood estimator.\\n2. True or False: The Fisher Information matrix is also the Hessian of the symmetrized\\nKL divergence.\\n533.2. PROBLEMS\\n3.2.6 Posterior & prior predictive distributions\\nPRB-59 \\uf059 CH.PRB- 3.30.\\nIn chapter 3 we discussed the notion of a prior and a posterior distribution.\\n1. Deﬁne the term posterior distribution.\\n2. Deﬁne the term prior predictive distribution.\\nPRB-60 \\uf059 CH.PRB- 3.31.\\nLet y be the number of successes in 5 independent trials, where the probability of success\\nis θ in each trial. Suppose your prior distribution for θ is as follows: P (θ = 1 /2) = 0 .25,\\nP (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y) after observing y.\\n2. Derive the prior predictive distribution for y.\\n3.2.7 Conjugate priors\\nPRB-61 \\uf059 CH.PRB- 3.32.\\nIn chapter 3 we discussed the notion of a prior and a posterior.\\n1. Deﬁne the term conjugate prior.\\n2. Deﬁne the term non-informative prior.\\nThe Beta-Binomial distribution\\nPRB-62 \\uf059 CH.PRB- 3.33.\\nThe Binomial distribution was discussed extensively in chapter 3. Here, we are going to\\nshow one of the most important results in Bayesian machine learning. Prove that the family\\nof beta distributions is conjugate to a binomial likelihood , so that if a prior is in that\\n54Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nfamily then so is the posterior. That is, show that:\\nx ∼ Ber(γ), γ ∼ B (α, β) ⇒ γ|x ∼ B (α′, β′) (3.8)\\nFor instance, for h heads and t tails, the posterior is:\\nB(h + α, t + β) (3.9)\\n3.2.8 Bayesian Deep Learning\\nPRB-63 \\uf059 CH.PRB- 3.34.\\nA recently published paper presents a new layer for a new Bayesian neural network\\n(BNN). The layer behaves as follows. During the feed-forward operation, each of the hidden\\nneurons Hn , n ∈ 1, 2 in the neural network (Fig. 3.10) may, or may not ﬁre independently\\nof each other according to a known prior distribution.\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 3.10: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ binomial(n, γ ) random variable\\nand ﬁres with a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U nif orm(0, γ) random variable\\nand ﬁres with a probability of γ.\\nPRB-64 \\uf059 CH.PRB- 3.35.\\nY our colleague, a veteran of the Deep Learning industry, comes up with an idea for for\\n553.2. PROBLEMS\\na BNN layer entitled OnOffLayer. He suggests that each neuron will stay on (the other\\nstate is off) following the distribution f (x) = e−x for x > 0 and f (x) = 0 otherwise\\n(Fig. 3.11). X indicates the time in seconds the neuron stays on . In a BNN, 200 such\\nneurons are activated independently in said OnOffLayer. The OnOffLayer is set to off (e.g.\\nnot active) only if at least 150 of the neurons are shut down . Find the probability that\\nthe OnOffLayer will be active for at least 20 seconds without being shut down.\\non offtime = f (x) = e−x\\nFIGURE 3.11: OnOffLayer in a BNN model.\\nPRB-65 \\uf059 CH.PRB- 3.36.\\nA Dropout layer [12] (Fig. 3.12) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 3.12: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [10], a Dropout layer is declared as follows ( 3.1):\\n56Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 3.1: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 3.1) indicates that the probability of zeroing an\\nelement is 0.2.\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 3.13: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 3.12). Here, for illustration purposes, all two\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\nY ou are interested in the proportionθ of dropped-out neurons. Assume that the chance of\\ndrop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the posterior\\nof θ.\\nPRB-66 \\uf059 CH.PRB- 3.37.\\nA new data scientist in your team, who was formerly a Quantum Physicist, suggests\\nthe following procedure for a Dropout layer entitled QuantumDrop which is based on\\nQuantum principles and the Maxwell Boltzmann distribution. In the Maxwell-Boltzmann\\n573.2. PROBLEMS\\ndistribution, the likelihood of ﬁnding a particle with a particular velocity v is provided by:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.10)\\n0 1 000 2 000 3 000 4 000 5 000\\n0\\n2\\n4\\n·10−4\\nv in m·s−1\\nP (v)\\nHelium\\nFIGURE 3.14: The Maxwell-Boltzmann distribution.\\nIn the suggested QuantumDrop layer ( 3.15), each of the neurons behaves like a molecule\\nand is distributed according to the Maxwell-Boltzmann distribution and ﬁres only when\\nthe most probable speed is reached . This speed is the velocity associated with the highest\\npoint in the Maxwell distribution ( 3.14). Using calculus, brain power and some mathem-\\natical manipulation, ﬁnd the most likely value (speed) at which the neuron will ﬁre .\\noff firedneuron − f ires\\nFIGURE 3.15: A QuantumDrop layer.\\n58Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3.3 Solutions\\n3.3.1 Expectation and Variance\\nSOL-30 \\uf14b CH.SOL- 3.1.\\nThe notion of a Bernoulli trial refers to an experiment with two dichotomous binary out-\\ncomes; success (x = 1), and failure (x = 0). \\x04\\nSOL-31 \\uf14b CH.SOL- 3.2.\\nA binomial random variable X = k represents k successes in n mutually independent\\nBernoulli trials. \\x04\\nSOL-32 \\uf14b CH.SOL- 3.3.\\nThe shorthand X ∼ Binomial(n, p ) indicates that the random variable X has the bi-\\nnomial distribution (Fig. 3.16). The positive integer parameter n indicates the number of\\nBernoulli trials and the real parameter p, 0 < p < 1 holds the probability of success in each of\\nthese trials.\\n0 10 20 30 40 50\\n0,0\\n0,2\\n0,4\\np(x = k) =\\n( n\\nk\\n)\\n· pk · (1 − p)n−k\\nx\\np(x)\\nn = 50, p = 0.3\\nn = 50, p = 0.7\\nn = 50, p = 0.9\\nFIGURE 3.16: The binomial distribution.\\n\\x04\\nSOL-33 \\uf14b CH.SOL- 3.4.\\n593.3. SOLUTIONS\\nThe random variable X ∼ Binomial(n, p ) has the following PMF:\\nP (X = k) =\\n(\\nn\\nk\\n)\\npk (1 − p)n−k ; k = 0, 1, 2, . . . , n. (3.11)\\n\\x04\\nSOL-34 \\uf14b CH.SOL- 3.5.\\nThe answers below regard a discrete random variable. The curious reader is encouraged to\\nexpend them to the continuous case.\\n1. For a random variable X with probability mass function P (X = k) and a set of out-\\ncomes K, the expected value of X is deﬁned as:\\nE[X] :=\\n∑\\nk∈K\\nkP (X = k). (3.12)\\nNote: The expectation of X may also be denoted by µX.\\n2. The variance of X is deﬁned as:\\nVar[X] := E\\n[\\n(X − E[X])2\\n]\\n. (3.13)\\nNote: The variance of X may also be denoted by σ2\\nX, while σX itself denotes the stand-\\nard deviation of X.\\n3. The population mean and variance of a binomial random variable with parameters n\\nand p are:\\nE[X] = np V [X] = np(1 − p) (3.14)\\nNote: Why is this solution intuitive? What information theory-related phenomenon\\noccurs when p = 1/2?\\n\\x04\\nSOL-35 \\uf14b CH.SOL- 3.6.\\n60Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1. This scenario describes an experiment that is repeated 200 times independently with a\\nsuccess probability of 0.1. Thus, if the random variable X denotes the number of times\\nsuccess was obtained, then it is best characterized by the binomial distribution with\\nparameters n = 200 and p = 0.1. Formally:\\nX ∼ Binomial(200, 0.1). (3.15)\\nThe expectation of X is given by:\\nx = E(x) = 200 × 0.1 = 20 , (3.16)\\nand its respective variance is:\\nV ar = 200 × 0.10(1 − 0.10) = 18 .0. (3.17)\\n2. Here we propose two distinguished methods to answer the question.\\nPrimarily, the straightforward solution is to employ the deﬁnition of the binomial dis-\\ntribution and substitute the value of X in it. Namely:\\nP (X = 60; n = 200, p = 0.1)\\n=\\n(\\n200\\n60\\n)\\n0.160 (1 − 0.1)200−60\\n=≈ 2.7 × e−15.\\n(3.18)\\nThis leads to an extremely high probability that the radiologist is mistaken.\\nThe following approach is longer and more advanced, but grants the reader with insights\\nand intuition regarding the results. T o derive how wrong the radiologist is, we can\\nemploy an approximation by considering the standard normal distribution. In statistics,\\nthe Z-score allows us to understand how far from the mean is a data point in units of\\nstandard deviation, thus revealing how likely it is to occur (Fig. 3.17).\\n613.3. SOLUTIONS\\nZ-score\\nz =\\nData point\\nx − µ\\nExpectation\\nσ\\nStandard dev .\\n. (3.19)\\nFIGURE 3.17: Z-score\\nTherefore, the probability of correctly hitting 60 cells is:\\nP (X ≥ 60) = P (Z ≥ 60 − 20√\\n18.0 ) = P (Z ≥ 9.428) ≈ 0. (3.20)\\nAgain, the outcome shows the likelihood that the radiologist was wrong approaches 1.\\nNote: Why is the relation depicted in Fig. 3.17 deduces that Z is a standard Gaussian?\\nUnder what terms is this conclusion valid? Why does eq. (3.20) employs the cumulative\\ndistribution function and not the probability mass function?\\n\\x04\\n3.3.2 Conditional Probability\\nSOL-36 \\uf14b CH.SOL- 3.7.\\n1. For two events A and B with P (B) > 0, the conditional probability of A given that\\nB has occurred is deﬁned as:\\nP (A|B) = P (A ∩ B)\\nP (B) . (3.21)\\nIt is easy to note that if P (B) = 0 , this relation is not deﬁned mathematically. In this\\ncase, P (A|B) = P (A ∩ B) = P (A).\\n2. The annotated probabilities are displayed in Fig. 3.18:\\n62Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nA given B\\nP (A|B) =\\nA and B\\nP (A ∩ B)\\nP (B)\\nB only\\n. (3.22)\\nFIGURE 3.18: Conditional probability\\n3. An example of a diagram depicting the intersected events A and B is displayed in Fig.\\n3.19:\\nA B\\nH\\nFIGURE 3.19: V enn diagram of the intersected events A and B in probability space H\\n\\x04\\nSOL-37 \\uf14b CH.SOL- 3.8.\\nThe Bayes formulae reads:\\nP (A|B) = P (B|A)P (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac), (3.23)\\nwhere P (Ac) is the complementary probability of P (A). The interpretation of the elements in\\n633.3. SOLUTIONS\\nBayes formulae is as follows:\\nposterior probability = likelihood of the data × prior probability\\nnormalization constant . (3.24)\\nNote: What is the important role of the normalization constant? Analyze the cases where\\nP (B) → 0 and P (B) → 1. The annotated probabilities are displayed in (Fig. 3.20):\\nPosterior\\nP (A|B) =\\nLikelihood\\nP (B|A)\\nPrior\\nP (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac)\\nB only\\n. (3.25)\\nFIGURE 3.20: Annotated components of the Bayes formula (eq. 3.23)\\n\\x04\\nSOL-38 \\uf14b CH.SOL- 3.9.\\nGiven X as a discrete randomly distributed variable and given γ as the parameter of\\ninterest, the likelihood and the log-likelihood of X given γ follows respectively:\\nLγ(X = x) = p(X = x|γ) (3.26)\\nℓγ(X = x) = ln ( p(X = x|γ)) (3.27)\\nThe term likelihood can be intuitively understood from this deﬁnition; it deduces how likely is\\nto obtain a value x when a prior information is given regarding its distribution, namely the\\nparameter γ. For example, let us consider a biased coin toss with ph = γ. Then:\\nLγ(X = “h′′) = p(X = “h′′|γ) = γ. (3.28)\\nℓγ(X = “h′′) = ln ( p(X = “h′′|γ)) = ln ( γ) . (3.29)\\n64Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nNote: The likelihood function may also follow continuous distributions such as the normal\\ndistribution. In the latter, it is recommended and often obligatory to employ the log-likelihood.\\nWhy? We encourage the reader to modify the above to the continuous case of normal distribu-\\ntion and derive the answer. \\x04\\nSOL-39 \\uf14b CH.SOL- 3.10.\\nThe continuous prior distribution, f (Γ = γ) represents what is known about the probab-\\nility of the value γ before the experiment has commenced. It is termed as being subjective,\\nand therefore may vary considerably between researchers. By proceeding the previous example,\\nf (Γ = 0.8) holds the probability of randomly ﬂipping a coin that yields “heads” with chance\\nof 80% of times. \\x04\\nSOL-40 \\uf14b CH.SOL- 3.11.\\nThe essence of Bayesian analysis is to draw inference of unknown quantities or quantiles\\nfrom the posterior distribution p(Γ = γ|X = x), which is traditionally derived from prior\\nbeliefs and data information. Bayesian statistical conclusions about chances to obtain the para-\\nmeter Γ = γ or unobserved values of random variable X = x, are made in terms of prob-\\nability statements. These probability statements are conditional on the observed values of X,\\nwhich is denoted as p(Γ = γ|X = x), called posterior distributions of parameter γ. Bayesian\\nanalysis is a practical method for making inferences from data and prior beliefs using probab-\\nility models for quantities we observe and for quantities which we wish to learn. Bayes rule\\nprovides a relationship of this form:\\nposterior ∝ p(x|γ)p(γ) ∝ data given prior × chance of prior . (3.30)\\n\\x04\\nSOL-41 \\uf14b CH.SOL- 3.12.\\nThe posterior density summarizes what is known about the parameter of interest γ after\\nthe data is observed. In Bayesian statistics, the posterior density p(Γ = γ|X = x) becomes\\nthe prior for this next experiment. This is part of the well-known Bayesian updating mech-\\nanism wherein we update our knowledge to reﬂect the actual distribution of data that we\\nobserved. T o summarize, from the perspective of Bayes Theorem, we update the prior distri-\\nbution to a posterior distribution after seeing the data. \\x04\\n653.3. SOLUTIONS\\nSOL-42 \\uf14b CH.SOL- 3.13.\\nTwo events A and B are statistically independent if (and only if):\\nP (A ∩ B) = P (A)P (B). (3.31)\\nNote: Use conditional probability and rationalize this outcome. How does this property be-\\ncome extremely useful in practical researches that consider likelihood of normally distributed\\nfeatures? \\x04\\n3.3.3 Bayes Rule\\nSOL-43 \\uf14b CH.SOL- 3.14.\\nLet γ stand for the number of half-integer spin states, and given the prior knowledge that\\nboth states are equally probable:\\nP (γ = 2|γ ≥ 1) (3.32)\\n= P (γ = 2, γ ≥ 1)\\nP (γ ≥ 1) (3.33)\\n= P (γ = 2)\\n1 − P (γ = 0) = 1/4\\n1 − 1/4 = 1\\n3 (3.34)\\nNote: Under what statistical property do the above relations hold? \\x04\\nSOL-44 \\uf14b CH.SOL- 3.15.\\nLet event A indicate present hereditary-disease and let event B to hold a positive test result.\\nThe calculated probabilities are presented in T able 3.1. We were asked to ﬁnd the probability\\nof a test indicating that hereditary-disease is present, namely P (B). According to the law of\\ntotal probability:\\nP (B) = P (B|A) ∗ P (A) + P (B|A) ∗ P (A)\\n= [0.95 ∗ 0.01] + [0.05 ∗ 0.99] = 0 .059 (3.35)\\nNote: In terms of performance evaluation, P (B|A) is often referred to as the probability of\\n66Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPROBABILITY EXPLANATION\\nP(A)= 0.01 The probability of hereditary-disease.\\nP(A)=1-0.01=.99 The probability of no hereditary-disease.\\nP(B|A)=0.95 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is NOT present [Ã].\\nP(B|B)=1-0.95=.05 The probability that the test will yield a positive result [B]\\nif hereditary-disease is NOT present [Ã] (probability of false\\nalarm).\\nP(B|A)=0.95 The probability that the test will yield a positive result [B] if\\nhereditary-disease is present [A] (probability of detection).\\nP(B|A)=1-0.95=.05 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is present [A].\\nTABLE 3.1: Probability values of hereditary-disease detection.\\ndetection and P (B|A) is considered the probability of false alarm. Notice that these measures\\ndo not, neither logically nor mathematically, combine to probability of 1. \\x04\\nSOL-45 \\uf14b CH.SOL- 3.16.\\nWe ﬁrst enumerate the probabilities one by one:\\nP (Dercum|f emale) = 0 .05, (3.36)\\nP (Dercum|male) = 0 .0025, (3.37)\\nP (male) = P (f emale) = 0 .5. (3.38)\\nWe are asked to ﬁnd P (f emale|Dercum). Using Bayes Rule:\\nP (f emale|Dercum) = P (Dercum|f emale)P (f emale)\\nP (Dercum) . (3.39)\\n673.3. SOLUTIONS\\nHowever we are missing the term P (Dercum). T o ﬁnd it, we apply the Law of T otal Probab-\\nility:\\nP (Dercum) = P (Dercum|f emale)P (f emale)\\n+P (Dercum|male)P (male)\\n=\\n0.05 · 0.5 + 0.0025 · 0.5 = 0 .02625.\\nAnd ﬁnally, returning to eq. ( 3.39):\\nP (f emale|Dercum) = 0.05 · 0.5\\n0.02625 ≈ 0.9524 (3.40)\\nNote: How could this result be reached with one mathematical equation? \\x04\\nSOL-46 \\uf14b CH.SOL- 3.17.\\nIn order to solve this problem, we introduce the following events:\\n1. AI: the AI predicts that the state of the stock option is 1.\\n2. State1: the state of the stock option is 1.\\n3. State0: the state of the stock option is 0.\\nA direct application of Bayes formulae yields:\\nP (State1|AI) = (3.41)\\nP (AI|State1)P (State1)\\nP (AI|State1)P (State1)+P (AI|State0)P (State0) (3.42)\\n= 0.85·2/3\\n0.85·2/3+0.15·1/3 ≈ 0.9189.\\n\\x04\\nSOL-47 \\uf14b CH.SOL- 3.18. In order to solve this problem, we introduce the following events:\\n1. H: a human.\\n68Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. M : a monkey.\\n3. C: a correct prediction.\\nBy employing Bayes theorem and the Law of T otal probability:\\nP (H|C) = P (H ∩ C)\\nP (C)\\n= P (C|H)P (H)\\nP (C|H)P (H) + P (C|M )P (M )\\n=\\n1\\n20 · 1\\n2\\n1\\n20 · 1\\n2 + 1\\n15 · 1\\n2\\n≈ 0.42.\\n(3.43)\\nNote: If something seems off in this outcome, do not worry - it is a positive sign for\\nunderstanding of conditional probability. \\x04\\nSOL-48 \\uf14b CH.SOL- 3.19.\\nIn order to solve this problem, we introduce the following events:\\n1. RU S: a Russian sleeper agent is speaking.\\n2. AM : an American is speaking.\\n3. L: the TTS system generates an “l”.\\nWe are asked to ﬁnd the value of P (RU S|L). Using Bayes Theorem we can write:\\nP (RU S|L) = P (L|RU S)P (RU S)\\nP (L) . (3.44)\\nWe were told that the Russians consist 1/5 of the attendees at the gathering, therefore:\\nP (RU S) = 1\\n5. (3.45)\\n693.3. SOLUTIONS\\nAdditionally, because \"v-o-k-s-a-l\" has a single l out of a total of six letters:\\nP (L|RU S) = 1\\n6. (3.46)\\nAdditionally, because \"V-a-u-x-h-a-l-l\" has two l’s out of a total of eight letters:\\nP (L|AM ) = 2\\n8. (3.47)\\nAn application of the Law of T otal Probability yields:\\nP (L) = P (AM )P (L|AM ) + P (RU S)P (L|RU S) (3.48)\\n=\\n( 4\\n5\\n) ( 2\\n8\\n)\\n+\\n( 1\\n5\\n) ( 1\\n6\\n)\\n= 7\\n30.\\nUsing Bayes Theorem we can write:\\nP (RU S|L) =\\n1\\n5\\n(\\n1\\n6\\n)\\n7\\n30\\n= 1\\n7. (3.49)\\nNote: What is the letter by which the algorithm is most likely to discover a Russian sleeper\\nagent? \\x04\\nSOL-49 \\uf14b CH.SOL- 3.20.\\nWe are given that:\\nP (X is erroneously received as a Z ) = 1 /7. Using Bayes Theorem we can write:\\nP (Z trans |Z received ) =\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received ) . (3.50)\\n70Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAn application of the Law of T otal Probability yields:\\nP (Z received ) =\\nP (Z received |Z trans )P (Z trans )\\n+P (Z received |X trans )P (X trans )\\n= 6\\n7 · 7\\n9 + 1\\n7 · 2\\n9\\n= 44\\n63.\\nSo, using Bayes Rule, we have that\\nP (Z trans |Z received )\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received )\\n=\\n6\\n7\\n7\\n9\\n44\\n63\\n= 44\\n63 = 0.95.\\n(3.51)\\n\\x04\\n3.3.4 Maximum Likelihood Estimation\\nSOL-50 \\uf14b CH.SOL- 3.21.\\nFor the set of i.i.d samples X1, · · · , Xn, the likelihood function is the product of the\\nprobability functions:\\nL(p) = p(X1 = x1; p)p(X2 = x2; p) · · ·p(Xn = xn; p)\\n=\\nn∏\\ni=1\\n(\\nn\\nxi\\n)\\npxi(1 − p)n−xi. (3.52)\\nNote: What is the distribution of X n when X is a Bernoulli distributed random variable?\\n\\x04\\n713.3. SOLUTIONS\\nSOL-51 \\uf14b CH.SOL- 3.22.\\nThe maximum likelihood estimator (MLE) of p is the value of all possible p values that\\nmaximizes L(p). Namely, the p value that renders the set of measurements X1, · · · , Xn as the\\nmost likely. Formally:\\nˆp = arg max0≤p≤1L(p) (3.53)\\nNote: The curious student is highly encouraged to derive ˆp from L(p). Notice that L(p) can\\nbe extremely simpliﬁed. \\x04\\nSOL-52 \\uf14b CH.SOL- 3.23.\\nThe log-likelihood is the logarithm of the likelihood function. Intuitively, maximizing\\nthe likelihood function L(γ) is equivalent to maximizing ln L(γ) in terms of ﬁnding the MLE\\nˆγ, since ln is a monotonically increasing function. Often, we maximize ln(f (γ)) instead of\\nthe f (γ). A common example is when L(γ) is comprised of normally distribution random\\nvariables.\\nFormally, if X1, · · · , Xn are i.i.d, each with probability mass function (PMF) of fXi(xi | γ),\\nthen\\nf (γ) =\\nn∏\\ni=1\\nfXi(xi | γ), (3.54)\\nln(f (γ)) =\\nn∑\\ni=1\\nln fXi(xi | γ). (3.55)\\n\\x04\\nSOL-53 \\uf14b CH.SOL- 3.24.\\nThe general procedure for ﬁnding the MLE, given that the likelihood function is differen-\\ntiable, is as follows:\\n1. Start by differentiating the log-likelihood function ln (L(γ)) with respect to a parameter\\nof interest γ.\\n2. Equate the result to zero.\\n72Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3. Solve the equation to ﬁnd ˆγ that holds:\\n∂ ln L(ˆγ | x1, · · ·xn)\\n∂γ = 0 (3.56)\\n4. Compute the second derivative to verify that you indeed have a maximum rather than\\na minimum.\\n\\x04\\nSOL-54 \\uf14b CH.SOL- 3.25.\\nThe ﬁrst derivative of the log-likelihood function is commonly known as the Fisher score\\nfunction, and is deﬁned as:\\nu(γ) = ∂ ln L(γ | x1, · · ·xn)\\n∂γ (3.57)\\n\\x04\\nSOL-55 \\uf14b CH.SOL- 3.26.\\nFisher information, is the term used to describe the expected value of the second derivat-\\nives (the curvature) of the log-likelihood function, and is deﬁned by:\\nI(γ) = −E\\n[\\n∂2 ln L(γ | x1, · · ·xn)\\n∂γ2\\n]\\n(3.58)\\n\\x04\\n3.3.5 Fisher Information\\nSOL-56 \\uf14b CH.SOL- 3.27.\\n1. Given L(γ):\\nln L(γ) = ln\\n(\\nny\\n)\\n+ y ∗ ln(γ) + (n − y) ln(1 − γ). (3.59)\\n733.3. SOLUTIONS\\n2. T o ﬁnd the gradient, we differentiate once:\\ng(γ) = yγ −1 − (n − y)(1 − γ)−1 =\\n(γ(1 − γ))−1y − n(1 − γ)−1. (3.60)\\n3. The Hessian is generated by differentiating g(γ):\\nH(γ) = −yγ −2 − (n − y)(1 − γ)−2 (3.61)\\n4. The Fisher information is calculated as follows:\\nI(γ) = −E(H(γ)) = n\\nγ(1 − γ), (3.62)\\nsince:\\nE(y|γ, n) = n ∗ γ (3.63)\\n5. Equating the gradient to zero and solving for our parameter γ, we get:\\nˆγ = y\\nn (3.64)\\nIn our case this equates to: 300/10000 = 0 .03. Regarding the error, there is a close\\nrelationship between the variance of γ and the Fisher information, as the former is the\\ninverse of the latter:\\nvar(γ) = [ I(γ)]−1\\nV (γ) = γ(1 − γ)\\nn\\n(3.65)\\nPlugging the numbers from our question:\\nˆV (ˆγ) = 0.03(1 − 0.03)\\n10000 = 2.9 × 10−7. (3.66)\\n74Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nStatistically, the standard error that we are asked to ﬁnd is the square root of eq. 3.66\\nwhich equals 5.3 × 10−4. Note: What desired property is revealed in this experiment?\\nAt was cost could we ensure a low standard error?\\n\\x04\\nSOL-57 \\uf14b CH.SOL- 3.28.\\nThe Fisher Information for the distributions is as follows:\\n1. Bernoulli:\\nΦ(x|γ) = x log γ + (1 − x) log(1 − γ), (3.67)\\nΦ′(x|γ) = x\\nγ − 1 − x\\n1 − γ , (3.68)\\nΦ′′(x|γ) = − x\\nγ2 − 1 − x\\n(1 − γ)2 , (3.69)\\nI(γ) = −Eγ\\n[\\nX(1 − γ)2 + (1 − X)γ2\\nγ2(1 − γ)2\\n]\\n= 1\\nγ(1 − γ). (3.70)\\n2. Poisson:\\nλ(x|θ) = x log θ − log x! − θ,\\nλ′(x|θ) = x − θ\\nθ ,\\nλ′′(x|θ) = − x\\nθ2 ,\\nI(θ) = −Eθ\\n[\\n(X − θ)2\\nθ2\\n]\\n= 1\\nθ .\\n(3.71)\\n\\x04\\nSOL-58 \\uf14b CH.SOL- 3.29.\\n753.3. SOLUTIONS\\n1. T rue.\\n2. T rue.\\n\\x04\\n3.3.6 Posterior & prior predictive distributions\\nSOL-59 \\uf14b CH.SOL- 3.30.\\n1. Given a sample of the form x = ( x1, · · · , xn) drawn from a density p(θ; x) and θ is\\nrandomly generated according to a prior density of p(θ). Then the posterior density is\\ndeﬁned by:\\np(θ|x) = p(θ; x)p(θ)\\np(x) . (3.72)\\n2. The prior predictive density is:\\np(x) =\\n∫\\nθ∈Θ p(θ; x)p(θ)dθ (3.73)\\n\\x04\\nSOL-60 \\uf14b CH.SOL- 3.31.\\n1. The posterior p(θ|y) ∝ p(y|θ)p(θ) is:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3\\n( 5\\ny\\n)\\n(1/2)y(1/2)5−y0.25, θ = 1/2( 5\\ny\\n)\\n(1/6)y(5/6)5−y0.5, θ = 1/6( 5\\ny\\n)\\n(1/4)y(3/4)5−y0.25, θ = 1/4\\n0, otherwise\\n2. The prior predictive distribution p(y):\\n(\\n5\\ny\\n)\\n((1/2)y(1/2)5−y0.25 (3.74)\\n76Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n+\\n(1/6)y(5/6)5−y0.5 + (1/4)y(3/4)5−y0.25). (3.75)\\n\\x04\\n3.3.7 Conjugate priors\\nSOL-61 \\uf14b CH.SOL- 3.32.\\n1. A class F of prior distributions is said to form a conjugate family if the posterior density\\nis in F for all each sample, whenever the prior density is in F.\\n2. Often we would like a prior that favours no particular values of the parameter over\\nothers. Bayesian analysis requires prior information, however sometimes there is no\\nparticularly useful information before data is collected. In these situations, priors with\\n“no information” are expected. Such priors are called non-informative priors.\\n\\x04\\nSOL-62 \\uf14b CH.SOL- 3.33.\\nIf x ∼ B(n, γ) so\\np(x|γ) ∝ γx(1 − γ)n−x\\nand the prior for γ is B(α, β) so\\np(γ) ∝ γα−1(1 − γ)β−1\\nthen the posterior is\\nγ|x ∼ B (α + x, β + n − x)\\nIt is immediately clear the family of beta distributions is conjugate to a\\nbinomial likelihood.\\n\\x04\\n3.3.8 Bayesian Deep Learning\\n773.3. SOLUTIONS\\nSOL-63 \\uf14b CH.SOL- 3.34.\\n1. The hidden neuron is distributed according to:\\nX ∼ binomial(n, γ ) random variable and ﬁres with a probability of γ. There are 100\\nneurons and only 20 are ﬁred.\\nP (x = 20|θ) =\\n\\uf8eb\\n\\uf8ed 100\\n20\\n\\uf8f6\\n\\uf8f8 θ20(1 − θ)80 (3.76)\\n2. The hidden neuron is distributed according to:\\nX unif orm(0, γ) random variable and ﬁres with a probability of γ.\\nThe uniform distribution is, of course, a very simple case:\\nf (x; a, b) = 1\\nb − a for a ≤ x ≤ b (3.77)\\nTherefore:\\nf (x|γ) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0 if γ < x or x < 0\\n1/γ if 0 ≤ x ≤ θ\\n(3.78)\\n\\x04\\nSOL-64 \\uf14b CH.SOL- 3.35.\\nThe provided distribution is from the exponential family. Therefore, a single neuron be-\\ncomes inactive with a probability of:\\np = P (X < 20) =\\n∫ 20\\n0\\ne−x dx = 1 − e−20. (3.79)\\nThe OnOffLayer is off only if at least 150 out of 200 neurons are off. Therefore, this may be\\nrepresented as a Binomial distribution and the probability for the layer to be off is:\\nV =\\n∑\\nn≥150\\n\\uf8eb\\n\\uf8ed 200\\nn\\n\\uf8f6\\n\\uf8f8 ˜pn(1 − ˜p)200−n (3.80)\\n78Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nHence, the probability of the layer being active for at least 20 seconds is 1 minus this value:\\n[1 − V ]. (3.81)\\n\\x04\\nSOL-65 \\uf14b CH.SOL- 3.36.\\nThe observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (3.82)\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (3.83)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (3.84)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (3.85)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(3.86)\\n\\x04\\nSOL-66 \\uf14b CH.SOL- 3.37.\\nNeurons are dropped whenever their value (or the equivalent quantum term- speed) reach\\n79REFERENCES\\nthe most likely value:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.87)\\nFrom calculus, we know that in order to maximize a function, we have to equate its ﬁrst\\nderivative to zero:\\nd\\ndv n(v) = 0 (3.88)\\nThe constants can be taken out as follows:\\nd\\ndv v2e− mv2\\n2kT = 0 (3.89)\\nApplying the chain rule from calculus:\\n2ve− mv2\\n2kT + v2\\n(\\n− m\\n2kT 2v\\n)\\ne− mv2\\n2kT = 0 (3.90)\\nWe notice that several terms cancel out:\\nv2 m\\n2kT = 1 (3.91)\\nNow the quadratic equation can be solved yielding:\\nvmost_probable =\\n√\\n2kT\\nm\\n(3.92)\\nTherefore, this is the most probable value at which the dropout layer will ﬁre.\\n\\x04\\nReferences\\n[1] M. Barati and P . ‘Comparison of complications of chorionic villus sampling and\\namniocentesis’. In: 5.4 (2012), pp. 241–244 (cit. on p. 46).\\n[2] J. D. e. a. Bell BP Damon IK. ‘Overview, Control Strategies, and Lessons Learned\\nin the CDC Response to the 20142016 Ebola Epidemic.’ In: Morbidity and Mortal-\\nity Weekly Report 65.3 (2016), pp. 4–11 (cit. on p. 52).\\n80Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n[3] J. C. Cook and G. P . Gross. Adiposis Dolorosa (Dercum, Anders Disease) . StatPearls\\n[Internet], 2019 (cit. on p. 47).\\n[4] G. Ecker. Particles, Field, From Quantum Mechanics to the Standard Model of Particle\\nPhysics. Springer., 2019 (cit. on p. 45).\\n[5] K. Gaj and A. Orlowski. ‘Facts and Myths of Enigma: Breaking Stereotypes’. In:\\nInternational Conference on the Theory and Applications of Cryptographic T echniques .\\n2003 (cit. on p. 50).\\n[6] B. Gottschalk. ‘Techniques of Proton Radiotherapy: Transport Theory’. In: arXiv\\n(2012) (cit. on p. 43).\\n[7] T. S. O. of Investor Education and Advocacy. Binary options and Fraud (cit. on\\np. 48).\\n[8] E. T. Jaynes. Probability Theory as Logic . Ed. by P . F. Fougère. Maximum-Entropy\\nand Bayesian Methods. Kluwer, Dordrecht, 1990 (cit. on p. 42).\\n[9] D. o. J. National Security Division. Conspiracy to Act as Unregistered Agents of a\\nForeign Government. 2010 (cit. on p. 49).\\n[10] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on p. 56).\\n[11] J. Salvatier, T. V . Wiecki and C. Fonnesbeck. ‘Probabilistic programming in Py-\\nthon using PyMC3’. In: PeerJ Computer Science 2 (Jan. 2016), e55 (cit. on p. 42).\\n[12] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 56).\\n[13] E. B. Starikov. ‘Bayesian Statistical Mechanics: Entropy Enthalpy Compensation\\nand Universal Equation of State at the Tip of Pen’. In: Frontiers in Physics 6 (2018),\\np. 2 (cit. on p. 42).\\n81REFERENCES\\n82HIGH SCHOOL\\nPART IIICHAPTER\\n4\\nINFORMATION THEORY\\nA basic idea in information theory is that information can be treated very much\\nlike a physical quantity, such as mass or energy.\\n— Claude Shannon, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 87\\nShannon\\'s Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen\\'s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 101\\nShannon\\'s Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\nKullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen\\'s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1184.1. INTRODUCTION\\n4.1 Introduction\\nI\\nNDUCTIVE inference, is the problem of reasoning under conditions of in-\\ncomplete information, or uncertainty. According to Shannon’s theory [ 2],\\ninformation and uncertainty are two sides of the same coin: the more uncer-\\ntainty there is, the more information we gain by removing the uncertainty .\\nEntropy plays central roles in many scientiﬁc realms ranging from physics and statist-\\nics to data science and economics. A basic problem in information theory is encoding\\nlarge quantities of information [ 2].\\nShannon’s discovery of the fundamental laws of data compression and transmis-\\nsion marked the birth of information theory . In his fundamental paper of 1948, “ A\\nMathematical Theory of Communication ” [4], Shannon proposed a measure of the uncer-\\ntainty associated with a random memory-less source, called Entropy.\\nH(X) H(Y )\\nH(Z)\\nH(Y |X)\\nH(Z|XY )\\nI(X; Z|Y )\\nFIGURE 4.1: Mutual information\\nEntropy ﬁrst emerged in thermodynamics in the 18 th century by\\nCarnot, [1] in his pioneering work on steam entitled “ Reﬂection on the Motive Power of\\nFire” (Fig. 4.2). Subsequently it appeared in statistical mechanics where it was viewed\\nas a measure of disorder. However, it was Boltzmann ( 4.30) who found the connection\\nbetween entropy and probability , and the notion of information as used by Shannon is\\na generalization of the notion of entropy . Shannon’s entropy shares some instinct with\\nBoltzmann’s entropy , and likewise the mathematics developed in information theory\\nis highly relevant in statistical mechanics.\\n86Chapter 4 INFORMATION THEORY\\nFIGURE 4.2: Reﬂection on the motive power of ﬁre.\\nThe majority of candidates I interview fail to come up with an answer to the fol-\\nlowing question: what is the entropy of tossing a non-biased coin? Surprisingly , even after\\nI explicitly provide them with Shannon’s formulae for calculating entropy ( 4.4), many\\nare still unable to calculate simple logarithms. The purpose of this chapter is to present\\nthe aspiring data scientist with some of the most signiﬁcant notions of entropy and\\nto elucidate its relationship to probability . Therefore, it is primarily focused on basic\\nquantities in information theory such as entropy , cross-entropy , conditional entropy ,\\nmutual information and Kullback-Leibler divergence, also known as relative entropy .\\nIt does not however, discuss more advanced topics such as the concept of ’active in-\\nformation’ introduced by Bohm and Hiley [ 3].\\n4.2 Problems\\n4.2.1 Logarithms in Information Theory\\nIt is important to note that all numerical calculations in this chapter use the binary\\nlogarithm log2. This speciﬁc logarithm produces units of bits, the commonly used units\\nof information in the ﬁeld on information theory .\\n874.2. PROBLEMS\\nPRB-67 \\uf059 CH.PRB- 4.1.\\nRun the following Python code ( 4.3) in a Python interpreter. What are the results?\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n5\\n6 print (math.log10(1.0/0.98)) # Common log (base 10)\\n7 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n8\\n9 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n10 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\nFIGURE 4.3: Natural ( ln), binary (log2) and common ( log10) logarithms.\\nPRB-68 \\uf059 CH.PRB- 4.2.\\nThe three basic laws of logarithms:\\n1. First law\\nlog A + log B = log AB. (4.1)\\nCompute the following expression:\\nlog10 3 + log10 4.\\n2. Second law\\nlog An = n log A. (4.2)\\n88Chapter 4 INFORMATION THEORY\\nCompute the following expression:\\nlog2 46.\\n3. Third law\\nlog A − log B = log A\\nB . (4.3)\\nTherefore, subtracting log B from log A results in log A\\nB .\\nCompute the following expression:\\nloge 15 − loge 3.\\n4.2.2 Shannon\\'s Entropy\\nPRB-69 \\uf059 CH.PRB- 4.3.\\nWrite Shannon\\'s famous general formulae for uncertainty.\\nPRB-70 \\uf059 CH.PRB- 4.4.\\nChoose exactly one, and only one answer.\\n1. For an event which is certain to happen, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N ), N being the number of possible events\\n894.2. PROBLEMS\\n2. For N equiprobable events, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N )\\nPRB-71 \\uf059 CH.PRB- 4.5.\\nShannon found that entropy was the only function satisfying three natural properties.\\nEnumerate these properties.\\nPRB-72 \\uf059 CH.PRB- 4.6.\\nIn information theory, minus the logarithm of the probability of a symbol (essentially\\nthe number of bits required to represent it efﬁciently in a binary code) is deﬁned to be the\\ninformation conveyed by transmitting that symbol. In this context, the entropy can be\\ninterpreted as the expected information conveyed by transmitting a single symbol from an\\nalphabet in which the symbols occur with the probabilities πk.\\nMark the correct answer : Information is a/an [decrease/increase] in uncertainty.\\nPRB-73 \\uf059 CH.PRB- 4.7.\\nClaud Shannon\\'s paper “A mathematical theory of communication” [ 4], marked the\\nbirth of information theory. Published in 1948, it has become since the Magna Carta of the\\ninformation age. Describe in your own words what is meant by the term Shannon bit.\\nPRB-74 \\uf059 CH.PRB- 4.8.\\nWith respect to the notion of surprise in the context of information theory:\\n1. Deﬁne what it actually meant by being surprised.\\n90Chapter 4 INFORMATION THEORY\\n2. Describe how it is related to the likelihood of an event happening.\\n3. True or False: The less likely the occurrence of an event, the smaller information it\\nconveys.\\nPRB-75 \\uf059 CH.PRB- 4.9.\\nAssume a source of signals that transmits a given message a with probability Pa. Assume\\nfurther that the message is encoded into an ordered series of ones and zeros (a bit string) and\\nthat a receiver has a decoder that converts the bit string back into its respective message.\\nShannon devised a formulae that describes the size that the mean length of the bit string can\\nbe compressed to. Write the formulae.\\nPRB-76 \\uf059 CH.PRB- 4.10.\\nAnswer the following questions:\\n1. Assume a source that provides a constant stream of N equally likely symbols\\n{x1, x2, . . . , xN }. What does Shannon\\'s formulae ( 4.4) reduce to in this particular\\ncase?\\n2. Assume that each equiprobable pixel in a monochrome image that is fed to a DL classi-\\nﬁcation pipeline, can have values ranging from 0 to 255. Find the entropy in bits.\\nPRB-77 \\uf059 CH.PRB- 4.11.\\nGiven Shannon\\'s famous general formulae for uncertainty ( 4.4):\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.4)\\n1. Plot a graph of the curve of probability vs. uncertainty.\\n2. Complete the sentence: The curve is [symmetrical/asymmetrical].\\n914.2. PROBLEMS\\n3. Complete the sentence: The curve rises to a [minimum/maximum] when the two\\nsymbols are equally likely ( Pa = 0.5).\\nPRB-78 \\uf059 CH.PRB- 4.12.\\nAssume we are provided with biased coin for which the event ‘heads’ is assigned probab-\\nility p, and ‘tails’ - a probability of 1 − p. Using (4.4), the respective entropy is:\\nH(p) = −p log p − (1 − p) log (1 − p) . (4.5)\\nTherefore, H ≥ 0 and the maximum possible uncertainty is attained when p = 1 /2, is\\nHmax = log 2 2.\\nGiven the above formulation, describe a helpful property of the entropy that follows from\\nthe concavity of the logarithmic function.\\nPRB-79 \\uf059 CH.PRB- 4.13.\\nTrue or False: Given random variables X, Y and Z where Y = X + Z then:\\nH(X, Y ) = H(X, Z). (4.6)\\nPRB-80 \\uf059 CH.PRB- 4.14.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n92Chapter 4 INFORMATION THEORY\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh)+ p(xt) = 1 , what is formulae\\nfor the average surprise?\\n6. What is the value of the average surprise in bits?\\n4.2.3 Kullback-Leibler Divergence (KLD)\\nPRB-81 \\uf059 CH.PRB- 4.15.\\nWrite the formulae for the Kullback-Leibler divergence between two discrete probability\\ndensity functions P and Q.\\nPRB-82 \\uf059 CH.PRB- 4.16.\\nDescribe one intuitive interpretation of the KL-divergence with respect to bits.\\nPRB-83 \\uf059 CH.PRB- 4.17.\\n1. True or False: The KL-divergence is not a symmetric measure of similarity, i.e.:\\nDKL(P ∥Q) ̸= D KL(Q∥P ).\\n2. True or False: The KL-divergence satisﬁes the triangle inequality.\\n3. True or False: The KL-divergence is not a distance metric.\\n4. True or False: In information theory, KLD is regarded as a measure of the informa-\\ntion gained when probability distribution Q is used to approximate a true probability\\ndistribution P .\\n5. True or False: The units of KL-divergence are units of information.\\n6. True or False: The KLD is always non-negative, namely:\\nDKL(P ∥Q) ≥ 0.\\n934.2. PROBLEMS\\n.\\n7. True or False: In a decision tree, high information gain indicates that adding a split\\nto the decision tree results in a less accurate model.\\nPRB-84 \\uf059 CH.PRB- 4.18.\\nGiven two distributions f1 and f2 and their respective joint distribution f , write the\\nformulae for the mutual information of f1 and f2.\\nPRB-85 \\uf059 CH.PRB- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem.\\n4.2.4 Classification and Information Gain\\nPRB-86 \\uf059 CH.PRB- 4.20.\\nThere are several measures by which one can determine how to optimally split attributes\\nin a decision tree. List the three most commonly used measures and write their formulae.\\nPRB-87 \\uf059 CH.PRB- 4.21.\\nComplete the sentence: In a decision tree, the attribute by which we choose to split is\\nthe one with [minimum/maximum] information gain.\\nPRB-88 \\uf059 CH.PRB- 4.22.\\nT o study factors affecting the decision of a frog to jump (or not), a deep learning re-\\nsearcher from a Brazilian rain-forest, collects data pertaining to several independent binary\\nco-variates.\\n94Chapter 4 INFORMATION THEORY\\nFIGURE 4.4: A Frog in its natural habitat. Photo taken by my son.\\nThe binary response variable Jump indicates whether a jump was observed. Referring to\\nT able (4.1), each row indicates the observed values, columns denote features and rows denote\\nlabelled instances while class label ( Jump) denotes whether the frog had jumped.\\nObservation Green Rain Jump\\nx1 1 0 +\\nx2 1 1 +\\nx3 1 0 +\\nx4 1 1 +\\nx5 1 0 +\\nx6 0 1 +\\nx7 0 0 −\\nx8 0 1 −\\nTABLE 4.1: Decision trees and frogs.\\nWithout explicitly determining the information gain values for each of the three attrib-\\nutes, which attribute should be chosen as the attribute by which the decision tree should be\\nﬁrst partitioned? e.g which attribute has the highest predictive power regarding the decision\\nof the frog (Fig. 4.4) to jump.\\n954.2. PROBLEMS\\nPRB-89 \\uf059 CH.PRB- 4.23.\\nThis question discusses the link between binary classiﬁcation, information gain and de-\\ncision trees. Recent research [ 5] suggests that Cannabis (Fig. 4.5), and Cannabinoids ad-\\nministration in particular may reduce the size of malignant tumours in rodents. The data\\n(T able9.2) comprises a training set of feature vectors with corresponding class labels which\\na researcher intents classifying using a decision tree.\\nFIGURE 4.5: Cannabis\\nT o study factors affecting tumour shrinkage, the deep learning researcher collects data\\nregrading two independent binary variables; θ1 (T/F) indicating whether the rodent is a fe-\\nmale, and θ2 (T/F) indicating whether the rodent was administrated with Cannabinoids. The\\nbinary response variable, γ, indicates whether tumour shrinkage was observed (e.g. shrink-\\nage=+, no shrinkage=-). Referring to T able ( 9.2), each row indicates the observed values,\\ncolumns (θi) denote features and class label ( γ) denotes whether shrinkage was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 4.2: Decision trees and Cannabinoids administration\\n96Chapter 4 INFORMATION THEORY\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\nPRB-90 \\uf059 CH.PRB- 4.24.\\nT o study factors affecting the expansion of stars, a physicist is provided with data re-\\ngrading two independent variables; θ1 (T/F) indicating whether a star is dense, and θ2 (T/F)\\nindicating whether a star is adjacent to a black-hole. He is told that the binary response vari-\\nable, γ, indicates whether expansion was observed.\\ne.g.:\\nexpansion=+, no expansion=-. Referring to table ( 4.3), each row indicates the observed val-\\nues, columns (θi) denote features and class label (γ) denotes whether expansion was observed.\\nγ (expansion) θ1 (dense) θ2 (black-hole)\\n+ F T\\n+ T T\\n+ T T\\n- F T\\n+ T F\\n- F F\\n- F F\\nTABLE 4.3: Decision trees and star expansion.\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (expansion)\\nbefore splitting.\\n2. Using log2 and the provided dataset, calculate the information gain of H(γ|θ1).\\n974.2. PROBLEMS\\n3. Using log2 and the provided dataset, calculate the information gain of H(γ|θ2).\\nPRB-91 \\uf059 CH.PRB- 4.25.\\nT o study factors affecting tumour shrinkage in humans, a deep learning researcher is\\nprovided with data regrading two independent variables; θ1 (S/M/L) indicating whether the\\ntumour is small(S), medium(M) or large(L), and θ2 (T/F) indicating whether the tumour\\nhas undergone radiation therapy. He is told that the binary response variable, γ, indicates\\nwhether tumour shrinkage was observed (e.g. shrinkage=+, no shrinkage=-).\\nReferring to table ( 4.4), each row indicates the observed values, columns ( θi) denote\\nfeatures and class label ( γ) denotes whether shrinkage was observed.\\nγ (shrinkage) θ1 θ2\\n- S F\\n+ S T\\n- M F\\n+ M T\\n+ H F\\n+ H T\\nTABLE 4.4: Decision trees and radiation therapy .\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (shrinkage).\\n2. Using log2 and the provided dataset, calculate the entropy of H(γ|θ1).\\n3. Using log2 and the provided dataset, calculate the entropy of H(γ|θ2).\\n4. True or false: We should split on a speciﬁc variable that minimizes the information\\ngain, therefore we should split on θ2 (radiation therapy).\\n4.2.5 Mutual Information\\nPRB-92 \\uf059 CH.PRB- 4.26.\\n98Chapter 4 INFORMATION THEORY\\nShannon described a communications system consisting ﬁve elements (4.6), two of which\\nare the source S and the destination D.\\nSourse S Trans\\nT\\nChannel\\nCH\\nReceiver\\nR\\nDest\\nD\\nMESSAGE\\nSIGNAL\\nSIGNAL\\nMESSAGE\\nFIGURE 4.6: Shannon\\'s ﬁve element communications system.\\n1. Draw a Venn diagram depicting the relationship between the entropies of the source\\nH(S) and of the destination H(D).\\n2. Annotate the part termed equivocation.\\n3. Annotate the part termed noise.\\n4. Annotate the part termed mutual information.\\n5. Write the formulae for mutual information.\\nPRB-93 \\uf059 CH.PRB- 4.27.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\n994.2. PROBLEMS\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\nPRB-94 \\uf059 CH.PRB- 4.28.\\nComplete the sentence: Mutual information is a Shannon entropy-based measure of\\ndependence between random variables. The mutual information between X and Z can be\\nunderstood as the (a) [___] of the (b) [___] in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.7)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X.\\n4.2.6 Mechanical Statistics\\nSome books have a tendency of sweeping \"unseen\" problems under the rug. We will\\nnot do that here. This subsection may look intimidating and for a good reason; it\\ninvolves equations that, unless you are a physicists, you have probably never en-\\ncountered before. Nevertheless, the ability to cope with new concepts lies at the heart\\nof every job interview.\\nFor some of the questions, you may need these constants:\\nPHYSICAL CONSTANTS\\nk Boltzmanns constant 1.381 × 10−23 J K−1\\nc Speed of light in vacum 2.998 × 108m s−1\\nh Planck’s constant 6.626 × 10−34 J s\\nPRB-95 \\uf059 CH.PRB- 4.29.\\nWhat is the expression for the Boltzmann probability distribution?\\nPRB-96 \\uf059 CH.PRB- 4.30.\\nInformation theory, quantum physics and thermodynamics are closely interconnected.\\nThere are several equivalent formulations for the second law of thermodynamics. One ap-\\nproach to describing uncertainty stems from Boltzmanns fundamental work on entropy in\\n100Chapter 4 INFORMATION THEORY\\nstatistical mechanics. Describe what is meant by Boltzmanns entropy.\\nPRB-97 \\uf059 CH.PRB- 4.31.\\nFrom Boltzmanns perspective, what is the entropy of an octahedral dice ( 4.7)?\\nFIGURE 4.7: An octahedral dice.\\n4.2.7 Jensen\\'s inequality\\nPRB-98 \\uf059 CH.PRB- 4.32.\\n1. Deﬁne the term concave function.\\n2. Deﬁne the term convex function.\\n3. State Jensen\\'s inequality and its implications.\\nPRB-99 \\uf059 CH.PRB- 4.33.\\nTrue or False: Using Jensen\\'s inequality, it is possible to show that the KL divergence\\nis always greater or equal to zero.\\n4.3 Solutions\\n4.3.1 Logarithms in Information Theory\\n1014.3. SOLUTIONS\\nSOL-67 \\uf14b CH.SOL- 4.1.\\nNumerical results (4.8) are provided using Python interpreter version 3.6.\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 > 0.02020270731751947\\n5 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n6 > 3.912023005428146\\n7 print (math.log10(1.0/0.98)) # Common log (base 10)\\n8 > 0.008773924307505152\\n9 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n10 > 1.6989700043360187\\n11 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n12 > 0.02914634565951651\\n13 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n14 > 5.643856189774724\\nFIGURE 4.8: Logarithms in information theory .\\n\\x04\\nSOL-68 \\uf14b CH.SOL- 4.2.\\nThe logarithm base is explicitly written in each solution.\\n1.\\nlog10 3 + log10 4 = log 10(3 × 4) = log 10 12.\\n2.\\nlog2 46 = 6 log2 4.\\n3.\\nloge 15 − loge 3 = log e\\n15\\n3 = log e 5.\\n102Chapter 4 INFORMATION THEORY\\n\\x04\\n4.3.2 Shannon\\'s Entropy\\nSOL-69 \\uf14b CH.SOL- 4.3.\\nShannons famous general formulae for uncertainty is:\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.8)\\n\\x04\\nSOL-70 \\uf14b CH.SOL- 4.4.\\n1. No information is conveyed by an event which is a-priori known to occur for certain\\n(Pa = 1), therefore the entropy is 0.\\n2. Equiprobable events mean that Pi = 1 /N ∀i ∈ [1, N]. Therefore for N equally-likely\\nevents, the entropy is log2(N ).\\n\\x04\\nSOL-71 \\uf14b CH.SOL- 4.5.\\nThe three properties are as follows:\\n1. H(X) is always non-negative, since information cannot be lost.\\n2. The uniform distribution maximizes H(X), since it also maximizes uncertainty.\\n3. The additivity property which relates the sum of entropies of two independent events.\\nFor instance, in thermodynamics, the total entropy of two isolated systems which co-\\nexist in equilibrium is the sum of the entropies of each system in isolation.\\n\\x04\\n1034.3. SOLUTIONS\\nSOL-72 \\uf14b CH.SOL- 4.6.\\nInformation is an [increase] in uncertainty. \\x04\\nSOL-73 \\uf14b CH.SOL- 4.7.\\nThe Shannon bit has two distinctive states; it is either 0 or 1, but never both at the same\\ntime. Shannon devised an experiment in which there is a question whose only two possible\\nanswers were equally likely to happen .\\nHe then deﬁned one bit as the amount of information gained (or alternatively, the amount\\nof entropy removed) once an answer to the question has been learned. He then continued to\\nstate that when the a-priori probability of any one possible answer is higher than the other, the\\nanswer would have conveyed less than one bit of information. \\x04\\nSOL-74 \\uf14b CH.SOL- 4.8.\\nThe notion of surprise is directly related to the likelihood of an event happening. Mathem-\\natically is it inversely proportional to the probability of that event.\\nAccordingly, learning that a high-probability event has taken place, for instance the sun rising,\\nis much less of a surprise and gives less information than learning that a low-probability\\nevent, for instance, rain in a hot summer day, has taken place. Therefore, the less likely the\\noccurrence of an event, the greater information it conveys.\\nIn the case where an event is a-priori known to occur for certain ( Pa = 1 ), then no inform-\\nation is conveyed by it. On the other hand, an extremely intermittent event conveys a lot of\\ninformation as it surprises us and informs us that a very improbable state exists. Therefore,\\nthe statement in part 3 is false.\\n\\x04\\nSOL-75 \\uf14b CH.SOL- 4.9.\\nThis quantity ISh, represented in the formulae is called the Shannon information of the\\nsource:\\nISh = −\\n∑\\na\\npa log2 pa. (4.9)\\nIt refers to the mean length in bits, per message, into which the messages can be compressed\\n104Chapter 4 INFORMATION THEORY\\nto. It is then possible for a communications channel to transmit ISh bits per message with a\\ncapacity of ISh. \\x04\\nSOL-76 \\uf14b CH.SOL- 4.10.\\n1. For N equiprobable events it holds that Pi = 1 /N, ∀i ∈ [1, N]. Therefore if we substi-\\ntute this into Shannon\\'s equation we get:\\nHequiprobable = −\\nN∑\\ni=1\\n1\\nN log2\\n1\\nN . (4.10)\\nSince N does not depend on i, we can pull it out of the sum:\\nHequiprobable = −( 1\\nN log2\\n1\\nN )\\nN∑\\ni=1\\n1 (4.11)\\n= −\\n( 1\\nN log2\\n1\\nN\\n)\\nN\\n= − log2\\n1\\nN (4.12)\\n= log 2 N.\\nIt can be shown that for a given number of symbols (i.e., N is ﬁxed) the uncertainty H\\nhas its largest value only when the symbols are equally probable.\\n2. The probability for each pixel to be assigned a value in the given range is:\\npi = 1/256. (4.13)\\nTherefore the entropy is:\\nH = −(256)(1/256)(−8) = 8 [bits/symbol]. (4.14)\\n\\x04\\nSOL-77 \\uf14b CH.SOL- 4.11.\\n1054.3. SOLUTIONS\\nRefer to Fig. 4.9 for the corresponding illustration of the graph, where information is\\nshown as a function of p. It is equal to 0 for p = 0 and for p = 1. This is reasonable because for\\nsuch values of p the outcome is certain, so no information is gained by learning the outcome.\\nThe entropy in maximal uncertainty equals to 1 bit for p = 0 .5. Thus, the information gain\\nis maximal when the probabilities of two possible events are equal. Furthermore, for the entire\\nrange of probabilities between p = 0.4 and p = 0.6 the information is close to 1 bit. \\x04\\nFIGURE 4.9: H vs. Probability\\nSOL-78 \\uf14b CH.SOL- 4.12.\\nAn important set of properties of the entropy follows from the concavity of the entropy,\\nwhich follows from the concavity of the logarithm. Suppose that in an experiment, we cannot\\ndecide whether the actual probability of ‘heads’ is p1 or p2. We may decide to assign probability\\nq to the ﬁrst alternative and probability 1 − q to the second. The actual probability of ‘heads’\\nthen is the mixture qp1 + (1 − q)p2. The corresponding entropies satisfy the inequality:\\nS (qp1 + (1 − q)p2) ≥ qS (p1) + (1 − q) S (p2) , (4.15)\\n106Chapter 4 INFORMATION THEORY\\nThese probabilities, are equal in the extreme cases where p1 = p2, or q = 0, or q = 1. \\x04\\nSOL-79 \\uf14b CH.SOL- 4.13.\\nGiven (X, Y ), we can determine X and Z = Y − X. Conversely, given (X, Z), we can\\ndetermine X and Y = X + Z. Hence, H(X, Y ) = H(X, Z) due to the existence of this\\nbijection. \\x04\\nSOL-80 \\uf14b CH.SOL- 4.14.\\nThe solution and numerical calculations are provided using log2.\\n1. We can predict ‘heads’ for each ﬂip with an accuracy of p(xh) = 98 %.\\n2. According to Fig. ( 4.10), if the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is log2(1/0.98) [bits] .\\n1 import math\\n2 import numpy\\n3 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n4 > 0.02914634565951651\\n5 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n6 > 5.643856189774724\\nFIGURE 4.10: Shannon information gain for a biased coin toss.\\n3. Likewise, if the result of the coin toss is ‘tails’, the amount of Shannon information\\ngained is log2(1/0.02) [bits] .\\n4. It is always true that the more information is associated with an outcome, the more\\nsurprising it is.\\n5. The formulae for the average surprise is:\\nH(x) = p(xh) log 1\\np(xh) + p(xt) log 1\\np(xt). (4.16)\\n1074.3. SOLUTIONS\\n6. The value of the average surprise in bits is ( 4.11):\\nH(x) = [0 .98 × 0.0291] + [0.02 × 5.643] (4.17)\\n= 0.1414 [bits].\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4 print (\"binaryEntropy(p) is:{}\\nbits\".format(binaryEntropy(0.98)))↪→\\n5 > binaryEntropy(p) is:0.1414 bits\\nFIGURE 4.11: Average surprise\\n\\x04\\n4.3.3 Kullback-Leibler Divergence\\nSOL-81 \\uf14b CH.SOL- 4.15.\\nFor discrete probability distributions P and Q, the Kullback-Leibler divergence from P\\nto Q, the KLD is deﬁned as:\\nD(P ∥ Q) =\\n∑\\nx\\nP (x) log P (x)\\nQ(x) (4.18)\\n= EP\\n[\\nlog 1\\nQ(x) − log 1\\nP (x)\\n]\\n= HP (Q)\\ued19 \\ued18\\ued17 \\ued1a\\nCross Entropy\\n− H(P )\\ued19 \\ued18\\ued17 \\ued1a\\nEntropy\\n.\\n\\x04\\n108Chapter 4 INFORMATION THEORY\\nSOL-82 \\uf14b CH.SOL- 4.16.\\nOne interpretation is the following: the KL-divergence indicates the average number of\\nadditional bits required for transmission of values x ∈ X which are distributed according\\nto P (x), but we erroneously encoded them according to distribution Q(x). This makes sense\\nsince you have to “pay” for additional bits to compensate for not knowing the true distribution,\\nthus using a code that was optimized according to other distribution. This is one of the reason\\nthat the KL-divergence is also known as relative entropy. Formally, the cross entropy has an\\ninformation interpretation quantifying how many bits are wasted by using the wrong code:\\nHP (Q) =\\n∑\\nx\\nP (x)\\ued19 \\ued18\\ued17 \\ued1a\\nSending P\\ncode for Q\\n\\ued17 \\ued1a\\ued19 \\ued18\\nlog 1\\nQ(x) . (4.19)\\n\\x04\\nSOL-83 \\uf14b CH.SOL- 4.17.\\n1. True KLD is a non-symmetric measure, i.e. D(P ∥ Q) ̸= D(Q ∥ P ).\\n2. False KLD does not satisfy the triangle inequality.\\n3. True KLD is not a distance metric.\\n4. True KLD is regarded as a measure of the information gain. Notice that, however, KLD\\nis the amount of information lost.\\n5. True The units of KL divergence are units of information (bits, nats, etc.).\\n6. True KLD is a non-negative measure.\\n7. True Performing splitting based on highly informative event usually leads to low model\\ngeneralization and a less accurate one as well.\\n\\x04\\nSOL-84 \\uf14b CH.SOL- 4.18.\\n1094.3. SOLUTIONS\\nFormally, mutual information attempts to measure how correlated two variables are with\\neach other:\\nI(X; Y ) =\\n∑\\nx,y\\nP (x, y) log P (x, y)\\nP (x)P (y) (4.20)\\n= E\\n[\\nlog 1\\nP (x) + log 1\\nP (y) − log 1\\nP (x, y)\\n]\\n= H(X) + H(Y ) − H(X, Y ).\\nRegarding the question at hand, given two distributions f1 and f2 and their joint distri-\\nbution f , the mutual information of f1 and f2 is deﬁned as I(f1, f2) = H(f, f1f2). If the\\ntwo distributions are independent, i.e. f = f1 · f2, the mutual information will vanish. This\\nconcept has been widely used as a similarity measure in image analysis. \\x04\\nSOL-85 \\uf14b CH.SOL- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem. \\x04\\n4.3.4 Classification and Information Gain\\nSOL-86 \\uf14b CH.SOL- 4.20.\\nThe three most widely used methods are:\\n1.\\nEntropy (t) = −\\nc−1∑\\ni=0\\np(i) log2 p(i). (4.21)\\n2.\\n1 −\\nc−1∑\\ni=0\\n[p(i)]2 (4.22)\\n110Chapter 4 INFORMATION THEORY\\n3.\\nClassiﬁcation error (t) = 1 − max\\ni\\n[p(i)]. (4.23)\\n\\x04\\nSOL-87 \\uf14b CH.SOL- 4.21.\\nIn a decision tree, the attribute by which we choose to split is the one with [maximum]\\ninformation gain. \\x04\\nSOL-88 \\uf14b CH.SOL- 4.22.\\nIt is clear that the entropy will be decreased more by ﬁrst splitting on Green rather than\\non Rain.\\nFIGURE 4.12: First split.\\n\\x04\\nSOL-89 \\uf14b CH.SOL- 4.23.\\n1. Information gain is the expected reduction in entropy caused by partitioning values in\\na dataset according to a given attribute.\\n2. A decision tree learning algorithm chooses the next attribute to partition the currently\\nselected node, by ﬁrst computing the information gain from the entropy, for instance,\\nas a splitting criterion.\\n3. There are 3 positive examples corresponding to Shrinkage=+, and 2 negative examples\\n1114.3. SOLUTIONS\\ncorresponding to Shrinkage=-. Using the formulae:\\nH(Y ) = −\\nk∑\\ni=1\\nP (Y = yi) log2 P (Y = yi) (4.24)\\nand the probabilities:\\nP (γ = +) = 3\\n5 , (4.25)\\nP (γ = −) = 2\\n5 , (4.26)\\nthe overall entropy before splitting is ( 4.13):\\nEorig = −(3/5) log(3/5) − (2/5) log(2/5)\\n= H(γ) ≈ 0.97095[bits/symbol]. (4.27)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is: 0.97095 bits\\nFIGURE 4.13: Entropy before splitting.\\n4. If we split on θ1, (4.5) the relative shrinkage frequency is:\\n112Chapter 4 INFORMATION THEORY\\nTotal θ1 = T θ1 = F\\n+ 3 0\\n- 1 1\\nTABLE 4.5: Splitting on θ1.\\nT o compute the information gain (IG) based on feature θ1, we must ﬁrst compute the\\nentropy of γ after a split based on θ1, H(γ|θ1):\\nH(γ|θ1)\\n= −\\nv∑\\nj=1\\n[ k∑\\ni=1\\nP (γ = γi|θ1 = θj) log2 P (γ = γi|θ1 = θj)\\n]\\nP (θ1 = θj).\\nTherefore, using the data for the the relative shrinkage frequency ( 4.5), the information\\ngain after splitting on θ1 is:\\nEθ1=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.8112,\\nEθ1=F = −0\\n1 log 0\\n1 − 1\\n1 log 1\\n1 = 0.0.\\n(4.28)\\nNow we know that P (θ1 = T ) = 4/5 and P (θ1 = F ) = 1/5 , therefore:\\n∆ = Eorig − (4/5) Eθ1=T − (1/5) Eθ1=F\\n= 0.97095 − (4/5) ∗ 0.8112 − (1/5) ∗ (0.0)\\n=≈ 0.32198 [bits/symbol].\\n(4.29)\\n\\x04\\nSOL-90 \\uf14b CH.SOL- 4.24.\\nThere are 4 positive examples corresponding to Expansion=+, and 3 negative examples\\n1134.3. SOLUTIONS\\ncorresponding to Expansion=-.\\n1. The overall entropy before splitting is ( 4.14):\\nEorig = −(4/7) log(4/7) − (3/7) log(3/7)\\n= 0.9852281 [bits/symbol]. (4.30)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is:0.9852281 bits\\nFIGURE 4.14: Entropy before splitting.\\n2. If we split on θ1, (4.6) the relative star expansion frequency is:\\nTotal θ1 = T θ1 = F\\n+ 3 1\\n- 0 3\\nTABLE 4.6: Splitting on θ1.\\nTherefore, the information gain after splitting on A is:\\nEθ1=T = −3\\n3 log 3\\n3 − 0\\n3 log 0\\n3 = 0.0,\\nEθ1=F = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.81127.\\n(4.31)\\n114Chapter 4 INFORMATION THEORY\\nNow we know that P (θ1 = T ) = 3/7 and P (θ1 = F ) = 4/7 , therefore:\\n∆ = Eorig − (3/7) Eθ1=T − (4/7) Eθ1=F\\n= 0.98522 − (3/7) ∗ 0.0 − (4/7) ∗ (0.81127)\\n= 0.52163 [bits/symbol].\\n(4.32)\\n3. If we split on θ2, (4.7) the relative star expansion frequency is:\\nTotal θ2 = T θ2 = F\\n+ 3 1\\n- 1 2\\nTABLE 4.7: Splitting on θ2.\\nThe information gain after splitting on B is:\\nEθ2=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.0.8112,\\nEθ2=F = −1\\n3 log 1\\n3 − 2\\n3 log 2\\n3 = 0.9182.\\n(4.33)\\nNow we know that P (θ2 = T ) = 4/7 and P (θ2 = F ) = 3/7 , therefore:\\n∆ = Eorig − (4/7) Eθ2=T − (3/7) Eθ2=F\\n= 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol].\\n∆ = 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol]. (4.34)\\n\\x04\\n1154.3. SOLUTIONS\\nSOL-91 \\uf14b CH.SOL- 4.25.\\n1.\\nH(γ) = −\\n( 2\\n6 log2\\n2\\n6 + 4\\n6 log2\\n4\\n6\\n)\\nH(γ) = −\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n≈ 0.92 [bits/symbol].\\n(4.35)\\n2.\\nH(γ|θ1) = −1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n−\\n1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n− 1\\n3 (1 log2 1) .\\nH(γ|θ1) = 1\\n3(1) + 1\\n3(1) + 1\\n3 (0).\\nH(γ|θ1) = 2\\n3 ≈ 0.66[bits/symbol].\\n(4.36)\\n3.\\nH(γ|θ2) = −1\\n2\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n− 1\\n2 (1 log2 1) .\\nH(γ|θ2) = 1\\n2\\n(\\nlog2 3 − 2\\n3\\n)\\n.\\nH(γ|θ2) = 1\\n2 log2 3 − 1\\n3 ≈ 0.46 [bits/symbol].\\n(4.37)\\n4. False.\\n\\x04\\n4.3.5 Mutual Information\\nSOL-92 \\uf14b CH.SOL- 4.26.\\n1. The diagram is depicted in Fig. 4.15.\\n116Chapter 4 INFORMATION THEORY\\nE N\\nH(S) H(D)\\nFIGURE 4.15: Mutual Information between H(S) & H(D).\\n2. Equivocation is annotated by E.\\n3. Noise is annotated by N .\\n4. The intersection (shaded area) in (4.15) corresponds to mutual information of the source\\nH(S) and of the destination H(D).\\n5. The formulae for mutual information is:\\nH(S; D) = H(S) − E = H(D) − N. (4.38)\\n\\x04\\nSOL-93 \\uf14b CH.SOL- 4.27.\\nThe relative entropy D(p||q) is the measure of difference between two distributions. It\\ncan also be expressed like a measure of the inefﬁciency of assuming that the distribution is q\\nwhen the true distribution is p. \\x04\\nSOL-94 \\uf14b CH.SOL- 4.28.\\nMutual information is a Shannon entropy-based measure of dependence between random\\nvariables. The mutual information between X and Z can be understood as the reduction of\\n1174.3. SOLUTIONS\\nthe uncertainty in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.39)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X. \\x04\\n4.3.6 Mechanical Statistics\\nSOL-95 \\uf14b CH.SOL- 4.29.\\nIs this question valuable? \\x04\\nSOL-96 \\uf14b CH.SOL- 4.30.\\nBoltzmann related the degree of disorder of the state of a physical system to the logarithm\\nof its probability. If, for example, the system has n non-interacting and identical particles,\\neach capable of existing in each of K equally likely states, the leading term in the logarithm of\\nthe probability of ﬁnding the system in a conﬁguration with n1 particles in state 1, n2 in state\\n2, etc, is given by the Boltzmann entropy Hπ = − ∑K\\n1 πi log(πi), where πi = ni/n. \\x04\\nSOL-97 \\uf14b CH.SOL- 4.31.\\nThere are 8 equiprobable events in each roll of the dice, therefore:\\nH = −\\n8∑\\ni=1\\n1\\n8 log2\\n1\\n8 = 3 [bits] . (4.40)\\n\\x04\\n4.3.7 Jensen\\'s inequality\\nSOL-98 \\uf14b CH.SOL- 4.32.\\n1. A function f is concave in the range [a, b] if f φ2 is negative in the range [a, b].\\n2. A function f is convex in the range [a, b] if f φ2 is positive in the range [a, b].\\n118Chapter 4 INFORMATION THEORY\\n3. The following inequality was published by J.L. Jensen in 1906:\\n(Jensen’s Inequality)Let f be a function convex up on (a, b). Then for any n ≥ 2\\nnumbers xi ∈ (a, b):\\nf\\n( ∑n\\ni=1 xi\\nn\\n)\\n≤\\n∑n\\ni=1 f (xi)\\nn ,\\nand that the equality is attained if and only if f is linear or all xi are equal.\\nFor a convex down function, the sign of the inequality changes to ≥.\\nJensen’s inequality states that if f is convex in the range [a, b], then:\\nf (a) + f (b)\\n2 ≥ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b. Jensen’s inequality states that if f is concave in the\\nrange [a, b], then:\\nf (a) + f (b)\\n2 ≤ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b.\\n\\x04\\nSOL-99 \\uf14b CH.SOL- 4.33.\\nTrue The non-negativity of KLD can be proved using Jensen\\'s inequality. \\x04\\nReferences\\n[1] S. Carnot. Reﬂections on the Motive Power of Fire: And Other Papers on the Second\\nLaw of Thermodynamics . Dover books on physics. Dover Publications, 2012 (cit.\\non p. 86).\\n[2] T. M. Cover and J. A. Thomas. Elements of Information Theory . John Wiley and\\nSons, Inc., 2006 (cit. on p. 86).\\n[3] B. J. Hiley. ‘From the Heisenberg Picture to Bohm: a New Perspective on Active\\nInformation and its relation to Shannon Information’. In: Proc. Conf. Quantum\\nTheory: reconsideration of foundations (2002), pp. 141–162 (cit. on p. 87).\\n119REFERENCES\\n[4] C. Shannon. ‘A mathematical theory of communication’. In: Bell System T echnical\\nJournal 27 (1948), pp. 379–423 (cit. on pp. 86, 90).\\n[5] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 96).\\n120CHAPTER\\n5\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1465.1. INTRODUCTION\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 155\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n5.1 Introduction\\nC\\nALCULUS is the mathematics of change; the differentiation of a function is\\nkey to almost every domain in the scientiﬁc and engineering realms and\\ncalculus is also very much central to DL. A standard curriculum of ﬁrst year\\ncalculus includes topics such as limits, differentiation, the derivative, Taylor\\nseries, integration, and the integral. Many aspiring data scientists who lack a relevant\\nmathematical background and are shifting careers, hope to easily enter the ﬁeld but\\nfrequently encounter a mental barricade.\\n122Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nf (x) f ′(x)\\nsin(x) cos(x)\\ncos(x) − sin(x)\\nlog(x) 1\\nx\\nex ex\\nThanks to the rapid advances in processing power and the proliferation of GPUs,\\nit is possible to lend the burden of computation to a computer with high efﬁciency\\nand precision. For instance, extremely fast implementations of backpropagation, the\\ngradient descent algorithm, and automatic differentiation (AD) [5] brought artiﬁcial in-\\ntelligence from a mere concept to reality .\\nCalculus is frequently taught in a way that is very burdensome to the student,\\ntherefore I tried incorporating the writing of Python code snippets into the learning\\nprocess and the usage of:\\nDAGs (Directed Acyclic Graphs). Gradient descent is the essence of optimization in\\ndeep learning, which requires efﬁcient access to ﬁrst and second order derivatives that\\nAD frameworks provide. While older AD frameworks were written in C++ ([ 4]), the\\nnewer ones are Python-based such as Autograd ([ 10]) and JAX ([ 3], [1]).\\nDerivatives are also crucial in graphics applications. For example, in a render-\\ning technique entitled global illumination, photons bounce in a synthetically generated\\nscene while their direction and colour has to be determined using derivatives based\\non the speciﬁc material each photon hits. In ray tracing algorithms, the colour of the\\npixels is determined by tracing the trajectory the photons travel from the eye of the\\nobserver through a synthetic 3D scene.\\nA function is usually represented by a DAG. For instance, one commonly used\\nform is to represent intermediate values as nodes and operations as arcs ( 5.2). One\\nother commonly used form is to represent not only the values but also the operations\\nas nodes ( 5.11).\\nThe ﬁrst representation of a function by a DAG goes back to [ 7].\\n1235.2. PROBLEMS\\nx\\ny\\nk\\nf (a)\\nf (b)\\na bc\\nFIGURE 5.1: Intermediate value theorem\\nManual differentiation is tedious and error-prone and practically unusable for real-\\ntime graphics applications wherein numerous successive derivatives have to be re-\\npeatedly calculated. Symbolic differentiation on the other hand, is a computer based\\nmethod that uses a collection of differentiation rules to analytically calculate an exact\\nderivative of a function resulting in a purely symbolic derivatives. Many symbolic\\ndifferentiation libraries utilize what is known as operator-overloading ([9]) for both the\\nforward and reverse forms of differentiation, albeit they are not quite as fast as AD.\\n5.2 Problems\\n5.2.1 AD, Gradient descent & Backpropagation\\nAD [5] is the application of the chain rule to functions by computers in order to auto-\\nmatically compute derivatives. AD plays a signiﬁcant role in training deep learning\\nalgorithms and in order to understand AD you need a solid grounding in Calculus. As\\nopposed to numerical differentiation, AD is a procedure for establishing exact deriv-\\natives without any truncation errors. AD breaks a computer program into a series of\\nfundamental mathematical operations, and the gradient or Hessian of the computer\\nprogram is found by successive application of the chain rule ( 5.1) to it’s elementary\\nconstituents.\\n124Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nFor instance, in the C++ programming language, two techniques ([ 4]) are com-\\nmonly utilized in transforming a program that calculates numerical values of a func-\\ntion into a program which calculates numerical values for derivatives of that function;\\n(1) an operator overloading approach and (2) systematic source code transformation.\\n∂\\n∂t f (g(t))\\n⏐⏐⏐⏐⏐\\nt=t0\\n=\\n\\uf8eb\\n\\uf8ed ∂\\n∂s f (s)\\n⏐⏐⏐⏐⏐\\ns=g(t0)\\n\\uf8f6\\n\\uf8f8\\n(\\n∂\\n∂t g(t)\\n⏐⏐⏐⏐⏐\\nt=t0\\n)\\n(5.1)\\nOne notable feature of AD is that the values of the derivatives produced by apply-\\ning AD, as opposed to numerical differentiation (ﬁnite difference formulas), are exact\\nand accurate. Two variants of AD are widely adopted by the scientiﬁc community: the\\nforward mode or the reverse mode where the underlying distinction between them is\\nthe order in which the chain rule is being utilized. The forward mode, also entitled\\ntangent mode, propagates derivatives from the dependent towards the independent\\nvariables, whereas the reverse or adjoint mode does exactly the opposite. AD makes\\nheavy use of a concept known as dual numbers (DN) ﬁrst introduced by Clifford ([ 2]).\\nx1 v1 v2 f\\n(x)2\\nln(1 + v1)\\nexp(v1)\\nv2 + 1\\nFIGURE 5.2: A Computation graph with intermediate values as nodes and operations as\\narcs.\\n5.2.2 Numerical differentiation\\nPRB-100 \\uf059 CH.PRB- 5.1.\\n1. Write the formulae for the ﬁnite difference rule used in numerical differentiation.\\n2. What is the main problem with this formulae?\\n1255.2. PROBLEMS\\n3. Indicate one problem with software tools which utilize numerical differentiation and\\nsuccessive operations on ﬂoating point numbers.\\nPRB-101 \\uf059 CH.PRB- 5.2.\\n1. Given a function f (x) and a point a, deﬁne the instantaneous rate of change of\\nf (x) at a.\\n2. What other commonly used alternative name does the instantaneous rate of change\\nhave?\\n3. Given a function f (x) and a point a, deﬁne the tangent line of f (x) at a.\\n5.2.3 Directed Acyclic Graphs\\nThere are two possible ways to traverse a DAG (Directed Acyclic Graph). One\\nmethod is simple. Start at the bottom and go through all nodes to the top of the com-\\nputational tree. That is nothing else than passing the corresponding computation se-\\nquence top down. Based on this method, the so called forward mode or of AD was\\ndeveloped [ 8]. In contrast to this forward mode the reverse mode was ﬁrst used by\\nSpeelpenning [ 13] who passed the underlying graph top down and propagated the\\ngradient backwards.\\nPRB-102 \\uf059 CH.PRB- 5.3.\\n1. State the deﬁnition of the derivative f (c) of a function f (x) at x = c.\\n2. With respect to the DAG depicted in 5.3:\\n126Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx √x\\n1\\n/\\ng(x)\\nFIGURE 5.3: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.3 and ﬁnd the function g(x) it represents.\\n(b) Using the deﬁnition of the derivative, ﬁnd g′(9).\\nPRB-103 \\uf059 CH.PRB- 5.4.\\n1. With respect to the expression graph depicted in 5.4, traverse the graph and ﬁnd the\\nfunction g(x) it represents.\\nx\\n**2\\n2\\n*\\n-\\n+\\n1\\ng(x)\\nFIGURE 5.4: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n2. Using the deﬁnition of the derivative ﬁnd the derivative of g(x).\\n5.2.4 The chain rule\\nPRB-104 \\uf059 CH.PRB- 5.5.\\n1275.2. PROBLEMS\\n1. The chain rule is key concept in differentiation. Deﬁne it.\\n2. Elaborate how the chain rule is utilized in the context of neural networks.\\n5.2.5 Taylor series expansion\\nThe idea behind a Taylor series is that if you know a function and all its derivatives\\nat one point x = a, you can approximate the function at other points near a. As an\\nexample, take f (x) = √x. You can use Taylor series to approximate\\n√\\n10 by knowing\\nf (9) and all the derivatives f ′(9), f ′′(9).\\nThe MacLaurin series ( 5.2) is a special case of Taylor series when f (0), f ′(0) are\\nknown:\\nf (x) = f (0) + xf ′(0) + x2\\n2! f ′′(0) + x3\\n3! f ′′′(0) + · · · =\\n∞∑\\np=0\\nxp\\np! f (p)(0) (5.2)\\nFor instance, the Maclaurin expansion of cos(x) is:\\nf (x) = cos x, f ′(x) = − sin x,\\nf ′′(x) = − cos x, f ′′′(x) = sin x (5.3)\\nWhen evaluated at 0 results in:\\ncos x = 1 − x2\\n2! + x4\\n4! − x6\\n6! + · · · (5.4)\\nPRB-105 \\uf059 CH.PRB- 5.6.\\nFind the T aylor series expansion for:\\n1.\\n1\\n1 − x (5.5)\\n128Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2.\\nex (5.6)\\n3.\\nsin(x) (5.7)\\n4.\\ncos(x) (5.8)\\nPRB-106 \\uf059 CH.PRB- 5.7.\\nFind the T aylor series expansion for:\\nlog(x) (5.9)\\nPRB-107 \\uf059 CH.PRB- 5.8.\\nFind the T aylor series expansion centered at x = −3 for:\\nf (x) = 5 x2 − 11x + 1 (5.10)\\nPRB-108 \\uf059 CH.PRB- 5.9.\\nFind the 101th degree T aylor polynomial centered at x = 0 for:\\nf (x) = cos( x) (5.11)\\nPRB-109 \\uf059 CH.PRB- 5.10.\\nAt x = 1, compute the ﬁrst 7 terms of the T aylor series expansion of:\\nf (x) = ln 3 x. (5.12)\\n1295.2. PROBLEMS\\n5.2.6 Limits and continuity\\nTheorem 1 (L’Hopital’s rule) .\\n[limx→a\\nf (x)\\ng(x) = limx→a\\nf ′(x)\\ng′(x) ]. (5.13)\\nPRB-110 \\uf059 CH.PRB- 5.11.\\nFind the following limits:\\n1. lim\\nx→3\\nex3\\n− e27\\n3x − 9\\n2. lim\\nx→0\\nex2\\n− x − 1\\n3 cos x − x − 3\\n3. limx→∞\\nx − ln x\\n100√x + 4\\n5.2.7 Partial derivatives\\nPRB-111 \\uf059 CH.PRB- 5.12.\\n1. True or false: When applying a partial derivative, there are two variables considered\\nconstants - the dependent and independent variable.\\n2. Given g(x, y), ﬁnd its partial derivative with respect to x:\\ng(x, y) = x2y + yx + 8y. (5.14)\\nPRB-112 \\uf059 CH.PRB- 5.13.\\n130Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe gradient of a two-dimensional function is given by\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j (5.15)\\n1. Find the gradient of the function:\\nf (x, y) = xy2 − y2 + x3 (5.16)\\n2. Given the function:\\ng(x, y) = x2y = xy2 − y − 1, (5.17)\\nevaluate it at (−1, 0), directed at (1, 1).\\nPRB-113 \\uf059 CH.PRB- 5.14.\\nFind the partial derivatives of:\\nf (x, y) = 3 sin 2(x − y) (5.18)\\nPRB-114 \\uf059 CH.PRB- 5.15.\\nFind the partial derivatives of:\\nz = 2 sin(x) sin(y) (5.19)\\n5.2.8 Optimization\\nPRB-115 \\uf059 CH.PRB- 5.16.\\nConsider f (x) = x2 + 1\\n(x + 2)2 .\\n1. Where is f (x) well deﬁned?\\n1315.2. PROBLEMS\\n2. Where is f (x) increasing and decreasing?\\n3. Where is f (x) reaching minimum and maximum values.\\nPRB-116 \\uf059 CH.PRB- 5.17.\\nConsider f (x) = 2 x3 − x.\\n1. Derive f (x) and conclude on its behavior.\\n2. Derive once again and discuss the concavity of the function f (x).\\nPRB-117 \\uf059 CH.PRB- 5.18.\\nConsider the function\\nf (x, y) = 2 x2 − xy + y2,\\nand ﬁnd maximum, minimum, and saddle points.\\n5.2.9 The Gradient descent algorithm\\nPRB-118 \\uf059 CH.PRB- 5.19.\\nThe gradient descent algorithm can be utilized for the minimization of convex functions.\\nStationary points are required in order to minimize a convex function. A very simple ap-\\nproach for ﬁnding stationary points is to start at an arbitrary point, and move along the\\ngradient at that point towards the next point, and repeat until converging to a stationary\\npoint.\\n1. What is the term used to describe the vector of all partial derivatives for a function\\nf (x)?\\n2. Complete the sentence: when searching for a minima, if the derivative is positive, the\\nfunction is increasing/decreasing.\\n132Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n3. The function x2 as depicted in 5.5, has a derivative of f ′(x) = 2 x. Evaluated at x =\\n−1, the derivative equals f ′(x = −1) = −2. At x = −1, the function is decreasing\\nas x gets larger. We will happen if we wish to ﬁnd a minima using gradient descent,\\nand increase (decrease) x by the size of the gradient , and then again repeatedly keep\\njumping?\\n4. How this phenomena can be alleviated?\\n5. True or False: The gradient descent algorithm is guaranteed to ﬁnd a local minimum\\nif the learning rate is correctly decreased and a ﬁnite local minimum exists.\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−1,0\\n1,0\\n2,0\\n3,0\\n4,0\\nx = −1\\nx\\ny\\nx2\\nFIGURE 5.5: x2 Function\\nPRB-119 \\uf059 CH.PRB- 5.20.\\n1. Is the data linearly separable?\\nX1 X2 Y\\n1 1 +\\n12 12 −\\n4 5 −\\n12 12 +\\n(5.20)\\n1335.2. PROBLEMS\\n2. What is loss function for linear regression?\\n3. What is the gradient descent algorithm to minimize a function f (x)?\\n5.2.10 The Backpropagation algorithm\\nThe most important, expensive and hard to implement part of any hardware realiz-\\nation of ANNs is the non-linear activation function of a neuron. Commonly applied\\nactivation functions are the sigmoid and the hyperbolic tangent. In the most used\\nlearning algorithm in present day applications, back-propagation, the derivatives of\\nthe sigmoid function are needed when back propagating the errors.\\nThe backpropagation algorithm looks for the minimum of the error function in\\nweight space using the method of gradient descent.\\nPRB-120 \\uf059 CH.PRB- 5.21.\\n1. During the training of an ANN, a sigmoid layer applies the sigmoid function to every\\nelement in the forward pass, while in the backward pass the chain rule is being util-\\nized as part of the backpropagation algorithm. With respect to the backpropagation\\nalgorithm, given a sigmoid σ(x) = ex\\n1+ex activation function, and a J as the cost func-\\ntion, annotate each part of equation (5.21):\\ndZ = dJ\\ndσ(x)\\ndσ(x)\\ndx = dA · σ(x) ·\\n(\\n1 − σ(x)\\n)\\n(5.21)\\n2. Code snippet 5.6 provides a pure Python-based (e.g. not using Autograd) implement-\\nation of the forward pass for the sigmoid function. Complete the backward pass that\\ndirectly computes the analytical gradients.\\n134Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5 def backward(self, grad):\\n6 grad_input = [???]\\n7 return grad_input\\nFIGURE 5.6: Forward pass for the sigmoid function.\\nPRB-121 \\uf059 CH.PRB- 5.22.\\nThis question deals with the effect of customized transfer functions. Consider a neural\\nnetwork with hidden units that use x3 and output units that use sin(2x) as transfer func-\\ntions. Using the chain rule, starting from ∂E/∂yk, derive the formulas for the weight updates\\n∆wjk and ∆wij. Notice - do not include partial derivatives in your ﬁnal answer.\\n5.2.11 Feed forward neural networks\\nUnderstanding the inner-workings of Feed Forward Neural Networks (FFNN) is\\ncrucial to the understanding of other, more advanced Neural Networks such as CNN’s.\\nA Neural Network (NN) is an interconnected assembly of simple processing\\nelements, units or nodes, whose functionality is loosely based on the animal\\nneuron. The processing ability of the network is stored in the inter-unit\\nconnection strengths, or weights, obtained by a process of adaptation to, or\\nlearning from, a set of training patterns. [ 6]\\nThe Backpropagation Algorithm is the most widely used learning algorithm for\\nFFNN. Backpropagation is a training method that uses the Generalized Delta Rule . Its\\nbasic idea is to perform a gradient descent on the total squared error of the network\\noutput, considered as a function of the weights. It was ﬁrst described by Werbos and\\nmade popular by Rumelhart’s, Hinton’s and Williams’ paper [ 12].\\n1355.2. PROBLEMS\\n5.2.12 Activation functions, Autograd/JAX\\nActivation functions, and most commonly the sigmoid activation function, are\\nheavily used for the construction of NNs. We utilize Autograd ([ 10]) and the recently\\npublished JAX ([ 1]) library to learn about the relationship between activation func-\\ntions and the Backpropagation algorithm.\\nUsing a logistic, or sigmoid, activation function has some beneﬁts in being able\\nto easily take derivatives and then interpret them using a logistic regression model.\\nAutograd is a core module in PyTorch ([ 11]) and adds inherit support for automatic\\ndifferentiation for all operations on tensors and functions. Moreover, one can imple-\\nment his own custom Autograd function by sub classing the autograd F unction and\\nimplementing the forward and backward passes which operate on PyTorch tensors.\\nPyTorch provides a simple syntax ( 5.7) which is transparent to both CPU/GPU sup-\\nport.\\nimport torch\\nfrom torch.autograd import Function\\nclass DLFunction(Function):\\n@staticmethod\\ndef forward(ctx, input):\\n...\\n@staticmethod\\ndef backward(ctx, grad_output):\\n...\\nFIGURE 5.7: PyTorch syntax for autograd.\\nPRB-122 \\uf059 CH.PRB- 5.23.\\n1. True or false:In Autograd, if any input tensor of an operation has requires_grad=T rue,\\nthe computation will be tracked. After computing the backward pass, a gradient w.r.t.\\nthis tensor is accumulated into .grad attribute\\n136Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. True or false: In Autograd, multiple calls to backward will sum up previously com-\\nputed gradients if they are not zeroed.\\nPRB-123 \\uf059 CH.PRB- 5.24.\\nY our friend, a veteran of the DL community wants to use logistic regression and im-\\nplement custom activation functions using Autograd. Logistic regression is used when the\\nvariable y that we want to predict can only take on discrete values (i.e. classiﬁcation). Con-\\nsidering a binary classiﬁcation problem (y = 0 or y = 1) ( 5.8), the hypothesis function could\\nbe deﬁned so that it is bounded between [0, 1] in which we use some form of logistic function,\\nsuch as the sigmoid function. Other, more efﬁcient functions exist such as the ReLU (Rec-\\ntiﬁed Linear Unit) which we discussed later. Note: The weights in ( 5.8) are only meant for\\nillustration purposes and are not part of the solution.\\nxn\\nx2\\nx1\\n1\\n∑\\nwn\\nw2\\nw1\\nw0\\n0\\n1\\n0\\n1\\nSummation Activation\\nyk =f(netk)\\ninputs weights\\nFIGURE 5.8: A typical binary classiﬁcation problem.\\n1. Given the sigmoid function: g(x) = 1\\n1+e−z what is the expression for the corresponding\\nhypothesis in logistic regression?\\n2. What is the decision boundary?\\n3. What does hΘ(x) = 0 .8 mean?\\n4. Using an Autograd based Python program, implement both the forward and backward\\npass for the sigmoid activation function and evaluate it’s derivative at x = 1\\n1375.2. PROBLEMS\\n5. Using an Autograd based Python program, implement both the forward and backward\\npass for the ReLU activation function and evaluate it’s derivative at x = 1\\nPRB-124 \\uf059 CH.PRB- 5.25.\\nFor real values, −1 < x < 1 the hyperbolic tangent function is deﬁned as:\\ntanh−1 x = 1\\n2 [ln(1 + x) − ln(1 − x)] (5.22)\\nOn the other hand, the artanh function, which returns the inverse hyperbolic tangent of\\nits argument x, is implemented in numpy as arctanh().\\nIts derivative is given by:\\n(arctanh(x))′ = 1\\n1 − x2 (5.23)\\nY our friend, a veteran of the DL community wants to implement a custom activation\\nfunction for the arctanh function using Autograd. Help him in realize the method.\\n1. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n2. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the forward pass for the arctanh function in Python.\\n3. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the backward pass for the arctanh function in Python.\\n4. Name the class ArtanhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\n5.2.13 Dual numbers in AD\\nDual numbers (DN) are analogous to complex numbers and augment real numbers\\n138Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nwith a dual element by adjoining an inﬁnitesimal element d, for which d2 = 0.\\nPRB-125 \\uf059 CH.PRB- 5.26.\\n1. Explain how AD uses ﬂoating point numerical rather than symbolic expressions.\\n2. Explain the notion of DN as introduced by ([ 2]).\\n3. What arithmetic operations are possible on DN?.\\n4. Explain the relationship between a T aylor series and DN.\\nPRB-126 \\uf059 CH.PRB- 5.27.\\n1. Expand the following function using DN:\\nsin(x + ˙xd) (5.24)\\n2. With respect to the expression graph depicted in 5.9:\\nx\\n3\\n* +\\n2\\ng(x)\\nFIGURE 5.9: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.9 and ﬁnd the function g(x) it represents.\\n(b) Expand the function g(x) using DN.\\n3. Show that the general identity :\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.25)\\n1395.2. PROBLEMS\\nholds in this particular case too.\\n4. Using the derived DN, evaluate the function g(x) at x = 2.\\n5. Using an Autograd based Python program implement the function and evaluate it’s\\nderivative at x = 2.\\nPRB-127 \\uf059 CH.PRB- 5.28.\\nWith respect to the expression graph depicted in 5.10:\\nx\\n**2\\n5\\n*\\n*\\n+\\n14\\ng(x)\\nFIGURE 5.10: An expression graph for g(x). Constants are shown in gray , crossed-out\\nsince derivatives should not be propagated to constant operands.\\n1. T raverse the graph5.10 and ﬁnd the function g(x) it represents.\\n2. Expand the function g(x) using DN.\\n3. Using the derived DN, evaluate the function g(x) at x = 5.\\n4. Using an AutoGrad based Python program implement the function and evaluate it’s\\nderivative at x = 5.\\n5.2.14 Forward mode AD\\nPRB-128 \\uf059 CH.PRB- 5.29.\\n140Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nWhen differentiating a function using forward-mode AD, the computation of such an\\nexpression can be computed from its corresponding directed a-cyclical graph by propagating\\nthe numerical values.\\n1. Find the function, g(A, B, C) represented by the expression graph in 5.11.\\nA\\nB\\nC\\nln\\n+* g (A, B, C))\\nFIGURE 5.11: A computation graph for g(x)\\n2. Find the partial derivatives for the function g(x).\\nPRB-129 \\uf059 CH.PRB- 5.30.\\nAnswer the following given that a computational graph of a function has N inputs and\\nM outputs.\\n1. True or False?:\\n(a) Forward and reverse mode AD always yield the same result.\\n(b) In reverse mode AD there are fewer operations (time) and less space for interme-\\ndiates (memory).\\n(c) The cost for forward mode grows with N.\\n(d) The cost for reverse mode grows with M.\\nPRB-130 \\uf059 CH.PRB- 5.31.\\n1415.2. PROBLEMS\\n1. T ransform the source code in code snippet 5.1 into a function g(x1, x2).\\nCODE 5.1: A function, g(x1, x2) in the C programming language.\\n1 float g( float x1 , float x2) {\\n2 float v1, v2, v3 , v4 , v5;\\n3 v1=x1;\\n4 v2=x2;\\n5 v3 = v1 * v2;\\n6 v4 = ln (v1 );\\n7 v5 = v3 + v4;\\n8 return v5;\\n9 }\\n2. T ransform the functiong(x1, x2) into an expression graph.\\n3. Find the partial derivatives for the function g(x1, x2).\\n5.2.15 Forward mode AD table construction\\nPRB-131 \\uf059 CH.PRB- 5.32.\\n1. Given the function:\\nf (x1, x2) = x1x2 + ln (x1) (5.26)\\nand the graph 5.1, annotate each vertex (edge) of the graph with the partial derivatives\\nthat would be propagated in forward mode AD.\\n2. T ransform the graph into a table that computes the function:\\ng(x1, x2) evaluated at (x1; x2) = ( e2; π) using forward-mode AD.\\n3. Write and run a Python code snippet to prove your results are correct.\\n4. Describe the role of seed values in forward-mode AD.\\n142Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n5. T ransform the graph into a table that computes the derivative of g(x1, x2) evalu-\\nated at (x1; x2) = ( e2; π) using forward-mode AD for x1 as the chosen independent\\nvariable.\\n6. Write and run a Python code snippet to prove your results are correct.\\n5.2.16 Symbolic differentiation\\nIn this section, we introduce the basic functionality of the SymPy (SYMbolic Python)\\nlibrary commonly used for symbolic mathematics as a means to deepen your under-\\nstanding in both Python and calculus. If you are using Sympy in a Jupyter notebook\\nin Google Colab (e.g. https://colab.research.google.com/) then rendering\\nsympy equations requires MathJax to be available within each cell output. The follow-\\ning is a hook function that will make this possible:\\nCODE 5.2: Sympy in Google Colab\\n1 from IPython.display import Math, HTML\\n2 def enable_sympy_in_cell():\\n3 display(HTML(\"<script\\nsrc=\\'https://cdnjs.cloudflare.com/ajax/libs/\"↪→\\n4 \"mathjax/2.7.3/latest.js?config=default\\'>\\n5 </script>\"))\\n6 get_ipython().events.register(\\'pre_run_cell\\' ,\\nenable_sympy_in_cell)↪→\\nAfter successfully registering this hook, SymPy rendering ( 5.3) will work correctly:\\nCODE 5.3: Rendering Sympy in Google Colab\\n1 import sympy\\n2 from sympy import *\\n3 init_printing()\\n4 x, y, z = symbols(\\'x y z\\' )\\n5 Integral(sqrt(1/x), (x, 0, oo))\\n1435.2. PROBLEMS\\nIt is also recommended to use the latest version of Sympy:\\nCODE 5.4: Updating Sympy\\n> pip install --upgrade sympy\\n5.2.17 Simple differentiation\\nPRB-132 \\uf059 CH.PRB- 5.33.\\nAnswer the following questions:\\n1. Which differentiation method is inherently prone to rounding errors?\\n2. Deﬁne the term symbolic differentiation.\\nPRB-133 \\uf059 CH.PRB- 5.34.\\nAnswer the following questions:\\n1. Implement the sigmoid function σ(x) = 1\\n1+e−x symbolically using a Python based\\nSymPy program.\\n2. Differentiate the sigmoid function using SymPy and compare it with the analytical\\nderivation σ′(x) = σ(x)(1 − σ(x)).\\n3. Using SymPy, evaluate the gradient of the sigmoid function at x = 0.\\n4. Using SymPy, plot the resulting gradient of the sigmoid function.\\n5.2.18 The Beta-Binomial model\\nPRB-134 \\uf059 CH.PRB- 5.35.\\n144Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nY ou will most likely not be given such a long programming task during a face-to-face\\ninterview. Nevertheless, an extensive home programming assignment is typically given at\\nmany of the start-ups I am familiar with. Y ou should allocate around approximately four to\\nsix hours to completely answer all questions in this problem.\\nWe discussed the Beta-Binomial model extensively in chapter 3. Recall that the Beta-\\nBinomial distribution is frequently used in Bayesian statistics to model the number of suc-\\ncesses in n trials. We now employ SymPy to do the same; demonstrate computationally how\\na prior distribution is updated to develop into a posterior distribution after observing the\\ndata via the relationship of the Beta-Binomial distribution.\\nProvided the probability of success, the number of successes after n trials follows a bino-\\nmial distribution. Note that the beta distribution is a conjugate prior for the parameter of\\nthe binomial distribution. In this case, the likelihood function is binomial, and a beta prior\\ndistribution yields a beta posterior distribution.\\nRecall that for the Beta-Binomial distribution the following relationships exist:\\nPrior of θ Beta(a,b)\\nLikelihood binomial (n, θ)\\nPosterior of θ Beta (a + x, b + n − x)\\nPosterior Mean (a + x)/(a + b + n − x)\\n(5.27)\\n1. Likelihood: The starting point for our inference problem is the Likelihood, the prob-\\nability of the observed data. Find the Likelihood function symbolically using sympy.\\nConvert the SymPy representation to a purely Numpy based callable function with a\\nLambda expression. Evaluate the Likelihood function at θ = 0 .5 with 50 successful\\ntrials out of 100.\\n2. Prior: The Beta Distribution. Deﬁne the Beta distribution which will act as our prior\\ndistribution symbolically using sympy. Convert the SymPy representation to a purely\\nNumpy based callable function. Evaluate the Beta Distribution at θ : 0.5, a : 2, b : 7\\n3. Plot the Beta distribution, using the Numpy based function.\\n4. Posterior: Find the posterior distribution by multiplying our Beta prior by the Bi-\\nnomial Likelihood symbolically using sympy. Convert the SymPy representation to\\n1455.3. SOLUTIONS\\na purely Numpy based callable function. Evaluate the Posterior Distribution at θ :\\n0.5, a : 2, b : 7\\n5. Plot the posterior distribution, using the Numpy based function.\\n6. Show that the posterior distribution has the same functional dependence on θ as the\\nprior, and it is just another Beta distribution.\\n7. Given:\\nPrior : Beta(θ|a = 2, b = 7) = 56 θ (−θ + 1)6 and:\\nLikelihood : Bin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47 ﬁnd the resulting posterior\\ndistribution and plot it.\\n5.3 Solutions\\n5.3.1 Algorithmic differentiation, Gradient descent\\n5.3.2 Numerical differentiation\\nSOL-100 \\uf14b CH.SOL- 5.1.\\n1. The formulae is:\\nf ′(x) ≈ f (x + h) − f (x)\\nh . (5.28)\\n2. The main problem with this formulae is that it suffers from numerical instability for\\nsmall values of h.\\n3. In some numerical software systems, the number\\n√\\n2 may be represented as the a ﬂoat-\\ning point number ≈ 1.414213562. Therefore, the result of:\\nf loat\\n( √\\n(2)\\n)\\n∗ f loat\\n( √\\n(2)\\n)\\nmay equal ≈ 2.000000446.\\n\\x04\\nSOL-101 \\uf14b CH.SOL- 5.2.\\n146Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The instantaneous rate of change equals:\\nlim\\nh→0\\nf (a + h) − f (a)\\na + h − a . (5.29)\\n2. The instantaneous rate of change of f (x) at a is also commonly known as the tangent\\nline of f (x) at a.\\n3. Given a function f (x) and a point a, the tangent (Fig. 5.12) line of f (x) at a is a line\\nthat touches f (a) but does not cross f (x) (sufﬁciently close to a).\\nFIGURE 5.12: A Tangent line\\n\\x04\\n5.3.3 Directed Acyclic Graphs\\nSOL-102 \\uf14b CH.SOL- 5.3.\\n1475.3. SOLUTIONS\\n1. The deﬁnition is:\\nf ′(c) = lim\\nh→0\\nf (c + h) − f (c)\\nh .\\n2. If we traverse the graph 5.3 from left to right we derive the following function:\\ng(x) = 1√x . (5.30)\\nf ′(9) = lim\\nh→0\\n1/\\n√\\n9 + h − 1/\\n√\\n9\\nh\\n= lim\\nh→0\\n√\\n9 −\\n√\\n9 + h√\\n9 ·\\n√\\n9 + h · h\\n= lim\\nh→0\\n(3 −\\n√\\n9 + h)(3 +\\n√\\n9 + h)\\n3\\n√\\n9 + h · (3 +\\n√\\n9 + h) · h\\n= lim\\nh→0\\n9 − (9 + h)\\n9\\n√\\n9 + h · h + 3 · (9 + h) · h\\n= − 1\\n9 · 3 + 3 · 9\\n= − 1\\n54\\n\\x04\\nSOL-103 \\uf14b CH.SOL- 5.4.\\n1. The function g(x) = 2 x2 − x + 1 represents the expression graph depicted in 5.4.\\n148Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. By the deﬁnition:\\nf ′(x) = lim\\nh→0\\nf (x + h) − f (x)\\nx + h − x\\n= lim\\nh→0\\n2(x + h)2 − (x + h) + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2(x2 + 2xh + h2) − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2x2 + 4xh + 2h2 − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n4xh + 2h2 − h\\nh\\n= lim\\nh→0\\n4x + 2h − 1\\n= 4x − 1.\\n(5.31)\\nf (x) = 2 x2 − x + 1\\nf ′(x) = 4 x − 1\\n\\x04\\n5.3.4 The chain rule\\nSOL-104 \\uf14b CH.SOL- 5.5.\\n1. The chain rule states that the partial derivative of E = E(x, y) with respect to x can be\\ncalculated via another variable y = y(x), as follows:\\n∂E\\n∂x = ∂E\\n∂y · ∂y\\n∂x (5.32)\\n2. For instance, the chain rule [ 8] is applied in neural networks to calculate the change in\\n1495.3. SOLUTIONS\\nits weights resulting from tuning the cost function. This derivative is calculated via a\\nchain of partial derivatives (e.g. of the activation functions).\\n\\x04\\n5.3.5 Taylor series expansion\\nSOL-105 \\uf14b CH.SOL- 5.6.\\n1.\\n1\\n1 − x =\\n∞∑\\nn=0\\nxn = 1 + x + x2 + x3\\n(when −1 < x < 1) (5.33)\\n2.\\nex =\\n∞∑\\nn=0\\nxn\\nn! = 1 + x + x2\\n2! + x3\\n3! + · · · (5.34)\\n3.\\nsin x =\\n∞∑\\nn=0\\n(−1)n\\n(2n + 1)! x2n+1 = x − x3\\n3! + x5\\n5! − · · · (5.35)\\n4.\\ncos x =\\n∞∑\\nn=0\\n(−1)n\\n(2n)! x2n = 1 − x2\\n2! + x4\\n4! − · · · (5.36)\\n\\x04\\nSOL-106 \\uf14b CH.SOL- 5.7.\\n150Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nlog x =\\n∞∑\\nn=1\\n(−1)n+1 (x − 1)n\\nn = (x − 1) − (x − 1)2\\n2 +\\n(x − 1)3\\n3 − (x − 1)4\\n4 + · · ·\\n(5.37)\\n\\x04\\nSOL-107 \\uf14b CH.SOL- 5.8.\\nIn this case, all derivatives can be computed:\\nf 0(x) = 5 x2 − 11x + 1,\\nf 0(−3) = 79 ,\\nf 1(x) = 10 x − 11,\\nf 1(−3) = −41,\\nf 2(x) = 10 ,\\nf 2(−3) = 10 ,\\nf n(x) = 0, ∀n ≥ 3.\\n(5.38)\\n\\x04\\nSOL-108 \\uf14b CH.SOL- 5.9.\\nThe immediate answer is 1. Refer to eq. 5.36 to verify this logical consequence. \\x04\\nSOL-109 \\uf14b CH.SOL- 5.10.\\nBy employing eq. 5.37, one can substitute x by 3 − x and generate the ﬁrst 7 terms of the\\nx-dependable outcome before assigning the point x = 1.\\n\\x04\\n5.3.6 Limits and continuity\\nSOL-110 \\uf14b CH.SOL- 5.11.\\n1515.3. SOLUTIONS\\n1. With an indeterminate form 0/0, L’Hopital’s rule holds. We look at\\nlim\\nx→3\\n3x2ex3\\n3 = 9e27,\\nwhich equals to the original limit.\\n2. Again, we yield 0/0 at interim, so we look at the ﬁrst order derivative\\nlim\\nx→0\\n2xex − 1\\n−3 sin x − 1 = 1.\\nThe original limit is also equal to 1.\\n3. This time, the intermediate form is of ∞/∞ and L’Hopital applies as well. The quotient\\nof the derivatives is\\n1 − 1\\nx\\n0.01x−99/100 = 100(x − 1)x1/99\\nAs x → ∞, this goes to ∞, so the original limit is equal to ∞ also.\\n\\x04\\n5.3.7 Partial derivatives\\nSOL-111 \\uf14b CH.SOL- 5.12.\\n1. T rue.\\n2. By treating y as constant, one can derive that\\n∂g\\n∂x = 2xy + y. (5.39)\\n\\x04\\nSOL-112 \\uf14b CH.SOL- 5.13.\\n152Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1.\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j\\n=\\n(\\ny2 + 3x2\\n)\\ni + (2xy − 2y) j\\n(5.40)\\n2. It can be shown that ∇g(x, y) = (2 xy + y2) i + (x2 + 2xy − 1) j at (−1, 0) equals\\n(0, 0). According to the deﬁnition of directional derivative:\\n(0, 0) · (1, 1)\\n|(1, 1)| = 0 (5.41)\\n\\x04\\nSOL-113 \\uf14b CH.SOL- 5.14.\\n∂f\\n∂x = 6 sin(x − y) cos(x − y)\\n∂f\\n∂y = −6 sin(x − y) cos(x − y)\\n(5.42)\\n\\x04\\nSOL-114 \\uf14b CH.SOL- 5.15.\\n∂z\\n∂x = 2 cos x sin y\\n∂z\\n∂y = 2 sin x cos y\\n(5.43)\\n\\x04\\n5.3.8 Optimization\\nSOL-115 \\uf14b CH.SOL- 5.16.\\n1535.3. SOLUTIONS\\n1. The function is only deﬁned where x ̸= −2, in the domain of:\\n(−∞, −2) ∪ (−2, +∞).\\n2. By a simple quotient-based derivation:\\nf ′(x) = 2(x + 2)(2x − 1)\\n(x + 2)4 . (5.44)\\nNamely, expect for the ill-deﬁned x = −2, the critical point of x = 0 .5 should be\\nconsidered. For x > 0.5, the derivative is positive and the function increases, in contrast\\nto x < 0.5.\\n3. The requested coordinate is (0.5, 0.2).\\n\\x04\\nSOL-116 \\uf14b CH.SOL- 5.17.\\n1. f ′(x) = 6 x2 − 1, which entails the behavior of the function changes around the points\\nx = ± 1√\\n6. The derivative is negative between x = − 1√\\n6 and x = 1√\\n6, i.e., it decreases\\nin the domain, and increases otherwise.\\n2. The second derivative is f ′′(x) = 12 x, which means the function is concave for negative\\nx values and convex otherwise.\\n\\x04\\nSOL-117 \\uf14b CH.SOL- 5.18.\\nThe function should be derived according to each variable separately and be equated to 0,\\nas follows:\\nfx(x, y) = 4 x − y = 0 , f y(x, y) = −y + 2y = 0 .\\nSo, the solution to these equations yield the coordinate (0, 0), and f (0, 0) = 0 .\\nLet us derive the second order derivative, as follows:\\n∂2f\\n∂x2 (x, y) = 4 , ∂2f\\n∂y2 (x, y) = 2 , ∂2f\\n∂x∂y (x, y) = −1 ,\\n154Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nAlso, the following relation exists:\\nD(x, y) = ∂2f\\n∂x2\\n∂2f\\n∂y2 −\\n(\\n∂2f\\n∂x∂y\\n) 2\\n= 7 ,\\nThus, the critical point (0, 0) is a minimum. \\x04\\n5.3.9 The Gradient descent algorithm\\nSOL-118 \\uf14b CH.SOL- 5.19.\\n1. It is the gradient of a function which is mathematically represented by:\\n∇f (x, y) =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\n∂f (x,y)\\n∂x\\n∂f (x,y)\\n∂y\\n\\uf8f6\\n\\uf8f7\\uf8f8 (5.45)\\n2. Increasing.\\n3. We will keep jumping between the same two points without ever reaching a minima.\\n4. This phenomena can be alleviated by using a learning rate or step size . For instance,\\nx+ = 2 ∗ η where η is a learning rate with small value such as η = 0.25.\\n5. T rue.\\n\\x04\\nSOL-119 \\uf14b CH.SOL- 5.20.\\n1. The point (12,12) has two classes, so the classes cannot be separated by any line.\\n2.\\nJ(θ) = 1\\n2m\\nm∑\\ni=1\\n(ˆyi − yi)2\\n(5.46)\\n1555.3. SOLUTIONS\\n3. Simple but fundamental algorithm for minimizing f . Just repeatedly move in the direc-\\ntion of the negative gradient\\n(a) Start with initial guess θ(0), step size η\\n(b) For k = 1, 2, 3, . . .:\\ni. Compute the gradient ∇f (θ(k−1))\\nii. Check if gradient is close to zero; is so stop, otherwise continue\\niii. Update θ(k) = θ(k−1) − η∇f (θ(k−1))\\n(c) Return ﬁnal θ(k) as approximate solution θ∗\\n\\x04\\n5.3.10 The Backpropagation algorithm\\nSOL-120 \\uf14b CH.SOL- 5.21.\\n1. The annotated parts of equation (5.21) appear in (5.47):\\nσ(x) = ex\\n1 + ex = The Sigmoid activation function\\nσ(x) ·\\n(\\n1 − σ(x)\\n)\\nThe deriviative of the Sigmoid activation function =\\n1Z = The input\\ndZ = The error introduced by input Z.\\nA = The output\\ndA = The error introduced by output A.\\n(5.47)\\n2. Code snippet 5.13 provides an implementation of both the forward and backward passes\\nfor the sigmoid function.\\n156Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5\\n6 def backward(self, grad):\\n7 grad_input = self.x*(1-self.x) * grad\\n8 return grad_input\\nFIGURE 5.13: Forward and backward passes for the sigmoid activation function in pure\\nPython.\\n\\x04\\nSOL-121 \\uf14b CH.SOL- 5.22.\\nThe key concept in this question is merely understanding that the transfer function and\\nits derivatives are changing compared to traditional activation functions, namely:\\n∂E\\n∂yk\\n= (yk − dk) (5.48)\\n∂E\\n∂netk\\n= ∂E\\n∂yk\\n· ∂yk\\n∂netk\\n= (yk − dk) · 2 cos(2netk) (5.49)\\n∆wjk = −η ∂E\\n∂wjk\\n= −η ∂E\\n∂netk\\n· ∂netk\\n∂wjk\\n= −η · (yk − dk) · 2 cos(2netk) · yj (5.50)\\n∂E\\n∂yj\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\n· ∂netk\\n∂yj\\n)\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\nwjk\\n)\\n(5.51)\\n∂E\\n∂netj\\n= ∂E\\n∂yj\\n· ∂yj\\n∂netj\\n= ∂E\\n∂yj\\n· 3net2\\nj (5.52)\\n1575.3. SOLUTIONS\\n∆wij = −η ∂E\\n∂wij\\n= −η ∂E\\n∂netj\\n· ∂netj\\n∂wij\\n= −η · (∑\\nk [(yk − dk) · 2 cos(2netk) · wjk]) · 3net2\\nj · yi\\n(5.53)\\n\\x04\\n5.3.11 Feed forward neural networks\\n5.3.12 Activation functions, Autograd/JAX\\nSOL-122 \\uf14b CH.SOL- 5.23.\\n1. T rue.\\n2. T rue.\\n\\x04\\nSOL-123 \\uf14b CH.SOL- 5.24.\\nThe answers are as follows:\\n1. hΘ(x) = g(ΘT x) = 1\\n1+e−Θ\\nT\\nx\\n.\\n2. The decision boundary for the logistic sigmoid function is where hΘ(x) = 0 .5 (values\\nless than 0.5 mean false, values equal to or more than 0.5 mean true).\\n3. That there is a 80% chance that the instance is of the corresponding class, therefore:\\n• hΘ(x) = g(Θ0 + Θ1x1 + Θ2x2). We can predict y = 1 if x0 + x1 + x2 ≥ 0.\\n4. The code snippet in 5.14 implements the function using Autograd.\\n158Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 from torch.autograd import Function\\n2 class Sigmoid(Function):\\n3 @staticmethod\\n4 def forward(ctx, x):\\n5 output = 1 / (1 + torch.exp(-x))\\n6 ctx.save_for_backward(output)\\n7 return output\\n8\\n9 @staticmethod\\n10 def backward(ctx, grad_output):\\n11 output, = ctx.saved_tensors\\n12 grad_x = output * (1 - output) * grad_output\\n13 return grad_x\\nFIGURE 5.14: Forward and backward for the sigmoid function in Autograd.\\n5. The code snippet in 5.15 implements the function using Autograd.\\n1595.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ReLU(torch.autograd.Function):\\n3 @staticmethod\\n4 def forward(ctx, input):\\n5 ctx.save_for_backward(input)\\n6 return input.clamp(min=0)\\n7\\n8 @staticmethod\\n9 def backward(ctx, grad_output):\\n10 input, = ctx.saved_tensors\\n11 grad_input = grad_output.clone()\\n12 grad_input[input < 0] = 0\\n13 return grad_input\\nFIGURE 5.15: Forward and backward for the ReLU function in Autograd.\\n\\x04\\nSOL-124 \\uf14b CH.SOL- 5.25. The answers are as follows:\\n1. Code snippet 5.16 implements the forward pass using pure Python.\\n160Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n3 requires_grad=True)).type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 arctanh_values = np.arctanh(xT_np)\\n7 print (\"Numpy:\", arctanh_values)\\n8 > Numpy: [[ 0.38842311 0.1944129 0.64900533]]\\nFIGURE 5.16: Forward pass for equation ( 5.23) using pure Python.\\n2. Code snippet 5.17 implements the forward pass using Autograd.\\n1 import torch\\n2 from torch.autograd import Function\\n3 class ArtanhFunction(Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward(x)\\n7 r = (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5)\\n8 return r\\nFIGURE 5.17: Forward pass for equation ( 5.23).\\n3. Code snippet 5.18 implements the backward pass using Autograd.\\n1615.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ArtanhFunction(Function):\\n3 @staticmethod\\n4 input, = ctx.saved_tensors\\n5 out= grad_output / (1 - input ** 2)\\n6 print (\"backward:{}\".format(out))\\n7 return out\\nFIGURE 5.18: Backward pass for equation ( 5.23).\\n4. Code snippet 5.19 veriﬁes the correctness of the implementation using gradcheck.\\n1 import numpy as np\\n2\\n3 xT =\\ntorch.abs(torch.tensor([[0.11,0.19,0.57]],requires_grad=True))↪→\\n4 .type(torch.DoubleTensor)\\n5 arctanh_values_torch = arctanhPyTorch(xT)\\n6 print (\"Torch:\", arctanh_values_torch)\\n7 from torch.autograd import gradcheck, Variable\\n8 f = ArtanhFunction.apply\\n9 test=gradcheck(lambda t: f(t), xT)\\n10 print(test)\\n11\\n12 > PyTorch version: 1.7.0\\n13 > Torch: tensor([[ 0.3884, 0.1944, 0.6490]], dtype =torch.float64,\\n14 > grad_fn=<ArtanhFunctionBackward>)\\n15 > backward:tensor([[1.1586, 1.0383,1.4838]], dtype =torch.float64,\\n16 grad_fn=<CopyBackwards>)\\nFIGURE 5.19: Invoking arctanh using gradcheck\\n162Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n\\x04\\n5.3.13 Dual numbers in AD\\nSOL-125 \\uf14b CH.SOL- 5.26.\\nThe answers are as follows:\\n1. The procedure of AD is to use verbatim text of a computer program which calculates\\na numerical value and to transform it into the text of a computer program called the\\ntransformed program which calculates the desired derivative values. The transformed\\ncomputer program carries out these derivative calculations by repeated use of the chain\\nrule however applied to actual ﬂoating point values rather than to a symbolic rep-\\nresentation.\\n2. Dual numbers extend all numbers by adding a second component x ↦→ x + ˙xd where\\nx + ˙x is the dual part.\\n3. The following arithmetic operations are possible on DN:\\n(a) d2 = 0\\n(b) (x + ˙xd) + (y + ˙yd) = x + y + ( ˙x + ˙y)d\\n(c) −(x + ˙xd) = −x − ˙xd\\n(d) 1\\nx+ ˙xd = 1\\nx − ˙x\\nx2 d\\n4. For f (x + ˙xd) the T aylor series expansion is:\\nf (x + ˙xd) = f (x) + f ′(x)\\n1! ˙xd + . . .0 (5.54)\\nThe immediate and important result is that all higher-order terms (n >= 2) disappear\\nwhich provides closed-form mathematical expression that represents a function and its\\nderivative.\\n\\x04\\nSOL-126 \\uf14b CH.SOL- 5.27.\\n1635.3. SOLUTIONS\\nThe answers are as follows:\\n1.\\nsin(x + ˙xd) = sin( x) + cos(x) ˙xd (5.55)\\n2. If we traverse the graph 5.9 from left to right we drive the following simple function:\\ng(x) = 3 ∗ x + 2 (5.56)\\n3. We know that:\\ng(x) = 3 ∗ x + 2 (5.57)\\ng′(x) = 3 (5.58)\\nNow if we expand the function using DN:\\ng(x + ˙xd) = 3 ∗ (x + ˙xd) + 2 = (5.59)\\n3 ∗ x + 3 ∗ ( ˙xd) + 2 (5.60)\\nRearranging:\\n3 ∗ x + 2 + 3 ∗ ( ˙xd) (5.61)\\nBut since g(x) = 3 ∗ x + 2 then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.62)\\n4. Evaluating the function g(x) at x = 2 using DN we get:\\ng(x = 2) = (3 ∗ 2 + 2) + (3) ˙xd = (5.63)\\n8 + (3) ˙xd (5.64)\\n5. The code snippet in 5.20 implements the function using Autograd.\\n164Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([2.0], dtype =float)\\n4 def f1(x):\\n5 return 3*x + 2\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 8.0\\n8 print(grad_f1(x)) # > 3.0\\nFIGURE 5.20: Autograd\\n\\x04\\nSOL-127 \\uf14b CH.SOL- 5.28. The answers are as follows:\\n1. If we traverse the graph 5.9 from left to right we drive the following function:\\ng(x) = 5 ∗ x2 + 4 ∗ x + 1 (5.65)\\n2. We know that:\\ng(x1) = 5 ∗ x2 + 4 ∗ x + 1 (5.66)\\ng′(x1) = 10 ∗ x1 + 4 (5.67)\\nNow if we expand the function using DN we get:\\ng(x + ˙xd) = 5 ∗ (x + ˙xd)2 + 4 ∗ (x + ˙xd) + 1 = (5.68)\\n5 ∗ (x2 + 2 ∗ x + ˙xd + ( ˙xd)2) + 4 ∗ x + 4 ∗ ( ˙xd) + 1 (5.69)\\n1655.3. SOLUTIONS\\nHowever by deﬁnition (d2) = 0 and therefore that term vanishes. Rearranging the\\nterms:\\n(5 ∗ x2 + 4 ∗ x + 1) + (10 ∗ x + 4) ˙xd (5.70)\\nBut since g(x) = (5 ∗ x2 + 4 ∗ x + 1) then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.71)\\n3. Evaluating the function g(x) at x = 5 using DN we get:\\ng(x = 4) = (5 ∗ 52 + 4 ∗ 5 + 1) + (10 ∗ 5 + 4) ˙xd =\\n146 + (54) ˙xd (5.72)\\n4. The code snippet in 5.21 implements the function using Autograd.\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([5.0], dtype =float)\\n4 def f1(x):\\n5 return 5*x**2 + 4*x +1\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 146.0\\n8 print(grad_f1(x)) # > 54.0\\nFIGURE 5.21: Autograd\\n\\x04\\n5.3.14 Forward mode AD\\nSOL-128 \\uf14b CH.SOL- 5.29.\\nThe answers are as follows:\\n166Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The function g(x) represented by the expression graph in 5.11 is:\\ng(x) = A + B ∗ ln(C) (5.73)\\n2. For a logarithmic function:\\nd\\ndx ln(x) = 1\\nx (5.74)\\nTherefore, the partial derivatives for the function g(x) are:\\n∂f\\n∂A = 1\\n∂f\\n∂B = ln(C)\\n∂f\\n∂C = B ∗ 1\\nC\\n(5.75)\\n\\x04\\nSOL-129 \\uf14b CH.SOL- 5.30. The answers are as follows:\\n1. T rue. Both directions yield the exact same results.\\n2. T rue. Reverse mode is more efﬁcient than forward mode AD (why?).\\n3. T rue.\\n4. T rue.\\n\\x04\\nSOL-130 \\uf14b CH.SOL- 5.31.\\nThe answers are as follows:\\n1675.3. SOLUTIONS\\n1. The function is\\nf (x1, x2) = x1x2 + ln (x1) (5.76)\\n2. The graph associated with the forward mode AD is as follows:\\nx1\\nx2\\n*\\n+\\nln\\nf (x1, x2)\\nFIGURE 5.22: A Computation graph for g(x1, x2) in 5.1\\n3. The partial derivatives are:\\n∂f\\n∂x1\\n= x2 − 1\\n(x1)\\n∂f\\n∂x2\\n= x1\\n(5.77)\\n\\x04\\n5.3.15 Forward mode AD table construction\\nSOL-131 \\uf14b CH.SOL- 5.32.\\nThe answers are as follows:\\n1. The graph with the intermediate values is depicted in ( 5.23)\\n168Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx1\\nx2\\n*\\n+\\nln\\ng(x1, x2)\\nv1\\nv2\\nv1 v4\\nv3\\nv5\\nFIGURE 5.23: A derivative graph for g(x1, x2) in 5.1\\n2. Forward mode AD for g (x1, x2) = ln ( x1) + x1x2 evaluated at (x1, x2) = ( e2, π).\\nForward-mode function evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\nv1 = ln v−1 = ln (e2) = 2\\nv2 = v−1 × v0 = e2 × π = 23.2134\\nv3 = v1 + v2 2 + 23.2134 = 25 .2134\\nf = v3 =≈ 25.2134\\nTABLE 5.1: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n3. The following Python code ( 5.24) proves that the numerical results are correct:\\n1695.3. SOLUTIONS\\n1 import math\\n2 print (math.log(math.e*math.e) + math.e*math.e*math.pi)\\n3 > 25.2134^^I\\nFIGURE 5.24: Python code- AD of the function g(x1, x2)\\n4. Seed values indicate the values by which the dependent and independent variables are\\ninitialized to before being propagated in a computation graph. For instance:\\n˙v1 = ∂x1\\n∂x1\\n= 1\\n˙v2 = ∂x2\\n∂x1\\n= 0\\nTherefore we set ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n5. Here we construct a table for the forward-mode AD for the derivative of f (x1, x2) =\\nln (x1) + x1x2 evaluated at (x1, x2) = ( e2, π) while setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.. In\\nforward-mode AD a derivative is called a tangent.\\nIn the derivation that follows, note that mathematically using manual differentiation:\\nd\\ndx1\\n[ln(x) + x2x]\\n= d\\ndx1\\n[ln(x1)] + x2 · d\\ndx1\\n[x1]\\n= 1\\nx1\\n+ x2 · 1\\n= 1\\nx1\\n+ x2\\nand also since d\\ndx ln(x) = 1\\nx then ˙v1 = 1\\nv−1\\n∗ ˙v−1 = ˙v−1/v−1 = 1\\ne2 ∗ 1 = 1 /e2.\\n170Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nForward-mode AD derivative evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\n˙v−1 = ˙x1 = 1\\n˙v0 = ˙x2 = 0\\n˙v1 = ˙v−1/v−1 = 1/e2\\n˙v2 = ˙v−1 × v0 + ˙v0 ×\\nv−1 = 1 × π + 0 ×\\ne2 = π\\n˙v4 = ˙v1 + ˙v2 = 1/e2 +\\nπ\\n˙f = ˙v4 = 1 /e2 +\\nπ =≈ 3.2769\\nTABLE 5.3: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute ∂y\\n∂x1\\n.\\n6. The following Python code ( 5.25) proves that the numerical results are correct:\\n1715.3. SOLUTIONS\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 import math\\n4\\n5 x1 = math.e* math.e\\n6 x2 = math.pi\\n7\\n8 def f1(x1,x2):\\n9 return (np.log(x1) + x1*x2)\\n10\\n11 grad_f1 = grad(f1)\\n12\\n13 print(f1(x1,x2)) # > 25.2134\\n14 print(grad_f1(x1,x2)) # > 3.2769\\nFIGURE 5.25: Python code- AD of the function g(x1, x2)\\n\\x04\\n5.3.16 Symbolic differentiation\\n5.3.17 Simple differentiation\\nSOL-132 \\uf14b CH.SOL- 5.33.\\nThe answers are as follows:\\n1. Approximate methods such as numerical differentiation suffer from numerical instabil-\\nity and truncation errors.\\n2. In symbolic differentiation, a symbolic expression for the derivative of a function is\\ncalculated. This approach is quite slow and requires symbols parsing and manipulation.\\nFor example, the number\\n√\\n2 is represented in SymPy as the object Pow(2,1/2). Since\\nSymPy employees exact representations Pow(2,1/2)*Pow(2,1/2) will always equal 2.\\n\\x04\\n172Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nSOL-133 \\uf14b CH.SOL- 5.34.\\n1. First:\\n1 import sympy\\n2 sympy.init_printing()\\n3 from sympy import Symbol\\n4 from sympy import diff, exp, sin, sqrt\\n5 y = Symbol(\\'y\\' )\\n6 y = sympy.Symbol(\"y\")\\n7 sigmoid = 1/(1+sympy.exp(-y))^^I\\nFIGURE 5.26: Sigmoid in SymPy\\n2. Second:\\n1 sig_der=sym.diff(sigmoid, y)\\nFIGURE 5.27: Sigmoid gradient in SymPy\\n3. Third:\\n1 sig_der.evalf(subs={y:0})\\n2 > 0.25\\nFIGURE 5.28: Sigmoid gradient in SymPy\\n1735.3. SOLUTIONS\\n4. The plot is depicted in 5.29.\\n1 p = sym.plot(sig_der);\\n10.0\\n 7.5\\n 5.0\\n 2.5\\n 0.0 2.5 5.0 7.5 10.0\\ny\\n0.00\\n0.05\\n0.10\\n0.15\\n0.20\\n0.25f(y)\\nFIGURE 5.29: SymPy gradient of the Sigmoid() function\\n\\x04\\n5.3.18 The Beta-Binomial model\\nSOL-134 \\uf14b CH.SOL- 5.35.\\nT o correctly render the generated LaT eX in this problem, we import and conﬁgure several\\nlibraries as depicted in 5.30.\\n174Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 import scipy.stats as st\\n3 import matplotlib.pyplot as plt\\n4 import sympy as sp\\n5 sp.interactive.printing.\\n6 init_printing(use_latex=True)\\n7 from IPython.display import display, Math, Latex\\n8 maths = lambda s: display(Math(s))\\n9 latex = lambda s: display(Latex(s)) ^^I\\nFIGURE 5.30: SymPy imports\\n1. The Likelihood function can be created as follows. Note the speciﬁc details of generating\\nthe Factorial function in SymPy.\\n1755.3. SOLUTIONS\\n1 n = sp.Symbol(\\'n\\' , integer =True, positive =True)\\n2 r = sp.Symbol(\\'r\\' , integer =True, positive =True)\\n3 theta = sp.Symbol(\\'theta\\' )\\n4 # Create the function symbolically\\n5 from sympy import factorial\\n6 cNkSym= (factorial(n))/ (factorial(r) *factorial(n-r))\\n7 cNkSym.evalf()\\n8 binomSym= cNkSym*((theta **r)*(1-theta)**(n-r))\\n9 binomSym.evalf()\\n10 #Convert it to a Numpy-callable function\\n11 binomLambda = sp.Lambda((theta,r,n), binomSym)\\n12 maths(r\"\\\\operatorname{Bin}(r|n,\\\\theta) = \" )\\n13 display (binomLambda .expr)\\n14 #Evaluating the SymPy version results in:\\n15 > binomSym.subs({theta:0.5,r:50,n:100})\\n16 #Evaluating the pure Numpy version results in:\\n17 > binomLambda(0.5,50,100)= 0.07958923\\nFIGURE 5.31: Likelihood function using SymPy\\nThe Symbolic representation results in the following LaT eX:\\nBin(r|n, θ) = θr (−θ + 1)n−r n!\\nr! (n − r)! (5.78)\\n2. The Beta distribution can be created as follows.\\n176Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 #mu = sp.Symbol(\\'mu\\', integer=False, positive=True)\\n4 # Create the function symbolically\\n5 G = sp.gamma\\n6 # The normalisation factor\\n7 BetaNormSym = G(a + b)/(G(a)*G(b))\\n8 # The functional form\\n9 BetaFSym = theta**(a-1) * (1-theta)**(b-1)\\n10 BetaSym=BetaNormSym * BetaFSym\\n11 BetaSym.evalf() # this works\\n12 # Turn Beta into a function\\n13 BetaLambda = sp.Lambda((theta,a,b), BetaNormSym * BetaFSym)\\n14 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) = \" )\\n15 display(BetaSym)\\n16 #Evaluating the SymPy version results in:\\n17 > BetaLambda(0.5,2,7)=0.4375\\n18 #Evaluating the pure Numpy version results in:\\n19 > BetaSym.subs({theta:0.5,a:2,b:7})=0.4375\\nFIGURE 5.32: Beta distribution using SymPy\\nThe result is:\\nBeta(θ|a, b) = θa−1Γ(a + b)\\nΓ(a)Γ(b) (−θ + 1)b−1 (5.79)\\n3. The plot is depicted in 5.33.\\n1775.3. SOLUTIONS\\n1 %pylab inline\\n2 mus = arange(0,1,.01)\\n3 # Plot for various values of a and b\\n4 for ab in [(.1,.1),(.5,.5),(2,20),(2,3), ( 1,1)]:\\n5 plot(mus, vectorize(BetaLambda)(mus, *ab), label =\"a=%s b=%s\" % ab)\\n6 legend(loc=0)\\n7 xlabel(r\"$\\\\theta$\", size =22)\\nFIGURE 5.33: A plot of the Beta distribution\\n4. We can ﬁnd the posterior distribution by multiplying our Beta prior by the Binomial\\nLikelihood.\\n178Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 BetaBinSym=BetaSym * binomSym\\n4 # Turn Beta-bin into a function\\n5 BetaBinLambda = sp.Lambda((theta,a,b,n,r), BetaBinSym)\\n6 BetaBinSym=BetaBinSym.powsimp()\\n7 display(BetaBinSym)\\n8 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) \\\\times\\n\\\\operatorname{Bin}(r|n,\\\\theta) \\\\propto %s\" %\\nsp.latex(BetaBinSym))\\n↪→\\n↪→\\n9 > BetaBinSym.subs({theta:0.5,a:2,b:7,n:10,r:3})= 0.051269\\n10 > BetaBinLambda ( 0.5,2,7, 10,3)= 0.051269\\nFIGURE 5.34: A plot of the Beta distribution\\nThe result is:\\nBeta(θ|a, b) × Bin(r|n, θ) ∝\\nθa+r−1 (−θ + 1)b+n−r−1 n!\\nr! (n − r)!Γ(a)Γ(b) Γ(a + b)\\nSo the posterior distribution has the same functional dependence on θ as the prior, it is\\njust another Beta distribution.\\n5. Mathematically, the relationship is as follows:\\n1795.3. SOLUTIONS\\nPrior :\\nBeta(θ|a = 2, b = 7)\\n= 56θ (−θ + 1)6\\nLikelihood :\\nBin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47\\nPosterior(normalised) :\\nBeta(θ|2, 7) × Bin(3|50, θ) = 1097600 θ4 (−θ + 1)53\\n(5.80)\\n180Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 prior = BetaLambda(theta,2,7)\\n2 maths(\"\\\\mathbf{Prior}:\\\\operatorname{Beta}(\\\\theta|a=2,b=7) = %s\" %\\nsp.latex(prior))↪→\\n3 likelihood = binomLambda(theta,3,50) # = binomLambda(0.5,3,10)\\n4 maths(\"\\\\mathbf{Likelihood}: \\\\operatorname{Bin}(r=3|n=6, \\\\theta) =\\n%s\" % sp.latex(likelihood))↪→\\n5 posterior = prior * likelihood\\n6 posterior=posterior.powsimp()\\n7 maths(r\"\\\\mathbf{Posterior\\n(normalised)}:\\\\operatorname{Beta}(\\\\theta|2,7) \\\\times\\n\\\\operatorname{Bin}(3|50,\\\\theta)=%s\"\\n↪→\\n↪→\\n8 posterior.subs({theta:0.5})\\n9 plt.plot(mus, (sp .lambdify(theta,posterior))(mus), \\'r\\' )\\n10 xlabel(\"$\\\\\\\\theta$\", size =22)\\nFIGURE 5.35: A plot of the Posterior with the provided data samples.\\n\\x04\\nReferences\\n[1] J. Bradbury et al. JAX: composable transformations of NumPy programs. 2018 (cit. on\\npp. 123, 136).\\n181REFERENCES\\n[2] W. K. Clifford. ‘Preliminary Sketch of Bi-quaternions’. In: Proceedings of the Lon-\\ndon Mathematical Society 4 (1873), pp. 381–95 (cit. on pp. 125, 139).\\n[3] R. Frostig et al. JAX: Autograd and XLA . 2018 (cit. on p. 123).\\n[4] A. Griewank, D. Juedes and J. Utke. ‘Algorithm 755; ADOL-C: a package for the\\nautomatic differentiation of algorithms written in C/C++’. In: ACM T ransactions\\non Mathematical Software 22.2 (June 1996), pp. 131–167 (cit. on pp. 123, 125).\\n[5] A. Griewank and A. Walther. Evaluating Derivatives: Principles and T echniques\\nof Algorithmic Differentiation . Second. USA: Society for Industrial and Applied\\nMathematics, 2008 (cit. on pp. 123, 124).\\n[6] K. Gurney. An Introduction to Neural Networks . 1 Gunpowder Square, London\\nEC4A 3DE, UK: UCL Press, 1998 (cit. on p. 135).\\n[7] L. V . Kantorovich. ‘On a mathematical symbolism convenient for performing\\nmachine calculations’. In: Dokl. Akad. Nauk SSSR . V ol. 113. 4. 1957, pp. 738–741\\n(cit. on p. 123).\\n[8] G. Kedem. ‘Automatic differentiation of computer programs’. In: ACM T ransac-\\ntions on Mathematical Software (TOMS) 6.2 (1980), pp. 150–165 (cit. on pp. 126,\\n149).\\n[9] S. Laue. On the Equivalence of Forward Mode Automatic Differentiation and Symbolic\\nDifferentiation. 2019. arXiv: 1904.02990 [cs.SC] (cit. on p. 124).\\n[10] D. Maclaurin, D. Duvenaud and R. P . Adams. ‘Autograd: Effortless gradients in\\nnumpy’. In: ICML 2015 AutoML Workshop . V ol. 238. 2015 (cit. on pp. 123, 136).\\n[11] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: (2017) (cit. on p. 136).\\n[12] D. Rumelhart, G. Hinton and R. Williams. ‘Learning representations by back\\npropagating errors’. In: Nature 323 (1986), pp. 533–536 (cit. on p. 135).\\n[13] B. Speelpenning. Compiling fast partial derivatives of functions given by algorithms .\\nTech. rep. Illinois Univ Urbana Dept of Computer Science, 1980 (cit. on p. 126).\\n182BACHELORS\\nPART IVCHAPTER\\n6\\nDEEP LEARNING: NN ENSEMBLES\\nThe saddest aspect of life right now is that gathers knowledge faster than society\\ngathers wisdom.\\n— Isaac Asimov\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 2026.1. INTRODUCTION\\n6.1 Introduction\\nI\\nNtuition and practice demonstrate that a poor or an inferior choice may\\nbe altogether prevented merely by motivating a group (or an ensemble)\\nof people with diverse perspectives to make a mutually acceptable choice.\\nLikewise, in many cases, neural network ensembles signiﬁcantly improve\\nthe generalization ability of single-model based AI systems [ 5, 11]. Shortly follow-\\ning the foundation of Kaggle, research in the ﬁeld had started blooming; not only\\nbecause researchers are advocating and using advanced ensembling approaches in\\nalmost every competition, but also by the empirical success of the top winning mod-\\nels. Though the whole process of training ensembles typically involves the utilization\\nof dozens of GPUs and prolonged training periods, ensembling approaches enhance\\nthe predictive power of a single model. Though ensembling obviously has a signiﬁc-\\nant impact on the performance of AI systems in general, research shows its effect is\\nparticularly dramatic in the ﬁeld of neural networks [ Russakovsky_2015, 1, 4, 7, 13].\\nTherefore, while we could examine combinations of any type of learning algorithms,\\nthe focus of this chapter is the combination of neural networks.\\n6.2 Problems\\n6.2.1 Bagging, Boosting and Stacking\\nPRB-135 \\uf059 CH.PRB- 6.1.\\nMark all the approaches which can be utilized to boost a single model performance:\\n(i) Majority Voting\\n(ii) Using K-identical base-learning algorithms\\n(iii) Using K-different base-learning algorithms\\n(iv) Using K-different data-folds\\n(v) Using K-different random number seeds\\n(vi) A combination of all the above approaches\\n186Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nPRB-136 \\uf059 CH.PRB- 6.2.\\nAn argument erupts between two senior data-scientists regarding the choice of an ap-\\nproach for training of a very small medical corpus. One suggest that bagging is superior\\nwhile the other suggests stacking. Which technique, bagging or stacking, in your opinion is\\nsuperior? Explain in detail.\\n(i) Stacking since each classier is trained on all of the available data.\\n(ii) Bagging since we can combine as many classiﬁers as we want by training each on a\\ndifferent sub-set of the training corpus.\\nPRB-137 \\uf059 CH.PRB- 6.3.\\nComplete the sentence: A random forest is a type of a decision tree which utilizes [bag-\\nging/boosting]\\nPRB-138 \\uf059 CH.PRB- 6.4.\\nThe algorithm depicted in Fig. 6.1 was found in an old book about ensembling. Name the\\nalgorithm.\\n1876.2. PROBLEMS\\nAlgorithm 1: Algo 1\\nData: A set of training data, Q with N elements has been established\\nwhile K times do\\nCreate a random subset of N ′ data by sampling from Q containing the N\\nsamples;\\nN ′ < N ;\\nExecute algorithm Algo 2;\\nReturn all N ′ back to Q\\nAlgorithm 2: Algo 2\\nChoose a learner hm;\\nwhile K times do\\nPick a training set and train with hm;\\nFIGURE 6.1: A speciﬁc ensembling approach\\nPRB-139 \\uf059 CH.PRB- 6.5.\\nFig. 6.2 depicts a part of a speciﬁc ensembling approach applied to the models x1, x2...xk.\\nIn your opinion, which approach is being utilized?\\nGenerelizerx3\\nx2\\nx1\\n...\\nxk\\nBase Learners\\nf\\n?\\nFIGURE 6.2: A speciﬁc ensembling approach\\n(i) Bootstrap aggregation\\n(ii) Snapshot ensembling\\n(iii) Stacking\\n188Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n(iv) Classical committee machines\\nPRB-140 \\uf059 CH.PRB- 6.6.\\nConsider training corpus consisting of balls which are glued together as triangles, each\\nof which has either 1, 3, 6, 10, 15, 21, 28, 36, or 45 balls.\\n1. We draw several samples from this corpus as presented in Fig. 6.3 wherein each sample\\nis equiprobable. What type of sampling approach is being utilized here?\\nFIGURE 6.3: Sampling approaches\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n2. Two samples are drawn one after the other. In which of the following cases is the\\ncovariance between the two samples equals zero?\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n3. During training, the corpus sampled with replacement and is divided into several\\nfolds as presented in Fig. 6.4.\\nT1:\\nT2:\\nT3:\\nT4:\\nFIGURE 6.4: Sampling approaches\\n1896.2. PROBLEMS\\nIf 10 balls glued together is a sample event that we know is hard to correctly classify,\\nthen it is impossible that we are using:\\n(i) Bagging\\n(ii) Boosting\\n6.2.2 Approaches for Combining Predictors\\nPRB-141 \\uf059 CH.PRB- 6.7.\\nThere are several methods by which the outputs of base classiﬁers can be combined to\\nyield a single prediction. Fig. 6.5 depicts part of a speciﬁc ensembling approach applied to\\nseveral CNN model predictions for a labelled data-set. Which approach is being utilized?\\n(i) Majority voting for binary classiﬁcation\\n(ii) Weighted majority voting for binary classiﬁcation\\n(iii) Majority voting for class probabilities\\n(iv) Weighted majority class probabilities\\n(v) An algebraic weighted average for class probabilities\\n(vi) An adaptive weighted majority voting for combining multiple classiﬁers\\n190Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 l = []\\n2 for i,f in enumerate(filelist):\\n3 temp = pd.read_csv(f)\\n4 l.append(temp)\\n5 arr = np.stack(l,axis=-1)\\n6 avg_results = pd.DataFrame(arr[:,:-1,:].mean(axis=2))\\n7 avg_results[\\'image\\' ] = l[0][\\'image\\' ]\\n8 avg_results.columns = l[0].columns\\nFIGURE 6.5: PyTorch code snippet for an ensemble\\nPRB-142 \\uf059 CH.PRB- 6.8.\\nRead the paper Neural Network Ensembles [3] and then complete the sentence: If the\\naverage error rate for a speciﬁc instance in the corpus is less than [...]% and the respective\\nclassiﬁers in the ensemble produce independent [...], then when the number of classiﬁers\\ncombined approaches inﬁnity, the expected error can be diminished to zero.\\nPRB-143 \\uf059 CH.PRB- 6.9.\\nTrue or false: A perfect ensemble comprises of highly correct classiﬁers that differ as\\nmuch as possible.\\nPRB-144 \\uf059 CH.PRB- 6.10.\\nTrue or false: In bagging, we re-sample the training corpus with replacement and there-\\nfore this may lead to some instances being represented numerous times while other instances\\nnot to be represented at all.\\n6.2.3 Monolithic and Heterogeneous Ensembling\\nPRB-145 \\uf059 CH.PRB- 6.11.\\n1916.2. PROBLEMS\\n1. True or false: T raining an ensemble of a single monolithic architecture results in\\nlower model diversity and possibly decreased model prediction accuracy.\\n2. True or false: The generalization accuracy of an ensemble increases with the number\\nof well-trained models it consists of.\\n3. True or false: Bootstrap aggregation (or bagging), refers to a process wherein a CNN\\nensemble is being trained using a random subset of the training corpus.\\n4. True or false: Bagging assumes that if the single predictors have independent errors,\\nthen a majority vote of their outputs should be better than the individual predictions.\\nPRB-146 \\uf059 CH.PRB- 6.12.\\nRefer to the papers: Dropout as a Bayesian Approximation [2] and Can Y ou Trust\\nY our Model’s Uncertainty? [12] and answer the following question: Do deep ensembles\\nachieve a better performance on out-of-distribution uncertainty benchmarks compared with\\nMonte-Carlo (MC)-dropout?\\nPRB-147 \\uf059 CH.PRB- 6.13.\\n1. In a transfer-learning experiment conducted by a researcher, a number of ImageNet-\\npretrained CNN classiﬁers, selected from T able 6.1 are trained on ﬁve different folds\\ndrawn from the same corpus. Their outputs are fused together producing a composite\\nmachine. Ensembles of these convolutional neural networks architectures have been\\nextensively studies an evaluated in various ensembling approaches [ 4, 9]. Is it likely\\nthat the composite machine will produce a prediction with higher accuracy than that\\nof any individual classiﬁer? Explain why.\\n192Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nCNN Model Classes Image Size Top-1 accuracy\\nResNet152 1000 224 78.428\\nDPN98 1000 224 79.224\\nSeNet154 1000 224 81.304\\nSeResneXT101 1000 224 80.236\\nDenseNet161 1000 224 77.560\\nInceptionV4 1000 299 80.062\\nTABLE 6.1: ImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches.\\n2. True or False: In a classiﬁcation task, the result of ensembling is always superior.\\n3. True or False: In an ensemble, we want differently trained models converge to differ-\\nent local minima.\\nPRB-148 \\uf059 CH.PRB- 6.14.\\nIn committee machines, mark all the combiners that do not make direct use of the input:\\n(i) A mixture of experts\\n(ii) Bagging\\n(iii) Ensemble averaging\\n(iv) Boosting\\nPRB-149 \\uf059 CH.PRB- 6.15.\\nTrue or False: Considering a binary classiﬁcation problem ( y = 0 or y = 1 ), ensemble\\naveraging, wherein the outputs of individual models are linearly combined to produce a fused\\noutput is a form of a static committee machine.\\n1936.2. PROBLEMS\\nMn\\nM2\\nM1\\n∑\\nwn\\nw2\\nw1\\n0\\n1\\n0\\n1\\nFIGURE 6.6: A typical binary classiﬁcation problem.\\nPRB-150 \\uf059 CH.PRB- 6.16.\\nTrue or false: When using a single model, the risk of overﬁtting the data increases when\\nthe number of adjustable parameters is large compared to cardinality (i.e., size of the set) of\\nthe training corpus.\\nPRB-151 \\uf059 CH.PRB- 6.17.\\nTrue or false:If we have a committee of K trained models and the errors are uncorrelated,\\nthen by averaging them the average error of a model is reduced by a factor of K.\\n6.2.4 Ensemble Learning\\nPRB-152 \\uf059 CH.PRB- 6.18.\\n1. Deﬁne ensemble learning in the context of machine learning.\\n2. Provide examples of ensemble methods in classical machine-learning.\\n3. True or false: Ensemble methods usually have stronger generalization ability.\\n4. Complete the sentence: Bagging is variance/bias reduction scheme while boosting\\nreduced variance/bias.\\n194Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n6.2.5 Snapshot Ensembling\\nPRB-153 \\uf059 CH.PRB- 6.19.\\nY our colleague, a well-known expert in ensembling methods, writes the following pseudo\\ncode in Python shown in Fig. 6.7 for the training of a neural network. This runs inside a\\nstandard loop in each training and validation step.\\n1 import torchvision.models as models\\n2 ...\\n3 models = [\\'resnext\\' ]\\n4 for m in models:\\n5 train ...\\n6 compute VAL loss ...\\n7 amend LR ...\\n8 if (val_acc > 90.0):\\n9 saveModel()\\nFIGURE 6.7: PyTorch code snippet for an ensemble\\n1. What type of ensembling can be used with this approach? Explain in detail.\\n2. What is the main advantage of snapshot ensembling? What are the disadvantages, if\\nany?\\nPRB-154 \\uf059 CH.PRB- 6.20.\\nAssume further that your colleague amends the code as follows in Fig. 6.8.\\n1956.2. PROBLEMS\\n1 import torchvision.models as models\\n2 import random\\n3 import np\\n4 ...\\n5 models = [\\'resnext\\' ]\\n6 for m in models:\\n7 train ...\\n8 compute loss ...\\n9 amend LR ...\\n10 manualSeed= draw a new random number\\n11 random.seed(manualSeed)\\n12 np.random.seed(manualSeed)\\n13 torch.manual_seed(manualSeed)\\n14 if (val_acc > 90.0):\\n15 saveModel()\\nFIGURE 6.8: PyTorch code snippet for an ensemble\\nExplain in detail what would be the possible effects of adding lines 10-13.\\n6.2.6 Multi-model Ensembling\\nPRB-155 \\uf059 CH.PRB- 6.21.\\n1. Assume your colleague, a veteran in DL and an expert in ensembling methods writes\\nthe following Pseudo code shown in Fig. 6.9 for the training of several neural networks.\\nThis code snippet is executed inside a standard loop in each and every training/valida-\\ntion epoch.\\n196Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 import torchvision.models as models\\n2 ...\\n3 models = [\\'resnext\\' ,\\'vgg\\' ,\\'dense\\' ]\\n4 for m in models:\\n5 train ...\\n6 compute loss /acc ...\\n7 if (val_acc > 90.0):\\n8 saveModel()\\nFIGURE 6.9: PyTorch code snippet for an ensemble\\nWhat type of ensembling is being utilized in this approach? Explain in detail.\\n2. Name one method by which NN models may be combined to yield a single prediction.\\n6.2.7 Learning-rate Schedules in Ensembling\\nPRB-156 \\uf059 CH.PRB- 6.22.\\n1. Referring to Fig. ( 6.10) which depicts a speciﬁc learning rate schedule, describe the\\nbasic notion behind its mechanism.\\n1976.3. SOLUTIONS\\n1\\n0,5\\n1\\nx\\ny\\nFIGURE 6.10: A learning rate schedule.\\n2. Explain how cyclic learning rates [10] can be effective for the training of convolutional\\nneural networks such as the ones in the code snippet of Fig. 6.10.\\n3. Explain how a cyclic cosine annealing schedule as proposed by Loshchilov [ 10] and\\n[13] is used to converge to multiple local minima.\\n6.3 Solutions\\n6.3.1 Bagging, Boosting and Stacking\\nSOL-135 \\uf14b CH.SOL- 6.1.\\nAll the presented options are correct. \\x04\\nSOL-136 \\uf14b CH.SOL- 6.2.\\nThe correct choice would be stacking. In cases where the given corpus is small, we would\\nmost likely prefer training our models on the full data-set. \\x04\\nSOL-137 \\uf14b CH.SOL- 6.3.\\nA random forest is a type of a decision tree which utilizes bagging. \\x04\\n198Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-138 \\uf14b CH.SOL- 6.4.\\nThe presented algorithm is a classic bagging. \\x04\\nSOL-139 \\uf14b CH.SOL- 6.5.\\nThe approach which is depicted is the ﬁrst phase of stacking. In stacking, we ﬁrst (phase\\n0) predict using several base learners and then use a generalizer (phase 1) that learns on top\\nof the base learners predictions. \\x04\\nSOL-140 \\uf14b CH.SOL- 6.6.\\n1. Sampling with replacement\\n2. Sampling without replacement\\n3. This may be mostly a result of bagging, since in boosting we would have expected miss-\\ncorrectly classiﬁed observations to repeatedly appear in subsequent samples.\\n\\x04\\n6.3.2 Approaches for Combining Predictors\\nSOL-141 \\uf14b CH.SOL- 6.7.\\nAn Algebraic weighted average for class probabilities. \\x04\\nSOL-142 \\uf14b CH.SOL- 6.8.\\nThis is true, [ 3] provides a mathematical proof. \\x04\\nSOL-143 \\uf14b CH.SOL- 6.9.\\nThis is true. For extension, see instance [ 8]. \\x04\\nSOL-144 \\uf14b CH.SOL- 6.10.\\nThis is true. In a bagging approach, we ﬁrst randomly draw (with replacement), K ex-\\n1996.3. SOLUTIONS\\namples where K is the size of the original training corpus therefore leading to an imbalanced\\nrepresentation of the instances. \\x04\\n6.3.3 Monolithic and Heterogeneous Ensembling\\nSOL-145 \\uf14b CH.SOL- 6.11.\\n1. True Due to their lack of diversity, an ensemble of monolithic architectures tends to\\nperform worse than an heterogeneous ensemble.\\n2. True This has be consistently demonstrated in [ 11, 5].\\n3. True In [6] there is a discussion about both using the whole corpus and a subset much\\nlike in bagging.\\n4. True The total error decreases with the addition of predictors to the ensemble.\\n\\x04\\nSOL-146 \\uf14b CH.SOL- 6.12.\\nY es, they do. \\x04\\nSOL-147 \\uf14b CH.SOL- 6.13.\\n1. Y es, it is very likely, especially if their errors are independent.\\n2. True It may be proven that ensembles of models perform at least as good as each of the\\nensemble members it consists of.\\n3. True Different local minima add to the diversiﬁcation of the models.\\n\\x04\\nSOL-148 \\uf14b CH.SOL- 6.14.\\nBoosting is the only one that does not. \\x04\\n200Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-149 \\uf14b CH.SOL- 6.15.\\nFalse By deﬁnition, static committee machines use only the output of the single predict-\\nors. \\x04\\nSOL-150 \\uf14b CH.SOL- 6.16.\\nTrue \\x04\\nSOL-151 \\uf14b CH.SOL- 6.17.\\nFalse Though this may be theoretically true, in practice the errors are rarely uncorrelated\\nand therefore the actual error can not be reduced by a factor of K. \\x04\\n6.3.4 Ensemble Learning\\nSOL-152 \\uf14b CH.SOL- 6.18.\\n1. Ensemble learning is an excellent machine learning idea which displays noticeable bene-\\nﬁts in many applications, one such notable example is the widespread use of ensembles\\nin Kaggle competitions. In an ensemble several individual models (for instance Res-\\nNet18 and VGG16) which were trained on the same corpus, work in tandem and during\\ninference, their predictions are fused by a pre-deﬁned strategy to yield a single predic-\\ntion.\\n2. In classical machine learning Ensemble methods usually refer to bagging, boosting and\\nthe linear combination of regression or classiﬁcation models.\\n3. True The stronger generalization ability stems from the voting power of diverse models\\nwhich are joined together.\\n4. Bagging is variance reduction scheme while boosting reduced bias.\\n\\x04\\n6.3.5 Snapshot Ensembling\\n2016.3. SOLUTIONS\\nSOL-153 \\uf14b CH.SOL- 6.19.\\n1. Since only a single model ie being utilized, this type of ensembling is known as snap-\\nshot ensembling. Using this approach, during the training of a neural network and\\nin each epoch, a snapshot, e.g. the weights of a trained instance of a model (a PTH\\nﬁle in PyT orch nomenclature) are persisted into permanent storage whenever a certain\\nperformance metrics, such as accuracy or loss is being surpassed. Therefore the name\\n“snapshot”; weights of the neural network are being snapshot at speciﬁc instances in\\ntime. After several such epochs the top-5 performing Snapshots which converged to\\nlocal minima [4] are combined as part of an ensemble to yield a single prediction.\\n2. Advantages: during a single training cycle, many model instances may be collected.\\nDisadvantages: inherent lack of diversity by virtue of the fact that the same models is\\nbeing repeatedly used.\\n\\x04\\nSOL-154 \\uf14b CH.SOL- 6.20.\\nChanging the random seed at each iteration/epoch, helps in introducing variation which\\nmay contribute to diversifying the trained neural network models. \\x04\\n6.3.6 Multi-model Ensembling\\nSOL-155 \\uf14b CH.SOL- 6.21.\\n1. Multi-model ensembling.\\n2. Both averaging and majority voting.\\n\\x04\\n6.3.7 Learning-rate Schedules in Ensembling\\nSOL-156 \\uf14b CH.SOL- 6.22.\\n202Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1. Capturing the best model of each training cycle allows to obtain multiple models settled\\non various local optima from cycle to cycle at the cost of training a single mode\\n2. The approach is based on the non-convex nature of neural networks and the ability to\\nconverge and escape from local minima using a speciﬁc schedule to adjust the learning\\nrate during training.\\n3. Instead of monotonically decreasing the learning rate, this method lets the learning rate\\ncyclically vary between reasonable boundary values.\\n\\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 186).\\n[2] Y . Gal and Z. Ghahramani. ‘Dropout as a Bayesian approximation’. In: arXiv\\npreprint arXiv:1506.02157 (2015) (cit. on p. 192).\\n[3] L. K. Hansen and P . Salamon. ‘Neural Network Ensembles’. In: IEEE T rans. Pat-\\ntern Anal. Mach. Intell. 12 (1990), pp. 993–1001 (cit. on pp. 191, 199).\\n[4] G. Huang et al. ‘Snapshot ensembles: Train 1, get M for free. arXiv 2017’. In:\\narXiv preprint arXiv:1704.00109 () (cit. on pp. 186, 192, 202).\\n[5] J. Huggins, T. Campbell and T. Broderick. ‘Coresets for scalable Bayesian logistic\\nregression’. In: Advances in Neural Information Processing Systems . 2016, pp. 4080–\\n4088 (cit. on pp. 186, 200).\\n[6] C. Ju, A. Bibaut and M. van der Laan. ‘The relative performance of ensemble\\nmethods with deep convolutional neural networks for image classiﬁcation’. In:\\nJournal of Applied Statistics 45.15 (2018), pp. 2800–2818 (cit. on p. 200).\\n[7] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on p. 186).\\n[8] A. Krogh and J. V edelsby. ‘Neural Network Ensembles, Cross Validation, and\\nActive Learning’. In: NIPS. 1994 (cit. on p. 199).\\n[9] S. Lee et al. ‘Stochastic multiple choice learning for training diverse deep en-\\nsembles’. In: Advances in Neural Information Processing Systems . 2016, pp. 2119–\\n2127 (cit. on p. 192).\\n203REFERENCES\\n[10] I. Loshchilov and F. Hutter. ‘Sgdr: Stochastic gradient descent with warm re-\\nstarts’. In: arXiv preprint arXiv:1608.03983 (2016) (cit. on p. 198).\\n[11] P . Oshiro et al.(2012)Oshiro and Baranauskas. ‘How many trees in a random\\nforest?’ In: International Workshop on Machine Learning and Data Mining in Pattern\\nRecognition. 2012 (cit. on pp. 186, 200).\\n[12] Y . Ovadia et al. ‘Can you trust your model’s uncertainty? Evaluating predict-\\nive uncertainty under dataset shift’. In: Advances in Neural Information Processing\\nSystems. 2019, p. 13991 (cit. on p. 192).\\n[13] L. N. Smith. ‘Cyclical learning rates for training neural networks’. In: 2017 IEEE\\nWinter Conference on Applications of Computer Vision (WACV). IEEE. 2017, pp. 464–\\n472 (cit. on pp. 186, 198).\\n204CHAPTER\\n7\\nDEEP LEARNING: CNN FEATURE EXTRACTION\\nWhat goes up must come down.\\n— Isaac Newton\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\\nNeural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\n7.1 Introduction\\nT\\nHE extraction of an n-dimensional feature vector (FV) or an embedding from\\none (or more) layers of a pre-trained CNN, is termed feature extraction (FE).\\nUsually , FE works by ﬁrst removing the last fully connected (FC) layer from\\na CNN and then treating the remaining layers of the CNN as a ﬁxed FE. As\\nexempliﬁed in Fig. ( 7.1) and Fig. ( 7.2), applying this method to the ResNet34 archi-\\ntecture, the resulting FV consists of 512 ﬂoating point values. Likewise, applying the\\nsame logic on the ResNet152 architecture, the resulting FV has 2048 ﬂoating point ele-\\nments.7.2. PROBLEMS\\n1 2 3 4 · · · k = 512\\nA ﬁxed k-element FV .\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nActual values of a normalized k-element FV .\\nFIGURE 7.1: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depicted is\\nthe ResNet CNN architecture with 34 layers.\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.2: PyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed).\\nThe premise behind FE is that CNNs which were originally trained on the Im-\\nageNet Large Scale Visual Recognition Competition [ 7], can be adapted and used (for\\ninstance in a classiﬁcation task) on a completely different (target) domain without any\\nadditional training of the CNN layers. The power of a CNN to do so lies in its ability\\nto generalize well beyond the original data-set it was trained on, therefore FE on a\\nnew target data-set involves no training and requires only inference.\\n7.2 Problems\\n7.2.1 CNN as Fixed Feature Extractor\\nBefore attempting the problems in this chapter you are highly encouraged to read the\\nfollowing papers [ 1, 3, 7]. In many DL job interviews, you will be presented with a\\npaper you have never seen before and subsequently be asked questions about it; so\\nreading these references would be an excellent simulation of this real-life task.\\n206Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-157 \\uf059 CH.PRB- 7.1.\\nTrue or False: While AlexNet [ 4] used 11 × 11 sized ﬁlters, the main novelty presented\\nin the VGG [ 8] architecture was utilizing ﬁlters with much smaller spatial extent, sized\\n3 × 3.\\nPRB-158 \\uf059 CH.PRB- 7.2.\\nTrue or False : Unlike CNN architectures such as AlexNet or VGG, ResNet does not\\nhave any hidden FC layers.\\nPRB-159 \\uf059 CH.PRB- 7.3.\\nAssuming the VGG-Net has 138, 357, 544 ﬂoating point parameters, what is the phys-\\nical size in Mega-Bytes (MB) required for persisting a trained instance of VGG-Net on\\npermanent storage?\\nPRB-160 \\uf059 CH.PRB- 7.4.\\nTrue or False : Most attempts at researching image representation using FE, focused\\nsolely on reusing the activations obtained from layers close to the output of the CNN, and\\nmore speciﬁcally the fully-connected layers.\\nPRB-161 \\uf059 CH.PRB- 7.5.\\nTrue or False: FE in the context of deep learning is particularly useful when the target\\nproblem does not include enough labeled data to successfully train CNN that generalizes\\nwell.\\nPRB-162 \\uf059 CH.PRB- 7.6.\\nWhy is a CNN trained on the ImageNet dataset [ 7] a good candidate for a source prob-\\nlem?\\nPRB-163 \\uf059 CH.PRB- 7.7.\\n2077.2. PROBLEMS\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of [...] layers.\\n2. It consists of [...] convolutional and 3 [...] layers.\\n3. The input image size is [...].\\n4. The number of input channels is [...].\\n5. Every image has it’s mean RGB value [subtracted / added].\\n6. Each convolutional layer has a [small/large] kernel sized [...].\\n7. The number of pixels for padding and stride is [...].\\n8. There are 5 [...] layers having a kernel size of [...] and a stride of [...] pixels.\\n9. For non-linearity a [rectiﬁed linear unit (ReLU [ 5])/sigmoid] is used.\\n10. The [...] FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of [...] features.\\n12. The last FC layer has only [...] features.\\n13. The last FC layer is terminated by a [...] activation layer.\\n14. Dropout [is / is not] being used between the FC layers.\\nPRB-164 \\uf059 CH.PRB- 7.8.\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture [ 8] for the classiﬁcation of pancreatic cancer. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with\\nit by utilizing the same logic. In Fig. ( 9.7) three different classes of pancreatic cancer are\\ndisplayed: A, B and C, curated from a dataset of 4K Whole Slide Images (WSI) labeled by\\na board certiﬁed pathologist. Y our task is to use FE to correctly classify the images in the\\ndataset.\\n208Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nFIGURE 7.3: A dataset of 4K histopathology WSI from three severity classes: A, B and C.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture [ 8]. As de-\\npicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters),\\nlearnable parameters (weights,biases), and FV size are presented.\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 7.1: Incomplete listing of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4K images from the dataset, how can\\nyou now classify the images into their respective categories?\\n2097.2. PROBLEMS\\nPRB-165 \\uf059 CH.PRB- 7.9.\\nStill referring to T able ( 9.3), a data scientist suggests using the output layer of the\\nVGG19 CNN as a ﬁxed FE. What is the main advantage of using this layer over using\\nfor instance, the f c7 layer? (Hint: think about an ensemble of feature extractors)\\nPRB-166 \\uf059 CH.PRB- 7.10.\\nStill referring to T able (9.3) and also to the code snippet in Fig. ( 7.4), which represents a\\nnew CNN derived from the VGG19 CNN:\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=[???])\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = [???]\\n11 self.classifier = torch.nn.Sequential([???])\\n12 self.num_feats = [???]\\n13\\n14 def forward(self, x):\\n15 f = self.features(x)\\n16 f = f.view(f.size(0), -1)\\n17 f = [???]\\n18 print (f.data.size())\\n19 return f\\nFIGURE 7.4: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n210Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. Complete line 6; what should be the value of pretrained ?\\n2. Complete line 10; what should be the value of self.features ?\\n3. Complete line 12; what should be the value of self.num_feats ?\\n4. Complete line 17; what should be the value of f ?\\nPRB-167 \\uf059 CH.PRB- 7.11.\\nWe are still referring to T able ( 9.3) and using the skeleton code provided in Fig. ( 7.5)\\nto derive a new CNN entitled ResNetBottom from the ResNet34 CNN, to extract a 512-\\ndimensional FV for a given input image. Complete the code as follows:\\n1. The value of self.features in line 7.\\n2. The forward method in line 11.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7\\n8 def forward(self, x):\\n9 x = [???]\\n10 x = x.view(x.size(0), -1)\\n11 return x\\nFIGURE 7.5: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\n2117.2. PROBLEMS\\nPRB-168 \\uf059 CH.PRB- 7.12.\\nStill referring to T able (9.3), the PyT orch based pseudo code snippet in Fig. (7.6) returns\\nthe 512-dimensional FV from the modiﬁed ResNet34 CNN, given a 3-channel RGB image\\nas an input.\\n1 import torchvision.models as models\\n2 from torchvision import transforms\\n3 ...\\n4\\n5 test_trans = transforms.Compose([\\n6 transforms.Resize(imgnet_size),\\n7 transforms.ToTensor(),\\n8 transforms.Normalize([0.485, 0.456, 0.406],\\n9 [0.229, 0.224, 0.225])])\\n10\\n11 def ResNet34FE(image, model):\\n12 f=None\\n13 image = test_trans(image)\\n14 image = Variable(image, requires_grad =False).cuda()\\n15 image= image.cuda()\\n16 f = model(image)\\n17 f = f.view(f.size(1), -1)\\n18 print (\"Size : {}\" .format(f.shape))\\n19 f = f.view(f.size(1),-1)\\n20 print (\"Size : {}\" .format(f.shape))\\n21 f =f.cpu().detach().numpy()[0]\\n22 print (\"Size : {}\" .format(f.shape))\\n23 return f\\nFIGURE 7.6: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\nAnswer the following questions regarding the code in Fig. ( 7.6):\\n212Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. What is the purpose of test_trans in line 5?\\n2. Why is the parameter requires_grad set to False in line 14?\\n3. What is the purpose of f.cpu() in line 23?\\n4. What is the purpose of detach() in line 23?\\n5. What is the purpose of numpy()[0] in line 23?\\n7.2.2 Fine-tuning CNNs\\nPRB-169 \\uf059 CH.PRB- 7.13.\\nDeﬁne the term ﬁne-tuning (FT) of an ImageNet pre-trained CNN .\\nPRB-170 \\uf059 CH.PRB- 7.14.\\nDescribe three different methods by which one can ﬁne-tune an ImageNet pre-trained\\nCNN.\\nPRB-171 \\uf059 CH.PRB- 7.15.\\nMelanoma is a lethal form of malignant skin cancer, frequently misdiagnosed as a benign\\nskin lesion or even left completely undiagnosed.\\nIn the United States alone, melanoma accounts for an estimated 6, 750 deaths per annum\\n[6]. With a 5-year survival rate of 98%, early diagnosis and treatment is now more likely\\nand possibly the most suitable means for melanoma related death reduction. Dermoscopy\\nimages, shown in Fig. ( 7.7) are widely used in the detection and diagnosis of skin lesions.\\nDermatologists, relying on personal experience, are involved in a laborious task of manually\\nsearching dermoscopy images for lesions.\\nTherefore, there is a very real need for automated analysis tools, providing assistance to\\nclinicians screening for skin metastases. In this question, you are tasked with addressing\\nsome of the fundamental issues DL researchers face when building deep learning pipelines.\\nAs suggested in [ 3], you are going to use ImageNet pre-trained CNN to resolve a classiﬁca-\\ntion task.\\n2137.2. PROBLEMS\\nFIGURE 7.7: Skin lesion categories. An exemplary visualization of melanoma.\\n1. Given that the skin lesions fall into seven distinct categories, and you are training us-\\ning cross-entropy loss, how should the classes be represented so that a typical PyT orch\\ntraining loop will successfully converge?\\n2. Suggest several data augmentation techniques to augment the data.\\n3. Write a code snippet in PyT orch to adapt the CNN so that it can predict 7 classes\\ninstead of the original source size of 1000.\\n4. In order to ﬁne tune our CNN, the (original) output layer with 1000 classes was\\nremoved and the CNN was adjusted so that the (new) classiﬁcation layer comprised\\nseven softmax neurons emitting posterior probabilities of class membership for each\\nlesion type.\\n7.2.3 Neural style transfer, NST\\nBefore attempting the problems in the section, you are strongly recommended to read\\nthe paper: “A Neural Algorithm of Artistic Style ” [2].\\nPRB-172 \\uf059 CH.PRB- 7.16.\\nBrieﬂy describe how neural style transfer (NST) [ 2] works.\\nPRB-173 \\uf059 CH.PRB- 7.17.\\nComplete the sentence : When using the VGG-19 CNN [ 8] for neural-style transfer,\\nthere different images are involved. Namely they are: [...], [...] and [...].\\n214Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-174 \\uf059 CH.PRB- 7.18.\\nRefer to Fig. 7.8 and answer the following questions:\\nFIGURE 7.8: Artistic style transfer using the style of Francis Picabia’s Udnie painting.\\n1. Which loss is being utilized during the training process?\\n2. Brieﬂy describe the use of activations in the training process.\\nPRB-175 \\uf059 CH.PRB- 7.19.\\nStill referring to Fig. 7.8:\\n1. How are the activations utilized in comparing the content of the content image to the\\ncontent of the combined image?.\\n2. How are the activations utilized in comparing the style of the content image to the\\n2157.3. SOLUTIONS\\nstyle of the combined image?.\\nPRB-176 \\uf059 CH.PRB- 7.20.\\nStill referring to Fig. 7.8. For a new style transfer algorithm, a data scientist extracts a\\nfeature vector from an image using a pre-trained ResNet34 CNN ( 7.9).\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.9: PyTorch declaration for a pre-trained ResNet34 CNN.\\nHe then deﬁnes the cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and :\\nv = {v1, v2, . . . , vN }\\nas:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures thecosine of the angle between\\nthe vectors irrespective of their magnitude. It is calculated as the dot product of two numeric\\nvectors, and is normalized by the product of the length of the vectors.\\nAnswer the following questions:\\n1. Deﬁne the term Gram matrix.\\n2. Explain in detail how vector similarity is utilised in the calculation of the Gram mat-\\nrix during the training of NST.\\n7.3 Solutions\\n7.3.1 CNN as Fixed Feature Extractor\\n216Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nSOL-157 \\uf14b CH.SOL- 7.1.\\nT rue. The increased depth in VGG-Net was made possible using smaller ﬁlters without\\nsubstantially increasing the number of learnable parameters. Albeit an unwanted side effect\\nof the usage of smaller ﬁlters is the increase in the number of ﬁlters per-layer. \\x04\\nSOL-158 \\uf14b CH.SOL- 7.2.\\nT rue. The ResNet architecture terminates with a global average pooling layer followed\\nby a K-way FC layer with a softmax activation function, where K is the number of classes\\n(ImageNet has 1000 classes). Therefore, the ResNet has no hidden FC layers. \\x04\\nSOL-159 \\uf14b CH.SOL- 7.3. Note that 1bit = 0.000000125 MB, therefore:\\n138, 357544 × 32 = 4427441408 bits = 553.430176 MB. (7.1)\\n\\x04\\nSOL-160 \\uf14b CH.SOL- 7.4.\\nT rue. There are dozens of published papers supporting this claim. Y ou are encouraged to\\nsearch them on Arxiv or Google Scholar. \\x04\\nSOL-161 \\uf14b CH.SOL- 7.5.\\nT rue. One of the major hurdles of training a medical AI system is the lack of annotated\\ndata. Therefore, extensive research is conducted to exploit ways for FE and transfer learning,\\ne.g., in the application of ImageNet trained CNNs, to target datasets in which labeled data is\\nscarce. \\x04\\nSOL-162 \\uf14b CH.SOL- 7.6.\\nThere are two main reasons why this is possible:\\n1. The huge number of images inside the ImageNet dataset ensures a CNN model that gen-\\neralizes to additional domains, like the histopathology domain, which is substantially\\ndifferent from the original domain the model was trained one (e.g., cats and dogs).\\n2177.3. SOLUTIONS\\n2. A massive array of disparate visual patterns is produced by an ImageNet trained CNN,\\nsince it consists of 1, 000 different groups.\\n\\x04\\nSOL-163 \\uf14b CH.SOL- 7.7.\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of 19 layers.\\n2. It consists of 5 convolutional and 3 FC layers.\\n3. The input image size is 244 , the default size most ImageNet trained CNNs work on.\\n4. The number of input channels is 3 .\\n5. Every image has its mean RGB value subtracted . (why?)\\n6. Each convolutional layer has a small kernel sized 3 × 3 . (why?)\\n7. The number of pixels for padding and stride is the same and equals 1 .\\n8. There are 5 convolutional layers having a kernel size of 2 × 2 and a stride of 2 pixels.\\n9. For non-linearity a rectiﬁed linear unit (ReLU [ 5]) is used.\\n10. The 3 FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of 4096 features.\\n12. The last FC layer has only 1000 features.\\n13. The last FC layer is terminated by a softmax activation layer.\\n14. Dropout is being used between the FC layers.\\n\\x04\\nSOL-164 \\uf14b CH.SOL- 7.8.\\n218Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. One or more layers of the VGG19 CNN are selected for extraction and a new CNN\\nis designed on top of it. Thus, during inference our target layers are extracted and\\nnot the original softmax layer. Subsequently, we iterate and run inference over all\\nthe images in our pancreatic cancer data-set, extract the features, and persist them to\\npermanent storage such as a solid-state drive (SSD) device. Ultimately, each image has\\na corresponding FV .\\n2. Regarding the VGG19 CNN, there are numerous ways of extracting and combining\\nfeatures from different layers. Of course, these different layers, e.g., the FC, conv4_3,\\nand fc7 layer may be combined together to form a larger feature vector. T o determine\\nwhich method works best, you shall have to experiment on your data-set; there is no way\\nof a-priory determining the optimal combination of layers. Here are several examples:\\n(a) Accessing the last FC layer resulting in a 1000-D FV . The output is the score for\\neach of the 1000 classes of the ImageNet data-set.\\n(b) Removing the last FC layer leaves the fc7 layer, resulting in a 4096-D FV .\\n(c) Directly accessing the conv4_3 layer results in a 512-D FV .\\n3. Once the FVs are extracted, we can train any linear classiﬁer such as an SVM or\\nsoftmax classiﬁer on the FV data-set, and not on the original images.\\n\\x04\\nSOL-165 \\uf14b CH.SOL- 7.9.\\nOne beneﬁt of using the FC layer is that other ImageNet CNNs can be used in tandem\\nwith the VGG19 to create an ensemble since they all produce the same 1000-D sized FV . \\x04\\nSOL-166 \\uf14b CH.SOL- 7.10. The full code is presented in Fig. ( 7.10).\\n2197.3. SOLUTIONS\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=True)\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = original_model.features\\n11 self.classifier = torch.nn.Sequential(\\n12 (*list(original_model.classifier.\\n13 children())[:-1]))\\n14 self.num_feats = 4096\\n15\\n16 def forward(self, x):\\n17 f = self.features(x)\\n18 f = f.view(f.size(0), -1) # (1, 4096) -> (4096,)\\n19 f = self.classifier(f)\\n20 print (f.data.size())\\n21 return f\\nFIGURE 7.10: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n1. The value of the parameter pretrained should be T rue in order to instruct PyT orch to\\nload an ImageNet trained weights.\\n2. The value of self.features should be original_model.features . This is because we like to\\nretain the layers of the original classiﬁer (original_model).\\n3. The value of self.num_feats should be 4096 . (Why?)\\n4. The value of f should be self.classiﬁer(f) since our newly created CNN has to be in-\\nvoked to generate the FV .\\n220Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n\\x04\\nSOL-167 \\uf14b CH.SOL- 7.11.\\n1. Line number 7 in Fig. ( 7.11) takes care of extracting the the correct 512-D FV .\\n2. Line number 11 in Fig. ( 7.11) extracts the correct 512-D FV by creating a sequential\\nmodule on top of the existing features.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7 def forward(self, x):\\n8 x = [???]\\n9 x = x.view(x.size(0), -1)\\n10 return x\\nFIGURE 7.11: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n\\x04\\nSOL-168 \\uf14b CH.SOL- 7.12.\\n1. T ransforms are incorporated into deep learning pipelines in order to apply one or more\\noperations on images which are represented as tensors. Different transforms are usu-\\nally utilized during training and inference. For instance, during training we can use a\\ntransform to augment our data-set, while during inference our transform may be lim-\\nited only to normalizing an image. PyT orch allows the use of transforms either during\\ntraining or inference. The purpose of test_trans in line 5 is to normalize the data.\\n2217.3. SOLUTIONS\\n2. The parameter requires_grad is set to False in line 14 since during inference the com-\\nputation of gradients is obsolete.\\n3. The purpose of f.cpu() in line 11 is to move a tensor that was allocated on the GPU\\nto the CPU. This may be required if we want to apply a CPU-based method from the\\nPython numpy package on a T ensor that does not live in the CPU.\\n4. detach() in line 23 returns a newly created tensor without affecting the current tensor.\\nIt also detaches the output from the current computational graph, hence no gradient is\\nbackpropagated for this speciﬁc variable.\\n5. The purpose of numpy()[0] in line 23 is to convert the variable (an array) to a numpy\\ncompatible variable and also to retrieve the ﬁrst element of the array.\\n\\x04\\n7.3.2 Fine-tuning CNNs\\nSOL-169 \\uf14b CH.SOL- 7.13.\\nThe term ﬁne-tuning (FT) of an ImageNet pre-trained CNN refers to the method by which\\none or more of the weights of the CNN are re-trained on a new target data-set, which may or\\nmay-not have similarities with the ImageNet data-set. \\x04\\nSOL-170 \\uf14b CH.SOL- 7.14. The three methods are as follows:\\n1. Replacing and re-training only the classiﬁer (usually the FC layer) of the ImageNet\\npre-trained CNN, on a target data-set.\\n2. FT all of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n3. FT part of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n\\x04\\nSOL-171 \\uf14b CH.SOL- 7.15.\\n222Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The categories have to be represented numerically. One such option is presented in Code\\n(7.1).\\n1 \\'MEL\\' : 0, \\'NV\\' : 1, \\'BCC\\' : 2, \\'AKIEC\\' : 3, \\'BKL\\' : 4, \\'DF\\' : 5,\\n\\'VASC\\' : 6↪→\\nCODE 7.1: The seven categories of skin lesions.\\n2. Several possible augmentations are presented in Code ( 7.2). It is usually, that by trial\\nand error one ﬁnds the best possible augmentation for a target data-set. However, meth-\\nods such as AutoAugment may render the manual selection of augmentations obsolete.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\n6 if brightness != 0:\\n7 self.transforms.append(PILBrightness())\\n8 if contrast != 0:\\n9 self.transforms.append(PILContrast())\\n10 if colorbalance != 0:\\n11 self.transforms.append(PILColorBalance())\\n12 if sharpness != 0:\\n13 self.transforms.append(PILSharpness())\\nCODE 7.2: Pseudeo code for augmentations.\\n3. In contrast to the ResNet CNN which ends by an FC layer, the ImageNet pre-trained\\nDPN CNN family, in this case the pretrainedmodels.dpn107, terminated by a Conv2d\\n2237.3. SOLUTIONS\\nlayer and hence must be adapted accordingly if one wishes to change the number fo\\nclasses from the 1000 (ImageNet) classes to our skin lession classiﬁcation problem (7\\nclasses). Line 7 in Code ( 7.3) demonstrated this idiom.\\n1 import torch\\n2 class Dpn107Finetune(nn.Module):\\n3 def __init__(self, num_classes: int, net_kwards):\\n4 super().__init__()\\n5 self.net = pretrainedmodels.dpn107(**net_kwards)\\n6 self.net.__name__= str (self.net)\\n7 self.net.classifier = torch.nn.Conv2d(2688,\\nnum_classes,kernel_size=1)↪→\\n8 print(self.net)\\nCODE 7.3: Change between 1000 classes to 7 classes for the ImageNet pre-trained DPN\\nCNN family .\\n\\x04\\n7.3.3 Neural style transfer\\nSOL-172 \\uf14b CH.SOL- 7.16.\\nThe images are: a content image, a style image and lastly a combined image. \\x04\\nSOL-173 \\uf14b CH.SOL- 7.17.\\nThe algorithm presented in the paper suggests how to combine the content a ﬁrst image\\nwith the style of a second image to generate a third, stylized image using CNNs.\\n\\x04\\nSOL-174 \\uf14b CH.SOL- 7.18.\\nThe answers are as follows:\\n224Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The training pipeline uses a combined loss which consists of a weighted average of the\\nstyle loss and the content loss.\\n2. Different CNN layers at different levels are utilized to capture both ﬁne-grained styl-\\nistic details as well as larger stylistic features.\\n\\x04\\nSOL-175 \\uf14b CH.SOL- 7.19.\\n1. The content loss is the mean square error (MSE) calculated as the difference between\\nthe CNN activations of the last convolutional layer of both the content image and the\\nstyle images.\\n2. The style loss amalgamates the losses of several layers together. For each layer, the gram\\nmatrix (see 7.2) for the activations at that layer is obtained for both the style and the\\ncombined images. Then, just like in the content loss, the MSE of the Gram matrices is\\ncalculated.\\n\\x04\\nSOL-176 \\uf14b CH.SOL- 7.20.\\nFor each feature map, a feature vector is extracted. The gram matrix captures the correl-\\nation between these feature vectors which is then being used in the loss function. Provided a\\nlist of feature vectors extracted from the images, u1, . . . , uk ∈ Rn, the Gram matrix is deﬁned\\nas: \\uf8eb\\n\\uf8ec\\uf8ec\\uf8ec\\uf8ed\\nu1 · u1 . . . u 1 · uk\\n... . . . ...\\nuk · u1 . . . u k · uk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f7\\uf8f8 (7.2)\\nThe Gram matrix \\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 206).\\n225REFERENCES\\n[2] L. A. Gatys, A. S. Ecker and M. Bethge. A Neural Algorithm of Artistic Style . 2015.\\narXiv: 1508.06576 [cs.CV] (cit. on p. 214).\\n[3] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on pp. 206, 213).\\n[4] A. Krizhevsky. One weird trick for parallelizing convolutional neural networks . 2014.\\narXiv: 1404.5997 [cs.NE] (cit. on p. 207).\\n[5] V . Nair and G. E. Hinton. ‘Rectiﬁed Linear Units Improve Restricted Boltzmann\\nMachines’. In: ICML 10 . Madison, WI, USA: Omnipress, 2010, pp. 807–814 (cit.\\non pp. 208, 218).\\n[6] A. J. R. L. Siegel K. D. Miller. ‘Cancer statistics 2016’. In: CA: a cancer journal for\\nclinicians 66,1 (2016), pp. 7–30 (cit. on p. 213).\\n[7] Russakovsky. ‘ImageNet Large Scale Visual Recognition Challenge’. In: Journal\\nof Computer Vision 115.3 (Apr. 2015), pp. 211–252 (cit. on pp. 206, 207).\\n[8] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 207–209, 214).\\n226CHAPTER\\n8\\nDEEP LEARNING\\nIt is the weight, not numbers of experiments that is to be regarded.\\n— Isaac Newton.\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 234\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 235\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 236\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 239\\nConvolution and correlation in python . . . . . . . . . . . . . . 240\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 241\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 244\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 246The Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 247\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 248\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 249\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 251\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 251\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 253\\nSigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 260\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 268\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 273\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 274\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 276\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 280\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 283\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 284\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\n228Chapter 8 DEEP LEARNING\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 286\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 291\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 291\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 292\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 293\\nConvolution and correlation in python . . . . . . . . . . . . . . 294\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 295\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 297\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 299\\nThe Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 300\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 301\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 301\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 304\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 305\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 306\\n229Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 318\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 324\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 324\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 326\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 326\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 327\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 328\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 329\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 331\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333\\n230Chapter 8 DEEP LEARNING\\n8.1 Introduction\\nI\\nT was Alex Krizhevsky who ﬁrst demonstrated that a convolutional neural\\nnetwork (CNN) can be effectively trained on the ImageNet large scale visual\\nrecognition challenge. A CNN automatically provides some degree of trans-\\nlation and assumes that we wish to learn ﬁlters, in a data-driven fashion, as\\na means to extract features describing the inputs. CNNs are applied to numerous com-\\nputer vision, imaging, and computer graphics tasks as in [ 24], [ 23], [ 15], [ 5]. Further-\\nmore, they have become extremely popular, and novel architectures and algorithms\\nare continually popping up overnight.\\n8.2 Problems\\n8.2.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nPRB-177 \\uf059 CH.PRB- 8.1.\\nFig (8.1) depicts two different cross-validation approaches. Name them.\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\nTRAIN VAL\\nFIGURE 8.1: Two CV approaches\\n2318.2. PROBLEMS\\nPRB-178 \\uf059 CH.PRB- 8.2.\\n1. What is the purpose of the following Python code snippet 8.2 ?\\n1 skf = StratifiedKFold(y, n_folds =5, random_state =989,\\nshuffle=True)↪→\\nFIGURE 8.2: Stratiﬁed K-fold\\n2. Explain the beneﬁts of using the K-fold cross validation approach.\\n3. Explain the beneﬁts of using the Stratiﬁed K-fold cross validation approach.\\n4. State the difference between K-fold cross validation and stratiﬁed cross validation.\\n5. Explain in your own words what is meant by “We adopted a 5-fold cross-validation\\napproach to estimate the testing error of the model”.\\nK-Fold CV\\nPRB-179 \\uf059 CH.PRB- 8.3.\\nT rue or False: In a K-fold CV approach, the testing set is completely excluded from the\\nprocess and only the training and validation sets are involved in this approach.\\nPRB-180 \\uf059 CH.PRB- 8.4.\\nT rue or False: In a K-fold CV approach, the ﬁnal test error is:\\nCV (k) = 1\\nk\\nk∑\\ni=1\\nMSEi (8.1)\\n232Chapter 8 DEEP LEARNING\\nPRB-181 \\uf059 CH.PRB- 8.5.\\nMark all the correct choices regarding a cross-validation approach:\\n(i) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted.\\n(ii) A 5-fold cross-validation approach results in 1 model instance being ﬁtted over and\\nover again 5 times.\\n(iii) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted\\nover and over again 5 times.\\n(iv) Uses K-different data-folds.\\nPRB-182 \\uf059 CH.PRB- 8.6.\\nMark all the correct choices regarding the approach that should be taken to compute the\\nperformance of K-fold cross-validation:\\n(i) We compute the cross-validation performance as the arithmetic mean over the K per-\\nformance estimates from the validation sets.\\n(ii) We compute the cross-validation performance as the best one over the K performance\\nestimates from the validation sets.\\nStratification\\nPRB-183 \\uf059 CH.PRB- 8.7.\\nA data-scientist who is interested in classifying cross sections of histopathology image\\nslices (8.3) decides to adopt a cross-validation approach he once read about in a book. Name\\nthe approach from the following options:\\n2338.2. PROBLEMS\\n1st\\n2nd\\n3rd\\nK-fold CV\\nVAL FOLD TRAIN FOLD\\nFIGURE 8.3: A speciﬁc CV approach\\n(i) 3-fold CV\\n(ii) 3-fold CV with stratiﬁcation\\n(iii) A (repeated) 3-fold CV\\nLOOCV\\nPRB-184 \\uf059 CH.PRB- 8.8.\\n1. T rue or false: The leave-one-out cross-validation (LOOCV) approach is a sub-case of\\nk-fold cross-validation wherein K equals N , the sample size.\\n2. T rue or false: It is always possible to ﬁnd an optimal value n, K = n in K-fold\\ncross-validation.\\n8.2.2 Convolution and correlation\\nThe convolution operator\\nPRB-185 \\uf059 CH.PRB- 8.9.\\nEquation 8.2 is commonly used in image processing:\\n(f ∗ g)(t) =\\n∫ ∞\\n−∞\\nf (τ )g(t − τ )dτ (8.2)\\n234Chapter 8 DEEP LEARNING\\n1. What does equation 8.2 represent?\\n2. What does g(t) represent?\\nPRB-186 \\uf059 CH.PRB- 8.10.\\nA data-scientist assumes that:\\ni A convolution operation is both linear and shift invariant.\\nii A convolution operation is just like correlation, except that we ﬂip over the ﬁlter before\\napplying the correlation operator.\\niii The convolution operation reaches a maximum, only in cases where the ﬁlter is mostly\\nsimilar to a speciﬁc section of the input signal.\\nIs he right in assuming so? Explain in detail the meaning of these statements.\\nThe correlation operator\\nPRB-187 \\uf059 CH.PRB- 8.11.\\nMark the correct choice(s):\\n1. The cross-correlation operator is used to ﬁnd the location where two different signals\\nare most similar.\\n2. The autocorrelation operator is used to ﬁnd when a signal is similar to a delayed ver-\\nsion of itself.\\nPRB-188 \\uf059 CH.PRB- 8.12.\\nA data-scientist provides you with a formulae for a discrete 2D convolution operation\\n(8.3):\\nf (x, y) ∗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf (m, n)h(x − m, y − n) (8.3)\\n2358.2. PROBLEMS\\nUsing only (8.3), write the equivalent 2D correlation operation.\\nPadding and stride\\nRecommended reading : “A guide to convolution arithmetic for deep learning ” by Vincent\\nDumoulin and Francesco Visin (2016) [ 22].\\nPRB-189 \\uf059 CH.PRB- 8.13.\\nWhen designing a convolutional neural network layer, one must also deﬁne how the ﬁlter\\nor kernel slides through the input signal. This is controlled by what is known as the stride\\nand padding parameters or modes. The two most commonly used padding approached in\\nconvolutions are the V ALIDand the SAME modes. Given an input stride of 1:\\n1. Deﬁne SAME\\n2. Deﬁne V ALID\\nPRB-190 \\uf059 CH.PRB- 8.14.\\nTrue or False: A valid convolution is a type of convolution operation that does not use\\nany padding on the input.\\nPRB-191 \\uf059 CH.PRB- 8.15.\\nY ou are provided with aK × K input signal and a θ × θ ﬁlter. The signal is subjected to\\nthe valid padding mode convolution. What are the resulting dimensions?\\narr = [\\n0 ... 0\\n0 ... 0\\n0 ... 0\\n] (8.4)\\nPRB-192 \\uf059 CH.PRB- 8.16.\\nAs depicted in ( 8.4), a ﬁlter is applied to a ×3 input signal. Identify the correct choice\\ngiven a stride of 1 and Same padding mode.\\n236Chapter 8 DEEP LEARNING\\nFIGURE 8.4: A padding approach\\nPRB-193 \\uf059 CH.PRB- 8.17.\\nAs depicted in in ( 8.5), a ﬁlter is applied to a 3 × 3 input signal, mark the correct choices\\ngiven a stride of 1.\\n(i) A represents a V ALID convolution and B represents a SAME convolution\\n(ii) A represents a SAME convolution and B represents a V ALID convolution\\n(iii) Both A and B represent a V ALID convolution\\n(iv) Both A and B represent a SAME convolution\\n2378.2. PROBLEMS\\nFIGURE 8.5: A padding approach\\nPRB-194 \\uf059 CH.PRB- 8.18.\\nIn this question we discuss the two most commonly used padding approaches in convo-\\nlutions; V ALIDand SAME . Fig.8.6 presents python code for generating an input signal\\narr001 and a convolution kernel f ilter001. The input signal, arr001 is ﬁrst initialized to\\nall zeros as follows:\\narr001 = [\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n] (8.5)\\n1. Without actually executing the code, determine what would be the resulting shape of\\nthe convolve2d() operation.\\n2. Manually compute the result of convolving the input signal with the provided ﬁlter.\\n3. Elaborate why the size of the resulting convolutions is smaller than the size of the\\ninput signal.\\n238Chapter 8 DEEP LEARNING\\n1 import numpy\\n2 import scipy.signal\\n3\\n4 arr01 = numpy.zeros((6, 6),dtype=float)\\n5 print (arr01)\\n6 arr01[:,:3] = 3.0\\n7 arr01[:,3:] = 1.0\\n8\\n9 filter001 = numpy.zeros((3, 3), dtype =float)\\n10 filter001[:,0] = 2.0\\n11 filter001[:,2] = -2.0\\n12\\n13 output = scipy.signal.convolve2d(arr01, filter, mode =\\'valid\\' )\\nFIGURE 8.6: Convolution and correlation in python\\nKernels and filters\\nPRB-195 \\uf059 CH.PRB- 8.19.\\nEquation 8.6 is the discrete equivalent of equation 8.2 which is frequently used in image\\nprocessing:\\n(y ∗ k)[i, j] =\\n∑\\nn\\n∑\\nm\\ny[i − n, j − m]k[n, m] (8.6)\\n1. Given the following discrete kernel in the X direction, what would be the equivalent Y\\ndirection?\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 1\\n−1 1\\n\\uf8f9\\n\\uf8fb (8.7)\\n2. Identify the discrete convolution kernel presented in ( 8.7).\\n2398.2. PROBLEMS\\nFIGURE 8.7: A 3 by 3 convolution kernel\\nPRB-196 \\uf059 CH.PRB- 8.20.\\nGiven an image of size w × h, and a kernel with width K, how many multiplications and\\nadditions are required to convolve the image?\\nConvolution and correlation in python\\nPRB-197 \\uf059 CH.PRB- 8.21.\\nFig.8.8 presents two built-in Python functions for the convolution and correlation oper-\\nators.\\n1 import nympy as np\\n2 np.convolve(A,B,\"full\") # for convolution\\n3 np.correlate(A,B,\"full\") # for cross correlation\\nFIGURE 8.8: Convolution and correlation in python\\n1. Implement the convolution operation from scratch in Python. Compare it with the\\n240Chapter 8 DEEP LEARNING\\nbuilt-in numpy equivalent.\\n2. Implement the correlation operation using the implementation of the convolution op-\\neration. Compare it with the built-in numpy equivalent.\\nSeparable convolutions\\nPRB-198 \\uf059 CH.PRB- 8.22.\\nThe Gaussian distribution in the 1D and 2D is shown in Equations 8.8 and 8.9.\\nG(x) = 1√\\n2πσ e− x2\\n2σ2 (8.8)\\nG(x, y) = 1\\n2πσ 2 e− x2+y2\\n2σ2 (8.9)\\nThe Gaussian ﬁlter, is an operator that is used to blur images and remove detail and\\nnoise while acting like a low-pass ﬁlter. This is similar to the way a mean ﬁlter works, but\\nthe Gaussian ﬁlter uses a different kernel. This kernel is represented with a Gaussian bell\\nshaped bump.\\nAnswer the following questions:\\n1. Can 8.8 be used directly on a 2D image?\\n2. Can 8.9 be used directly on a 2D image?\\n3. Is the Gaussian ﬁlter separable? if so, what are the advantages of separable ﬁlters.\\n8.2.3 Similarity measures\\nImage, text similarity\\nPRB-199 \\uf059 CH.PRB- 8.23.\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n2418.2. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 8.9: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\n1 void xxx(std::vector<float>& arr) {\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nAn unknown algorithm in C++11\\nFIGURE 8.10: listing\\nWhich results in this vector ( 8.11):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 8.11: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n242Chapter 8 DEEP LEARNING\\nPRB-200 \\uf059 CH.PRB- 8.24.\\nFurther to the above, the scientist then applies the following algorithm:\\nAlgorithm 3: Algo 1\\nData: Two vectors v1 and v2 are provided\\nApply algorithm xxx on the two vectors\\nRun algorithm 2\\nAlgorithm 4: Algo 2\\n1 float algo2(const std::vector<float>& v1, const\\nstd::vector<float>& v2){↪→\\n2 double mul = 0;\\n3 for (size_t i = 0; i < v1.size(); ++i){\\n4 mul += v1[i] * v2[i];\\n5 }\\n6 if (mul < 0) {\\n7 return 0;\\n8 }\\n9 return mul;\\n10 }\\nFIGURE 8.12: An unknown algorithm\\n1. Name the algorithm algo2 that he used and explain in detail what he used it for.\\n2. Write the mathematical formulae behind it.\\n3. What are the minimum and maximum values it can return?\\n4. An alternative similarity measures between two vectors is:\\nsimeuc(v1, v2) = −||v1 − v2||. (8.10)\\nName the measure.\\n2438.2. PROBLEMS\\nJacard similarity\\nPRB-201 \\uf059 CH.PRB- 8.25.\\n1. What is the formulae for the Jaccard similarity [ 12] of two sets?:\\n2. Explain the formulae in plain words.\\n3. Find the Jacard similarity given the sets depicted in ( 8.13)\\nFIGURE 8.13: Jaccard similarity .\\n4. Compute the Jaccard similarity of each pair of the following sets:\\ni 12, 14, 16, 18.\\nii 11, 12, 13, 14, 15.\\niii 11, 16, 17.\\nThe Kullback-Leibler Distance\\nPRB-202 \\uf059 CH.PRB- 8.26.\\nIn this problem, you have to actually read 4 different papers, so you will probably not\\nencounter such a question during an interview, however reading academic papers is an ex-\\ncellent skill to master for becoming a DL researcher.\\nRead the following papers which discuss aspects of the Kullback-Leibler divergence:\\ni Bennet [2]\\n244Chapter 8 DEEP LEARNING\\nii Ziv [29]\\niii Bigi [3]\\niv Jensen [1]\\nThe Kullback-Leibler divergence, which was discussed thoroughly in chap 4 is a meas-\\nure of how different two probability distribution are. As noted, the KL divergence of the\\nprobability distributions P , Q on a set X is deﬁned as shown in Equation 8.11.\\nDKL(P ||Q) =\\n∑\\nx∈X\\nP (x)log P (x)\\nQ(x) (8.11)\\nNote however that since KL divergence is a non-symmetric information theoretical meas-\\nure of distance of P from Q, then it is not strictly a distance metric. During the past years,\\nvarious KL based distance measures (rather than divergence based) have been introduced in\\nthe literature generalizing this measure.\\nName each of the following KL based distances:\\nDKLD 1(P ||Q) = DKL(P ||Q) + DKL(Q||P ) (8.12)\\nDKLD 2(P ||Q) =\\n∑\\nx∈X\\n(P (x) − Q(x))log P (x)\\nQ(x) (8.13)\\nDKLD 3(P ||Q) = 1\\n2\\n[\\nDKL\\n(\\nP ||P + Q\\n2\\n)\\n+ DKL\\n(\\nQ||P + Q\\n2\\n)]\\n(8.14)\\nDKLD 4(P ||Q) = max (DKL(P ||Q) + DKL(Q||P )) (8.15)\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nPRB-203 \\uf059 CH.PRB- 8.27.\\nWhat is the goal of hashing? Draw a simple HashMap of keys and values. Explain what\\nis a collision and the notion of buckets. Explain what is the goal of MinHash.\\n2458.2. PROBLEMS\\nPRB-204 \\uf059 CH.PRB- 8.28.\\nWhat is Locality Sensitive Hashing or LSH?\\nPRB-205 \\uf059 CH.PRB- 8.29.\\nComplete the sentence : LSH main goal is to [...] the probability of a colliding, for\\nsimilar items in a corpus.\\n8.2.4 Perceptrons\\nThe Single Layer Perceptron\\nPRB-206 \\uf059 CH.PRB- 8.30.\\n1. complete the sentence : In a single-layer feed-forward NN, there are [...] input(s)\\nand [...]. output layer(s) and no [...] connections at all.\\nPRB-207 \\uf059 CH.PRB- 8.31.\\nIn its simplest form, a perceptron (8.16) accepts only a binary input and emits a binary\\noutput. The output, can be evaluated as follows:\\noutput =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0, if ∑\\nj wjxj + b ≤ 0,\\n1, if\\n∑\\nj wjxj + b > 0\\n. (8.16)\\nWhere weights are denoted by wj and biases are denoted by b. Answer the following ques-\\ntions:\\n1. T rue or False: If such a perceptron is trained using a labelled corpus, for each parti-\\ncipating neuron the values wj and b are learned automatically.\\n2. T rue or False: If we instead use a new perceptron (sigmoidial) deﬁned as follows:\\nσ(wx + b) (8.17)\\n246Chapter 8 DEEP LEARNING\\nwhere σ is the sigmoid function:\\nσ(z) = 1\\n1 + e−z . (8.18)\\nThen the new perceptron can process inputs ranging between 0 and 1 and emit output\\nranging between 0 and 1.\\n3. Write the cost function associated with the sigmoidial neuron.\\n4. If we want to train the perceptron in order to obtain the best possible weights and\\nbiases, which mathematical equation do we have to solve?\\n5. Complete the sentence: T o solve this mathematical equation, we have to apply [...]\\n6. What does the following equation stands for?\\n∇C = 1\\nn\\n∑\\nx\\n∇Cx (8.19)\\nWhere:\\nCx = 1\\n2∥y(x) − a(x, w, b)∥2 (8.20)\\n7. Complete the sentence: Due to the time-consuming nature of computing gradients for\\neach entry in the training corpus, modern DL libraries utilize a technique that gauges\\nthe gradient by ﬁrst randomly sampling a subset from the training corpus, and then\\naveraging only this subset in every epoch. This approach is known as [...]. The actual\\nnumber of randomly chosen samples in each epoch is termed [...]. The gradient itself\\nis obtained by an algorithm known as [...].\\nThe Multi Layer Perceptron\\nPRB-208 \\uf059 CH.PRB- 8.32.\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\n2478.2. PROBLEMS\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 8.14: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the value resulting from the application the sum operator?\\n3. Verify the correctness of your results using PyT orch.\\nActivation functions in perceptrons\\nPRB-209 \\uf059 CH.PRB- 8.33.\\nThe following questions refer to the MLP depicted in ( 8.15).\\n1. Further to the above, the ReLU non-linear activation function g(z) = max {0, z} is\\napplied ( 8.15) to the output of the linear transformation. What is the value of the\\noutput (out2) now?\\nx1\\nH1\\nx2\\ng(x1, x2)\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1 out2\\n0.001\\nInputs Hidden ActivationSum\\nFIGURE 8.15: Several nodes in a MLP .\\n248Chapter 8 DEEP LEARNING\\n2. Conﬁrm your manual calculation using PyT orch tensors.\\nBack-propagation in perceptrons\\nPRB-210 \\uf059 CH.PRB- 8.34.\\nY our co-worker, an postgraduate student at M.I.T, suggests using the following activa-\\ntion functions in a MLP . Which ones can never be back-propagated and why?\\ni\\nf (x) = |x| (8.21)\\nii\\nf (x) = x (8.22)\\niii\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx sin(1/x) if x ̸= 0\\n0 if x = 0\\n(8.23)\\niv\\nf (x) =\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f3\\nx2 x > 0\\n−x x < 0\\n0 x = 0\\n(8.24)\\nPRB-211 \\uf059 CH.PRB- 8.35.\\nY ou are provided with the following MLP as depicted in 8.16.\\n2498.2. PROBLEMS\\nθ0\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nγ2\\nFIGURE 8.16: A basic MLP\\nThe ReLU non-linear activation function g(z) = max {0, z} is applied to the hidden\\nlayers H1...H3 and the bias term equals 0.001.\\nAt a certain point in time it has the following values 8.17 all of which are belong to the\\ntype torch.F loatT ensor:\\n1 import torch\\n2 x= torch.tensor([0.9,0.7]) # Input\\n3 w= torch.tensor([\\n4 [-0.3,0.15],\\n5 [0.32,-0.91],\\n6 [0.37,0.47],\\n7 ]) # Weights\\n8 B= torch.tensor([0.002]) # Bias\\nFIGURE 8.17: MLP operations.\\n1. Using Python, calculate the output of the MLP at the hidden layers H1...H3.\\n2. Further to the above, you discover that at a certain point in time that the weights\\nbetween the hidden layers and the output layers γ1 have the following values:\\n1 w1= torch.tensor([\\n2 [0.15,-0.46,0.59],\\n3 [0.10,0.32,-0.79],\\n4 )\\n250Chapter 8 DEEP LEARNING\\nWhat is the value observed at the output nodes γ1..γ2?\\n3. Assume now that a Softmax activation is applied to the output. What are the resulting\\nvalues?\\n4. Assume now that a cross-entropy loss is applied to the output of the Softmax.\\nL = −\\n∑\\ni\\nˆyi log (yi) (8.25)\\nWhat are the resulting values?\\nThe theory of perceptrons\\nPRB-212 \\uf059 CH.PRB- 8.36. If someone is quoted saying:\\nMLP networks are universal function approximators.\\nWhat does he mean?\\nPRB-213 \\uf059 CH.PRB- 8.37.\\nT rue or False: the output of a perceptron is 0 or 1.\\nPRB-214 \\uf059 CH.PRB- 8.38.\\nT rue or False: A multi-layer perceptron falls under the category of supervised machine\\nlearning.\\nPRB-215 \\uf059 CH.PRB- 8.39.\\nT rue or False: The accuracy of a perceptron is calculated as the number of correctly\\nclassiﬁed samples divided by the total number of incorrectly classiﬁed samples.\\nLearning logical gates\\n2518.2. PROBLEMS\\nPRB-216 \\uf059 CH.PRB- 8.40.\\nThe following questions refer to the SLP depicted in ( 8.18). The weights in the SLP are\\nw1 = 1 and w2 = 1 respectively. There is a single hidden node, H1. The bias term, B1 equals\\n−2.5.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1 =\\n1\\nw2 =\\n1\\nout1\\n−2.5\\nInputs\\nHidden\\nSum\\nFIGURE 8.18: A single layer perceptron.\\n1. Assuming the inputs to the SLP in ( 8.18) are\\ni x1 = 0.0 and x2 = 0.0\\nii x1 = 0.0 and x2 = 1.0\\niii x1 = 1.0 and x2 = 0.0\\niv x1 = 1.0 and x2 = 1.0\\nWhat is the value resulting from the application the sum operator?\\n2. Repeat the above, assuming now that the bias term B1 was amended and equals −0.25.\\n3. Deﬁne what is the perceptron learning rule.\\n4. What was the most crucial difference between Rosenblatt’s original algorithm and\\nHinton’s fundamental papers of 1986:\\n“Learning representations by back-propagating errors ” [22]\\nand 2012:\\n“ImageNet Classiﬁcation with Deep Convolutional Neural Networks ” [18]?\\n5. The AND logic gate [ 7] is deﬁned by the following table ( 8.19):\\n252Chapter 8 DEEP LEARNING\\nx1 x2 y\\n1 1 1\\n1 0 0\\n0 1 0\\n0 0 0\\nFIGURE 8.19: Logical AND gate\\nCan a perceptron with only two inputs and a single output function as an AND logic\\ngate? If so, ﬁnd the weights and the threshold and demonstrate the correctness of your\\nanswer using a truth table.\\n8.2.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\nPRB-217 \\uf059 CH.PRB- 8.41.\\nThe Sigmoid sc(x) = 1\\n1+e−cx , also commonly known as the logistic function (Fig. 8.20),\\nis widely used in binary classiﬁcation and as a neuron activation function in artiﬁcial neural\\nnetworks. Typically, during the training of an ANN, a Sigmoid layer applies the Sigmoid\\nfunction to elements in the forward pass, while in the backward pass the chain rule is be-\\ning utilized as part of the backpropagation algorithm. In 8.20 the constant c was selected\\narbitrarily as 2 and 5 respectively.\\n2538.2. PROBLEMS\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−2x\\nσ(x) = 1\\n1+e−5x\\nσ(x) = 1\\n1+2−1.5x\\nFIGURE 8.20: Examples of two sigmoid functions and an approximation.\\nDigital hardware implementations of the sigmoid function do exist but they are expens-\\nive to compute and therefore several approximation methods were introduced by the research\\ncommunity. The method by [ 10] uses the following formulas to approximate the exponential\\nfunction:\\nex ≈ Ex(x) ≈ 21.44x (8.26)\\nBased on this formulation, one can calculate the sigmoid function as:\\nSigmoid (x) ≈ 1\\n1 + 2−1.44x ≈ 1\\n1 + 2−1.5x (8.27)\\n1. Code snippet 8.21 provides a pure C++ based (e.g. not using Autograd) implementa-\\ntion of the forward pass for the Sigmoid function. Implement the backward pass that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19] style tensors.\\n254Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001( const torch::Tensor & x ){\\n5 torch::Tensor sig = 1.0 / (1.0 + torch::exp(( -x)));\\n6 return sig;\\n7 }\\nFIGURE 8.21: Forward pass for the Sigmoid function using Libtorch\\n2. Code snippet 8.22 provides a skeleton for printing the values of the sigmoid and its\\nderivative for a range of values contained in the vector v. Complete the code (lines 7-8)\\nso that the values are printed.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 ...\\n8 ...\\n9 }\\n10 }\\n.\\nFIGURE 8.22: Evaluation of the sigmoid and its derivative using Libtorch\\n3. Manually derive the derivative of eq. 8.27, e.g:\\nd\\ndx\\n[ 1\\n1 + 2−1.5x\\n]\\n(8.28)\\n2558.2. PROBLEMS\\n4. Implement both the forward pass for the Sigmoid function approximation eq. 8.27 that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19].\\n5. Print the values of the Sigmoid function and the Sigmoid function approximation eq.\\n8.27 for the following vector:\\nv = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] (8.29)\\nTanh\\nPRB-218 \\uf059 CH.PRB- 8.42.\\nThe Hyperbolic tangent nonlinearity, or the tanh function (Fig. 8.23), is a widely used\\nneuron activation function in artiﬁcial neural networks:\\nftanh (x) = sinh(x)\\ncosh(x) = ex − e−x\\nex + e−x (8.30)\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−4,0\\n−2,0\\n2,0\\n4,0\\nx\\nyσ(x) = 4 ∗ tanh x\\n4\\nσ(x) = tanh x\\n4\\nFIGURE 8.23: Examples of two tanh functions.\\n1. Manually derive the derivative of the tanh function.\\n256Chapter 8 DEEP LEARNING\\n2. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n3. Use the PyT orch based torch.autograd.F unction class to write a custom Function\\nthat implements the forward and backward passes for the tanh function in Python.\\n4. Name the class T anhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\nPRB-219 \\uf059 CH.PRB- 8.43.\\nThe code snippet in 8.24 makes use of the tanh function.\\n1 import torch\\n2\\n3 nn001 = nn.Sequential(\\n4 nn.Linear(200, 512),\\n5 nn.Tanh(),\\n6 nn.Linear(512, 512),\\n7 nn.Tanh(),\\n8 nn.Linear(512, 10),\\n9 nn.LogSoftmax(dim=1)\\n10 )\\nFIGURE 8.24: A simple NN based on tanh in PyTorch.\\n1. What type of a neural network does nn001 in 8.24 represent?\\n2. How many hidden layers does the layer entitles nn001 have?\\nPRB-220 \\uf059 CH.PRB- 8.44.\\n2578.2. PROBLEMS\\nY our friend, a veteran of the DL community claims that MLPs based on tanh activation\\nfunction, have a symmetry around 0 and consequently cannot be saturated. Saturation, so\\nhe claims is a phenomenon typical of the top hidden layers in sigmoid based MLPs. Is he\\nright or wrong?\\nPRB-221 \\uf059 CH.PRB- 8.45.\\nIf we initialize the weights of a tanh based NN, which of the following approaches will\\nlead to the vanishing gradients problem?.\\ni Using the normal distribution, with parameter initialization method as suggested by\\nKaiming [14].\\nii Using the uniform distribution, with parameter initialization method as suggested by\\nXavier Glorot [9].\\niii Initialize all parameters to a constant zero value.\\nPRB-222 \\uf059 CH.PRB- 8.46.\\nY ou friend, who is experimenting with the tanh activation function designed a small\\nCNN with only one hidden layer and a linear output ( 8.25):\\nFIGURE 8.25: A small CNN composed of tanh blocks.\\nHe initialized all the weights and biases (biases not shown for brevity) to zero. What is\\nthe most signiﬁcant design ﬂaw in his architecture?\\nHint: think about back-propagation.\\nReLU\\nPRB-223 \\uf059 CH.PRB- 8.47.\\n258Chapter 8 DEEP LEARNING\\nThe rectiﬁed linear unit, or ReLU g(z) = max {0, z} is the default for many CNN archi-\\ntectures. It is deﬁned by the following function:\\nfReLU(x) = max(0 , x) (8.31)\\nOr:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.32)\\n1. In what sense is the ReLU better than traditional sigmoidal activation functions?\\nPRB-224 \\uf059 CH.PRB- 8.48.\\nY ou are experimenting with the ReLU activation function, and you design a small CNN\\n(8.26) which accepts an RGB image as an input. Each CNN kernel is denoted by w.\\nFIGURE 8.26: A small CNN composed of ReLU blocks.\\nWhat is the shape of the resulting tensor W ?\\nPRB-225 \\uf059 CH.PRB- 8.49.\\nName the following activation function where a ∈ (0, 1):\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx if x > 0\\nax otherwise\\n(8.33)\\nSwish\\n2598.2. PROBLEMS\\nPRB-226 \\uf059 CH.PRB- 8.50.\\nIn many interviews, you will be given a paper that you have never encountered before,\\nand be required to read and subsequently discuss it. Please read Searching for Activation\\nFunctions [21] before attempting the questions in this question.\\n1. In [21], researchers employed an automatic pipeline for searching what exactly?\\n2. What types of functions did the researchers include in their search space?\\n3. What were the main ﬁndings of their research and why were the results surprising?\\n4. Write the formulae for the Swish activation function.\\n5. Plot the Swish activation function.\\n8.2.6 Performance Metrics\\nComparing different machine learning models, tuning hyper parameters and learn-\\ning rates, ﬁnding optimal augmentations, are all important steps in ML research. Typ-\\nically our goal is to ﬁnd the best model with the lowest errors on both the training\\nand validation sets. To do so we need to be able to measure the performance of each\\napproach/model/parameter setting etc. and compare those measures. For valuable\\nreference, read: “Evaluating Learning Algorithms: A Classiﬁcation Perspective ” [22]\\nConfusion matrix, precision, recall\\nPRB-227 \\uf059 CH.PRB- 8.51.\\nY ou design a binary classiﬁer for detecting the presence of malfunctioning temperature\\nsensors. Non-malfunctioning (N) devices are the majority class in the training corpus. While\\nrunning inference on an unseen test-set, you discover that the Confusion Metrics (CM) has\\nthe following values 8.27:\\n260Chapter 8 DEEP LEARNING\\nPredicted\\nP N\\nActual P 12 7\\nN 24 1009\\nFIGURE 8.27: A confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices.\\n1. Find: TP , TN, FP , FN and correctly label the numbers in table 8.27.\\n2. What is the accuracy of the model?\\n3. What is the precision of the model?\\n4. What is the recall of the model?\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\nFIGURE 8.28: Receiver Operating Characteristic curve.\\n2618.2. PROBLEMS\\nPRB-228 \\uf059 CH.PRB- 8.52.\\nComplete the following sentences:\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween [...] and [...].\\n2. It is a plot of [...] vs. the [...]. In place of [...], one could also use [...] which are essen-\\ntially {1 - ‘true negatives’ }.\\n3. A typical ROC curve has a concave shape with [...] as the beginning and [...] as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely con-\\nfused and cannot at all distinguish between the two classes, has an AUC of [...] which\\nis the [...] line in an ROC curve plot.\\nPRB-229 \\uf059 CH.PRB- 8.53.\\nThe code 8.30 and Figure 8.29 are the output from running XGBOOST for a binary\\nclassiﬁcation task.\\nFIGURE 8.29: RUC AUC\\n262Chapter 8 DEEP LEARNING\\n1 XGBClassifier(base_score=0.5, colsample_bylevel =1,\\ncolsample_bytree=0.5,↪→\\n2 gamma=0.017, learning_rate =0.15, max_delta_step =0, max_depth =9,\\n3 min_child_weight=3, missing =None, n_estimators =1000, nthread =-1,\\n4 objective=\\'binary:logistic\\' , reg_alpha =0, reg_lambda =1,\\n5 scale_pos_weight=1, seed =0, silent =1,\\nsubsample=0.9)shape:(316200, 6)↪→\\n6\\n7 >ROC AUC: 0.984439608912\\n8 >LOG LOSS: 0.0421598347226\\nFIGURE 8.30: XGBOOST for binary classiﬁcation.\\nHow would you describe the results of the classiﬁcation?.\\n8.2.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nPRB-230 \\uf059 CH.PRB- 8.54.\\nGiven an input of size of n × n, ﬁlters of size f × f and a stride of s with padding of p,\\nwhat is the output dimension?\\nPRB-231 \\uf059 CH.PRB- 8.55.\\nReferring the code snippet in Fig. ( 8.31), answer the following questions regarding the\\nVGG11 architecture [25]:\\n2638.2. PROBLEMS\\n1 import torchvision\\n2 import torch\\n3 def main():\\n4 vgg11 = torchvision.models.vgg11(pretrained=True)\\n5 vgg_layers = vgg11.features\\n6 for param in vgg_layers.parameters():\\n7 param.requires_grad = False\\n8\\n9 example = [torch.rand(1, 3, 224, 224),\\n10 torch.rand(1, 3, 512, 512),\\n11 torch.rand(1, 3, 704, 1024)]\\n12 vgg11.eval()\\n13 for e in example:\\n14 out=vgg_layers(e)\\n15 print(out.shape)\\n16 if __name__ == \"__main__\":\\n17 main()^^I^^I\\nFIGURE 8.31: CNN arithmetics on the VGG11 CNN model.\\n1. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the VGG11 CNN to the respective input.\\n2. Choose the correct option. The last layer of the VGG11 architecture is:\\ni Conv2d\\nii MaxPool2d\\niii ReLU\\nPRB-232 \\uf059 CH.PRB- 8.56.\\nStill referring the code snippet in Fig. ( 8.31), and speciﬁcally to line 7, the code is\\namended so that the line is replaced by the line:\\nvgg_layers=vgg11.features[:3] .\\n264Chapter 8 DEEP LEARNING\\n1. What type of block is now represented by the new line? Print it using PyT orch.\\n2. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the block:\\nvgg_layers=vgg11.features[:3] to the respective input.\\nPRB-233 \\uf059 CH.PRB- 8.57.\\nT able (8.1) presents an incomplete listing of the of the VGG11 architecture [ 25]. As\\ndepicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters) are\\npresented.\\nLayer #Filters\\nconv4_3 512\\nfc6 4,096\\nfc7 4,096\\noutput 1,000\\nTABLE 8.1: Incomplete listing of the VGG11 architecture.\\nComplete the missing parts regarding the dimensions and arithmetics of the VGG11\\nCNN architecture:\\n1. The VGG11 architecture consists of [...] convolutional layers.\\n2. Each convolutional layer is followed by a [...] activation function, and ﬁve [...] opera-\\ntions thus reducing the preceding feature map size by a factor of [...].\\n3. All convolutional layers have a [...] kernel.\\n4. The ﬁrst convolutional layer produces [...] channels.\\n5. Subsequently as the network deepens, the number of channels [...] after each [...] oper-\\nation until it reaches [...].\\n2658.2. PROBLEMS\\nDropout\\nPRB-234 \\uf059 CH.PRB- 8.58.\\nA Dropout layer [26] (Fig. 8.32) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 8.32: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [20], a Dropout layer is declared as follows ( 8.2):\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 8.2: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 8.2) indicates that the probability of zeroing an\\nelement is 0.2.\\n266Chapter 8 DEEP LEARNING\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 8.33: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 8.32). Here, for illustration purposes, all four\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\n1. Y ou are interested in the proportionθ of dropped-out neurons. Assume that the chance\\nof drop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the\\nposterior of θ.\\n2. Describe the similarities of dropout to bagging.\\nPRB-235 \\uf059 CH.PRB- 8.59.\\nA co-worker claims he discovered an equivalence theorem where, two consecutive Dro-\\npout layers [26] can be replaced and represented by a single Dropout layer 8.34.\\nFIGURE 8.34: Two consecutive Dropout layers\\nHi realized two consecutive layers in PyT orch [20], declared as follows ( 8.3):\\n2678.2. PROBLEMS\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Sequential(\\n4 nn.Conv2d(1024, 32),\\n5 nn.ReLU(),\\n6 nn.Dropout(p=P, inplace =True),\\n7 nn.Dropout(p=Q, inplace =True)\\n8 )\\nCODE 8.3: Consequtive dropout in PyTorch\\nWhere nn.Dropout(0.1) (Line #6 in 8.3) indicates that the probability of zeroing an\\nelement is 0.1.\\n1. What do you think about his idea, is he right or wrong?\\n2. Either prove that he is right or provide a single example that refutes his theorem.\\nConvolutional Layer\\nThe convolution layer is probably one of the most important layers in the theory and\\npractice of modern deep learning and computer vision in particular.\\nTo study the optimal number of convolutional layers for the classiﬁcation of two\\ndifferent types of the Ebola virus, a researcher designs a binary classiﬁcation pipeline\\nusing a small CNN with only a few layers ( 8.35):\\n268Chapter 8 DEEP LEARNING\\nFIGURE 8.35: A CNN based classiﬁcation system.\\nAnswer the following questions while referring to ( 8.35):\\nPRB-236 \\uf059 CH.PRB- 8.60.\\nIf he uses the following ﬁlter for the convolutional operation, what would be the resulting\\ntensor after the application of the convolutional layer?\\nFIGURE 8.36: A small ﬁlter for a CNN\\nPRB-237 \\uf059 CH.PRB- 8.61.\\nWhat would be the resulting tensor after the application of the ReLU layer ( 8.37)?\\n2698.2. PROBLEMS\\nFIGURE 8.37: The result of applying the ﬁlter.\\nPRB-238 \\uf059 CH.PRB- 8.62.\\nWhat would be the resulting tensor after the application of the MaxPool layer ( 8.78)?\\nPooling Layers\\nA pooling layer transforms the output of a convolutional layer, and neurons in a pool-\\ning layer accept the outputs of a number of adjacent feature maps and merge their\\noutputs into a single number.\\nMaxPooling\\nPRB-239 \\uf059 CH.PRB- 8.63.\\nThe following input 8.38 is subjected to a MaxPool2D(2,2) operation having 2 × 2 max-\\npooling ﬁlter with a stride of 2 and no padding at all.\\n270Chapter 8 DEEP LEARNING\\nFIGURE 8.38: Input to MaxPool2d operation.\\nAnswer the following questions:\\n1. What is the most common use of max-pooling layers?\\n2. What is the result of applying the MaxPool2d operation on the input?\\nPRB-240 \\uf059 CH.PRB- 8.64.\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and evaluate its behaviour during inference:\\n2718.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 8.4: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n272Chapter 8 DEEP LEARNING\\nFIGURE 8.39: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet a second MaxPool2D(2,2).\\nWhat is the resulting tensor shape after running line 9? and line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\nBatch normalization, Gaussian PDF\\nRecommended readings for this topic are “ Batch Normalization: Accelerating Deep Net-\\nwork T raining by Reducing Internal Covariate Shift ” [16] and “ Delving deep into rectiﬁers:\\nSurpassing human-level performance on imagenet classiﬁcation ” [14].\\nA discussion of batch normalization (BN) would not be complete without a discus-\\nsion of the Gaussian normal distribution. Though it would be instructive to develop\\nthe forward and backwards functions for a BN operation from scratch, it would also\\nbe quite complex. As an alternative we discuss several aspects of the BN operation\\nwhile expanding on the Gaussian distribution.\\n2738.2. PROBLEMS\\nThe Gaussian distribution\\nPRB-241 \\uf059 CH.PRB- 8.65.\\n1. What is batch normalization?\\n2. The normal distribution is deﬁned as follows:\\nP (x) = 1\\nσ\\n√\\n2π e−(x−µ)2/2σ2\\n(8.34)\\nGenerally i.i.d. X ∼ N (µ, σ2) however BN uses the standard normal distribution.\\nWhat mean and variance does the standard normal distribution have?\\n3. What is the mathematical process of normalization?\\n4. Describe, how normalization works in BN.\\nPRB-242 \\uf059 CH.PRB- 8.66.\\nIn python, the probability density function for a normal distribution is given by 8.40:\\n1 import scipy\\n2 scipy.stats.norm.pdf(x, mu, sigma)\\nFIGURE 8.40: Normal distribution in Python.\\n1. Without using Scipy, implement the normal distribution from scratch in Python.\\n2. Assume, you want to back propagate on the normal distribution, and therefore you\\nneed the derivative. Using Scipy write a function for the derivative.\\nBN\\nPRB-243 \\uf059 CH.PRB- 8.67.\\n274Chapter 8 DEEP LEARNING\\nY our friend, a novice data scientist, uses an RGB image ( 8.41) which he then subjects to\\nBN as part of training a CNN.\\nFIGURE 8.41: A convolution and BN applied to an RGB image.\\n1. Help him understand, during BN, is the normalization applied pixel-wise or per colour\\nchannel?\\n2. In the PyT orch implementation, he made a silly mistake 8.42, help him identify it:\\n2758.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class BNl001(nn.Module):\\n4 def __init__(self):\\n5 super(BNl001, self).__init__()\\n6 self.cnn = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 64, kernel_size =3, padding =2),\\n8 )\\n9 self.math= torch.nn.Sequential(\\n10 torch.nn.BatchNorm2d(32),\\n11 torch.nn.PReLU(),\\n12 torch.nn.Dropout2d(0.05)\\n13 )\\n14 def forward(self, x):\\n15 ...\\nFIGURE 8.42: A mistake in a CNN\\nTheory of CNN design\\nPRB-244 \\uf059 CH.PRB- 8.68.\\nTrue or false: An activation function applied after a Dropout, is equivalent to an activ-\\nation function applied before a dropout.\\nPRB-245 \\uf059 CH.PRB- 8.69.\\nWhich of the following core building blocks may be used to construct CNNs? Choose all\\nthe options that apply:\\ni Pooling layers\\nii Convolutional layers\\niii Normalization layers\\niv Non-linear activation function\\n276Chapter 8 DEEP LEARNING\\nv Linear activation function\\nPRB-246 \\uf059 CH.PRB- 8.70.\\nY ou are designing a CNN which has a single BN layer. Which of the following core CNN\\ndesigns are valid? Choose all the options that apply:\\ni CONV → act → BN → Dropout → . . .\\nii CONV → act → Dropout → BN → . . .\\niii CONV → BN → act → Dropout → . . .\\niv BN → CONV → act → Dropout → . . .\\nv CONV → Dropout → BN → act → . . .\\nvi Dropout → CONV → BN → act → . . .\\nPRB-247 \\uf059 CH.PRB- 8.71.\\nThe following operator is known as the Hadamard product:\\nOUT = A ⊙ B (8.35)\\nWhere:\\n(A ⊙ B)i,j := (A)i,j(B)i,j (8.36)\\nA scientist, constructs a Dropout layer using the following algorithm:\\ni Assign a probability of p for zeroing the output of any neuron.\\nii Accept an input tensor T , having a shape S\\niii Generate a new tensor T ‘∈ {0, 1}S\\niv Assign each element in T ‘a randomly and independently sampled value from a Bernoulli\\ndistribution:\\nT ‘i ∼ B(1, p) (8.37)\\n2778.2. PROBLEMS\\nv Calculate the OU T tensor as follows:\\nOUT = T ‘⊙ T (8.38)\\nY ou are surprised to ﬁnd out that his last step is to multiply the output of a dropout layer\\nwith:\\n1\\n1 − p (8.39)\\nExplain what is the purpose of multiplying by the term 1\\n1−p .\\nPRB-248 \\uf059 CH.PRB- 8.72.\\nVisualized in (8.43) from a high-level view, is an MLP which implements a well-known\\nidiom in DL.\\nFIGURE 8.43: A CNN block\\n1. Name the idiom.\\n2. What can this type of layer learn?\\n3. A fellow data scientist suggests amending the architecture as follows ( 8.44)\\n278Chapter 8 DEEP LEARNING\\nFIGURE 8.44: A CNN block\\nName one disadvantage of this new architecture.\\n4. Name one CNN architecture where the input equals the output.\\nCNN residual blocks\\nPRB-249 \\uf059 CH.PRB- 8.73.\\nAnswer the following questions regarding residual networks ([ 13]).\\n1. Mathematically, the residual block may be represented by:\\ny = x + F(x) (8.40)\\nWhat is the function F?\\n2. In one sentence, what was the main idea behind deep residual networks (ResNets) as\\nintroduced in the original paper ([ 13])?\\nPRB-250 \\uf059 CH.PRB- 8.74.\\nY our friend was thinking about ResNet blocks, and tried to visualize them in ( 8.45).\\n2798.2. PROBLEMS\\nFIGURE 8.45: A resnet CNN block\\n1. Assuming a residual of the form y = x + F(x), complete the missing parts in Fig.\\n(8.45).\\n2. What does the symbol ⊕ denotes?\\n3. A fellow data scientist, who had coffee with you said that residual blocks may compute\\nthe identity function. Explain what he meant by that.\\n8.2.8 Training, hyperparameters\\nHyperparameter optimization\\nPRB-251 \\uf059 CH.PRB- 8.75.\\nA certain training pipeline for the classiﬁcation of large images (1024 x 1024) uses the\\nfollowing Hyperparameters (8.46):\\n280Chapter 8 DEEP LEARNING\\nHyperparameter Value\\nInitial learning rate 0.1\\nWeight decay 0.0001\\nMomentum 0.9\\nBatch size 1024\\n1 optimizer = optim.SGD(model.parameters(), lr =0.1,\\n2 momentum=0.9,\\n3 weight_decay=0.0001)\\n4 ...\\n5 trainLoader = torch.utils.data.DataLoader(\\n6 datasets.LARGE(\\'../data\\' , train =True, download =True,\\n7 transform=transforms.Compose([\\n8 transforms.ToTensor(),\\n9 ])),\\n10 batch\\\\_size=1024, shuffle =True)\\nFIGURE 8.46: Hyperparameters.\\nIn your opinion, what could possibly go wrong with this training pipeline?\\nPRB-252 \\uf059 CH.PRB- 8.76.\\nA junior data scientist in your team who is interested in Hyperparameter tuning, wrote\\nthe following code ( 8.5) for spiting his corpus into two distinct sets and ﬁtting an LR model:\\n2818.2. PROBLEMS\\n1 from sklearn.model_selection import train_test_split\\n2 dataset = datasets.load_iris()\\n3 X_train, X_test, y_train, y_test =\\n4 train_test_split(dataset.data, dataset .target, test_size =0.2)\\n5 clf = LogisticRegression(data_norm=12)\\n6 clf.fit(X_train, y_train)\\nCODE 8.5: Train and Validation split.\\nHe then evaluated the performance of the trained model on the Xtest set.\\n1. Explain why his methodology is far from perfect.\\n2. Help him resolve the problem by utilizing a difference splitting methodology.\\n3. Y our friend now amends the code an uses:\\n1 clf = GridSearchCV(method, params, scoring =\\'roc_auc\\' , cv =5)\\n2 clf.fit(train_X, train_y)\\nExplain why his new approach may work better.\\nPRB-253 \\uf059 CH.PRB- 8.77.\\nIn the context of Hyperparameter optimization, explain the difference between grid search\\nand random search.\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nPRB-254 \\uf059 CH.PRB- 8.78.\\n282Chapter 8 DEEP LEARNING\\nNon-invasive methods that forecast the existence of lung nodules ( 8.47), is a precursor\\nto lung cancer. Y et, in spite of acquisition standardization attempts, the manual detection of\\nlung nodules still remains predisposed to inter mechanical and observer variability. What is\\nmore, it is a highly laborious task.\\nFIGURE 8.47: Pulmonary nodules.\\nIn the majority of cases, the training data is manually labelled by radiologists who make\\nmistakes. Imagine you are working on a classiﬁcation problem and hire two radiologists for\\nlung cancer screening based on low-dose CT (LDCT). Y ou ask them to label the data, the\\nﬁrst radiologist labels only the training set and the second the validation set. Then you hire\\na third radiologist to label the test set.\\n1. Do you think there is a design ﬂow in the curation of the data sets?\\n2. A friend suggests that all there radiologists read all the scans and label them independ-\\nently thus creating a majority vote. What do you think about this idea?\\nValidation curve ACC\\nPRB-255 \\uf059 CH.PRB- 8.79.\\nAnswer the following questions regarding the validation curve visualized in ( 8.48):\\n2838.2. PROBLEMS\\n20 40 60 80 100\\n0,2\\n0,4\\n0,6\\n0,8\\nEPOCH\\nERR V ALID\\nTRAIN\\nFIGURE 8.48: A validation curve.\\n1. Describe in one sentence, what is a validation curve.\\n2. Which hyperparameter is being used in the curve?\\n3. Which well-known metric is being used in the curve? Which other metric is commonly\\nused?\\n4. Which positive phenomena happens when we train a NN longer?\\n5. Which negative phenomena happens when we train a NN longer than we should?\\n6. How this negative phenomena is reﬂected in 8.48?\\nValidation curve Loss\\nPRB-256 \\uf059 CH.PRB- 8.80.\\nRefer to the validation log-loss curve visualized in ( 8.49) and answer the following ques-\\ntions:\\n284Chapter 8 DEEP LEARNING\\nFIGURE 8.49: Log-loss function curve.\\n1. Name the phenomena that starts happening right after the marking by the letter E and\\ndescribe why it is happening.\\n2. Name three different weight initialization methods.\\n3. What is the main idea behind these methods?\\n4. Describe several ways how this phenomena can be alleviated.\\n5. Y our friend, a fellow data-scientist, inspects the code and sees the following Hyper-\\nparameters are being used:\\nHyperparameter Value\\nInitial LR 0.00001\\nMomentum 0.9\\nBatch size 1024\\nHe then tells you that the learning rate (LR) is constant and suggests amending the\\ntraining pipeline by adding the following code ( 8.50):\\n2858.2. PROBLEMS\\n1 scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt)\\nFIGURE 8.50: A problem with the log-loss curve.\\nWhat do you think about his idea?\\n6. Provide one reason against the use of the log-loss curve.\\nInference\\nPRB-257 \\uf059 CH.PRB- 8.81.\\nY ou ﬁnished training a face recognition algorithm, which uses a feature vector of 128\\nelements. During inference, you notice that the performance is not that good. A friend tells\\nyou that in computer vision faces are gathered in various poses and perspectives. He there-\\nfore suggests that during inference you would augment the incoming face ﬁve times, run\\ninference on each augmented image and then fuse the output probability distributions by\\naveraging.\\n1. Name the method he is suggesting.\\n2. Provide several examples of augmentation that you might use during inference.\\nPRB-258 \\uf059 CH.PRB- 8.82.\\nComplete the sentence: If the training loss is insigniﬁcant while the test loss is signiﬁc-\\nantly higher, the network has almost certainly learned features which are not present in an\\n[...] set. This phenomena is referred to as [...]\\n8.2.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nPRB-259 \\uf059 CH.PRB- 8.83.\\nWhat does the term stochastic in SGD actually mean? Does it use any random number\\n286Chapter 8 DEEP LEARNING\\ngenerator?\\nPRB-260 \\uf059 CH.PRB- 8.84.\\nExplain why in SGD, the number of epochs required to surpass a certain loss threshold\\nincreases as the batch size decreases?\\nMomentum\\nPRB-261 \\uf059 CH.PRB- 8.85.\\nHow does momentum work? Explain the role of exponential decay in the gradient descent\\nupdate rule.\\nPRB-262 \\uf059 CH.PRB- 8.86.\\nIn your training loop, you are using SGD and a logistic activation function which is\\nknown to suffer from the phenomenon of saturated units.\\n1. Explain the phenomenon.\\n2. Y ou switch to using the tanh activation instead of the logistic activation, in your\\nopinion does the phenomenon still exists?\\n3. In your opinion, is using the tanh function makes the SGD operation to converge\\nbetter?\\nPRB-263 \\uf059 CH.PRB- 8.87.\\nWhich of the following statements holds true?\\ni In stochastic gradient descent we ﬁrst calculate the gradient and only then adjust weights\\nfor each data point in the training set.\\nii In stochastic gradient descent, the gradient for a single sample is not so different from\\nthe actual gradient, so this gives a more stable value, and converges faster.\\niii SGD usually avoids the trap of poor local minima.\\n2878.2. PROBLEMS\\niv SGD usually requires more memory.\\nNorms, L1, L2\\nPRB-264 \\uf059 CH.PRB- 8.88.\\nAnswer the following questions regarding norms.\\n1. Which norm does the following equation represent?\\n|x1 − x2| + |y1 − y2| (8.41)\\n2. Which formulae does the following equation represent?\\n\\ued6a\\ued6b\\ued6b√\\nn∑\\ni=1\\n(xi − yi)2 (8.42)\\n3. When your read that someone penalized the L2 norm, was the euclidean or the Man-\\nhattan distance involved?\\n4. Compute both the Euclidean and Manhattan distance of the vectors:\\nx1 = [6 , 1, 4, 5] and x2 = [2 , 8, 3, −1].\\nPRB-265 \\uf059 CH.PRB- 8.89.\\nY ou are provided with a pure Python code implementation of the Manhattan distance\\nfunction (8.51):\\n1 from scipy import spatial\\n2 x1=[6,1,4,5]\\n3 x2=[2,8,3,-1]\\n4 cityblock = spatial.distance.cityblock(x1, x2)\\n5 print(\"Manhattan:\", cityblock)\\nFIGURE 8.51: Manhattan distance function.\\n288Chapter 8 DEEP LEARNING\\nIn many cases, and for large vectors in particular, it is better to use a GPU for imple-\\nmenting numerical computations. PyT orch has full support for GPU’s (and its my favourite\\nDL library ... ), use it to implement the Manhattan distance function on a GPU.\\nPRB-266 \\uf059 CH.PRB- 8.90.\\nY our friend is training a logistic regression model for a binary classiﬁcation problem\\nusing the L2 loss for optimization. Explain to him why this is a bad choice and which loss he\\nshould be using instead.\\n8.3 Solutions\\n8.3.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nSOL-177 \\uf14b CH.SOL- 8.1.\\nThe ﬁrst approach is a leave-one-out CV (LOOCV) and the second is a K-fold cross-\\nvalidation approach. \\x04\\nSOL-178 \\uf14b CH.SOL- 8.2.\\nCross Validation is a cornerstone in machine learning, allowing data scientists to take\\nfull gain of restricted training data. In classiﬁcation, effective cross validation is essential to\\nmaking the learning task efﬁcient and more accurate. A frequently used form of the technique\\nis identiﬁed as K-fold cross validation. Using this approach, the full data set is divided into K\\nrandomly selected folds, occasionally stratiﬁed, meaning that each fold has roughly the\\nsame class distribution as the overall data set . Subsequently, for each fold, all the other\\n(K − 1) folds are used for training, while the present fold is used for testing. This process\\nguarantees that sets used for testing, are not used by a classiﬁer that also saw it during\\ntraining.\\n\\x04\\nK-Fold CV\\n2898.3. SOLUTIONS\\nSOL-179 \\uf14b CH.SOL- 8.3.\\nT rue. We never utilize the test set during a K-fold CV process. \\x04\\nSOL-180 \\uf14b CH.SOL- 8.4.\\nT rue. This is the average of the individual errors of K estimates of the test error:\\nMSE1, . . . ,MSEk (8.43)\\n\\x04\\nSOL-181 \\uf14b CH.SOL- 8.5.\\nThe correct answer is: A 5-fold cross-validation approach results in 5-different model in-\\nstances being ﬁtted. It is a common misconception to think that in a K-fold approach the same\\nmodel instance is repeatedly used. We must create a new model instance in each fold. \\x04\\nSOL-182 \\uf14b CH.SOL- 8.6.\\nThe correct answer is: we compute the cross-validation performance as the arithmetic\\nmean over the K performance estimates from the validation sets. \\x04\\nStratification\\nSOL-183 \\uf14b CH.SOL- 8.7.\\nThe correct answer is: 3-fold CV . A k-fold cross-validation is a special case of cross-\\nvalidation where we iterate over a dataset set k times. In each round, we split the dataset\\ninto k parts: one part is used for validation, and the remaining k − 1 parts are merged into\\na training subset for model evaluation. Stratiﬁcation is used to balance the classes in the\\ntraining and validation splits in cases where the corpus is imbalanced. \\x04\\nLOOCV\\nSOL-184 \\uf14b CH.SOL- 8.8.\\n1. T rue: In (LOOCV) K = N the full sample size.\\n2. False: There is no way of a-priori ﬁnding an optimal value for K, and the relationship\\n290Chapter 8 DEEP LEARNING\\nbetween the actual sample size and the resulting accuracy is unknown.\\n\\x04\\n8.3.2 Convolution and correlation\\nThe convolution operator\\nSOL-185 \\uf14b CH.SOL- 8.9.\\n1. This is the deﬁnition of a convolution operation on the two signals f and g.\\n2. In image processing, the term g(t) represents a ﬁltering kernel.\\n\\x04\\nSOL-186 \\uf14b CH.SOL- 8.10.\\n1. T rue. These operations have two key features: they are shift invariant, and they are\\nlinear. Shift invariance means that we perform the same operation at every point in the\\nimage. Linearity means that this operation is linear, that is, we replace every pixel with\\na linear combination of its neighbours\\n2. T rue. See for instance Eq. (8.3).\\n3. T rue.\\n\\x04\\nThe correlation operator\\nSOL-187 \\uf14b CH.SOL- 8.11.\\n1. T rue.\\n2. T rue.\\n\\x04\\n2918.3. SOLUTIONS\\nSOL-188 \\uf14b CH.SOL- 8.12.\\nA convolution operation is just like correlation, except that we ﬂip over the ﬁlter both\\nhorizontally and vertically before correlating.\\nf (x, y) ⊗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf ∗(m, n)h(x + m, y + n) (8.44)\\n\\x04\\nPadding and stride\\nRecommended reading : “ A guide to convolution arithmetic for deep learning by Vincent\\nDumoulin and Francesco Visin (2016) ” [22].\\nSOL-189 \\uf14b CH.SOL- 8.13.\\n1. The Valid padding only uses values from the original input; however, when the data\\nresolution is not a multiple of the stride, some boundary values are ignored entirely in\\nthe feature calculation.\\n2. The Same padding ensures that every input value is included, but also adds zeros near\\nthe boundary which are not in the original input.\\n\\x04\\nSOL-190 \\uf14b CH.SOL- 8.14.\\nT rue. Contrast this with the two other types of convolution operations. \\x04\\nSOL-191 \\uf14b CH.SOL- 8.15.\\n⌊\\nK − θ\\nθ\\n⌋\\n+ 1 ×\\n⌊\\nn − θ\\nθ\\n⌋\\n+ 1 (8.45)\\n\\x04\\nSOL-192 \\uf14b CH.SOL- 8.16.\\n292Chapter 8 DEEP LEARNING\\nA is the correct choice. \\x04\\nSOL-193 \\uf14b CH.SOL- 8.17.\\nA represents the V ALID mode while B represents the SAME mode. \\x04\\nSOL-194 \\uf14b CH.SOL- 8.18.\\n1. The resulting output has a shape of 4 × 4.\\n2. Convolution operation\\n[[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]]\\n[[ 2. 0. -2.]\\n[ 2. 0. -2.]\\n[ 2. 0. -2.]]\\n3. By deﬁnition, convolutions in the valid mode, reduce the size of the resulting input\\ntensor.\\n[[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]]\\n\\x04\\nKernels and filters\\nSOL-195 \\uf14b CH.SOL- 8.19.\\n2938.3. SOLUTIONS\\n1. Flipping by 180 degrees we get:\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 −1\\n1 1\\n\\uf8f9\\n\\uf8fb (8.46)\\n2. The Sobel ﬁlter which is being frequently used for edge detection in classical computer\\nvision.\\n\\x04\\nSOL-196 \\uf14b CH.SOL- 8.20.\\nThe resulting complexity is given by:\\nK 2wh (8.47)\\n\\x04\\nConvolution and correlation in python\\nSOL-197 \\uf14b CH.SOL- 8.21.\\n1. Convolution operation:\\n294Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 def convolution(A,B):\\n3 l_A = np.size(A)\\n4 l_B = np.size(B)\\n5 C = np.zeros(l_A + l_B -1)\\n6\\n7 for m in np.arange(l_A):\\n8 for n in np.arange(l_B):\\n9 C[m+n] = C[m+n] + A[m]*B[n]\\n10\\n11 return C\\nFIGURE 8.52: Convolution and correlation in python\\n2. Correlation operation:\\n1 def crosscorrelation(A,B):\\n2 return convolution(np.conj(A),B[::-1])\\nFIGURE 8.53: Convolution and correlation in python\\n\\x04\\nSeparable convolutions\\nSOL-198 \\uf14b CH.SOL- 8.22.\\n1. No.Since images are usually stored as discrete pixel values one would have to use a\\ndiscrete approximation of the Gaussian function on the ﬁltering mask before performing\\nthe convolution.\\n2. No.\\n2958.3. SOLUTIONS\\n3. Y es it is separable, a factor that has great implications. For instance, separability means\\nthat a 2D convolution can be reduced to two consequent 1D convolutions reducing the\\ncomputational runtime from O (n2 m2) to O (n2 m).\\n\\x04\\n8.3.3 Similarity measures\\nImage, text similarity\\nSOL-199 \\uf14b CH.SOL- 8.23.\\nThe algorithm presented in ( 8.12) normalizes the input vector. This is usually done prior\\nto applying any other method to the vector or before persisting a vector to a database of FVs.\\n\\x04\\nSOL-200 \\uf14b CH.SOL- 8.24.\\n1. The algorithm presented in ( 8.1) is one of the most commonly used image similarity\\nmeasures and is entitled cosine similarity. It can be applied to any pair of images.\\n2. The mathematical formulae behind it is:\\nThe cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and v = {v1, v2, . . . , vN } is deﬁned as:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures the cosine of the angle\\nbetween the vectors irrespective of their magnitude. It is calculated as the dot product\\nof two numeric vectors, and is normalized by the product of the length of the vectors.\\n3. The minimum and maximum values it can return are 0 and 1 respectively. Thus, a\\ncosine similarity value which is close to 1 indicated a very high similarity while that\\nclose to 0 indicates a very low similarity.\\n4. It represents the negative distance in Euclidean space between the vectors.\\n296Chapter 8 DEEP LEARNING\\n\\x04\\nJacard similarity\\nSOL-201 \\uf14b CH.SOL- 8.25.\\n1. The general formulae for the Jaccard similarity of two sets is given as follows:\\nJ(A, B) = |A ∩ B|\\n|A ∪ B|\\n2. That is, the ratio of the size of the intersection of A and B to the size of their union.\\n3. The Jaccard similarity equals:\\n2\\n7\\n4. Given (8.13)\\nFor the three combinations of pairs above, we have\\nJ({11, 16, 17}, {12, 14, 16, 18}) = 1\\n6\\nJ({11, 12, 13, 14, 15}, {11, 16, 17}) = 1\\n7\\nJ({11, 12, 13, 14, 15}, {12, 14, 16, 18}) = 2\\n7\\n\\x04\\nThe Kullback-Leibler Distance\\nSOL-202 \\uf14b CH.SOL- 8.26.\\nEach KLD corresponds to the deﬁnition of:\\ni Jensen [1]\\n2978.3. SOLUTIONS\\nii Bennet [2]\\niii Bigi [3]\\niv Ziv [29]\\n\\x04\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nSOL-203 \\uf14b CH.SOL- 8.27.\\nA Hashing function ( 8.54) maps a value into a constant length string that can be com-\\npared with other hashed values.\\nFIGURE 8.54: The idea of hashing\\nThe idea behind hashing is that items are hashed into buckets, such that similar items\\nwill have a higher probability of hashing into the same buckets.\\nThe goal of MinHash is to compute the Jaccard similarity without actually computing the\\nintersection and union of the sets, which would be slower. The main idea behind MinHash\\nis to devise a signature scheme such that the probability that there is a match between the\\nsignatures of two sets, S1 and S2, is equal to the Jaccard measure [ 12].\\n\\x04\\n298Chapter 8 DEEP LEARNING\\nSOL-204 \\uf14b CH.SOL- 8.28.\\nLocality-Sensitive Hashing (LSH) is a method which is used for determining which items\\nin a given set are similar. Rather than using the naive approach of comparing all pairs of items\\nwithin a set, items are hashed into buckets, such that similar items will be more likely to hash\\ninto the same buckets.\\n\\x04\\nSOL-205 \\uf14b CH.SOL- 8.29.\\nMaximise.\\n\\x04\\n8.3.4 Perceptrons\\nThe Single Layer Perceptron\\nSOL-206 \\uf14b CH.SOL- 8.30.\\nAnswer: one, one, feedback.\\n\\x04\\nSOL-207 \\uf14b CH.SOL- 8.31.\\n1. T rue.\\n2. T rue.\\n3.\\nC(w, b) = 1\\n2n\\n∑\\nx\\n∥y(x) − a(x, w, b)∥2 (8.48)\\nwhere w denotes the collection of all weights in the network, b all the biases, n is the\\ntotal number of training inputs and a(x, w, b) is the vector of outputs from the network\\nwhich has weights w, biases b and the input x.\\n4.\\narg min\\nw,b\\nC(w, b). (8.49)\\n5. Gradient descent.\\n2998.3. SOLUTIONS\\n6. The gradient.\\n7. Stochastic gradient descent. Batch size. Back-propagation.\\n\\x04\\nThe Multi Layer Perceptron\\nSOL-208 \\uf14b CH.SOL- 8.32.\\n1. This operation is a dot product with the given weights. Therefore:\\nout = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 = −0.164 (8.50)\\n2. This operation (sum) is a dot product with the given weights and with the given bias\\nadded. Therefore:\\nout1 = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 + 0.001 = −0.165 (8.51)\\n3. Code snippet 8.55 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 # .type(torch.FloatTensor)\\n3 x= torch.tensor([0.9,0.7])\\n4 w= torch.tensor([-0.3,0.15])\\n5 B= torch.tensor([0.001])\\n6 print (torch.sum(x*w))\\n7 print (torch.sum(x*w) + B)\\nFIGURE 8.55: MLP operations.\\n\\x04\\n300Chapter 8 DEEP LEARNING\\nActivation functions in perceptrons\\nSOL-209 \\uf14b CH.SOL- 8.33.\\n1. Since by deﬁnition:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.52)\\nAnd the output of the linear sum operation was −0.164 then, the output out2 = 0 .\\n2. Code snippet 8.56 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 x= torch.tensor([0.9,0.7])\\n3 w= torch.tensor([-0.3,0.15])\\n4 B= torch.tensor([0.001])\\n5 print (torch.sum(x*w))\\n6 print (torch.sum(x*w) + B)\\n7 print (torch.relu(torch.sum(x*w + B)))\\nFIGURE 8.56: MLP operations.\\n\\x04\\nBack-propagation in perceptrons\\nSOL-210 \\uf14b CH.SOL- 8.34. The answers are as follows:\\n1. Non-differentiable at 0.\\n2. Non-differentiable at 0.\\n3018.3. SOLUTIONS\\n3. Even though for x ̸= 0:\\nf ′(x) = sin 1\\nx − 1\\nx cos 1\\nx, (8.53)\\nthe function is still non-differentiable at 0.\\n4. Non-differentiable at 0.\\n\\x04\\nSOL-211 \\uf14b CH.SOL- 8.35.\\n1. Fig 8.57 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 for i in range(0,w.size(0)):\\n2 print (torch.relu(torch.sum(x*w[i]) + B))\\n3 > tensor([0.])\\n4 > tensor([0.])\\n5 > tensor([0.6630])\\nFIGURE 8.57: MLP operations- values.\\n2. The values at each hidden layer are depicted in 8.58\\n302Chapter 8 DEEP LEARNING\\n0.0\\n0.0\\n0.6630\\nOutput\\nFIGURE 8.58: Hidden layer values, simple MLP .\\n3. Fig 8.59 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 x1= torch.tensor([0.0,0.0,0.6630])# Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 for i in range(0,w1.size(0)):\\n7 print (torch.sum(x1*w1[i]))\\n8 > tensor(0.3912)\\n9 > tensor(-0.5238)\\nFIGURE 8.59: MLP operations- values at the output.\\n4. We can apply the Softmax function like so 8.60:\\n3038.3. SOLUTIONS\\n1 x1= torch.tensor([0.0,0.0,0.6630]) # Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 out1 = torch.tensor([[torch.sum(x1*w1[0]).item()],\\n7 [torch.sum(x1*w1[1]).item()]])\\n8 print (out1)\\n9 yhat = torch.softmax(out1, dim =0)\\n10 print (yhat)\\n11 > tensor([[ 0.3912],\\n12 [-0.5238]])\\n13 > tensor([[0.7140],\\n14 [0.2860]])\\nFIGURE 8.60: MLP operations- Softmax.\\n5. For the cross-entropy loss, we use the Softmax values and calculate the result as follows:\\n−1.0 ∗ log(0.7140) − 0.0 ∗ log(0.2860) = 1 .31 (8.54)\\n\\x04\\nThe theory of perceptrons\\nSOL-212 \\uf14b CH.SOL- 8.36.\\nHe means that theoretically [ 6], a non-linear layer followed by a linear layer, can ap-\\nproximate any non-linear function with arbitrary accuracy, provided that there are enough\\nnon-linear neurons\\n\\x04\\nSOL-213 \\uf14b CH.SOL- 8.37. T rue \\x04\\nSOL-214 \\uf14b CH.SOL- 8.38. T rue \\x04\\n304Chapter 8 DEEP LEARNING\\nSOL-215 \\uf14b CH.SOL- 8.39.\\nFalse. Divided by the training samples, not the number of incorrectly classiﬁed samples. \\x04\\nLearning logical gates\\nSOL-216 \\uf14b CH.SOL- 8.40.\\n1. The values are presented in the following table ( 8.61):\\nBias = −2.5\\nInput Weighted sum Output\\n(0,0) -2.5 0\\n(0,1) -1.5 0\\n(1,0) -1.5 0\\n(1,1) -0.5 0\\nFIGURE 8.61: Logical AND: B=-2.5\\n2. The values are presented in the following table ( 8.62):\\nBias = −0.25\\nInput Weighted sum Output\\n(0,0) -0.25 0\\n(0,1) -0.75 0\\n(1,0) -0.75 0\\n(1,1) 1.75 1\\nFIGURE 8.62: Logical AND: B=-0.25\\n3. The perceptron learning rule is an algorithm that can automatically compute optimal\\nweights for the perceptron.\\n3058.3. SOLUTIONS\\n4. The main addition by [ 22] and [ 18] was the introduction of a differentiable activation\\nfunction.\\n5. if we select w1 = 1;w2 = 1 and threshold=1. We get:\\nx1 = 1, x2 = 1 :\\nn = 1 × 1 + 1 × 1 = 2 ,thus,y = 1\\nx1 = 1, x2 = −1 :\\nn = 1 × 1 + 1 × (−1) = 0 ,thus,y = −1\\nx1 = −1, x2 = 1 :\\nn = 1 × (−1) + 1 × 1 = 0 ,thus,y = −1\\nx1 = −1, x2 = −1 :\\nn = 1 × (−1) + 1 × (−1) = −2,thus,y = −1\\n(8.55)\\nOr summarized in a table ( 8.63):\\nAND gate\\nin1 in2 out\\n0 0 0\\n0 1 0\\n1 0 0\\n1 1 1\\nFIGURE 8.63: Logical AND gate\\n\\x04\\n8.3.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\n306Chapter 8 DEEP LEARNING\\nSOL-217 \\uf14b CH.SOL- 8.41.\\n1. Remember that the analytical derivative is of the sigmoid:\\nd\\ndxs(x) = d\\ndx((1 + e−x)−1) (8.56)\\nd\\ndxs(x) = −1((1 + e−x)(−1−1)) d\\ndx(1 + e−x) (8.57)\\nd\\ndxs(x) = −1((1 + e−x)(−2))( d\\ndx (1) + d\\ndx(e−x)) (8.58)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(0 + e−x( d\\ndx(−x))) (8.59)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(e−x)(−1) (8.60)\\nd\\ndx s(x) = ((1 + e−x)(−2))(e−x) (8.61)\\nd\\ndxs(x) = 1\\n(1 + e−x)2 (e−x) (8.62)\\nd\\ndxs(x) = (e−x)\\n(1 + e−x)2 (8.63)\\nCode snippet 8.64 provides a pure C++ based implementation of the backward pass that\\ndirectly computes the analytical gradients in C++.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001_d(torch ::Tensor & x) {\\n5 torch::Tensor s = sigmoid001(x);\\n6 return (1 - s) * s;\\n7 }\\nFIGURE 8.64: Backward pass for the Sigmoid function using Libtorch.\\n3078.3. SOLUTIONS\\n2. Code snippet 8.65 depicts one way of printing the values.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"\\n9 << sigmoid001_d (t0).data().detach().item().toFloat()\\n10 << \\'\\\\n\\' ;\\n11 }\\n12 }\\nFIGURE 8.65: Evaluation of the sigmoid and its derivative in C++ using Libtorch.\\n3. The manual derivative of eq. 8.27 is:\\n3 ln(2)×\\n[\\n2−1.5x\\n(2−1.5x + 1)2\\n]\\n(8.64)\\n4. The forward pass for the Sigmoid function approximation eq. 8.27 is presented in code\\nsnippet 8.66:\\n308Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 torch::Tensor sig_approx( const torch::Tensor & x ){\\n4 torch::Tensor sig = 1.0 / (1.0 + torch::pow(2,( -1.5*x)));\\n5 return sig;\\n6 }\\nFIGURE 8.66: Forward pass for the Sigmoid function approximation in C++ using Libtorch.\\n5. The values are 8.67: :\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"<< sig_approx (t0).data().detach().item().\\n9 toFloat()<<\\'\\\\n\\' ;\\n10 }\\nFIGURE 8.67: Printing the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch.\\nAn the values are presented in T able 8.2:\\n3098.3. SOLUTIONS\\nValue Sig Approx\\n0 0.5 0.5\\n0.1 0.524979 0.52597\\n0.2 0.549834 0.5518\\n0.3 0.574443 0.577353\\n0.4 0.598688 0.602499\\n0.5 0.622459 0.627115\\n0.6 0.645656 0.65109\\n0.7 0.668188 0.674323\\n0.8 0.689974 0.69673\\n0.9 0.710949 0.71824\\n0.99 0.729088 0.736785\\nTABLE 8.2: Computed values for the Sigmoid and the Sigmoid approximation.\\n\\x04\\nTanh\\nSOL-218 \\uf14b CH.SOL- 8.42.\\nThe answers are as follows:\\n1. The derivative is:\\nftanh(x) = 1 − ftanh(x)2 (8.65)\\n2. Code snippet 8.68 implements the forward pass using pure Python.\\n310Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 xT =\\ntorch.abs(torch.tensor([[0.37,0.192,0.571]],requires_grad=True))↪→\\n3 .type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 tanh_values = np.tanh(xT_np)\\n7 print (\"Numpy:\", tanh_values)\\n8 > Numpy: [[ 0.35399172 0.18967498 0.51609329]]\\nFIGURE 8.68: Forward pass for tanh using pure Python.\\n3. In order to implement a PyT orch based torch.autograd.F unction function such as\\ntanh, we must provide both the forward and backward passes implementation. The\\nmechanism behind this idiom in PyT orch is via the use of a context, abbreviated ctx\\nwhich is like a state manager for automatic differentiation. The implementation is de-\\npicted in 8.69:\\n3118.3. SOLUTIONS\\n1 import torch\\n2\\n3 class TanhFunction(torch.autograd.Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward( x )\\n7 y = x.tanh()\\n8 return y\\n9\\n10 @staticmethod\\n11 def backward(ctx, grad_output):\\n12 input, = ctx.saved_tensors\\n13 dy_dx = 1 / (input.cosh() ** 2)\\n14 out = grad_output * dy_dx\\n15 print (\"backward:{}\".format(out))\\n16 return out\\nFIGURE 8.69: Tanh in PyTorch.\\n4. Code snippet 8.70 veriﬁes the correctness of the implementation using gradcheck.\\n312Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 import numpy as np\\n3 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n4 requires_grad=True))\\n5 .type(torch.DoubleTensor)\\n6 xT_np=xT.detach().cpu().numpy()\\n7 tanh_values = np.tanh(xT_np)\\n8 tanh_values_torch = tanhPyTorch(xT)\\n9 print (\"Torch:\", tanh_values_torch)\\n10 from torch.autograd import gradcheck, Variable\\n11 f = TanhFunction.apply\\n12 test=gradcheck(lambda t: f(t), xT)\\n13 print(test)\\n14 > PyTorch version: 1.7.0\\n15 > Torch: tensor([[ 0.3540, 0.1897, 0.5161]], dtype =torch.float64)\\n16 > backward:tensor([[0.8747, 0.9640, 0.7336]],dtype=torch.float64)\\nFIGURE 8.70: Invoking gradcheck on tanh.\\n\\x04\\nSOL-219 \\uf14b CH.SOL- 8.43.\\n1. The type of NN is a MultiLayer Perceptron or MLP .\\n2. There are two hidden layers.\\n\\x04\\nSOL-220 \\uf14b CH.SOL- 8.44.\\nHe is partially correct , see for example Understanding the difﬁculty of training deep\\nfeedforward neural networks [9]. \\x04\\n3138.3. SOLUTIONS\\nSOL-221 \\uf14b CH.SOL- 8.45.\\nInitialize all parameters to a constant zero value. When we apply the tanh function to an\\ninput which is very large, the output which is almost zero, will be propagated to the remaining\\npartial derivatives leading to the well known phenomenon.\\n\\x04\\nSOL-222 \\uf14b CH.SOL- 8.46.\\nDuring the back-propagation process, derivatives are calculated with respect to (W (1))\\nand also (W (2)). The design ﬂaw:\\ni Y our friend initialized all weights and biases to zero.\\nii Therefore any gradient with respect to (W (2)) would also be zero.\\niii Subsequently, (W (2)) will never be updated.\\niv This would inadvertently cause the derivative with respect to (W (1)) to be always zero.\\nv Finally, would also never be updated (W (1)).\\n\\x04\\nReLU\\nSOL-223 \\uf14b CH.SOL- 8.47.\\nThe ReLU function has the beneﬁt of not saturating for positive inputs since its derivative\\nis one for any positive value.\\n\\x04\\nSOL-224 \\uf14b CH.SOL- 8.48.\\nThe shape is:\\n3 × 3 × 3 × 16\\n\\x04\\nSOL-225 \\uf14b CH.SOL- 8.49.\\nThe activation function is a leaky ReLU which in some occasions may outperform the\\n314Chapter 8 DEEP LEARNING\\nReLU activation function. \\x04\\nSwish\\nSOL-226 \\uf14b CH.SOL- 8.50.\\n1. They intended to ﬁnd new better-performing activation functions.\\n2. They had a list of basic mathematical functions to choose from, for instance the expo-\\nnential families exp(), sin(), min and max.\\n3. Previous research found several activation function properties which were considered\\nvery useful. For instance, gradient preservation and non-monotonicity. However the\\nsurprising discovery was that the swish function violates both of these previously deemed\\nuseful properties.\\n4. The equation is:\\nf (x) = x · σ(x) (8.66)\\n5. The plot is 8.71\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n−1,0\\n−0,5\\n0,5\\n1,0\\nx\\nyx ∗ σ(x) = x ∗ 1\\n1+e−4x\\nFIGURE 8.71: A plot of the Swish activation function.\\n\\x04\\n3158.3. SOLUTIONS\\n8.3.6 Performance Metrics\\nConfusion matrix, precision, recall\\nSOL-227 \\uf14b CH.SOL- 8.51.\\n1. The values are labelled inside 8.27:\\nPredicted\\nP N\\nTruth P TP=12 FN=7\\nN FP=24 TN=1009\\nFIGURE 8.72: TP , TN, FP , FN.\\n2.\\nacc = 12 + 1009\\n12 + 7 + 24 + 1009 = 0.97 (8.67)\\n3.\\nprec = 12\\n12 + 24 = 0.333 (8.68)\\n4.\\nrecall = 12\\n12 + 7 = 0.631 (8.69)\\n\\x04\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\n316Chapter 8 DEEP LEARNING\\nFIGURE 8.73: Receiver Operating Characteristic curve.\\nSOL-228 \\uf14b CH.SOL- 8.52.\\nROC allows to attest the relationship between sensitivity and speciﬁcity of a binary clas-\\nsiﬁer. Sensitivity or true positive rate measures the proportion of positives correctly classiﬁed;\\nspeciﬁcity or true negative rate measures the proportion of negatives correctly classiﬁed. Con-\\nventionally, the true positive rate tpr is plotted against the false positive rate fpr, which is one\\nminus true negative rate.\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween selectivity and sensitivity.\\n2. It is a plot of ‘true positives’ vs. the ‘true negatives’ . In place of ‘true negatives’ ,\\none could also use ‘false positives’ which are essentially 1 - ‘true negatives’ .\\n3. A typical ROC curve has a concave shape with (0,0) as the beginning and (1,1) as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely confused\\nand cannot at all distinguish between the two classes, has an AUC of 0.5, the ‘x = y’\\nline in an ROC curve plot.\\n3178.3. SOLUTIONS\\n\\x04\\nSOL-229 \\uf14b CH.SOL- 8.53.\\nThe ROC curve of an ideal classiﬁer (100% accuracy) has an AUC of 1, with 0.0 ‘false\\npositives’ and 1.0 ‘true positives’ . The ROC curve in our case, is almost ideal, which may\\nindicate over-ﬁtting of the XGBOOST classiﬁer to the training corpus. \\x04\\n8.3.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nSOL-230 \\uf14b CH.SOL- 8.54.\\nOutput dimension: L × L × M where L = n−f +2p\\ns + 1 \\x04\\nSOL-231 \\uf14b CH.SOL- 8.55.\\nThe answers are as follows:\\n1. Output dimensions:\\ni torch.Size([1, 512, 7, 7])\\nii torch.Size([1, 512, 16, 16])\\niii torch.Size([1, 512, 22, 40])\\n2. The layer is MaxPool2d.\\n\\x04\\nSOL-232 \\uf14b CH.SOL- 8.56.\\nThe answers are as follows:\\n1. A convolutional block 8.74.\\n318Chapter 8 DEEP LEARNING\\n1 Sequential(\\n2 (0): Conv2d( 3, 64, kernel_size =(3, 3), stride =(1, 1), padding =(1,\\n1))↪→\\n3 (1): ReLU(inplace =True)\\n4 (2): MaxPool2d(kernel_size =2, stride =2, padding =0, dilation =1,\\nceil_mode=False↪→\\n5 )\\nFIGURE 8.74: Convolutional block from the VGG11 architecture.\\n2. The shapes are as follows:\\ni torch.Size([1, 64, 112, 112])\\nii torch.Size([1, 64, 256, 256])\\niii torch.Size([1, 64, 352, 512])\\n\\x04\\nSOL-233 \\uf14b CH.SOL- 8.57.\\nThe VGG11 architecture contains seven convolutional layers, each followed by a ReLU\\nactivation function, and ﬁve max-polling operations, each reducing the respective feature\\nmap by a factor of 2. All convolutional layers have a 3 × 3 kernel. The ﬁrst convolutional\\nlayer produces 64 channels and subsequently, as the network deepens, the number of channels\\ndoubles after each max-pooling operation until it reaches 512. \\x04\\nDropout\\nSOL-234 \\uf14b CH.SOL- 8.58.\\n1. The observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (8.70)\\n3198.3. SOLUTIONS\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (8.71)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (8.72)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (8.73)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(8.74)\\n2. In dropout, in every training epoch, neurons are randomly pruned with probability\\nP = p sampled from a Bernoulli distribution. During inference, all the neurons are used\\nbut their output is multiplied by the a-priory probability P . This approach resembles to\\nsome degree the model averaging approach of bagging.\\n\\x04\\nSOL-235 \\uf14b CH.SOL- 8.59.\\nThe answers are as follows:\\n1. The idea is true and a solid one.\\n2. The idiom may be exempliﬁed as follows 8.75:\\n320Chapter 8 DEEP LEARNING\\nFIGURE 8.75: Equivalence of two consecutive dropout layers\\nThe probabilities add up by multiplication at each layer, resulting in a single dropout\\nlayer with probability:\\n1 − (1 − p)(1 − q) (8.75)\\n\\x04\\nConvolutional Layer\\nSOL-236 \\uf14b CH.SOL- 8.60.\\nThe result is ( 8.76):\\nFIGURE 8.76: The result of applying the ﬁlter.\\n\\x04\\n3218.3. SOLUTIONS\\nSOL-237 \\uf14b CH.SOL- 8.61.\\nThe result is ( 8.77):\\nFIGURE 8.77: The result of applying a ReLU activation.\\n\\x04\\nSOL-238 \\uf14b CH.SOL- 8.62.\\nThe result is ( 8.78):\\nFIGURE 8.78: The result of applying a MaxPool layer.\\n\\x04\\nPooling Layers\\nMaxPooling\\n322Chapter 8 DEEP LEARNING\\nSOL-239 \\uf14b CH.SOL- 8.63.\\nThe answers are as follows:\\n1. A max-pooling layer is most commonly used after a convolutional layer in order to\\nreduce the spatial size of CNN feature maps.\\n2. The result is 8.79:\\nFIGURE 8.79: Output of the MaxPool2d operation.\\n\\x04\\nSOL-240 \\uf14b CH.SOL- 8.64.\\n1. In MaxPool2D(2,2), the ﬁrst parameter is the size of the pooling operation and the\\nsecond is the stride of the pooling operation.\\n2. The BatchNorm2D operation does not change the shape of the tensor from the previous\\nlayer and therefore it is:\\ntorch.Size ([1, 32, 222, 222]).\\n3. During the training of a CNN we use model.train() so that Dropout layers are ﬁred.\\nHowever, in order to run inference, we would like to turn this ﬁring mechanism off,\\nand this is accomplished by model.eval() instructing the PyT orch computation graph\\nnot to activate dropout layers.\\n4. The resulting tensor shape is:\\ntorch.Size ([1, 32, 55, 55])\\nIf we reshape the tensor like in line 17 using:\\nx = x.view(x.size(0), −1)\\n3238.3. SOLUTIONS\\nThen the tensor shape becomes:\\ntorch.Size ([1, 96800])\\n5. Y es, you should agree with him, as depicted by the following plot 8.80:\\nFIGURE 8.80: A single MaxPool layer.\\n\\x04\\nBatch normalization, Gaussian PDF\\nThe Gaussian distribution\\nSOL-241 \\uf14b CH.SOL- 8.65.\\nThe answers are as follows:\\n1. BN is a method that normalizes the mean and variance of each of the elements during\\ntraining.\\n2. X ∼ N (0, 1) a mean of zero and a variance of one. The standard normal distribution\\noccurs when (σ)2 = 1 and µ = 0.\\n3. In order to normalize we:\\ni Step one is to subtract the mean to shift the distribution.\\nii Divide all the shifted values by their standard deviation (the square root of the\\nvariance).\\n4. In BN, the normalization is applied on an element by element basis. During training at\\neach epoch, every element in the batch has to be shifted and scaled so that it has a zero\\nmean and unit variance within the batch.\\n\\x04\\n324Chapter 8 DEEP LEARNING\\nSOL-242 \\uf14b CH.SOL- 8.66.\\n1. One possible realization is as follows 8.81:\\n1 from math import sqrt\\n2 import math\\n3 def normDist(x, mu, sigSqrt):\\n4 return (1 / sqrt(2 * math.pi * sigSqrt)) * math.e ** ((-0.5) *\\n(x - mu) ** 2 / sigSqrt)↪→\\nFIGURE 8.81: Normal distribution in Python: from scratch.\\n2. The derivative is given by 8.82:\\n1 scipy.stats.norm.pdf(x, mu, sigma) *(mu - x)/sigma**2\\nFIGURE 8.82: The derivative of a Normal distribution in Python.\\n\\x04\\nBN\\nSOL-243 \\uf14b CH.SOL- 8.67.\\n1. During training of a CNN, when a convolution is being followed by a BN layer, for\\neach of the three RGB channels a single separate mean and variance is being computed.\\n2. The mistake he made is using a BN with a batch size of 32, while the output from the\\nconvolutional layer is 64.\\n\\x04\\n3258.3. SOLUTIONS\\nTheory of CNN design\\nSOL-244 \\uf14b CH.SOL- 8.68.\\nT rue.\\n\\x04\\nSOL-245 \\uf14b CH.SOL- 8.69.\\nAll the options may be used to build a CNN. \\x04\\nSOL-246 \\uf14b CH.SOL- 8.70. While the original paper ([ 16]) suggests that BN layers be\\nused before an activation function, it is also possible to use BN after the activation function.\\nIn some cases, it actually leads to better results ([ 4]).\\n\\x04\\nSOL-247 \\uf14b CH.SOL- 8.71.\\nWhen dropout is enabled during the training process, in order to keep the expected output\\nat the same value, the output of a dropout layer must be multiplied with this term. Of course,\\nduring inference no dropout is taking place at all. \\x04\\nSOL-248 \\uf14b CH.SOL- 8.72.\\n1. The idiom is a bottleneck layer ([ 27]), which may act much like an autoencoder.\\n2. Reducing and then increasing the activations, may force the MLP to learn a more com-\\npressed representation.\\n3. The new architecture has far more connections and therefore it would be prone to over-\\nﬁtting.\\n4. Once such architecture is an autoencoder ([ 28]).\\n\\x04\\nCNN residual blocks\\nSOL-249 \\uf14b CH.SOL- 8.73.\\n326Chapter 8 DEEP LEARNING\\n1. The function F is the residual function.\\n2. The main idea was to add an identity connection which skips two layers all together.\\n\\x04\\nSOL-250 \\uf14b CH.SOL- 8.74.\\n1. The missing parts are visualized in ( 8.83).\\nFIGURE 8.83: A resnet CNN block\\n2. The symbol represents the addition operator.\\n3. Whenever F returns a zero, then the input X will reach the output without being\\nmodiﬁed. Therefore, the term identity function.\\n\\x04\\n8.3.8 Training, hyperparameters\\nHyperparameter optimization\\nSOL-251 \\uf14b CH.SOL- 8.75.\\nThe question states that image size is quite large, and the batch size is 1024, therefore it\\nmay fail to allocate memory on the GPU with an Out Of Memory (OOM) error message. This\\n3278.3. SOLUTIONS\\nis one of the most commonly faced errors when junior data-scientist start training models.\\n\\x04\\nSOL-252 \\uf14b CH.SOL- 8.76.\\n1. Since hs is tuning his Hyperparameters on the validation set, he would most probably\\noverﬁt to the validation set which he also used for evaluating the performance of the\\nmodel.\\n2. One way would be to amend the splitting, is by ﬁrst keeping a fraction of the training set\\naside, for instance 0.1, and then split the remaining .90 into a training and a validation\\nset, for instance 0.8 and 0.1.\\n3. His new approach uses GridSearchCV with 5-fold cross-validation to tune his Hyper-\\nparameters. Since he is using cross validation with ﬁve folds, his local CV metrics would\\nbetter reﬂect the performance on an unseen data set.\\n\\x04\\nSOL-253 \\uf14b CH.SOL- 8.77.\\nIn grid search, a set of pre-determined values is selected by a user for each dimension in\\nhis search space, and then thoroughly attempting each and every combination. Naturally, with\\nsuch a large search space the number of the required combinations that need to be evaluated\\nscale exponentially in the number of dimensions in the grid search.\\nIn random search the main difference is that the algorithm samples completely random\\npoints for each of the dimensions in the search space. Random search is usually faster and may\\neven produce better results.\\n\\x04\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nSOL-254 \\uf14b CH.SOL- 8.78.\\nThere is a potential for bias in certain settings such as this. If the whole training set\\nis labelled only by a single radiologist, it may be possible that his professional history would\\n328Chapter 8 DEEP LEARNING\\ninadvertently generate bias into the corpus. Even if we use the form of radiology report reading\\nknown as double reading it would not be necessarily true that the annotated scans would be\\ndevoid of bias or that the quality would be better [ 8].\\n\\x04\\nValidation curve ACC\\nSOL-255 \\uf14b CH.SOL- 8.79.\\nThe answers are as follows:\\n1. A validation curve displays on a single graph a chosen hyperparameter on the hori-\\nzontal axis and a chosen metric on the vertical axis.\\n2. The hyperparameter is the number of epochs\\n3. The quality metric is the error (1 -accuracy). Accuracy, error = (1`accuracy) or loss are\\ntypical quality metrics.\\n4. The longer the network is trained, the better it gets on the training set.\\n5. At some point the network is ﬁt too well to the training data and loses its capability to\\ngeneralize. While the classiﬁer is still improving on the training set, it gets worse on\\nthe validation and the test set.\\n6. At this point the quality curve of the training set and the validation set diverge.\\n\\x04\\nValidation curve Loss\\nSOL-256 \\uf14b CH.SOL- 8.80.\\nThe answers are as follows:\\n1. What we are witnessing is phenomena entitled a plateau. This may happen when the\\noptimization protocol can not improve the loss for several epochs.\\n2. There possible methods are:\\ni Constant\\nii Xavier/Glorot uniform\\n3298.3. SOLUTIONS\\niii Xavier/Glorot normal\\n3. Good initialization would optimally generate activations that produce initial gradients\\nthat are larger than zero. One idea is that the training process would converge faster if\\nunit variance is achieved ([ 16]). Moreover, weights should be selected carefully so that:\\ni They are large enough thus preventing gradients from decaying to zero.\\nii They are not too large causing activation functions to over saturate.\\n4. There are several ways to reduce the problem of plateaus:\\ni Add some type of regularization.\\nii In cases wherein the plateau happens right at the beginning, amend the way weights\\nare initialized.\\niii Amending the optimization algorithm altogether, for instance using SGD instead\\nof Adam and vice versa.\\n5. Since the initial LR is already very low, his suggestion may worsen the situation since\\nthe optimiser would not be able to jump off and escape the plateau.\\n6. In contrast to accuracy, Log loss has no upper bounds and therefore at times may be\\nmore difﬁcult to understand and to explain.\\n\\x04\\nInference\\nSOL-257 \\uf14b CH.SOL- 8.81.\\n1. Usually data augmentation, is a technique that is heavily used during training, espe-\\ncially for increasing the number of instances of minority classes. In this case, augment-\\nations are using during inference and this method is entitled T est Time Augmentation\\n(TTA).\\n2. Here are several image augmentation methods for TTA, with two augmentations shown\\nalso in PyT orch.\\n330Chapter 8 DEEP LEARNING\\nHorizontal ﬂip\\nV ertical ﬂip\\nRotation\\nScaling\\nCrops\\n1 transforms.HorizolntalFlip(p=1)(image)\\n2 transforms.VerticalFlip(p=1)(image)\\nFIGURE 8.84: Several image augmentation methods for TTA.\\n\\x04\\nSOL-258 \\uf14b CH.SOL- 8.82.\\ni Unseen\\nii Overﬁtting\\n\\x04\\n8.3.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nSOL-259 \\uf14b CH.SOL- 8.83.\\nThere is no relation to random number generation, the true meaning is the use of batches\\nduring the training process.\\n\\x04\\nSOL-260 \\uf14b CH.SOL- 8.84.\\nA larger batch size decreases the variance of the gradient estimation of SGD. Therefore, if\\nyour training loop uses larger batches, the model will converge faster. On the other hand, smal-\\n3318.3. SOLUTIONS\\nler batch sizes increase the variance, leading to the opposite phenomena; longer convergence\\ntimes.\\n\\x04\\nMomentum\\nSOL-261 \\uf14b CH.SOL- 8.85.\\nMomentum introduces an extra term which comprises a moving average which is used\\nin gradient descent update rule to exponentially decay the historical gradients Using such\\nterm has been demonstrated to accelerate the training process ([ 11]) requiring less epochs to\\nconverge.\\n\\x04\\nSOL-262 \\uf14b CH.SOL- 8.86.\\nThe answers are as follows:\\n1. The derivative of the logistic activation function is extremely small for either negtive or\\npositive large inputs.\\n2. The use of the tanh function does not alleviate the problem since we can scale and\\ntranslate the sigmoid function to represent the tanh function:\\ntanh(z) = 2 σ(2z) − 1 (8.76)\\nWhile the sigmoid function is centred around 0.5, the tanh activation is centred around\\nzero. Similar to the application of BN, centring the activations may aid the optimizer con-\\nverge faster. Note: there is no relation to SGD; the issue exists when using other optimization\\nfunctions as well. \\x04\\nSOL-263 \\uf14b CH.SOL- 8.87.\\nThe answers are as follows:\\ni T rue.\\nii False. In stochastic gradient descent, the gradient for a single sample is quite different\\n332Chapter 8 DEEP LEARNING\\nfrom the actual gradient, so this gives a more noisy value, and converges slower\\niii T rue.\\niv False. SGD requires less memory.\\n\\x04\\nNorms, L1, L2\\nSOL-264 \\uf14b CH.SOL- 8.88.\\n1. The L2 norm.\\n2. The Euclidean distance which is calculated as the square root of the sum of differences\\nbetween each point in a set of two points.\\n3. The Manhattan distance is an L1 norm (introduced by Hermann Minkowski) while the\\nEuclidean distance is an L2 norm.\\n4. The Manhattan distance is:\\n|6 − 2| + |1 − 8| + |4 − 3| + |5 − (−1)|\\n= 4 + 7 + 1 + 6 = 18 (8.77)\\n5. The Euclidean distance is:\\n√\\n(6 − 2)2 + (1 − 8)2 + (4 − 3)2 + (5 − (−1))2\\n=\\n√\\n102\\n(8.78)\\n\\x04\\nSOL-265 \\uf14b CH.SOL- 8.89.\\nThe PyT orch implementation is in ( 8.85). Note that we are allocating tensors on a GPU\\nbut ﬁrst they are created on a CPU using numpy. This is also always the interplay between\\nthe CPU and the GPU when training NN models. Note that this only work if you have GPU\\navailable; in case there is no GPU detected, the code has a fallback to the CPU.\\n333REFERENCES\\n1 %reset -f\\n2 import torch\\n3 import numpy\\n4\\n5 use_cuda = torch.cuda.is_available()\\n6 device = torch.device(\"cuda\" if use_cuda else \"cpu\")\\n7 print (device)\\n8 x1np=numpy.array([6,1,4,5])\\n9 x2np=numpy.array([2,8,3,-1])\\n10 x1t=torch.FloatTensor(x1np).to(device) # Move to GPU if available\\n11 x2t=torch.FloatTensor(x2np).to(device)\\n12 dist = torch.sqrt (torch .pow(x1t - x2t, 2).sum())\\n13 dist\\n14 >cuda\\n15 >tensor(10.0995, device =\\'cuda:0\\' )\\nFIGURE 8.85: Manhattan distance function in PyTorch.\\n\\x04\\nSOL-266 \\uf14b CH.SOL- 8.90.\\nThe L2 loss is suitable for a target, or a response variable that is continuous. On the other\\nhand, in a binary classiﬁcation problem using LR we would like the output to match either\\nzero or one and a natural candidate for a loss function is the binary cross-entropy loss. \\x04\\nReferences\\n[1] F. T. B. Fuglede. ‘Jensen-Shannon Divergence and Hilbert space embedding’. In:\\nIEEE Int Sym. Information Theory (2004) (cit. on pp. 245, 297).\\n[2] C. Bennett. ‘Information Distance’. In: IEEE T rans. Pattern Anal. Inform. Theory.\\n44:4 (1998), pp. 1407–1423 (cit. on pp. 244, 298).\\n[3] B. Bigi. ‘Using Kullback-Leibler Distance for Text Categorization’. In: In Pro-\\nceedings of the ECIR-2003, Lecture Notes in Computer Science, Springer-Verlag 2633\\n(2003), pp. 305–319 (cit. on pp. 245, 298).\\n334Chapter 8 DEEP LEARNING\\n[4] G. Chen. Rethinking the Usage of Batch Normalization and Dropout in the T raining of\\nDeep Neural Networks. 2019. arXiv: 1905.05928 [cs.LG] (cit. on p. 326).\\n[5] Y . S. Chen et al. ‘Deep photo enhancer: Unpaired learning for image enhance-\\nment from photographs with gans’. In: IEEE Conference on Computer Vision and\\nPattern Recognition. 2018, p. 6306 (cit. on p. 231).\\n[6] I. Ciuca and J. A. Ware. ‘Layered neural networks as universal approximators’.\\nIn: Computational Intelligence Theory and Applications . Ed. by B. Reusch. Berlin,\\nHeidelberg: Springer Berlin Heidelberg, 1997, pp. 411–415 (cit. on p. 304).\\n[7] T. Floyd. Digital Fundamentals. Prentice Hall, 2003 (cit. on p. 252).\\n[8] H. Geijer and M. Geijer. ‘Added value of double reading in diagnostic radi-\\nology ,a systematic review’. In: Insights into Imaging 9 (Mar. 2018). DOI : 10.1007/\\ns13244-018-0599-0 (cit. on pp. 282, 328, 329).\\n[9] X. Glorot and Y . Bengio. ‘Understanding the difﬁculty of training deep feedfor-\\nward neural networks’. In: Journal of Machine Learning Research - Proceedings T rack\\n9 (Jan. 2010), pp. 249–256 (cit. on pp. 258, 313).\\n[10] S. Gomar, M. Mirhassani and M. Ahmadi. ‘Precise digital implementations of\\nhyperbolic tanh and sigmoid function’. In: 2016 50th Asilomar Conference on Sig-\\nnals, Systems and Computers (2016) (cit. on p. 254).\\n[11] I. Goodfellow, Y . Bengio and A. Courville. Adaptive computation and machine\\nlearning. MIT Press, 2016 (cit. on p. 332).\\n[12] J. Gurmeet Singh Manku. ‘Detecting near-duplicates for web crawling’. In: Pro-\\nceedings of the 16th International Conference on World Wide Web (2007), p. 141 (cit.\\non pp. 244, 245, 298).\\n[13] K. He. Deep Residual Learning for Image Recognition . 2015. arXiv: 1512 . 03385\\n(cit. on p. 279).\\n[14] K. He et al. Delving Deep into Rectiﬁers: Surpassing Human-Level Performance on\\nImageNet Classiﬁcation. 2015. arXiv: 1502.01852 [cs.CV] (cit. on pp. 258, 273).\\n[15] A. Ignatov et al. ‘Dslr-quality photos on mobile devices with deep convolu-\\ntional networks’. In: IEEE International Conference on Computer Vision (ICCV) .\\n2017, pp. 3297–3305 (cit. on p. 231).\\n[16] S. Ioffe and C. Szegedy. ‘Batch Normalization’. In: CoRR abs/1502.03167 (2015).\\narXiv: 1502.03167 (cit. on pp. 273, 326, 330).\\n335REFERENCES\\n[17] R. Kohavi. ‘A Study of Cross-Validation and Bootstrap for Accuracy Estima-\\ntion and Model Selection’. In: Morgan Kaufmann, 1995, pp. 1137–1143 (cit. on\\npp. 231, 289).\\n[18] A. Krizhevsky , I. Sutskever and G. E. Hinton. ‘ImageNet Classiﬁcation with\\nDeep Convolutional Neural Networks’. In: Advances in Neural Information Pro-\\ncessing Systems . Ed. by F. Pereira et al. V ol. 25. Curran Associates, Inc., 2012,\\npp. 1097–1105 (cit. on pp. 252, 306).\\n[19] Libtorch: The PyT orch C++ frontend is a C++14 library for CPU and GPU tensor com-\\nputation. 2020 (cit. on pp. 254, 256).\\n[20] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on pp. 266, 267).\\n[21] P . Ramachandran.Searching for Activation Functions . 2017. arXiv: 1710.05941\\n[cs.NE] (cit. on p. 260).\\n[22] D. E. Rumelhart and G. E. Hinton. ‘Learning Representations by Back Propagat-\\ning Errors’. In: Neurocomputing: Foundations of Research . Cambridge, MA, USA:\\nMIT Press, 1988, pp. 696–699 (cit. on pp. 236, 252, 260, 292, 306).\\n[23] S. Sengupta et al. ‘Sfsnet: Learning shape, reﬂectance and illuminance of faces\\nin the wild’. In: Computer Vision and Pattern Regognition (CVPR) . 2018 (cit. on\\np. 231).\\n[24] Z. Shu, E. Yumer and S. Hadap. ‘Neural face editing with intrinsic image dis-\\nentangling’. In: Computer Vision and Pattern Recognition (CVPR) IEEE Conference .\\n2017, pp. 5444–5453 (cit. on p. 231).\\n[25] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 263, 265).\\n[26] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on pp. 266, 267).\\n[27] C. Szegedy et al. ‘Inception v4, Inception-ResNet and the Impact of Residual\\nConnections on Learning’. In: ICLR 2016 Workshop. 2016 (cit. on p. 326).\\n[28] P . Vincent et al. ‘Extracting and composing robust features with denoising au-\\ntoencoders’. In: Proceedings of the 25th international conference on Machine learning .\\n2008, pp. 1096–1103 (cit. on p. 326).\\n336Chapter 8 DEEP LEARNING\\n[29] J. Ziv and N. Merhav . ‘A measure of relative entropy between individual se-\\nquences with application to universal classiﬁcation’. In: IEEE T ransactions on In-\\nformation Theory 39(4) (1993), pp. 1270–1279 (cit. on pp. 245, 298).\\n337REFERENCES\\n338PRACTICE EXAM\\nPART VCHAPTER\\n9\\nJOB INTER VIEW MOCK EXAM\\nA man who dares to waste one hour of time has not discovered the value of life.\\n— Charles Darwin\\nContents\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nClassiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nStressful events, such as a job interview, prompt concern and anxiety (as they do for\\nvirtually every person), but it’s the lack of preparation that fuels unnecessary nervous-\\nness. Many perceive the interview as a potentially threatening event. Testing your\\nknowledge in AI using a mock exam, is an effective way to not only identifying your\\nweaknesses and to pinpointing the concepts and topics that need brushing up, but\\nalso to becoming more relaxed in similar situations. Remember that at the heart of job\\ninterview conﬁdence is feeling relaxed.\\nDoing this test early enough, gives you a head-start before the actual interview, so\\nthat you can target areas that require perfection. The exam includes questions from\\na wide variety of topics in AI, so that these areas are recognised and it would then\\nbe a case of solving all the problems in this book over a period of few months to be\\nproperly prepared. Do not worry even if you can not solve any of the problems in the\\nexam as some of them are quite difﬁcult.DEEP LEARNING JOB INTER VIEW MOCK EXAM\\nEXAM INSTRUCTIONS :\\nYOU SHOULD NOT SEARCH FOR SOLUTIONS ON THE WEB . M ORE GENERALLY , YOU\\nARE URGED TO TRY AND SOLVE THE PROBLEMS WITHOUT CONSULTING ANY REFER -\\nENCE MATERIAL , AS WOULD BE THE CASE IN A REAL JOB INTERVIEW .\\n9.0.1 Rules\\nREMARK: In order to receive credits, you must:\\ni Show all work neatly .\\nii A sheet of formulas and calculators are permitted but not notes or texts.\\niii Read the problems CAREFULLY\\niv Do not get STUCK at any problem (or in local minima ...) for too much time!\\nv After completing all problems, a double check is STRONGLY advised.\\nvi You have three hours to complete all questions.\\n342Chapter 9 JOB INTER VIEW MOCK EXAM\\n9.1 Problems\\n9.1.1 Perceptrons\\nPRB-267 \\uf059 CH.PRB- 9.1. [PERCEPTRONS]\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 9.1: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the resulting value from the application of the sum operator?\\n3. Using PyT orch tensors, verify the correctness of your answers.\\n9.1.2 CNN layers\\nPRB-268 \\uf059 CH.PRB- 9.2. [CNN LAYERS]\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and examine its behaviour during inference:\\n3439.1. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 9.1: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n344Chapter 9 JOB INTER VIEW MOCK EXAM\\nFIGURE 9.2: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet\\na second MaxPool2D(2,2). What is the resulting tensor shape after running line 9?\\nand line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\n9.1.3 Classification, Logistic regression\\nPRB-269 \\uf059 CH.PRB- 9.3. [CLASSIFICATION, LR]\\nT o study factors that affect the survivability of humans infected with COVID19 using\\nlogistic regression, a researcher considers the link between lung cancer and COVID19 as a\\n3459.1. PROBLEMS\\nplausible risk factor. The predictor variable is a count of removed pulmonary nodules (Fig.\\n9.3) in the lungs.\\nFIGURE 9.3: Pulmonary nodules.\\nThe response variable Y measures whether the patient shows any remission (as in the\\nmanifestations of a disease, e. g. yes=1, no=0) when the pulmonary nodules count shifts up\\nor down. The output from training a logistic regression classiﬁer is as follows:\\nStandard\\nParameter DF Estimate Error\\nIntercept 1 -4.8792 1.0732\\nPulmonary nodules 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of removed pulmonary nod-\\nules of a patient is 33.\\n2. Find out the removed pulmonary nodules count at which the estimated probability of\\nimprovement is 0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1, in the total\\nremoved pulmonary nodule count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total removed pulmonary nodule count. Remember that The most common\\nconﬁdence levels are 90%, 95%, 99%, and 99.9%.\\n346Chapter 9 JOB INTER VIEW MOCK EXAM\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 9.1: Common conﬁdence levels\\nT able9.1 lists the z values for these levels.\\n9.1.4 Information theory\\nPRB-270 \\uf059 CH.PRB- 9.4. [INFORMATION THEORY]\\nThis question discusses the link between binary classiﬁcation, information gain and\\ndecision trees. Recent research suggests that the co-existence of inﬂuenza (Fig. 9.4) and\\nCOVID19 virus may decrease the survivability of humans infected with the COVID 19\\nvirus. The data (T able 9.2) comprises a training set of feature vectors with corresponding\\nclass labels which a researcher intents classifying using a decision tree.\\nT o study factors affecting COVID19 eradication, the deep-learning researcher collects\\ndata regrading two independent binary variables; θ1 (T/F) indicating whether the patient is\\na female, and θ2 (T/F) indicating whether the human tested positive for the inﬂuenza virus.\\nThe binary response variable, γ, indicates whether eradication was observed (e.g. eradica-\\ntion=+, no eradication=-).\\n3479.1. PROBLEMS\\nFIGURE 9.4: The inﬂuenza virus.\\nReferring to T able ( 9.2), each row indicates the observed values, columns ( θi) denote\\nfeatures and rows (< θ i, γi >) denote labelled instances while class label ( γ) denotes whether\\neradication was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 9.2: Decision trees and the COVID19 virus.\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\n348Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-271 \\uf059 CH.PRB- 9.5.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh) + p(xt) = 1 , what is the\\nformula for the average surprise?\\n6. What is the value of the average surprise in bits?\\nPRB-272 \\uf059 CH.PRB- 9.6.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\n9.1.5 Feature extraction\\nPRB-273 \\uf059 CH.PRB- 9.7. [FEATURE EXTRACTION]\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n3499.1. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 9.5: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\nCODE 9.2: An unknown algorithm in C++11\\n1 void xxx(std::vector<float>& arr){\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nWhich results in this vector ( 9.6):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 9.6: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n350Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-274 \\uf059 CH.PRB- 9.8.\\n[FEATURE EXTRACTION]\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture for the classiﬁcation of the COVID19 pathogen. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with it\\nby utilizing the same logic.\\nIn (Fig. 9.7), 2 different classes of human cells are displayed; infected and not-infected,\\nwhich were curated from a dataset of 4K images labelled by a majority vote of two expert\\nvirologists. Y our task is to use FE to correctly classify the images in the dataset.\\nFIGURE 9.7: A dataset of human cells infected by the COVID19 pathogen.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture. As depicted,\\nfor each layer the number of ﬁlters (i. e. neurons with unique set of parameters), learnable\\nparameters (e. g. weights and biases), and FV size are presented.\\n3519.1. PROBLEMS\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 9.3: Incomplete listing of the of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4k images from the dataset, how can\\nyou now classify the images into their respective categories?\\n9.1.6 Bayesian deep learning\\nPRB-275 \\uf059 CH.PRB- 9.9. [BAYESIAN DEEP LEARNING]\\nA recently published paper presents a new layer for Bayesian neural networks (BNNs).\\nThe layer behaves as follows. During the feed-forward operation, each of the hidden neurons\\nHn , n ∈ { 1, 2, } in the neural network in (Fig. 9.8) may, or may not ﬁre, independently\\nof each other, according to a known prior distribution.\\n352Chapter 9 JOB INTER VIEW MOCK EXAM\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 9.8: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ B(n, γ ) random variable and ﬁres\\nwith a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U (0, γ) random variable and ﬁres\\nwith a probability of γ.\\nPRB-276 \\uf059 CH.PRB- 9.10.\\nDuring pregnancy, the Placenta Chorion T est is commonly used for the diagnosis of\\nhereditary diseases (Fig. 9.9).\\nFIGURE 9.9: Foetal surface of the placenta\\nAssume, that a new test entitled the Placenta COVID19 T est has the exact same proper-\\nties as the Placenta Chorion T est. The test has a probability of 0.95 of being correct whether\\nor not a COVID19 pathogen is present. It is known that 1/100 of pregnancies result in\\n3539.1. PROBLEMS\\nCOVID19 virus being passed to foetal cells. Calculate the probability of a test indicating\\nthat a COVID19 virus is present.\\nPRB-277 \\uf059 CH.PRB- 9.11.\\nA person who was unknowingly infected with the COVID19 pathogen takes a walk in\\na park crowded with people. Let y be the number of successful infections in 5 independent\\nsocial interactions or infection attempts (trials), where the probability of “success\" (infecting\\nsomeone else) is θ in each trial. Suppose your prior distribution for θ is as follows: P (θ =\\n1/2) = 0 .25, P (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y).\\n2. Derive the prior predictive distribution for y.\\nPRB-278 \\uf059 CH.PRB- 9.12.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history with a death tool far exceeding all past\\noutbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976 in\\nSudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 9.10: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the centre for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\n354Chapter 9 JOB INTER VIEW MOCK EXAM\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y,\\nγ ∈ [0, 1], y = 1, 2, . . . , n ,\\n(9.1)\\nwhere: \\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 = n!\\n(n − y)!y!. (9.2)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ, the\\nproportion of infected humans in the entire population.\\nThe expectation and variance of the binomial are:\\nE(y|γ, n) = nγ, , V (y|γ, n) = nγ(1 − γ). (9.3)\\nAnswer the following:\\n1. For the likelihood function of the form lx(γ) = log Lx(γ) what is the log-likelihood\\nfunction?\\n2. Find the log-likelihood function ln (L(γ))\\n3. Find the gradient vector g(γ)\\n4. Find the Hessian matrix H(γ)\\n5. Find the Fisher information I(γ)\\n6. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\n3559.1. PROBLEMS\\n356VOLUME TWO\\nPART VICHAPTER\\n10\\nVOLUME TWO - PLAN\\nNothing exists until it is measured.\\n— Niels Bohr, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nV ariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . 36110.1. INTRODUCTION\\nT ext to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\n10.1 Introduction\\nI\\nT is important at the outset to understand we could not possibly include\\neverything we wanted to include in the ﬁrst VOLUME of this series. While\\nthe ﬁrst volume is meant to introduce many of the core subjects in AI, the\\nsecond volume takes another step down that road and includes numerous,\\nmore advanced subjects. This is a short glimpse into the plan for VOLUME-2 of this\\nseries. This second volume focuses on more advanced topics in AI\\n10.2 AI system design\\n10.3 Advanced CNN topologies\\n10.4 1D CNN’s\\n10.5 3D CNN’s\\n10.6 Data augmentations\\n10.7 Object detection\\n10.8 Object segmentation\\n10.9 Semantic segmentation\\n10.10 Instance segmentation\\n10.11 Image classification\\n10.12 Image captioning\\n10.13 NLP\\n360Chapter 10 VOLUME TWO - PLAN\\n10.14 RNN\\n10.15 LSTM\\n10.16 GANs\\n10.17 Adversarial attacks and defences\\n10.18 Variational auto encoders\\n10.19 FCN\\n10.20 Seq2Seq\\n10.21 Monte carlo, ELBO, Re-parametrization\\n10.22 Text to speech\\n10.23 Speech to text\\n10.24 CRF\\n10.25 Quantum computing\\n10.26 RL\\n36110.26. RL\\n362List of Tables\\nTumour eradication statistics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\nCommon conﬁdence levels. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nTumour shrinkage in rats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nProbability values of hereditary-disease detection. . . . . . . . . . . . . . . . . 67\\nDecision trees and frogs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\\nDecision trees and Cannabinoids administration . . . . . . . . . . . . . . . . . 96\\nDecision trees and star expansion. . . . . . . . . . . . . . . . . . . . . . . . . . 97\\nDecision trees and radiation therapy . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nSplitting on θ2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . 169\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute\\n∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\\nImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches. . . 193\\nIncomplete listing of the VGG19 architecture . . . . . . . . . . . . . . . . . . . 209\\nIncomplete listing of the VGG11 architecture. . . . . . . . . . . . . . . . . . . . 265\\nComputed values for the Sigmoid and the Sigmoid approximation. . . . . . . 310\\nCommon conﬁdence levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nDecision trees and the COVID19 virus. . . . . . . . . . . . . . . . . . . . . . . . 348\\nIncomplete listing of the of the VGG19 architecture . . . . . . . . . . . . . . . . 352LIST OF TABLES\\n364List of Figures\\nExamples of two sigmoid functions. . . . . . . . . . . . . . . . . . . . . . . . . 15\\nPulmonary nodules (left) and breast cancer (right). . . . . . . . . . . . . . . . . 16\\nA multi-detector positron scanner used to locate tumours. . . . . . . . . . . . 18\\nA dental amalgam. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nA chain of spherical bacteria. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nCannabis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nLogistic regression in CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nA linear model in PyTorch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 25\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 26\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds vs. probability values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\nBinary entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nLogistic regression in C++ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nHistopathology for pancreatic cancer cells. . . . . . . . . . . . . . . . . . . . . 44\\nBosons and fermions: particles with half-integer spin are fermions. . . . . . . 46\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe Dercum disease . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe New York Stock Exchange. . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\nHedge funds and monkeys. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nDialect detection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nThe Morse telegraph code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nOnOffLayer in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 57\\nThe Maxwell-Boltzmann distribution. . . . . . . . . . . . . . . . . . . . . . . . 58\\nA QuantumDrop layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nThe binomial distribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nZ-score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62LIST OF FIGURES\\nConditional probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\nV enn diagram of the intersected events A and B in probability space H . . . . 63\\nAnnotated components of the Bayes formula (eq. 3.23) . . . . . . . . . . . . . . 64\\nMutual information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nReﬂection on the motive power of ﬁre. . . . . . . . . . . . . . . . . . . . . . . . 87\\nNatural (ln), binary (log2) and common ( log10) logarithms. . . . . . . . . . . . . 88\\nA Frog in its natural habitat. Photo taken by my son. . . . . . . . . . . . . . . . 95\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\\nShannon\\'s ﬁve element communications system. . . . . . . . . . . . . . . . . . 99\\nAn octahedral dice. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in information theory . . . . . . . . . . . . . . . . . . . . . . . . . . 102\\nH vs. Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\nShannon information gain for a biased coin toss. . . . . . . . . . . . . . . . . . 107\\nAverage surprise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nFirst split. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nMutual Information between H(S) & H(D). . . . . . . . . . . . . . . . . . . . . 117\\nIntermediate value theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nA Computation graph with intermediate values as nodes and operations as\\narcs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nx2 Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\\nForward pass for the sigmoid function. . . . . . . . . . . . . . . . . . . . . . . . 135\\nPyTorch syntax for autograd. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 137\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 139\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 140\\nA computation graph for g(x) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nA Tangent line . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\n366Chapter 10 LIST OF FIGURES\\nForward and backward passes for the sigmoid activation function in pure\\nPython. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\\nForward and backward for the sigmoid function in Autograd. . . . . . . . . . 159\\nForward and backward for the ReLU function in Autograd. . . . . . . . . . . . 160\\nForward pass for equation ( 5.23) using pure Python. . . . . . . . . . . . . . . . 161\\nForward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . . 161\\nBackward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nInvoking arctanh using gradcheck . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nA Computation graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . 168\\nA derivative graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . . . 169\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 170\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 172\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSymPy gradient of the Sigmoid() function . . . . . . . . . . . . . . . . . . . . . 174\\nSymPy imports . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\\nLikelihood function using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . 176\\nBeta distribution using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\nA plot of the Posterior with the provided data samples. . . . . . . . . . . . . . 181\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 191\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 194\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 195\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 196\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 197\\nA learning rate schedule. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\n367LIST OF FIGURES\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depic-\\nted is the ResNet CNN architecture with 34 layers. . . . . . . . . . . . . . 206\\nPyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 206\\nA dataset of 4K histopathology WSI from three severity classes: A, B and C. . 209\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\\nSkin lesion categories. An exemplary visualization of melanoma. . . . . . . . 214\\nArtistic style transfer using the style of Francis Picabia’s Udnie painting. . . . 215\\nPyTorch declaration for a pre-trained ResNet34 CNN. . . . . . . . . . . . . . . 216\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\\nTwo CV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nStratiﬁed K-fold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nA speciﬁc CV approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 239\\nA 3 by 3 convolution kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 240\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 242\\nlisting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nAn unknown algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\\nJaccard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nA basic MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\n368Chapter 10 LIST OF FIGURES\\nA single layer perceptron. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nExamples of two sigmoid functions and an approximation. . . . . . . . . . . . 254\\nForward pass for the Sigmoid function using Libtorch . . . . . . . . . . . . . . 255\\nEvaluation of the sigmoid and its derivative using Libtorch . . . . . . . . . . . 255\\nExamples of two tanh functions. . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nA simple NN based on tanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 257\\nA small CNN composed of tanh blocks. . . . . . . . . . . . . . . . . . . . . . . 258\\nA small CNN composed of ReLU blocks. . . . . . . . . . . . . . . . . . . . . . 259\\nA confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 261\\nRUC AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\\nXGBOOST for binary classiﬁcation. . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics on the VGG11 CNN model. . . . . . . . . . . . . . . . . . . . 264\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nTwo consecutive Dropout layers . . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nA CNN based classiﬁcation system. . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nA small ﬁlter for a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nInput to MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . . . . 271\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 273\\nNormal distribution in Python. . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nA convolution and BN applied to an RGB image. . . . . . . . . . . . . . . . . . 275\\nA mistake in a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\\nA validation curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog-loss function curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\\nA problem with the log-loss curve. . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nManhattan distance function. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\n369LIST OF FIGURES\\nThe idea of hashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301\\nMLP operations- values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\\nHidden layer values, simple MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- values at the output. . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- Softmax. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\\nLogical AND: B=-2.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND: B=-0.25 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nBackward pass for the Sigmoid function using Libtorch. . . . . . . . . . . . . . 307\\nEvaluation of the sigmoid and its derivative in C++ using Libtorch. . . . . . . 308\\nForward pass for the Sigmoid function approximation in C++ using Libtorch. 309\\nPrinting the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\\nForward pass for tanh using pure Python. . . . . . . . . . . . . . . . . . . . . . 311\\nTanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\\nInvoking gradcheck on tanh. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313\\nA plot of the Swish activation function. . . . . . . . . . . . . . . . . . . . . . . 315\\nTP , TN, FP , FN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 317\\nConvolutional block from the VGG11 architecture. . . . . . . . . . . . . . . . . 319\\nEquivalence of two consecutive dropout layers . . . . . . . . . . . . . . . . . . 321\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nThe result of applying a ReLU activation. . . . . . . . . . . . . . . . . . . . . . 322\\nThe result of applying a MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . 322\\nOutput of the MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . 323\\nA single MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324\\nNormal distribution in Python: from scratch. . . . . . . . . . . . . . . . . . . . 325\\nThe derivative of a Normal distribution in Python. . . . . . . . . . . . . . . . . 325\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nSeveral image augmentation methods for TTA. . . . . . . . . . . . . . . . . . . 331\\nManhattan distance function in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 334\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 345\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346\\n370Chapter 10 LIST OF FIGURES\\nThe inﬂuenza virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 350\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\\nA dataset of human cells infected by the COVID19 pathogen. . . . . . . . . . . 351\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354\\n371LIST OF FIGURES\\n372Alphabetical Index\\nA\\nA 2D convolution . . . . . . . . . . . . . . . . . .235\\nA 512 dimension embedding . . . . . . . 206\\nA mathematical theory of\\ncommunication . . . . . . . . . . . . . 90\\nA random forest . . . . . . . . . . . . . . . . . . . 187\\nACC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .329\\nAccuracy . . . . . . . . . . . . . . . . .251, 283, 329\\nActivation functions . 125, 135 ff., 139 ff.,\\n157 f., 160, 163, 165, 168, 248,\\n256, 301, 306\\nActivation layer . . . . . . . . . . . . . . .253, 306\\nAD . . . . . . . . . . . . . . . . .123 f., 137, 140, 166\\nAdam . . . . . . . . . . . . . . . . . . . . . . . . . . . . .330\\nAdditivity property . . . . . . . . . . . . . . . .103\\nAlexNet . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nAlgorithmic differentiation . . . .125, 135,\\n137, 139 ff., 146, 157 f., 160, 163,\\n165, 168\\nAlzheimer’s disease . . . . . . . . . . . . . . . . . 20\\nAmalgam ﬁllings . . . . . . . . . . . . . . . . . . . 18\\nAnalytical gradients . . . . . . . . . . . . . . . 134\\nAnalyze a paper . . . . . . . . . . . . . . . . . . . 260\\nAND logic gate . . . . . . . . . . . . . . . . . . . . 252\\nANN . . . . . . . . . . . . . . . . . . . . . . . . . . .15, 135\\nAnnotated probabilities . . . . . . . . . . . . .62\\nAnnotations . . . . . . . . . . . . . . . . . . . . . . .282\\nANNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\\nANOV A . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nApproaches for combining predictors\\n190, 199\\nArithmetic operations . . . . . . . . . 138, 163\\nArithmetical methods . . . . . . . . . . . . . . .41\\nArtiﬁcial neural networks . . . . . . . 12, 15\\nAUC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nAugmentation . . . . . . . . . . . . . . . . . . . . .222\\nAugmentations . . . . . . . . . . . . . . . . . . . . . . 8\\nAuto correlation . . . . . . . . . . . . . . .235, 291\\nAutoAugment . . . . . . . . . . . . . . . . . . . . .223\\nAutoencoder . . . . . . . . . . . . . . . . . .279, 326\\nAutoGrad . . . . . . . . . . . . . . . . . . . . .158, 173\\nAutograd124 f., 135–141, 157 f., 160, 163,\\n165, 168, 310\\nAutomatic differentiation . . . .123 f., 173\\nAveraging and majority voting . . . . .202\\nB\\nBack-propagation in perceptrons . . 249,\\n301\\nBack-propogation . . . . . . . . . . . . . . . . . .247\\nBackprop learning . . . . . . . . . . . . . . . . .134\\nBackprop learning rule . . . . . . . . . . . . 134\\nBackpropagation . . . . . . . . . 123, 134, 158\\nBackpropagation algorithm . . . 135, 156\\nBackward pass125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nBagging . . . . . . . . . . . . . .186, 189, 193, 198\\nBasic laws of logarithms . . . . . . . . . . . . 88\\nBatch normalization . . . . . . . . . . .273, 324\\nBatchNorm2D . . . . . . . . . . . . . . . . 271, 343\\nBayes formulae . . . . . . . . . . . . . . . . . .45, 64\\nBayes rule . . . . . . . . . . . . . 45, 47, 66, 353 f.ALPHABETICAL INDEX\\nBayes theorem . . . . 42, 46–50, 65 f., 68 ff.\\nBayesian . . . . . . . . . . . . . . . . . . . . . . . . . . . .77\\nBayesian analysis . . . . . . . . . . . . . . . .65, 77\\nBayesian approximation . . . . . . . . . . . 192\\nBayesian deep learning . . . . . 55, 77, 352\\nBayesian dropout . . . . . . . . . . . . . . . . . .352\\nBayesian inference . . . . . . . . . . . . . . .42, 45\\nBayesian machine learning . . . . . . . . . .54\\nBayesian neural networks . . . . . .55 f., 79\\nBayesian paradigm . . . . . . . . . . . . . . . . . 42\\nBayesian statistical conclusions . . . . . 65\\nBayesian statistics . . . . . . . . . . . . . . . 42, 65\\nBernoulli . . . . . . . . . . . . . . . . . . . . . . .75, 277\\nBernoulli distribution . . . . . . . . . . . . . . .53\\nBernoulli random variable . . . . . . . . . . 18\\nBernoulli trial . . . . . . . . . . . . . . 42 f., 59, 62\\nBeta binomial . . . . . . . . . . . . . . . . . . . . . .146\\nBeta binomial distribution . . . . . . . . .54 f.\\nBeta distribution . . . . . . . 42, 55, 146, 176\\nBeta prior . . . . . . . . . . . . . . . . . . . . . . . . . . .55\\nBias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .282\\nBiased coin . . . . . . . . . . . . . . . . . . . . .92, 349\\nBiased coin toss . . . . . . . . . . . . . . . . . 64, 92\\nBiases . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nBinary class . . . . . . . . . . . . . . . . . . . . . . . . .38\\nBinary classiﬁcation 12, 15, 96, 137, 190,\\n193 f., 246\\nBinary code . . . . . . . . . . . . . . . . . . . . . . . . .90\\nBinary logistic regression . . . . . . . . 14, 31\\nBinary options . . . . . . . . . . . . . . . . . . . . 48 f.\\nBinary response . . . . . . . . . . . . . . . . . . . . .14\\nBinary response variable . . . . . 19, 94, 97\\nBinomial . . . . . . . . . . . . . . . . . . . .43, 53, 354\\nBinomial distribution31, 43, 52 f., 55, 59,\\n78\\nBinomial likelihood . . . . . . . . . . . . 54, 178\\nBinomial random variable . . . . . 43, 59 f.\\nBlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .318\\nBN . . . . . . . . . . . . . . . . . . .273 f., 277, 324 ff.\\nBNN . . . . . . . . . . . . . . . . . . . . . . . . . . 55 f., 79\\nBNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nBohm and Hiley . . . . . . . . . . . . . . . . . . . . 87\\nBoltzmann . . . . . . . . . . . .58, 86, 100 f., 118\\nBoltzmann entropy . . . . . . . . . . . . . . . . 118\\nBoltzmann’s constant . . . . . . . . . . . . . . 100\\nBoltzmanns entropy . . . . . . . . . . . . . . . 101\\nBoosting . . . . . . . . .186, 189, 193, 198, 200\\nBootstrap aggregation . . . . . . . . .189, 192\\nBosons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nBosons and fermions . . . . . . . . . . . . . . . .46\\nBottleneck . . . . . . . . . . . . . . . . . . . . 279, 326\\nBrazilian rain forest . . . . . . . . . . . . . . . . .94\\nBreast cancer . . . . . . . . . . . . . . . . . . . . . . . 17\\nC\\nCalculus . . . . . . . . . . . . . . . . .80, 122 f., 143\\nCalculus in deep learning . . . . . . . . . . 123\\nCancer . . . . . . . . . . . . . . . . . . . . . .16, 43, 208\\nCannabinoids . . . . . . . . . . . . . . . . . . . . . . .96\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . .96\\nCDC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354\\nCE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nChain of spherical bacteria . . . . . . . . . . 20\\nChain rule . . . . . . . . . . . . . . . . . . . . . . . . .163\\nChaotic distribution . . . . . . . . . . . . . . . . 38\\nCI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .35\\nClass probabilities . . . . . . . . . . . . .190, 199\\nClassic bagging . . . . . . . . . . . . . . . . . . . .199\\nClassic logistic regression . . . . . . . . . . . 35\\nClassic normalization . . . . . . . . . . . . . . .29\\nClassical committee machines . . . . . .189\\nClassical machine learning . . . . . . . . . 201\\nClassical probability . . . . . . . . . . . . . . . . 42\\n374Chapter 10 ALPHABETICAL INDEX\\nClassiﬁcation . . . . . 32, 206, 208, 289, 345\\nClassiﬁcation and information gain . 94,\\n110\\nClaud Shannon . . . . . . . . . . . . . . . . . . . . .90\\nCM . . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nCNN . . . 8, 190, 192, 205 f., 216, 272, 274,\\n318, 326, 344, 349\\nCNN arithmetics . . . . . . . . . . . . . . . . . . 318\\nCNN as Fixed Feature Extractor . . . 206,\\n216\\nCNN classiﬁers . . . . . . . . . . . . . . . . . . . .192\\nCNN feature extraction . . . . . . . . . . . . 206\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . .343\\nCNN model predictions . . . . . . . . . . . 190\\nCNN parameters . . . . . . . . . . . . . . . . . . 207\\nCNN residual blocks . . . . . . . . . . . . . . .326\\nCoefﬁcients . . . . . . . . . . . . . . . . . . 12, 16, 27\\nCoffee consumption . . . . . . . . . . . . . . . . 36\\nCoin toss . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nCoin toss probabillity . . . . . . . . . . . . . . . 93\\nCommon conﬁdence levels . . . . . . . . . .21\\nComplementary probability . . . . . . . . .63\\nComputational graph . . . . . . . . . . . . . .140\\nComputational graphs . . 127, 140 f., 165,\\n168\\nConcave . . . . . . . . . . . . . . . . . . . . . . 154, 202\\nConcave and Convex functions . . . . 101\\nConcavity . . . . . . . . . . . . . . . . . . . . .106, 154\\nConcavity of the logarithm . . . . . . . . 106\\nConditional entropy . . . . . . . . . . . . . . . 118\\nConditional independence . . . . . . . . . . 66\\nConditional probability42, 44–50, 62, 69\\nConﬁdence intervals . . . . . . . . . . . . . . . . 37\\nConfusion matrics . . . . . . . . . . . . .261, 316\\nConfusion matrix . . . . . . . . . . . . . . . . . .316\\nConjugate prior . . . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . .54 f., 77\\nContent loss . . . . . . . . . . . . 214, 216, 224 f.\\nConv2D . . . . . . . . . . . . . . . . . . . . . . .271, 343\\nConv2d layer . . . . . . . . . . . . . . . . . . . . . .223\\nConv4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nConvex . . . . . . . . . . . . . . . . . . . . . . . 132, 202\\nConvex down function . . . . . . . . . . . . 119\\nConvex functions . . . . . . . . . . . . . . . . . .132\\nConvNet’s as ﬁxed feature extractors\\n206\\nConvolution . . . . . . . . . . . . . .234, 277, 291\\nConvolution and correlation in python\\n294\\nConvolution complexity . . . . . . . . . . . 240\\nConvolution layer . . . . . . . . . . . . .268, 321\\nConvolutional layer . . . . . . . . . 268, 321 f.\\nConvolutional neural network . . . . . . . 8\\nConvolutional neural networks192, 198\\nCorrelation . . . . . . . . . . . . . . . . . .234 f., 291\\nCost . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nCost function . . . . . . . . . . . . . . . . . . . . . .247\\nCovariance . . . . . . . . . . . . . . . . . . . . . . . .189\\nCovariates . . . . . . . . . . . . . . . . . . . . . . . . . .17\\nCOVID19 . . . . . . . . . . . . . . . . . . . . .345, 351\\nCPP 23 f., 38 f., 142 f., 168 f., 242 f., 254 f.,\\n307 ff.\\nCPP hypothesis . . . . . . . . . . . . . . . . . . . . .23\\nCPU . . . . . . . . . . . . . . . . . . . . . . . . . .222, 289\\nCPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\nCross correlation . . . . . . . . . . . . . .235, 291\\nCross entropy . . . . . . . . . . . . . . . . 25 f., 251\\nCross entropy loss . . . . . . . . . . . . .214, 251\\nCross validation . . . . . . . . . . 231, 289, 328\\nCross validation approaches . . .231, 289\\nCUDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . .289\\nCV . . . . . . . . . . . . . . . . . . . . . . . . . . . .231, 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . 289\\n375ALPHABETICAL INDEX\\nD\\nDAG . . . . . . . . . . . . . . . . .123, 126, 141, 168\\nData Science . . . . . . . . . . . . . . . . . . . . . . . . .4\\nDecision boundary . . . . . . . . . . . . . . . . . .14\\nDecision tree . . . 94 f., 97 f., 111, 187, 198\\nDecision trees . . . . . . . . . . . . . 94, 96 f., 348\\nDecision trees and cannabinoids\\nadministration . . . . . . . . . . . . . . 96\\nDeep Learning . . . . . . . . . . . . . . . . . . . . . . .4\\nDeep learning . . . . . 22, 77, 123, 196, 352\\nDeep Learning Job Interviews . . . . . . . . 6\\nDeep learning pipelines . . . . . . . . . . . .221\\nDental amalgam . . . . . . . . . . . . . . . . . . . .19\\nDercum disease . . . . . . . . . . . . . . . . . . . . .47\\nDifferentiation . . . . . . . . . .122, 143 f., 150\\nDifferentiation in deep learning . . . . 123\\nDirect derivation . . . . . . . . . . . . . . . . . . . .32\\nDirected Acyclic Graph . . . . . . . . . . . . 168\\nDirected acyclic graph . . . . . . . . . . . . . 141\\nDirected acyclic graphs . . . . . . . .126, 147\\nDirectional derivative . . . . . . . . . . . . . .131\\nDirectional derivatives . . . . . . . . . . . . .125\\nDistribution . . . . . . . . . . . . . . . . . . . . . . . . 45\\nDL . . . . . . . . . . . . . . 123, 196, 206, 221, 352\\nDL classiﬁcation pipeline . . . . . . . . . . . 91\\nDL job interviews . . . . . . . . . . . . . . . . . .206\\nDN . . . . . . . . . . . . . . . . . . . . . . . . . .138 f., 163\\nDouble reading . . . . . . . . . . . . . .282 f., 329\\nDPN CNN . . . . . . . . . . . . . . . . . . . . . . . . .223\\nDropout8, 57, 267 f., 277, 319 f., 326, 352\\nDropout as a bayesian approximation\\n192\\nDropout in PyTorch . . . . . . . . . . . . . . . . .56\\nDropout layer . . . . . . . . . . 57, 267 f., 319 f.\\nDropped out neurons . . . . . . . . . . . . . . . 57\\nDual numbers . . . . . . . . . .138 ff., 163, 165\\nDual numbers in AD . . . . . . . . . . 138, 163\\nE\\nEbola . . . . . . . . . . . . . . . . . . . . . . . . .53, 354 f.\\nEmbedding . . . . . . . . . . . . . . . . . . . . . . . .206\\nEncoded messages . . . . . . . . . . . . . . . . . .51\\nEncrypted communications . . . . . . . . . 50\\nEnigma machine . . . . . . . . . . . . . . . . . . . .50\\nEnsemble averaging . . . . . . . . . . . . . . . 193\\nEnsemble learning . . . . . . . .186, 194, 201\\nEnsemble methods . . . . . . . . . . . . 190, 195\\nEnsembling . . . . . .186 ff., 190, 194 f., 197\\nEntropy 22, 38, 86 f., 89, 93, 95, 97 f., 106,\\n108, 214, 349\\nEntry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .186\\nEpidemic . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nEquiprobable events . 90 f., 103, 105, 118\\nEquiprobable sample . . . . . . . . . . . . . . 189\\nEquivocation . . . . . . . . . . . . . . . . . . . . . . . 99\\nEradication . . . . . . . . . . . . . . . . . . . . . . . .347\\nEradication probabillity . . . . . . . . . . . . .18\\nEuclidean . . . . . . . . . . . . . . . . . . . . .288, 333\\nExpansion of stars . . . . . . . . . . . . . . . . . . 97\\nExpectation . . . . . . . . . . . . . . . . . . . . . . . . .62\\nExpectation and variance . . . . . . . . 42, 59\\nExplanatory variable . . . . . . . . . . . . . . . .17\\nExponential family . . . . . . . . . . . . . . . . . .78\\nF\\nFc7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nFeature extraction 214 f., 224 f., 349, 351\\nFeature vector . . . . . . . . . . . . . . . . .205, 350\\nFeature vectors . . . . . . . . . . . . . . . . . . . . . 96\\nFeed forward neural networks 135, 158\\nFermions . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nFFNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\n376Chapter 10 ALPHABETICAL INDEX\\nFiltering . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nFiltering kernel . . . . . . . . . . . . . . . . . . . . 234\\nFilters . . . . . . . . . . . . . . . . . . . . . . . . .239, 293\\nFinancial mathematics . . . . . . . . . . . . . . 42\\nFine tuning CNNs . . . . . . . . . . . . 213, 222\\nFinite difference rule . . . . . . . . . . 125, 147\\nFisher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nFisher information . . . . . . . . . 51, 53, 73 f.\\nFisher score . . . . . . . . . . . . . . . . . . . . . . . . .73\\nFliping . . . . . . . . . . . . . . . . . . . . . . . . . . . .294\\nForward mode . . . . . . . . . .131, 140 f., 168\\nForward mode AD . 140 f., 163, 166, 168\\nForward mode AD table construction\\n142, 168\\nForward pass . 125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nG\\nGausiian distribution . . . . . . . . . .241, 295\\nGaussian . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nGaussian bell . . . . . . . . . . . . . . . . . . . . . .241\\nGaussian distribution . . . . . . . . . 274, 324\\nGaussian PDF . . . . . . . . . . . . . . . . . . . . . 324\\nGeneral concepts . . . . . . . . . . . . . . . . 12, 27\\nGeneralization . . . . . . . . . . . . . . . . 186, 206\\nGeneralized delta rule . . . . . . . . . . . . . 135\\ngeneralized linear models . . . . . . . . . . .14\\nGLM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\\nGLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\nGPU . . . . . . . . . . . . . . . . .222, 281, 289, 327\\nGPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\ngradcheck . . . . . . . . . . . . . . . . . . . . . . . . .310\\nGradient . . . . . . . . . . . . . . . . . . . . . .130, 247\\nGradient descent 123, 130, 146, 158, 247\\nGradient descent algorithm . . . . . . . . 132\\nGradient descent and backpropagation\\n124\\nGradients . . . . . . . . . . . . . . . . . . . . . . . . . .222\\nGram matrix . . . . . . . . . . . . . . . . . . . . . . .225\\nGrid search . . . . . . . . . . . . . . . . . . . 282, 328\\nGum bacteria . . . . . . . . . . . . . . . . . . . . . . .20\\nGUR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\nH\\nHereditary disease . . . . . . . . . . . . . . . . . .66\\nHereditary diseases . . . . . . . . . . . . . . . . .47\\nHessian . . . . . . . . . . . . . . . . . . . . . . . . . . . . .74\\nHessian matrix . . . . . . . . . . . . . . . . . . . . . 52\\nHeterogeneous ensembling . . . .191, 200\\nHidden layer . . . . . . . . . . . . . . . . . . .78, 248\\nHidden layers . . . . . . . . . . . . . . . . . . . . . 250\\nHidden node . . . . . . . . . . . . . 248, 252, 343\\nHinton . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nHistopathology . . . . . . . . . . . .43, 217, 351\\nHuang1704snapshot . . . . . . . . . . . . . . .202\\nHuman voice activity . . . . . . . . . . . . . . . 31\\nHyperbolic tangent . . . . . . . . . . . . . . . . 134\\nHyperbolig tangent . . . . . . . . . . . . . . . .138\\nHyperparameter optimization . . . . . 282,\\n327 f.\\nHyperparameters . . . . . . . . . . . . . . . . . .328\\nHypotheis . . . . . . . . . . . . . . . . . . . . . . . . . .16\\nI\\nIdeal classiﬁer . . . . . . . . . . . . . . . . .262, 317\\nIdentity connection . . . . . . . . . . . . . . . . 326\\nImage analysis . . . . . . . . . . . . . . . . . . . . .110\\nImage and text similarity . . . . . . . . . . 296\\nImage processing . . . . . . . . . . . . . . . . . .234\\nImageNet . . . . . . . . . . . . . . . . . .206 f., 222 f.\\nImageNet pre trained CNNs . . . . . . . 213\\n377ALPHABETICAL INDEX\\nImageNet pretrained CNN classiﬁers\\n192\\nImproper prior . . . . . . . . . . . . . . . . . . . . . 54\\nIndependent binary co variates . . . . . 94\\nIndependent events . . . . . . . . . . . . . . . . .45\\nIndependent variables . . . . . . . . . . .19, 97\\nIndividual predictions . . . . . . . . . . . . . 192\\nInductive inference . . . . . . . . . . . . . . . . . 86\\nInference . . . . . . . . . . . . . . . . . . . . . .286, 330\\nInformation gain . . . . . . . . . . 94–98, 106 f.\\nInformation gain values . . . . . . . . . . . . .95\\nInformation matrix . . . . . . . . . . . . . . . . . 53\\nInformation theory . . . . . . . 58, 86, 88–93,\\n98–101, 106, 347\\nInteractions . . . . . . . . . . . . . . . . . . . . . . . . .13\\nIntermediate value theorem . . . . . . . .124\\nIntersected events . . . . . . . . . . . . . . . . . . .63\\nIntroduction . . . .12, 42, 86, 122, 186, 205\\nJ\\nJacard similarity . . . . . . . . . . . . . . . . . . .297\\nJAX . . . . . . . . . . . . . . . . . . . . . . . . . . .136, 158\\nJensen . . . . . . . . . . . . . . . . . . . . . . . . 101, 119\\nJensen’s inequality . . . . . . . . . . . . 101, 118\\nJob Interview . . . . . . . . . . . . . . . . . . . . . . . . 4\\nJohn von Neumann . . . . . . . . . . . . . . . . . 41\\nJoint distribution . . . . . . . . . . . . . . . . . . 110\\nJupyter notebook . . . . . . . . . . . . . . . . . . 143\\nK\\nK Fold cross validation . . . . . . . . . . . . 289\\nK way FC layer . . . . . . . . . . . . . . . . . . . . 217\\nK-Fold cross validation . . . . . . . . . . . . 232\\nKaggle . . . . . . . . . . . . . . . . . . . . . . . .186, 201\\nKaggle competitions . . . . . . . . . . . . . . .201\\nKaiming . . . . . . . . . . . . . . . . . . . . . . . . . . .258\\nKernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nKernels . . . . . . . . . . . . . . . . . . . . . . . 239, 293\\nKL divergence . . . . . . . .53, 93, 100 f., 109\\nKLD . . . . . . . . . . . . . . . . . . . . . . .93, 119, 297\\nKullback Leibler . . . . . . . . . . . . . . . . . . .297\\nKullback Leibler divergence 87, 93, 108\\nL\\nL1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288, 333\\nL2 . . . . . . . . . . . . . . . . . . . . . . . . . . .288, 333 f.\\nLabelling and bias . . . . . . . . . . . . . . . . . 328\\nLaTeX . . . . . . . . . . . . . . . . . . . . . . . . .174, 176\\nLaw of total probability42, 46–50, 66–70\\nLaws of data compression . . . . . . . . . . 86\\nLDCT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nLeaky ReLU . . . . . . . . . . . . . . . . . . . . . . .259\\nLearning logical gates . . . . . . . . . . . . . .305\\nLearning rate schedules in ensembling\\n197, 202\\nLeave one out CV . . . . . . . . . . . . . . . . . .290\\nLeave-one-out CV . . . . . . . . . . . . . . . . . 234\\nLibtorch . . . . . . . . . . . . . .254 f., 257, 307 ff.\\nLikelihood . . . . . . . . . . . . . . . . . . . .44 f., 353\\nLikelihood function . . . 51, 53, 56, 73, 79\\nLikelihood parameter . . . . . . . . . . . . . . .45\\nLimits and continuity . . . . . . . . . 130, 151\\nLinear classiﬁers . . . . . . . . . . . . . . . . . . .219\\nLinear combination of regression . . 201\\nLinear decision boundary . . . . . . . . . . . 14\\nLinear logistic regression model . . . . . 33\\nLinear model in PyTorch . . . . . . . . . . . .24\\nLinear regression . . . . . . . . . . . . . . . . . . 133\\nLinear transformation . . . . . . . . . . . . . 343\\nLinearity . . . . . . . . . . . . . . . . . . . . . . . . . . 235\\nLink function . . . . . . . . . . . . . . . . . . . . . . .31\\nLocal minima . . . . . . . . . . . . . . . . . 198, 202\\n378Chapter 10 ALPHABETICAL INDEX\\nLog likelihood . . . . . . . . . . . . . . . . . . . . . .13\\nLog likelihood function . . 51, 53, 73, 355\\nLog loss . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog odds . . . . . . . . . . . . 13 f., 17 f., 20 f., 29\\nLogarithm . . . . . . . . . . . . . . . . . . . 35, 53, 72\\nLogarithmic function . . . . . . . . . . . . . . 166\\nLogarithms . . . . . . . . . . . .88 f., 101 ff., 172\\nLogarithms in information theory . . . 87\\nLogic gate . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical gates . . . . . . . . . . . . . . . . . .251, 305\\nLogistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogistic inverse . . . . . . . . . . . . . . . . . . . . .14\\nLogistic regression 12–16, 24 ff., 28 f., 31,\\n36, 137, 345\\n• Sigmoid . . . . . . . . . . . . . . . . . . . . . .253\\nLogistic regression classiﬁer . . . . . . . . .19\\nLogistic regression coefﬁcients . . . . . . 16\\nLogistic regression implementation23 f.\\nLogistic regression in C++ . . . . . . . . . . 39\\nLogistic regression in Python . . . . . . . 26\\nLogistic regression model . . . . . . . .27, 35\\nLogistic regression predictor variable12\\nLogistic regression threashold . . . . . . .39\\nLogistic response function . . . . . . . . . . 33\\nLogit . . . . . . . . . . . . . . . . . . . . . . . . . . . .14, 32\\nLogit equation . . . . . . . . . . . . . . . . . . . . . .16\\nLogit function . . . . . . . . . . . . . . . .14, 22, 31\\nLogit inverse . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogit transformation . . . . . . . . . . . . . . . .14\\nLogit value . . . . . . . . . . . . . . . . . . . . . . . . . 33\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . .234, 290\\nLoss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .334\\nLoss function . . . . . . . . . . . . . . . . . . . . . .133\\nLow model generalization . . . . . . . . . 109\\nLow standard error . . . . . . . . . . . . . . . . . 75\\nLower entropy . . . . . . . . . . . . . . . . . . . . . .38\\nLR . . . . . . . . . . . . . 16, 27, 33, 133, 137, 345\\nLR coefﬁcients . . . . . . . . . . . . . . . . . . . . . .16\\nLung cancer . . . . . . . . . . . . . . . . . . . .17, 282\\nM\\nM.Sc in Artiﬁcial Intelligence . . . . . . . . . 4\\nMachine learning . . . . . . 13 f., 25, 28, 316\\nMachine learning terminology . . . . . . 13\\nMacLaurin expansion . . . . . . . . . . . . . .128\\nMacLaurin series . . . . . . . . . . . . . . . . .128 f.\\nMagna Carta . . . . . . . . . . . . . . . . . . . . . . . .90\\nMajority voting . . . . . . . . . . .186, 190, 202\\nMalignant tumour . . . . . . . . . . . . . . . . . . 17\\nMalignant tumours . . . . . . . . . . . . . . . . . 96\\nManhattan . . . . . . . . . . . . . . . . . . . .288, 333\\nManual differentiation . . . . . . . . 124, 170\\nMaster’s programme in Artiﬁcial\\nIntelligence . . . . . . . . . . . . . . . . . . .4\\nMasters programme . . . . . . . . . . . . . . . . . 4\\nMathJax . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nMaximum likelihood estimatator . . . .73\\nMaximum likelihood estimation . 51, 71\\nMaxpool2D . . . . . . . . . . . . . . . . . . .271, 343\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxwell Boltzmann distribution . . . . 57\\nMaxwell distribution . . . . . . . . . . . . . . . 58\\nMean ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .241\\nMean square error . . . . . . . . . . . . . . . . . 225\\nMeasurement vector . . . . . . . . . . . . . . . . 16\\nMechanical statistics . . . . . . . 42, 100, 118\\nMedical AI . . . . . . . . . . . . . . . . . . . . . . . . 217\\nMelanoma . . . . . . . . . . . . . . . . . . . . . . . . .213\\nMigraine probabillity . . . . . . . . . . . . . . . 20\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . .298\\nML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .316\\nMLE . . . . . . . . . . . . . . . . . . .51, 53, 72 f., 355\\nMLP . . . . . . . . . . . . . . .246 ff., 252, 299, 343\\n379ALPHABETICAL INDEX\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . .332\\nMonolithic and heterogeneous\\nensembling . . . . . . . . . . . .191, 200\\nMonolithic architectures . . . . . . . . . . . 200\\nMonolithic ensembling . . . . . . . . . . . . 191\\nMonotonically increasing function . . 72\\nMonte Carlo dropout . . . . . . . . . . . . . . 192\\nMSE . . . . . . . . . . . . . . . . . . . . . .225, 288, 333\\nMulti class responses . . . . . . . . . . . . . . . 29\\nMulti Layer Perceptrons . . . . . . . . . . . 246\\nMulti layer perceptrons . . . . . . . . . . . . 299\\nMulti model ensembling . . . . . . 196, 202\\nMulticlass classiﬁcation . . . . . . . . . . . . . 12\\nMulticlass classiﬁcation problems . . . 12\\nMultivariable . . . . . . . . . . . . . . . . . . . . . . .12\\nMultivariable methods . . . . . . . . . . . . . .12\\nMutual information . . .86, 94, 98 ff., 110,\\n116\\nMutual information formulae . . . . . . 117\\nN\\nN dimensional feature vector . . . . . . 205\\nNatural logistic function . . . . . . . . . . . . 14\\nNatural logistic sigmoid . . . . . . . . . . . . 14\\nNegative log likelihood . . . . . . . . . . . . . 13\\nNeural network . . . . . . . . . . . . . . .195, 202\\nNeural network ensembles . . . . 186, 191\\nNeural networks . . 55, 57, 127, 135, 158,\\n186\\nNeural style transfer . . . . . . . . . . . . . 214 f.\\nNeuron activation function . . . . . . . . . 15\\nNew York stock exchange . . . . . . . . . . .48\\nNLL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .13\\nNN . . . . . . . . . . 55, 127, 135, 158, 186, 202\\nNN Layers . . . . . . . . . . . . . . . . . . . . . . . . 318\\nNoise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99\\nNon convex neural networks . . . . . . 203\\nNon informative prior . . . . . . . . . . . . . . 54\\nNon informative priors . . . . . . . . . . . . . 77\\nNon interacting identical particles . 118\\nNon linearity . . . . . . . . . . . . . . . . . . . . . .301\\nNon-differentiable . . . . . . . . . . . . . . . . .301\\nNon-linearity . . . . . . . . . . . . . . . . . . . . . .248\\nNonlinear layer . . . . . . . . . . . . . . . 253, 306\\nNormal distribution . . . . . . . . . . .274, 324\\nNormalization constant . . . . . . . . . . . . .64\\nNST . . . . . . . . . . . . . . . . . . . . . . . . . . . . .214 f.\\nNumerical Differentiation . . . . . . . . . .147\\nNumerical differentiation . . .124 ff., 146,\\n173\\nNumerical instability . . . . . . . . . . . . . . 146\\nNumpy . . . . . . . . . . . . . . . . . . . . . . . . . . . .221\\nO\\nOctahedral dice . . . . . . . . . . . . . . . . . . . .101\\nOdds . . . . . . . . . . . . . . . . . . . . . . . . . .12 f., 29\\nOdds of success in a binary response 14\\nOnOffLayer . . . . . . . . . . . . . . . . . . . . .56, 78\\nOOM . . . . . . . . . . . . . . . . . . . . . . . . .281, 327\\nOptimization . . . . . . . . . . . . . . . . . .131, 153\\nOptimization loss . . . . . . . . . . . . . . . . . .331\\nOrdinary predictors . . . . . . . . . . . . . . . . .28\\nOut of memory . . . . . . . . . . . . . . . 281, 327\\nOverﬁtting . . . . . . . . . . . . . . . . . .12, 27, 194\\nP\\nP value . . . . . . . . . . . . . . . . . . . . . . . . . . . . .36\\nPadding . . . . . . . . . . . . . . . . . . . . . . 236, 292\\nPancreactic cancer . . . . . . . . . . . . . . . . . . 43\\nPancreatic cancer classiﬁcation . . . . . 208\\nPartial derivative . . . . . . . . . . . . . . . . . . . 53\\nPartial derivatives . . . . . .130 ff., 142, 152\\n380Chapter 10 ALPHABETICAL INDEX\\nParticle physics . . . . . . . . . . . . . . . . . . . . .45\\nPDF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nPerceptron . . . . . . . . . . . . . . . . . . . .246, 299\\nPerceptron learning rule . . . . . . . . . . . 252\\nPerceptrons . . . . . . . . . .299, 301, 304, 343\\nPerformance metrics . . . . . . . . . . . . . . .316\\nPhysical constants . . . . . . . . . . . . . . . . . 100\\nPlacenta Chorion Test . . . . . . . . . . . . . .353\\nPlacenta chorion test . . . . . . . . . . . . . . 46 f.\\nPlanck’s constant . . . . . . . . . . . . . . . . . . 100\\nPlateau . . . . . . . . . . . . . . . . . . . . . . . . . . . .284\\nPMF . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43, 59\\nPoisson . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75\\nPoisson distribution . . . . . . . . . . . . . . . . 53\\nPooling Layer . . . . . . . . . . . . . . . . . . . . . 270\\nPooling layer . . . . . . . . . . . . . . . . . . . . . . 322\\nPosterior . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPosterior and prior predictive\\ndistributions . . . . . . . . . . . . . . . . 54\\nPosterior distribution . 54, 146, 180, 354\\nPosterior predictive distributions . . . 76\\nPre trained CNN . . . . . . . . . . . . . . . . . . 349\\nPre trained CNNs . . . . . . . . . . . . . . . . . .205\\nPre trained VGG19 CNN model . . . . 220\\nPrecision . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nPredictor variables . . . . . . . . . . . . . . . . . .28\\nPrior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPrior distribution . . . . . . . . . . . . . . . . . . . 45\\nPrior distributions . . . . . . . . . . . . . . . . . . 77\\nPrior predictive distribution . . . . 54, 354\\nProbabilistic programming . . . . . . . . . .42\\nProbability distribution . . . . . . . . . .13, 94\\nProbability mass function . . . . . . . .43, 60\\nProbability of failure . . . . . . . . . . . . . . . .28\\nProbability space . . . . . . . . . . . . . . . . . . . 44\\nProbability statements . . . . . . . . . . . . . . 65\\nProblems . . . . . . . . . . . . . . . . . .12, 186, 206\\nProton theraphy . . . . . . . . . . . . . . . . . . . . 43\\nProton therapy . . . . . . . . . . . . . . . . . . 16, 43\\nPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .16, 43\\nPulmonary nodules . . . . . . . . . . . 282, 345\\nPyMc3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nPython . 7, 23–27, 38 ff., 42, 56 f., 88, 102,\\n107 f., 112, 114, 123, 134, 136,\\n138, 140, 143 f., 157, 159 f., 163,\\n165 f., 170, 172 f., 175 ff., 179,\\n181, 191, 195–198, 202, 206,\\n210 f., 218, 221, 223 f., 232,\\n239 ff., 250 f., 256 f., 263 f., 266 ff.,\\n272, 282, 288, 294 f., 300–304,\\n312, 319 f., 330, 343 f., 349\\nPython coin toss . . . . . . . . . . . . . . . . . . . 108\\nPython interpreter . . . . . . . . . . . . . . . . . . 88\\nPyTorch . 7, 23–26, 38, 40, 56 f., 123, 134,\\n136, 138, 140, 143, 157, 159 f.,\\n163, 165 f., 170, 173, 176 f., 181,\\n191, 195 ff., 202, 206, 210 f., 218,\\n221, 223 f., 254–257, 267 f., 272,\\n288, 307 ff., 319 f., 343 f., 349\\nPytorch . . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nPyTorch code snippet for an ensemble\\n191\\nPyTorch sequential . . . . . . . . . . . . . . . . 257\\nPyTorch tanh . . . . . . . . . . . . . . . . . . . . . .257\\nQ\\nQuadratic equation . . . . . . . . . . . . . . . . . 80\\nQuantum drop . . . . . . . . . . . . . . . . . . . . . .57\\nQuantum physics . . . . . . . . . . . . . . . . . .100\\nQuantum states . . . . . . . . . . . . . . . . . . . . .45\\nQuantum term speed . . . . . . . . . . . . . . . 79\\n381ALPHABETICAL INDEX\\nR\\nRadiation therapy . . . . . . . . . . . . . . . 17, 98\\nRadiation therapy planning . . . . . . . . . 17\\nRadiology . . . . . . . . . . . . . . . . . . . . . . . . .282\\nRandom guess classiﬁer . . . . . . . 262, 317\\nRandom number seeds . . . . . . . . . . . . 186\\nRandom search . . . . . . . . . . . . . . . 282, 328\\nRecall . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic . . 261\\nReceiver operating characteristic . . . 316\\nRectiﬁcation . . . . . . . . . . . . . . . . . . . . . . .306\\nRelative entropy . . . . .98 f., 109, 117, 349\\nRelative maxima and minima . . . . . . 132\\nRelative risk . . . . . . . . . . . . . . . . . . . . . . . .34\\nRelative shrinkage frequency . . . . . . 112\\nRelative star expansion frequency . . 115\\nReLU . . . .248 f., 253, 258 f., 301, 306, 314\\nRendering sympy in Google colab . 143\\nResNet . . . . . . . . . . 205, 207, 211, 217, 223\\nResNet152 . . . . . . . . . . . . . . . . . . . . . . . . .205\\nResNet18 . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nResNet34 . . . . . . . . . . . . . . . . .205, 211, 349\\nResNet34 CNN . . . . . . . . . . . . . . . . . . . .211\\nResNetBottom . . . . . . . . . . . . . . . . . . . . .211\\nResNets . . . . . . . . . . . . . . . . . . . . . . . . . . .326\\nResponse variable . . . . . . . . . . 12 f., 17, 29\\nReversing probabilities . . . . . . . . . . . . . 47\\nROC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nROC AUC . . . . . . . . . . . . . . . . . . . . . . . . .316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . .261\\nRosenblatt . . . . . . . . . . . . . . . . . . . . . . . . .252\\nRR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34\\nRussakovsky . . . . . . . . . . . . . . . . . . . . . . 206\\nRussakovsky 2015 . . . . . . . . . . . . . . . . . 206\\nS\\nSaddle points . . . . . . . . . . . . . . . . . . . . . .155\\nSame padding . . . . . . . . . . . . 236, 238, 292\\nSample odds ratio . . . . . . . . . . . . . . . . . . 37\\nSampling approaches . . . . . . . . . . . . . .189\\nSampling with replacement . . . 189, 199\\nSampling without replacement 189, 199\\nSearch space . . . . . . . . . . . . . . . . . . 282, 328\\nSecond derivative test . . . . . . . . . . . . . 132\\nSeed values in AD . . . . . . . . . . . . .142, 170\\nSequential . . . . . . . . . . . . . . . . . . . . . . . . .221\\nSGD . . . . . . . . . . . . . . . . . . . . . .286 f., 330 ff.\\nShannon . . . . . . . 86 f., 89, 100, 103 f., 117\\nShannon bit . . . . . . . . . . . . . . . . . . . . . . . . .90\\nShannon’s famous general formulae\\n103\\nShannon’s general formulae . . . . . . . . 89\\nShift-invariance . . . . . . . . . . . . . . . . . . . .235\\nSigmoid . . . 15, 23, 32, 134, 137, 144, 160,\\n253, 306\\nSigmoid activation function . . . . 33, 137,\\n157 f., 160\\nSigmoid derivative . . . . . . . . . . . . . . . . . 15\\nSigmoid function . . . . . . . . . . . . . . . . . . 157\\nSigmoid gradient . . . . . . . . . . . . . .144, 173\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . 173\\nSigmoidal neuron . . . . . . . . . . . . . . . . . .247\\nSigmoidal perceptron . . . . . . . . . . . . . .246\\nSimilarity measures . . . . . . . . . . . . . . . .296\\nSimple differentiation . . . . . . . . . 144, 172\\nSingle Layer Perceptrons . . . . . . . . . . .246\\nSingle layer perceptrons . . . . . . . . . . . 299\\nSingle model based AI systems . . . . 186\\nSingle predictors . . . . . . . . . . . . . . . . . . .201\\nSkip connection . . . . . . . . . . . . . . . . . . . .326\\nSnapshot ensembling . . . 189 f., 195, 201\\n382Chapter 10 ALPHABETICAL INDEX\\nSobel ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .294\\nSoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nsoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . . .217\\nSoftmax activation . . . . . . . . . . . . . . . . .251\\nSoftmax activation function . . . . . . . . . 32\\nSoftmax derivation . . . . . . . . . . . . . . . . . 32\\nSoftmax function . . . . . . . . . . . . . . . . 32, 40\\nSoftmax layers . . . . . . . . . . . . . . . . . . . . . .29\\nSoftmax neurons . . . . . . . . . . . . . . . . . . .214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . .198\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . .49\\nSpeed of light in vacum . . . . . . . . . . . . 100\\nSperable convolutions . . . . . . . . .241, 295\\nSplitting criterion . . . . . . . . . . . . . . . . . .111\\nStacking . . . . . . . . . . . . . . . . . .186, 189, 198\\nStacking and bagging . . . . . . . . . . . . . .187\\nStan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nStandard deviation . . . . . . . . . . . . . . . . . 61\\nStar density . . . . . . . . . . . . . . . . . . . . . . . . .97\\nStar expansion . . . . . . . . . . . . . . . . . . . . .115\\nStatic committee machines . . . . . . . . . 201\\nStatistical distribution . . . . . . . . . . . . . . .44\\nStatistical independence . . . . . . . . . . . . 45\\nStatistical mechanics . . . . . . . . . . . . .11, 86\\nStochastic . . . . . . . . . . . . . . . . . . . . . . . . . .287\\nStochastic gradient descent . . . . 247, 331\\nStochastic gradient descent, SGD . . 286\\nStock markets . . . . . . . . . . . . . . . . . . . . . . .48\\nStocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .48\\nStratiﬁcation . . . . . . . . . . . . . . . . . . 233, 290\\nStratiﬁed K fold . . . . . . . . . . . . . . . . . . . 290\\nStratiﬁed K-Fold . . . . . . . . . . . . . . . . . . .233\\nStride . . . . . . . . . . . . . . . . . . . . 236, 292, 323\\nSTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\nStyle loss . . . . . . . . . . . . . . . 214, 216, 224 f.\\nStyle transfer . . . . . . . . . . . . . . 214 f., 224 f.\\nSupervised learning . . . . . . . . . . . . . . . . 28\\nSupervised machine learning . . . . . . . 12\\nSurprise . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . .260, 315\\nSymbolic differentiation . . . 123 f., 143 f.,\\n172 f.\\nSymPy . . . . . . . . .124, 143 f., 146, 173, 177\\nT\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310\\ntanh . . . . . . . . . . . . . . . . . . . . 253, 256 f., 306\\nTaylor series . . . . . . . . . . . . . . . . .122, 128 f.\\nTaylor series and dual numbers . . . . 163\\nTaylor series expansion . . . . . . 128 f., 150\\nTest set . . . . . . . . . . . . . . . . . . . . . . . . . . . .328\\nThe backpropagation algorithm . . . . 134\\nThe bayesian school of thought . . . . . 42\\nThe beta binomial model . . . . . . 144, 174\\nThe chain rule . . . . . . . . . . . . . . . . .127, 149\\nThe convolution operator . . . . . 234, 291\\nThe correlation operator . . . . . . .234, 291\\nThe gaussian distribution . . . . . . . . . . 324\\nThe gradient descent algorithm . . . . 155\\nThe gram matrix . . . . . . . . . . . . . . . . . . .225\\nThe hyperplane . . . . . . . . . . . . . . . . . 14, 31\\nThe Kullback Leibler distance . . . . . . 297\\nThe Likelihood function . . . . . . . . . . . 174\\nThe logit function and entropy . . . . . . 38\\nThe multi layer perceptron . . . . . . . . . 300\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . .32\\nThe sigmoid . . . . . . . . . . . . . . . . . . . . . . . . 15\\nThe sigmoid function . . . . . . . . . . . . . . . 29\\nThe theory of perceptrons . . . . . . . . . .304\\nTheory of CNN design . . . . . . . . . . . . .326\\nThermodynamics . . . . . . . . . . 86, 100, 103\\nTopologies . . . . . . . . . . . . . . . . . . . . . . . . .318\\nToxic mercury fumes . . . . . . . . . . . . . .18 f.\\n383ALPHABETICAL INDEX\\nTrain validation split . . . . . . . . . . . . . . .281\\nTraining corpus . . . . . . . . . . . . . . . 189, 200\\nTraining curve curve . . . . . . . . . . 283, 329\\nTraining hyperparameters . . . . . . . . . 327\\nTraining validation epoch . . . . . . . . . .196\\nTransformation . . . . . . . . . . . . . . . . . . . .222\\nTriangle inequality . . . . . . . . . . . . . . . . .109\\nTrue probability distribution . . . . . . . . 93\\nTruly understanding LR . . . . . . . . . 16, 33\\nTTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .69\\nTumors . . . . . . . . . . . . . . . . . . . . . . . . . . . . .98\\nTumour eradication . . . . . . . . . . . . . 17, 34\\nTumour shrinkage . . . . . . . . . . . . . . . . . .96\\nTumour shrinkage in rats . . . . . . . . . . . 22\\nTwo dimensional matrix . . . . . . . . . . . . 24\\nU\\nUncertainty . . . . . . . . . . . . . . . . . . . . . . .89 f.\\nUniversal function approximators . 251\\nV\\nValid padding . . . . . . . . . . . . 236, 238, 292\\nValidation curve . . . . . . . . . . . . . . 283, 329\\nValidation curve ACC . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . .329\\nValidation set . . . . . . . . . . . . . . . . . . . . . .328\\nVanilla linear regression . . . . . . . . . . . . .14\\nVanishing gradients . . . . . . . . . . . . . . . .258\\nVariance . . . . . . . . . . . .42 f., 59, 62, 74, 201\\nV enn diagram . . . . . . . . . . . . . . . . .44 f., 99\\nVGG . . . . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nVGG conv43 layer . . . . . . . . . . . . . . . . . 209\\nVGG fc7 layer . . . . . . . . . . . . . . . . . . . . . 209\\nVGG Net . . . . . . . . . . . . . . . . . . . . . .205, 216\\nVGG16 . . . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nVGG19 . . . . . . . . . . . . . . . . . . . 209, 221, 351\\nVGG19 architecture . . . . . . . . . . . . . . . .208\\nVGG19 CNN . . . . . . . . . . . . . 208, 218, 351\\nV oting power . . . . . . . . . . . . . . . . . . . . . .201\\nVumulative distribution . . . . . . . . . . . . .62\\nW\\nWald chi squared test . . . . . . . . . . . . . . . 28\\nWeight initialization247, 253, 258, 299 f.,\\n314\\nWest African ebola . . . . . . . . . . . . . . . . . .52\\nWSI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .208\\nWW2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .50\\nX\\nXavier . . . . . . . . . . . . . . . . . . . . . . . . 258, 330\\n384'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter, TokenTextSplitter\n",
        "split_question_gen=TokenTextSplitter(\n",
        "    encoding_name=\"cl100k_base\",\n",
        "    chunk_size=10000,\n",
        "    chunk_overlap=200\n",
        ")"
      ],
      "metadata": {
        "id": "3GXELFlA_MDv"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_ques_gen=split_question_gen.split_text(question_gen)\n"
      ],
      "metadata": {
        "id": "iA_6MKSFA7qf"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunk_ques_gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2vlikSKBIu-",
        "outputId": "89690c13-93e8-4c7e-fd16-b592adedb708"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"SHLOMO KASHANI\\nDeep Learning Interviews is home to hundreds of fully-solved problems, \\nfrom a wide range of key topics in AI. It is designed to both rehearse \\ninterview or exam-specific topics and provide machine learning M.Sc./Ph.D. \\nstudents, and those awaiting an interview a well-organized overview of the \\nfield. The problems it poses are tough enough to cut your teeth on and to \\ndramatically improve your skills-but they’re framed within thought-\\nprovoking questions and engaging stories.\\nThat is what makes the volume so specifically valuable to students and job \\nseekers: it provides them with the ability to speak confidently and quickly on \\nany relevant topic, to answer technical questions clearly and correctly, and to \\nfully understand the purpose and meaning \\nof interview questions and \\nanswers. These are powerful, indispensable advantages to have when walking \\ninto the interview room.\\nThe book’s contents is a large inventory of numerous topics relevant to DL \\njob interviews and graduate-level exams. That places \\nthis work at the \\nforefront \\nof the growing trend in science to teach a core set of practical \\nmathematical and computational \\nskills. It is widely accepted that the \\ntraining of every computer scientist must include the fundamental theorems \\nof ML, and AI appears in the curriculum of \\nnearly every \\nuniversity. This \\nvolume is designed as an excellent reference for graduates of \\nsuch programs.\\nShlomo Kashani, Author. \\nwww.interviews.ai\\nDEEP LEARNING INTERVIEWS\\nDEEP LEARNING \\nINTERVIEWS\\nSHLOMO KASHANI deep learning interviews\\nAmir Ivry, Chief Editor.\\n    REAL-WORLD DEEP LEARNING INTERVIEW \\nPROBLEMS & SOLUTIONS\\n• Logistic Regression\\n• Information Theory\\n• Calculus\\n• Algorithmic Differentiation\\n• Bayesian Deep Learning\\n• Probabilistic Programming\\n• Ensemble Learning\\n• CNN Feature Extraction\\n• Deep Learning: Expanded Chapter\\nsecond editionSHLOMO KASHANI\\nDEEP LEARNING INTERVIEWS\\nBy Shlomo Kashani, M.Sc, QMUL, UK.\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nPublished by Shlomo Kashani, Tel-Aviv , ISRAEL.\\nVisit: http://www.interviews.ai\\nCopyright, 2020\\nThis book is protected by copyright.\\nNo part may be reproduced in any manner without written permission from the publisher.\\nPrinting version: VER . 26 TH OCTOBER 2021\\nPrinted in the United States of America.\\nLibrary of Congress Cataloging-in-Publication Data\\nA catalog record for this book is available from the Library of CongressCOPYRIGHT.\\n© 2016-2020 Shlomo Kashani, entropy@interviews.ai\\nA\\nLL RIGHTS RESERVED .The content contained within this book may not be\\nreproduced, duplicated or transmitted without direct written permission\\nfrom the author or the publisher. Under no circumstances will any blame\\nor legal responsibility be held against the publisher, or author, for any dam-\\nages, reparation, or monetary loss due to the information contained within this book.\\nEither directly or indirectly . This book is copyright protected. This book is only for\\npersonal use. You cannot amend, distribute, sell, use, quote or paraphrase any part, or\\nthe content within this book, without the consent of the author or publisher.\\nPlease note the information contained within this document is for educational and\\nentertainment purposes only . All effort has been executed to present accurate, up to\\ndate, and reliable, complete information. No warranties of any kind are declared or\\nimplied. Readers acknowledge that the author is not engaging in the rendering of\\nlegal, ﬁnancial, medical or professional advice. The content within this book has been\\nderived from various sources. Please consult a licensed professional before attempt-\\ning any techniques outlined in this book. By reading this document, the reader agrees\\nthat under no circumstances is the author responsible for any losses, direct or indirect,\\nwhich are incurred as a result of the use of information contained within this docu-\\nment, including, but not limited to errors, omissions, or inaccuracies.\\nNo part of this publication may be reproduced, stored in a retrieval system, or trans-\\nmitted in any form or by any means, electronic, mechanical, photocopying, record-\\ning, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976\\nUnited States Copyright Act, without the prior written permission of the Publisher.\\nLimit of Liability/Disclaimer of Warranty . While the publisher and author have used\\ntheir best efforts in preparing this book, they make no representations or warranties\\nwith respect to the accuracy or completeness of the contents of this book and spe-\\nciﬁcally disclaim any implied warranties of merchantability or ﬁtness for a particular\\npurpose. No warranty may be created or extended by sales representatives or writ-\\nten sales materials. The advice and strategies contained herein may not be suitable\\nfor your situation. You should consult with a professional where appropriate. Neitherthe publisher nor author shall be liable for any loss of proﬁt or any other commer-\\ncial damages, including but not limited to special, incidental, consequential, or other\\ndamages.\\nNotices. Knowledge and best practice in this ﬁeld are constantly changing. As new\\nresearch and experience broaden our understanding, changes in research methods,\\nprofessional practices, or medical treatment may become necessary . Practitioners and\\nresearchers must always rely on their own experience and knowledge in evaluating\\nand using any information, methods, compounds, or experiments described herein.\\nIn using such information or methods they should be mindful of their own safety and\\nthe safety of others, including parties for whom they have a professional responsibil-\\nity . To the fullest extent of the law, neither the Publisher nor the authors, contributors,\\nor editors, assume any liability for any injury and/or damage to persons or property\\nas a matter of products liability , negligence or otherwise, or from any use or operation\\nof any methods, products, instructions, or ideas contained in the material herein.FOREWORD.\\nWe will build a machine that will ﬂy.\\n— Joseph Michael Montgolﬁer, French Inventor/Aeronaut (1740-1810)\\nD\\nEEP learning interviews are technical, dense, and thanks to the ﬁelds com-\\npetitiveness, often high-stakes. The prospect of preparing for one can be\\ndaunting, and the fear of failure can be paralyzing and many interviewees\\nﬁnd their ideas slipping away alongside their conﬁdence.\\nThis book was written for you: an aspiring data scientist with a quantitative back-\\nground, facing down the gauntlet of the interview process in an increasingly competit-\\nive ﬁeld. For most of you, the interview process is the most signiﬁcant hurdle between\\nyou and a dream job. Even though you have the ability , the background, and the mo-\\ntivation to excel in your target position, you might need some guidance on how to get\\nyour foot in the door.\\nThough this book is highly technical it is not too dense to work through quickly . It\\naims to be comprehensive, including many of the terms and topics involved in modern\\ndata science and deep learning. That thoroughness makes it unique; no other single\\nwork offers such breadth of learning targeted so speciﬁcally at the demands of the\\ninterview.\\nMost comparable information is available in a variety of formats, locations, struc-\\ntures, and resourcesblog posts, tech articles, and short books scattered across the inter-\\nnet. Those resources are simply not adequate to the demands of deep learning inter-\\nview or exam preparation and were not assembled with this explicit purpose in mind.\\nIt is hoped that this book does not suffer the same shortcomings.\\nT\\nHIS books creation was guided by a few key principles: clarity and depth,\\nthoroughness and precision, interest and accuracy . The volume was de-\\nsigned for use by job seekers in the ﬁelds of machine learning and deep\\nlearning whose abilities and background locate them ﬁrmly within STEM\\n(science, technology , engineering, and mathematics). The book will still be of use to\\nother readers, such as those still undergoing their initial education in a STEM ﬁeld.\\nHowever, it is tailored most directly to the needs of active job seekers and stu-\\ndents attending M.Sc/Ph.D programmes in AI . It is, in any case, a book for engineers,\\nmathematicians, and computer scientists: nowhere does it include the kind of very\\nbasic background material that would allow it to be read by someone with no priorknowledge of quantitative and mathematical processes.\\nThe books contents are a large inventory of numerous topics relevant to deep learn-\\ning job interviews and graduate level exams. Ideas that are interesting or pertinent\\nhave been excluded if they are not valuable in that context. That places this work at\\nthe forefront of the growing trend in education and in business to emphasize a core\\nset of practical mathematical and computational skills. It is now widely understood\\nthat the training of every computer scientist must include a course dealing with the\\nfundamental theorems of machine learning in a rigorous manner; Deep Learning ap-\\npears in the curriculum of nearly every university; and this volume is designed as a\\nconvenient ongoing reference for graduates of such courses and programs.\\nThe book is grounded in both academic expertise and on-the-job experience and\\nthus has two goals. First, it compresses all of the necessary information into a coher-\\nent package. And second, it renders that information accessible and makes it easy to\\nnavigate. As a result, the book helps the reader develop a thorough understanding of\\nthe principles and concepts underlying practical data science. None of the textbooks I\\nread met all of those needs, which are:\\n1. Appropriate presentation level. I wanted a friendly introductory text accessible\\nto graduate students who have not had extensive applied experience as data\\nscientists.\\n2. A text that is rigorous and builds a solid understanding of the subject without\\ngetting bogged down in too many technicalities.\\n3. Logical and notational consistency among topics . There are intimate connec-\\ntions between calculus, logistic regression, entropy , and deep learning theory ,\\nwhich I feel need to be emphasized and elucidated if the reader is to fully under-\\nstand the ﬁeld. Differences in notation and presentation style in existing sources\\nmake it very difﬁcult for students to appreciate these kinds of connections.\\n4. Manageable size. It is very useful to have a text compact enough that all of the\\nmaterial in it can be covered in few weeks or months of intensive review. Most\\ncandidates will have only that much time to prepare for an interview, so a longer\\ntext is of no use to them.\\nThe text that follows is an attempt to meet all of the above challenges. It will\\ninevitably prove more successful at handling some of them than others, but it\\nhas at least made a sincere and devoted effort.A note about Bibliography\\nThe book provides a carefully curated bibliography to guide further study , whether\\nfor interview preparation or simply as a matter of interest or job-relevant research. A\\ncomprehensive bibliography would be far too long to include here, and would be of\\nlittle immediate use, so the selections have been made with deliberate attention to the\\nvalue of each included text.\\nOnly the most important books and articles on each topic have been included, and\\nonly those written in English that I personally consulted. Each is given a brief annota-\\ntion to indicate its scope and applicability . Many of the works cited will be found to\\ninclude very full bibliographies of the particular subject treated, and I recommend\\nturning there if you wish to dive deeper into a speciﬁc topic, method, or process.\\nWe have a web page for this book, where we list errata, examples, and any ad-\\nditional information. You can access this page at: http://www.interviews.ai.\\nTo comment or ask technical questions about this book, send email to: entropy@\\ninterviews.ai.\\nI would also like to solicit corrections, criticisms, and suggestions from students\\nand other readers. Although I have tried to eliminate errors over the multi year\\nprocess of writing and revising this text, a few undoubtedly remain. In particular,\\nsome typographical infelicities will no doubt ﬁnd their way into the ﬁnal version. I\\nhope you will forgive them .\\nTHE AUTHOR .\\nTEL AVIV ISRAEL, D ECEMBER , 2020. F IRST PRINTING , D ECEMBER 2020.ACKNOWLEDGEMENTS.\\nThe thanks and acknowledgements of the publisher are due to the following:\\nMy dear son, Amir Ivry , Matthew Isaac Harvey , Sandy Noymer, Steve foot and V elimir\\nGayevskiy .AUTHOR ’S BIOGRAPHY .\\nWhen Shlomo typed his book in LATEX, he wanted it to\\nreﬂect some of his passions: AI, design, typography , and\\nmost notably coding. On a typical day , his two halves - the\\nscientist and the artist - spend hours meticulously design-\\ning AI systems, from epilepsy prediction and pulmonary\\nnodule detection, to training a computer-vision model on\\na cluster.\\nShlomo spends whole days in a lab full of GPUs work-\\ning on his many interesting research projects. Though re-\\nsearch satisﬁes his itch for discovery , his most important\\nscientiﬁc contribution, he says, is helping other researchers.\\nAnd the results are evident in his publications. But, al-\\nthough theoretical studies are important, practical experi-\\nence has many great virtues. As the Head of AI at DeepOncology , he developed uses\\nof Deep Learning for precise tumour detection, expanding and reﬁning what human\\nexperts are capable of. The work, which relies on CNN’s, marks the culmination of a\\ncareer spent applying AI techniques to problems in medical AI. Shlomo holds an MSc\\nin Digital Signal Processing (Distinction) from the University of London.\\nA PERSONAL NOTE : In this ﬁrst volume, I purposely present a coherent, cumu-\\nlative, and content-speciﬁc core curriculum of the data science ﬁeld, including topics\\nsuch as information theory , Bayesian statistics, algorithmic differentiation, logistic re-\\ngression, perceptrons, and convolutional neural networks.\\nI hope you will ﬁnd this book stimulating. It is my belief that you the postgradu-\\nate students and job-seekers for whom the book is primarily meant will beneﬁt from\\nreading it; however, it is my hope that even the most experienced researchers will ﬁnd\\nit fascinating as well.\\nSHLOMO KASHANI ,T EL-AVIV,ISRAEL.ABOUT\\nTHE CHIEF\\nEDITOR .\\nAmir Ivry has been an applied research scientist in the ﬁelds\\nof deep learning and speech signal processing since 2015. A direct\\nPhD candidate in the Electrical and Computer Engineering Fac-\\nulty in the Technion - Israel Institute of Technology , Amir is the\\nauthor of over a dozen academic papers in leading IEEE journ-\\nals and top-tier conferences. For his contribution to the ﬁeld of\\nhands-free speech communication using deep neural networks,\\nAmir has received more than a dozen awards and honors, in-\\ncluding back-to-back Jacobs citations for research excellence, and\\nmost recently the international speech communication associ-\\nation grant. Being only 28 years old, he has been cemented as a popular lecturer in the\\nmachine learning community , and delivered technological sessions for MIT, Google\\nfor startups, Alibaba, and more. Amir is currently holding a position as an applied\\nresearch intern in Microsoft Advanced Technology Labs.Contents\\nI Rusty Nail 1\\nHOW-TO USE THIS BOOK 3\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\nII Kindergarten 9\\nLOGISTIC REGRESSION 11\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38PROBABILISTIC PROGRAMMING & BA YESIAN DL 41\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nIII High School 83\\nINFORMATION THEORY 85\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 87\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 101\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103Kullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION 121\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 155The Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\nIV Bachelors 183\\nDEEP LEARNING: NN ENSEMBLES 185\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 202\\nDEEP LEARNING: CNN FEATURE EXTRACTION 205\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213Neural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\nDEEP LEARNING 227\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 253\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 306\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nV Practice Exam 339\\nJOB INTERVIEW MOCK EXAM 341\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343Classiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nVI V olume two 357\\nVOLUME TWO - PLAN 359\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nVariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . . . 361\\nText to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL\",\n",
              " 'ization . . . . . . . . . . . . . . . . . . . . . . 361\\nText to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nxviRUSTY NAIL\\nPART ICHAPTER\\n1\\nHOW-TO USE THIS BOOK\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nStarting Your Career . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nAdvancing Your Career . . . . . . . . . . . . . . . . . . . . . . . 5\\nDiving Into Deep Learning . . . . . . . . . . . . . . . . . . . . . 5\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.1 Introduction\\nFirst of all, welcome to world of Deep Learning Interviews.\\n1.1.1 What makes this book so valuable\\nT\\nARGETED advertising. Deciphering dead languages. Detecting malignant\\ntumours. Predicting natural disasters. Every year we see dozens of new\\nuses for deep learning emerge from corporate R&R, academia, and plucky\\nentrepreneurs. Increasingly , deep learning and artiﬁcial intelligence are in-\\ngrained in our cultural consciousness. Leading universities are dedicating programs\\nto teaching them, and they make the headlines every few days.\\nThat means jobs. It means intense demand and intense competition. It means a\\ngeneration of data scientists and machine learning engineers making their way into1.1. INTRODUCTION\\nthe workforce and using deep learning to change how things work. This book is for\\nthem, and for you. It is aimed at current or aspiring experts and students in the ﬁeld\\npossessed of a strong grounding in mathematics, an active imagination, engaged cre-\\nativity , and an appreciation for data. It is hand-tailored to give you the best possible\\npreparation for deep learning job interviews by guiding you through hundreds of\\nfully solved questions.\\nThat is what makes the volume so speciﬁcally valuable to students and job seekers:\\nit provides them with the ability to speak conﬁdently and quickly on any relevant\\ntopic, to answer technical questions clearly and correctly , and to fully understand the\\npurpose and meaning of interview questions and answers.\\nThose are powerful, indispensable advantages to have when walking into the in-\\nterview room.\\nThe questions and problems the book poses are tough enough to cut your teeth\\non-and to dramatically improve your skills but theyre framed within thought provok-\\ning questions, powerful and engaging stories, and cutting edge scientiﬁc information.\\nWhat are bosons and fermions? What is choriionic villus? Where did the Ebola virus\\nﬁrst appear, and how does it spread? Why is binary options trading so dangerous?\\nYour curiosity will pull you through the book’s problem sets, formulas, and in-\\nstructions, and as you progress, you’ll deepen your understanding of deep learning.\\nThere are intricate connections between calculus, logistic regression, entropy , and deep\\nlearning theory; work through the book, and those connections will feel intuitive.\\n1.1.2 What will I learn\\nStarting Your Career\\nAre you actively pursuing a career in deep learning and data science, or hoping to do\\nso? If so, you’re in luck everything from deep learning to artiﬁcial intelligence is in\\nextremely high demand in the contemporary workforce. Deep learning professionals\\nare highly sought after and also ﬁnd themselves among the highest-paid employee\\ngroups in companies around the world.\\nSo your career choice is spot on, and the ﬁnancial and intellectual beneﬁts of land-\\ning a solid job are tremendous. But those positions have a high barrier to entry: the\\ndeep learning interview. These interviews have become their own tiny industry , with\\nHR employees having to specialize in the relevant topics so as to distinguish well-\\nprepared job candidates from those who simply have a loose working knowledge of\\nthe material. Outside the interview itself, the difference doesn’t always feel import-\\n4Chapter 1 HOW-TO USE THIS BOOK\\nant. Deep learning libraries are so good that a machine learning pipeline can often be\\nassembled with little high-skill input from the researcher themselves. But that level\\nof ability won’t cut it in the interview. You’ll be asked practical questions, technical\\nquestions, and theoretical questions, and expected to answer them all conﬁdently and\\nﬂuently .\\nFor unprepared candidates, that’s the end of the road. Many give up after repeated\\npost-interview rejections.\\nAdvancing Your Career\\nSome of you will be more conﬁdent. Those of you with years on the job will be highly\\nmotivated, exceptionally numerate, and prepared to take an active, hands-on role in\\ndeep learning projects. You probably already have extensive knowledge in applied\\nmathematics, computer science, statistics, and economics. Those are all formidable\\nadvantages.\\nBut at the same time, it’s unlikely that you will have prepared for the interview\\nitself. Deep learning interviews especially those for the most interesting, autonom-\\nous, and challenging positions demand that you not only know how to do your job\\nbut that you display that knowledge clearly , eloquently , and without hesitation. Some\\nquestions will be straightforward and familiar, but others might be farther aﬁeld or\\ndraw on areas you haven’t encountered since college.\\nThere is simply no reason to leave that kind of thing to chance. Make sure you’re\\nprepared. Conﬁrm that you are up-to-date on terms, concepts, and algorithms. Refresh\\nyour memory of fundamentals, and how they inform contemporary research practices.\\nAnd when the interview comes, walk into the room knowing that you’re ready for\\nwhat’s coming your way .\\nDiving Into Deep Learning\\n\"Deep Learning Job Interviews\" is organized into chapters that each consist of an Intro-\\nduction to a topic, Problems illustrating core aspects of the topic, and complete Solu-\\ntions. You can expect each question and problem in this volume to be clear, practical,\\nand relevant to the subject. Problems fall into two groups, conceptual and application-\\nbased. Conceptual problems are aimed at testing and improving your knowledge of\\nbasic underlying concepts, while applications are targeted at practicing or applying\\nwhat you’ve learned (most of these are relevant to Python and PyTorch). The chapters\\nare followed by a reference list of relevant formulas and a selective bibliography for\\nguide further reading.\\n51.1. INTRODUCTION\\n1.1.3 How to Work Problems\\nIn real life, like in exams, you will encounter problems of varying difﬁculty . A good\\nskill to practice is recognizing the level of difﬁculty a problem poses. Job interviews\\nwill have some easy problems, some standard problems, and some much harder prob-\\nlems.\\nEach chapter of this book is usually organized into three sections: Introduction,\\nProblems, and Solutions. As you are attempting to tackle problems, resist the tempta-\\ntion to prematurely peek at the solution; It is vital to allow yourself to struggle for\\na time with the material. Even professional data scientists do not always know right\\naway how to resolve a problem. The art is in gathering your thoughts and ﬁguring\\nout a strategy to use what you know to ﬁnd out what you don’t.\\nPRB-1 \\uf059 CH.PRB- 1.1.\\nProblems outlined in grey make up the representative question set . This set of prob-\\nlems is intended to cover the most essential ideas in each section. These problems are usually\\nhighly typical of what you’d see on an interview, although some of them are atypical but\\ncarry an important moral. If you ﬁnd yourself unconﬁdent with the idea behind one of these,\\nit’s probably a good idea to practice similar problems. This representative question set is our\\nsuggestion for a minimal selection of problems to work on. Y ou are highly encouraged to\\nwork on more.\\nSOL-1 \\uf14b CH.SOL- 1.1. I am a solution. \\x04\\nIf you ﬁnd yourself at a real stand-off, go ahead and look for a clue in one of the\\nrecommended theory books. Think about it for a while, and don’t be afraid to read\\nback in the notes to look for a key idea that will help you proceed. If you still can’t\\nsolve the problem, well, we included the Solutions section for a reason! As you’re\\nreading the solutions, try hard to understand why we took the steps we did, instead\\nof memorizing step-by-step how to solve that one particular problem.\\nIf you struggled with a question quite a lot, it’s probably a good idea to return to it\\nin a few days. That might have been enough time for you to internalize the necessary\\nideas, and you might ﬁnd it easily conquerable. If you’re still having troubles, read\\nover the solution again, with an emphasis on understanding why each step makes\\nsense. One of the reasons so many job candidates are required to demonstrate their\\nability to resolves data science problems on the board, is that it hiring managers as-\\nsume it reﬂects their true problem-solving skills.\\n6Chapter 1 HOW-TO USE THIS BOOK\\nIn this volume, you will learn lots of concepts, and be asked to apply them in\\na variety of situations. Often, this will involve answering one really big problem by\\nbreaking it up into manageable chunks, solving those chunks, then putting the pieces\\nback together. When you see a particularly long question, remain calm and look for a\\nway to break it into pieces you can handle.\\n1.1.4 Types of Problems\\nTwo main types of problems are presented in this book.\\nCONCEPTUAL : The ﬁrst category is meant to test and improve your understanding\\nof basic underlying concepts. These often involve many mathematical calculations.\\nThey range in difﬁculty from very basic reviews of deﬁnitions to problems that require\\nyou to be thoughtful about the concepts covered in the section.\\nAn example in Information Theory follows.\\nPRB-2 \\uf059 CH.PRB- 1.2.\\nWhat is the distribution of maximum entropy, that is, the distribution which has the\\nmaximum entropy among all distributions on the bounded interval [a, b],(−∞, +∞)\\nSOL-2 \\uf14b CH.SOL- 1.2.\\nThe uniform distribution has the maximum entropy among all distributions on the\\nbounded interval: [a, b],(−∞, +∞).\\nThe variance of U (a, b) is σ2 = 1/12(b − a)2.\\nTherefore the entropy is:\\n1/2 log 12 + log σ. (1.1)\\n\\x04\\nAPPLICATION : Problems in this category are for practicing skills. It’s not enough to\\nunderstand the philosophical grounding of an idea: you have to be able to apply it in\\nappropriate situations. This takes practice! mostly in Python or in one of the available\\nDeep Learning Libraries such as PyTorch.\\nAn example in PyTorch follows.\\n71.1. INTRODUCTION\\nPRB-3 \\uf059 CH.PRB- 1.3.\\nDescribe in your own words, what is the purpose of the following code in the context of\\ntraining a Convolutional Neural Network.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\nSOL-3 \\uf14b CH.SOL- 1.3.\\nDuring the training of a Convolutional Neural Network, data augmentation, and to some\\nextent dropout are used as core methods to decrease overﬁtting. Data augmentation is a regu-\\nlarization scheme that synthetically expands the data-set by utilizing label-preserving trans-\\nformations to add more invariant examples of the same data samples. It is most commonly\\nperformed in real time on the CPU during the training phase whilst the actual training mode\\ntakes place on the GPU. This may consist for instance, random rotations, random ﬂips, zoom-\\ning, spatial translations etc. \\x04\\n8KINDERGARTEN\\nPART IICHAPTER\\n2\\nLOGISTIC REGRESSION\\nY ou should call it entropy for two reasons. In the ﬁrst place, your uncertainty\\nfunction has been used in statistical mechanics under that name. In the second\\nplace, and more importantly, no one knows what entropy really is, so in a debate\\nyou will always have the advantage.\\n— John von Neumann to Claude Shannon\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382.1. INTRODUCTION\\n2.1 Introduction\\nM\\nUltivariable methods are routinely utilized in statistical analyses across a\\nwide range of domains. Logistic regression is the most frequently used\\nmethod for modelling binary response data and binary classiﬁcation.\\nWhen the response variable is binary , it characteristically takes the form of 1/0,\\nwith 1 normally indicating a success and 0 a failure. Multivariable methods usually\\nassume a relationship between two or more independent, predictor variables, and\\none dependent, response variable. The predicted value of a response variable may be\\nexpressed as a sum of products, wherein each product is formed by multiplying the\\nvalue of the variable and its coefﬁcient. How the coefﬁcients are computed? from a\\nrespective data set. Logistic regression is heavily used in supervised machine learning\\nand has become the workhorse for both binary and multiclass classiﬁcation problems.\\nMany of the questions introduced in this chapter are crucial for truly understanding\\nthe inner-workings of artiﬁcial neural networks.\\n2.2 Problems\\n2.2.1 General Concepts\\nPRB-4 \\uf059 CH.PRB- 2.1.\\nTrue or False: For a ﬁxed number of observations in a data set, introducing more vari-\\nables normally generates a model that has a better ﬁt to the data. What may be the drawback\\nof such a model ﬁtting strategy?\\nPRB-5 \\uf059 CH.PRB- 2.2.\\nDeﬁne the term “odds of success” both qualitatively and formally. Give a numerical\\nexample that stresses the relation between probability and odds of an event occurring.\\nPRB-6 \\uf059 CH.PRB- 2.3.\\n1. Deﬁne what is meant by the term \"interaction\", in the context of a logistic regression\\npredictor variable.\\n12Chapter 2 LOGISTIC REGRESSION\\n2. What is the simplest form of an interaction? Write its formulae.\\n3. What statistical tests can be used to attest the signiﬁcance of an interaction term?\\nPRB-7 \\uf059 CH.PRB- 2.4.\\nTrue or False: In machine learning terminology, unsupervised learning refers to the\\nmapping of input covariates to a target response variable that is attempted at being predicted\\nwhen the labels are known.\\nPRB-8 \\uf059 CH.PRB- 2.5.\\nComplete the following sentence: In the case of logistic regression, the response vari-\\nable is the log of the odds of being classiﬁed in [...].\\nPRB-9 \\uf059 CH.PRB- 2.6.\\nDescribe how in a logistic regression model, a transformation to the response variable is\\napplied to yield a probability distribution. Why is it considered a more informative repres-\\nentation of the response?\\nPRB-10 \\uf059 CH.PRB- 2.7.\\nComplete the following sentence: Minimizing the negative log likelihood also means\\nmaximizing the [...] of selecting the [...] class.\\n2.2.2 Odds, Log-odds\\nPRB-11 \\uf059 CH.PRB- 2.8.\\nAssume the probability of an event occurring is p = 0.1.\\n1. What are the odds of the event occurring?.\\n2. What are the log-odds of the event occurring?.\\n132.2. PROBLEMS\\n3. Construct the probability of the event as a ratio that equals 0.1.\\nPRB-12 \\uf059 CH.PRB- 2.9.\\nTrue or False: If the odds of success in a binary response is 4, the corresponding probab-\\nility of success is 0.8.\\nPRB-13 \\uf059 CH.PRB- 2.10.\\nDraw a graph of odds to probabilities , mapping the entire range of probabilities to\\ntheir respective odds.\\nPRB-14 \\uf059 CH.PRB- 2.11.\\nThe logistic regression model is a subset of a broader range of machine learning models\\nknown as generalized linear models (GLMs), which also include analysis of variance (AN-\\nOV A), vanilla linear regression, etc. There are three components to a GLM; identify these\\nthree components for binary logistic regression.\\nPRB-15 \\uf059 CH.PRB- 2.12.\\nLet us consider the logit transformation, i.e., log-odds. Assume a scenario in which the\\nlogit forms the linear decision boundary:\\nlog\\n(\\nPr(Y = 1|X)\\nPr(Y = 0|X)\\n)\\n= θ0 + θT X, (2.1)\\nfor a given vector of systematic components X and predictor variables θ. Write the mathem-\\natical expression for the hyperplane that describes the decision boundary.\\nPRB-16 \\uf059 CH.PRB- 2.13.\\nTrue or False: The logit function and the natural logistic (sigmoid) function are inverses\\nof each other.\\n14Chapter 2 LOGISTIC REGRESSION\\n2.2.3 The Sigmoid\\nThe sigmoid (Fig. 2.1) also known as the logistic function, is widely used in binary\\nclassiﬁcation and as a neuron activation function in artiﬁcial neural networks.\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−4x\\nσ(x) = 1\\n1+e−15x\\nFIGURE 2.1: Examples of two sigmoid functions.\\nPRB-17 \\uf059 CH.PRB- 2.14.\\nCompute the derivative of the natural sigmoid function:\\nσ(x) = 1\\n1 + e−x ∈ (0, 1). (2.2)\\nPRB-18 \\uf059 CH.PRB- 2.15.\\nRemember that in logistic regression, the hypothesis function for some parameter vector\\nβ and measurement vector x is deﬁned as:\\nhβ(x) = g(βT x) = 1\\n1 + e−βT x\\n= P (y = 1|x; β), (2.3)\\n152.2. PROBLEMS\\nwhere y holds the hypothesis value.\\nSuppose the coefﬁcients of a logistic regression model with independent variables are as\\nfollows: β0 = −1.5, β1 = 3, β2 = −0.5.\\nAssume additionally, that we have an observation with the following values for the dependent\\nvariables: x1 = 1, x2 = 5. As a result, the logit equation becomes:\\nlogit = β0 + β1x1 + β2x2. (2.4)\\n1. What is the value of the logit for this observation?\\n2. What is the value of the odds for this observation?\\n3. What is the value of P (y = 1) for this observation?\\n2.2.4 Truly Understanding Logistic Regression\\nPRB-19 \\uf059 CH.PRB- 2.16.\\nProton therapy (PT) [ 2] is a widely adopted form of treatment for many types of cancer\\nincluding breast and lung cancer (Fig. 2.2).\\nFIGURE 2.2: Pulmonary nodules (left) and breast cancer (right).\\nA PT device which was not properly calibrated is used to simulate the treatment of\\ncancer. As a result, the PT beam does not behave normally. A data scientist collects inform-\\nation relating to this simulation. The covariates presented in T able 2.1 are collected during\\n16Chapter 2 LOGISTIC REGRESSION\\nthe experiment. The columns Yes and No indicate if the tumour was eradicated or not, re-\\nspectively.\\nTumour eradication\\nCancer Type Yes No\\nBreast 560 260\\nLung 69 36\\nTABLE 2.1: Tumour eradication statistics.\\nReferring to T able2.1:\\n1. What is the explanatory variable and what is the response variable?\\n2. Explain the use of relative risk and odds ratio for measuring association.\\n3. Are the two variables positively or negatively associated?\\nFind the direction and strength of the association using both relative risk and odds\\nratio.\\n4. Compute a 95% conﬁdence interval (CI) for the measure of association.\\n5. Interpret the results and explain their signiﬁcance.\\nPRB-20 \\uf059 CH.PRB- 2.17.\\nConsider a system for radiation therapy planning (Fig. 2.3). Given a patient with a ma-\\nlignant tumour, the problem is to select the optimal radiation exposure time for that patient.\\nA key element in this problem is estimating the probability that a given tumour will be erad-\\nicated given certain covariates. A data scientist collects information relating to this radiation\\ntherapy system.\\n172.2. PROBLEMS\\nFIGURE 2.3: A multi-detector positron scanner used to locate tumours.\\nThe following covariates are collected; X1 denotes time in milliseconds that a patient is\\nirradiated with, X2 = holds the size of the tumour in centimeters, and Y notates a binary re-\\nsponse variable indicating if the tumour was eradicated. Assume that each response’ variable\\nYi is a Bernoulli random variable with success parameter pi, which holds:\\npi = eβ0+β1x1+β2x2\\n1 + eβ0+β1x1+β2x2\\n. (2.5)\\nThe data scientist ﬁts a logistic regression model to the dependent measurements and pro-\\nduces these estimated coefﬁcients:\\nˆβ0 = −6,\\nˆβ1 = 0.05,\\nˆβ2 = 1.\\n(2.6)\\n1. Estimate the probability that, given a patient who undergoes the treatment for 40\\nmilliseconds and who is presented with a tumour sized 3.5 centimetres, the system\\neradicates the tumour.\\n2. How many milliseconds the patient in part (a) would need to be radiated with to have\\nexactly a 50% chance of eradicating the tumour?\\n18Chapter 2 LOGISTIC REGRESSION\\nPRB-21 \\uf059 CH.PRB- 2.18.\\nRecent research [ 3] suggests that heating mercury containing dental amalgams may\\ncause the release of toxic mercury fumes into the human airways. It is also presumed that\\ndrinking hot coffee, stimulates the release of mercury vapour from amalgam ﬁllings (Fig.\\n2.4).\\nFIGURE 2.4: A dental amalgam.\\nT o study factors that affect migraines, and in particular, patients who have at least four\\ndental amalgams in their mouth, a data scientist collects data from 200K users with and\\nwithout dental amalgams. The data scientist then ﬁts a logistic regression model with an\\nindicator of a second migraine within a time frame of one hour after the onset of the ﬁrst mi-\\ngraine, as the binary response variable (e.g., migraine=1, no migraine=0). The data scientist\\nbelieves that the frequency of migraines may be related to the release of toxic mercury fumes.\\nThere are two independent variables:\\n1. X1 = 1 if the patient has at least four amalgams; 0 otherwise.\\n2. X2 = coffee consumption (0 to 100 hot cups per month).\\nThe output from training a logistic regression classiﬁer is as follows:\\nAnalysis of LR Parameter Estimates\\nParameter Estimate Std.Err Z-val Pr>|Z|\\nIntercept -6.36347 3.21362 -1.980 0.0477\\n$X_1$ -1.02411 1.17101 -0.875 0.3818\\n$X_2$ 0.11904 0.05497 2.165 0.0304\\n192.2. PROBLEMS\\n1. Using X1 and X2, express the odds of a patient having a migraine for a second time.\\n2. Calculate the probability of a second migraine for a patient that has at least four\\namalgams and drank 100 cups per month?\\n3. For users that have at least four amalgams, is high coffee intake associated with an\\nincreased probability of a second migraine?\\n4. Is there statistical evidence that having more than four amalgams is directly associ-\\nated with a reduction in the probability of a second migraine?\\nPRB-22 \\uf059 CH.PRB- 2.19.\\nT o study factors that affect Alzheimer’s disease using logistic regression, a researcher\\nconsiders the link between gum (periodontal) disease and Alzheimer as a plausible risk factor\\n[1]. The predictor variable is a count of gum bacteria (Fig. 2.5) in the mouth.\\nFIGURE 2.5: A chain of spherical bacteria.\\nThe response variable, Y , measures whether the patient shows any remission (e.g. yes=1).\\nThe output from training a logistic regression classiﬁer is as follows:\\nParameter DF Estimate Std\\nIntercept 1 -4.8792 1.2197\\ngum bacteria 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of gum bacteria of a patient\\nis 33.\\n20Chapter 2 LOGISTIC REGRESSION\\n2. Find out the gum bacteria count at which the estimated probability of improvement is\\n0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1 in the total gum\\nbacteria count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total gum bacteria count. Remember that the most common conﬁdence levels\\nare 90%, 95%, 99%, and 99.9%. T able9.1 lists the z values for these levels.\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 2.2: Common conﬁdence levels.\\nPRB-23 \\uf059 CH.PRB- 2.20.\\nRecent research [ 4] suggests that cannabis (Fig. 2.6) and cannabinoids administration\\nin particular, may reduce the size of malignant tumours in rats.\\nFIGURE 2.6: Cannabis.\\n212.2. PROBLEMS\\nT o study factors affecting tumour shrinkage, a deep learning researcher collects data from\\ntwo groups; one group is administered with placebo (a substance that is not medicine) and\\nthe other with cannabinoids. His main research revolves around studying the relationship\\n(T able2.3) between the anticancer properties of cannabinoids and tumour shrinkage:\\nTumour Shrinkage In Rats\\nGroup Yes No Sum\\nCannabinoids 60 6833 6893\\nPlacebo 130 6778 6909\\nSum 190 13611 13801\\nTABLE 2.3: Tumour shrinkage in rats.\\nFor the true odds ratio:\\n1. Find the sample odds ratio.\\n2. Find the sample log-odds ratio.\\n3. Compute a 95% conﬁdence interval ( z0.95 = 1.645; z0.975 = 1.96) for the true log odds\\nratio and true odds ratio.\\n2.2.5 The Logit Function and Entropy\\nPRB-24 \\uf059 CH.PRB- 2.21.\\nThe entropy (see Chapter 4) of a single binary outcome with probability p to receive 1 is\\ndeﬁned as:\\nH(p) ≡ −p log p − (1 − p) log(1 − p). (2.7)\\n1. At what p does H(p) attain its maximum value?\\n2. What is the relationship between the entropy H(p) and the logit function, given p?\\n22Chapter 2 LOGISTIC REGRESSION\\n2.2.6 Python/PyTorch/CPP\\nPRB-25 \\uf059 CH.PRB- 2.22.\\nThe following C++ code (Fig. 2.7) is part of a (very basic) logistic regression implement-\\nation module. For a theoretical discussion underlying this question, refer to problem 2.17.\\n1 #include ...\\n2 std::vector<double> theta { -6,0.05,1.0};\\n3 double sigmoid(double x) {\\n4 double tmp =1.0 / (1.0 + exp(-x));\\n5 std::cout << \"prob=\" << tmp<<std::endl;\\n6 return tmp;\\n7 }\\n8 double hypothesis(std::vector<double> x){\\n9 double z;\\n10 z=std::inner_product(std::begin(x), std ::end(x),\\nstd::begin(theta), 0.0);↪→\\n11 std::cout << \"inner_product=\" << z<<std::endl;\\n12 return sigmoid(z);\\n13 }\\n14 int classify(std::vector<double> x){\\n15 int hypo=hypothesis(x) > 0.5f;\\n16 std::cout << \"hypo=\" << hypo<<std::endl;\\n17 return hypo;\\n18 }\\n19 int main() {\\n20 std::vector<double> x1 { 1,40,3.5};\\n21 classify(x1);\\n22 }\\nFIGURE 2.7: Logistic regression in CPP\\n1. Explain the purpose of line 10, i.e., inner_product.\\n2. Explain the purpose of line 15, i.e., hypo(x) > 0.5f.\\n232.2. PROBLEMS\\n3. What does θ (theta) stand for in line 2?\\n4. Compile and run the code, you can use:\\nhttps://repl.it/languages/cpp11 to evaluate the code.\\nWhat is the output?\\nPRB-26 \\uf059 CH.PRB- 2.23.\\nThe following Python code (Fig. 2.8) runs a very simple linear model on a two-dimensional\\nmatrix.\\n1 import torch\\n2 import torch.nn as nn\\n3\\n4 lin = nn.Linear(5, 7)\\n5 data = (torch.randn(3, 5))\\n6\\n7 print(lin(data).shape)\\n8 >?\\nFIGURE 2.8: A linear model in PyTorch\\nWithout actually running the code, determine what is the size of the matrix printed as a\\nresult of applying the linear model on the matrix.\\nPRB-27 \\uf059 CH.PRB- 2.24.\\nThe following Python code snippet (Fig. 2.9) is part of a logistic regression implementa-\\ntion module in Python.\\n24Chapter 2 LOGISTIC REGRESSION\\n1 from scipy.special import expit\\n2 import numpy as np\\n3 import math\\n4\\n5 def Func001(x):\\n6 e_x = np.exp(x - np.max(x))\\n7 return e_x / e_x.sum()\\n8\\n9 def Func002(x):\\n10 return 1 / (1 + math.exp(-x))\\n11\\n12 def Func003(x):\\n13 return x * (1-x)\\nFIGURE 2.9: Logistic regression methods in Python.\\nAnalyse the methods Func001 , Func002 and Func003 presented in Fig. 2.9, ﬁnd their\\npurposes and name them.\\nPRB-28 \\uf059 CH.PRB- 2.25.\\nThe following Python code snippet (Fig. 2.10) is part of a machine learning module in\\nPython.\\n252.2. PROBLEMS\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5 ^^I^^I\\n6 def Func006(y_hat, y):\\n7 if y == 1:\\n8 return -np.log(y_hat)\\n9 else:\\n10 return -np.log(1 - y_hat)^^I\\nFIGURE 2.10: Logistic regression methods in Python.\\nAnalyse the method Func006 presented in Fig. 2.10. What important concept in machine-\\nlearning does it implement?\\nPRB-29 \\uf059 CH.PRB- 2.26.\\nThe following Python code snippet (Fig. 2.11) presents several different variations of the\\nsame function.\\n26Chapter 2 LOGISTIC REGRESSION\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5\\n6 def Ver001(x):\\n7 return 1 / (1 + math.exp(-x))\\n8\\n9 def Ver002(x):\\n10 return 1 / (1 + (np.exp(-x)))\\n11\\n12 WHO_AM_I = 709\\n13\\n14 def Ver003(x):\\n15 return 1 / (1 + np.exp(-(np.clip(x, -WHO_AM_I, None))))\\nFIGURE 2.11: Logistic regression methods in Python.\\n1. Which mathematical function do these methods implement?\\n2. What is signiﬁcant about the number 709 in line 11?\\n3. Given a choice, which method would you use?\\n2.3 Solutions\\n2.3.1 General Concepts\\nSOL-4 \\uf14b CH.SOL- 2.1.\\nTrue. However, when an excessive and unnecessary number of variables is used in a lo-\\ngistic regression model, peculiarities (e.g., speciﬁc attributes) of the underlying data set dis-\\nproportionately affect the coefﬁcients in the model, a phenomena commonly referred to as\\n“overﬁtting”. Therefore, it is important that a logistic regression model does not start training\\nwith more variables than is justiﬁed for the given number of observations. \\x04\\n272.3. SOLUTIONS\\nSOL-5 \\uf14b CH.SOL- 2.2.\\nThe odds of success are deﬁned as the ratio between the probability of success p ∈ [0, 1]\\nand the probability of failure 1 − p. Formally:\\nOdds(p) ≡\\n(\\np\\n1 − p\\n)\\n. (2.8)\\nFor instance, assuming the probability of success of an event is p = 0 .7. Then, in our\\nexample, the odds of success are 7/3, or 2.333 to 1. Naturally, in the case of equal probabilities\\nwhere p = 0.5, the odds of success is 1 to 1.\\n\\x04\\nSOL-6 \\uf14b CH.SOL- 2.3.\\n1. An interaction is the product of two single predictor variables implying a non-additive\\neffect.\\n2. The simplest interaction model includes a predictor variable formed by multiplying two\\nordinary predictors. Let us assume two variables X and Z. Then, the logistic regression\\nmodel that employs the simplest form of interaction follows:\\nβ0 + β1X + β2Z + β3XZ, (2.9)\\nwhere the coefﬁcient for the interaction term XZ is represented by predictor β3.\\n3. For testing the contribution of an interaction, two principal methods are commonly\\nemployed; the Wald chi-squared test or a likelihood ratio test between the model with\\nand without the interaction term. Note: How does interaction relates to information\\ntheory? What added value does it employ to enhance model performance?\\n\\x04\\nSOL-7 \\uf14b CH.SOL- 2.4.\\nFalse. This is exactly the deﬁnition of supervised learning; when labels are known then\\nsupervision guides the learning process. \\x04\\n28Chapter 2 LOGISTIC REGRESSION\\nSOL-8 \\uf14b CH.SOL- 2.5.\\nIn the case of logistic regression, the response variable is the log of the odds of being clas-\\nsiﬁed in a group of binary or multi-class responses. This deﬁnition essentially demonstrates\\nthat odds can take the form of a vector. \\x04\\nSOL-9 \\uf14b CH.SOL- 2.6.\\nWhen a transformation to the response variable is applied, it yields a probability distribu-\\ntion over the output classes, which is bounded between 0 and 1; this transformation can be\\nemployed in several ways, e.g., a softmax layer, the sigmoid function or classic normalization.\\nThis representation facilitates a soft-decision by the logistic regression model, which permits\\nconstruction of probability-based processes over the predictions of the model. Note: What are\\nthe pros and cons of each of the three aforementioned transformations? \\x04\\nSOL-10 \\uf14b CH.SOL- 2.7.\\nMinimizing the negative log likelihood also means maximizing the likelihood of selecting\\nthe correct class. \\x04\\n2.3.2 Odds, Log-odds\\nSOL-11 \\uf14b CH.SOL- 2.8.\\n1. The odds of the event occurring are, by deﬁnition:\\nodds = ( 0.1\\n0.9 ) = 0 .11. (2.10)\\n2. The log-odds of the event occurring are simply taken as the log of the odds:\\nlog-odds = ln(0.1/0.9) = −2.19685. (2.11)\\n3. The probability may be constructed by the following representation:\\nprobability = odds\\nodds + 1 = 0.11\\n1.11 = 0.1, (2.12)\\n292.3. SOLUTIONS\\nor, alternatively:\\np = exp (ln odds)\\nexp (ln odds) + 1 = 0.11\\n1.11 = 0.1. (2.13)\\nNote: What is the intuition behind this representation?\\n\\x04\\nSOL-12 \\uf14b CH.SOL- 2.9.\\nTrue. By deﬁnition of odds, it is easy to notice that p = 0.8 satisﬁes the following relation:\\nodds = ( 0.8\\n0.2) = 4 (2.14)\\n\\x04\\nSOL-13 \\uf14b CH.SOL- 2.10.\\nThe graph of odds to probabilities is depicted in Figure 2.12.\\n0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 0,9\\n2,0\\n4,0\\n6,0\\n8,0\\n10,0\\nProbability\\nOdds odds(p) = p\\n1−p\\nFIGURE 2.12: Odds vs. probability values.\\n\\x04\\n30Chapter 2 LOGISTIC REGRESSION\\nSOL-14 \\uf14b CH.SOL- 2.11.\\nA binary logistic regression GLM consists of there components:\\n1. Random component: refers to the probability distribution of the response variable (Y ),\\ne.g., binomial distribution for Y in the binary logistic regression, which takes on the\\nvalues Y = 0 or Y = 1.\\n2. Systematic component: describes the explanatory variables:\\n(X1, X2, ...) as a combination of linear predictors. The binary case does not constrain\\nthese variables to any degree.\\n3. Link function: speciﬁes the link between random and systematic components. It says\\nhow the expected value of the response relates to the linear predictor of explanatory\\nvariables.\\nNote: Assume that Y denotes whether a human voice activity was detected ( Y = 1 )\\nor not ( Y = 0 ) in a give time frame. Propose two systematic components and a link\\nfunction adjusted for this task.\\n\\x04\\nSOL-15 \\uf14b CH.SOL- 2.12.\\nThe hyperplane is simply deﬁned by:\\nθ0 + θT X = 0. (2.15)\\nNote: Recall the use of the logit function and derive this decision boundary rigorously. \\x04\\nSOL-16 \\uf14b CH.SOL- 2.13.\\nTrue. The logit function is deﬁned as:\\nz(p) = logit(p) = log\\n(\\np\\n1 − p\\n)\\n, (2.16)\\n312.3. SOLUTIONS\\nfor any p ∈ [0, 1]. A simple set of algebraic equations yields the inverse relation:\\np(z) = exp z\\n1 + exp z , (2.17)\\nwhich exactly describes the relation between the output and input of the logistic function, also\\nknown as the sigmoid. \\x04\\n2.3.3 The Sigmoid\\nSOL-17 \\uf14b CH.SOL- 2.14.\\nThere are various approaches to solve this problem, here we provide two; direct derivation\\nor derivation via the softmax function.\\n1. Direct derivation:\\nd\\ndx σ(x) = d\\ndx ((1 + e−x)−1) = −((1 + e−x)(−2)) d\\ndx (1 + e−x) = e−x\\n(1+e−x)2 .\\n2. Softmax derivation:\\nIn a classiﬁcation problem with mutually exclusive classes, where all of the values are\\npositive and sum to one, a softmax activation function may be used. By deﬁnition, the\\nsoftmax activation function consists of n terms, such that ∀i ∈ [1, n]:\\nf (θi) = eθi\\n∑\\nk evk\\n= 1\\n1 + e−θi\\n∑\\nk̸=i eθk\\n. (2.18)\\nT o compute the partial derivative of 2.18, we treat all θk where k ̸= i as constants and\\nthen differentiate θi using regular differentiation rules. For a given θi, let us deﬁne:\\nβ =\\n∑\\nk̸=i\\n',\n",
              " '\\ndx (1 + e−x) = e−x\\n(1+e−x)2 .\\n2. Softmax derivation:\\nIn a classiﬁcation problem with mutually exclusive classes, where all of the values are\\npositive and sum to one, a softmax activation function may be used. By deﬁnition, the\\nsoftmax activation function consists of n terms, such that ∀i ∈ [1, n]:\\nf (θi) = eθi\\n∑\\nk evk\\n= 1\\n1 + e−θi\\n∑\\nk̸=i eθk\\n. (2.18)\\nT o compute the partial derivative of 2.18, we treat all θk where k ̸= i as constants and\\nthen differentiate θi using regular differentiation rules. For a given θi, let us deﬁne:\\nβ =\\n∑\\nk̸=i\\neθk, (2.19)\\nand\\nf (θi) = 1\\n1 + βe−θi\\n= (1 + βe−θi)−1. (2.20)\\nIt can now be shown that the derivative with respect to θi holds:\\nf ′(θi) =\\n(\\n1 + βe−θi\\n) −2\\nβe−θi, (2.21)\\n32Chapter 2 LOGISTIC REGRESSION\\nwhich can take on the informative form of:\\nf ′(θi) = f (θi)(1 − f (θi)). (2.22)\\nIt should be noted that 2.21 holds for any constant β, and for β = 1 it clearly reduces\\nto the sigmoid activation function.\\nNote: Characterize the sigmoid function when its argument approaches 0, ∞ and −∞.\\nWhat undesired properties of the sigmoid function do this values entail when considered as an\\nactivation function?\\n\\x04\\nSOL-18 \\uf14b CH.SOL- 2.15.\\n1. The logit value is simply obtained by substituting the values of the dependent variables\\nand model coefﬁcients into the linear logistic regression model, as follows:\\nlogit = β0 + β1x1 + β2x2 = −1.5 + 3 · 1 + −0.5 · 5 = −1. (2.23)\\n2. According to the natural relation between the logit and the odds, the following holds:\\nodds = elogit = eβ0+β1x1+β2x2 = e−1 = 0.3678794. (2.24)\\n3. The odds ratio is, by deﬁnition:\\nodds = P (y = 1)\\nP (y = 0) , (2.25)\\nso the logistic response function is:\\nP (y = 1) = 1\\n1 + e−logit = 1\\n1 + e1 = 0.2689414. (2.26)\\n\\x04\\n2.3.4 Truly Understanding Logistic Regression\\n332.3. SOLUTIONS\\nSOL-19 \\uf14b CH.SOL- 2.16.\\n1. T umour eradication (Y ) is the response variable and cancer type ( X) is the explanatory\\nvariable.\\n2. Relative risk (RR) is the ratio of risk of an event in one group (e.g., exposed group)\\nversus the risk of the event in the other group (e.g., non-exposed group). The odds ratio\\n(OR) is the ratio of odds of an event in one group versus the odds of the event in the\\nother group.\\n3. If we calculate odds ratio as a measure of association:\\nˆθ = 560 × 36\\n69 × 260 = 1.23745. (2.27)\\nAnd the log-odds ratio is (log(1.23745)) = 0 .213052:\\nThe odds ratio is larger than one, indicating that the odds for a breast cancer is more\\nthan the odds for a lung cancer to be eradicated. Notice however, that this result is too\\nclose to one, which prevents conclusive decision regarding the odds relation.\\nAdditionally, if we calculate relative risk as a measure of association:\\nRR =\\n560\\n560+260\\n69\\n69+36\\n= 1.0392. (2.28)\\n4. The 95% conﬁdence interval for the odds-ratio, θ is computed from the sample conﬁd-\\nence interval for log odds ratio:\\nˆσ\\n(\\nlog(ˆθ)\\n)\\n=\\n√\\n1\\n560 + 1\\n260 + 1\\n69 + 1\\n36 = 0.21886. (2.29)\\nTherefore, the 95% CI for log (θ) is:\\n0.213052 ± 1.95 × 0.21886 = (0 .6398298, −0.2137241). (2.30)\\n34Chapter 2 LOGISTIC REGRESSION\\nTherefore, the 95% CI for θ is:\\n(e−0.210, e0.647) = (0 .810, 1.909). (2.31)\\n5. The CI (0.810, 1.909) contains 1, which indicates that the true odds ratio is not signi-\\nﬁcantly different from 1 and there is not enough evidence that tumour eradication is\\ndependent on cancer type.\\n\\x04\\nSOL-20 \\uf14b CH.SOL- 2.17.\\n1. By using the deﬁned values for X1 and X2, and the known logistic regression model,\\nsubstitution yields:\\nˆp(X) = e−6+0.05X1+X2\\n(1 + e−6+0.05X1+X2) = 0.3775. (2.32)\\n2. The equation for the predicted probability tells us that:\\ne−6+0.05X1+3.5\\n(1 + e−6+0.05X1+3.5) = 0.5, (2.33)\\nwhich is equivalent to constraining:\\ne−6+0.05X1+3.5 = 1. (2.34)\\nBy taking the logarithm of both sides, we get that the number of milliseconds needed is:\\nX1 = 2.5\\n0.05 = 50. (2.35)\\n\\x04\\nSOL-21 \\uf14b CH.SOL- 2.18.\\n352.3. SOLUTIONS\\nFor the purpose of this exercise, it is instructive to pre-deﬁne z as:\\nz (X1, X2) = −6.36 − 1.02 × X1 + 0.12 × X2. (2.36)\\n1. By employing the classic logistic regression model:\\nodds = exp(z (X1, X2)). (2.37)\\n2. By substituting the given values of X1, X2 into z (X1, X2), the probability holds:\\np = exp(z (1, 100))/(1 + exp(z (1, 100))) = 0 .99. (2.38)\\n3. Y es. The coefﬁcient for coffee consumption is positive ( 0.119) and the p-value is less\\nthan 0.05 (0.0304).\\nNote: Can you describe the relation between these numerical relations and the positive\\nconclusion?\\n4. No. The p-value for this predictor is 0.3818 > 0.05.\\nNote: Can you explain why this inequality implicates a lack of statistical evidence?\\n\\x04\\nSOL-22 \\uf14b CH.SOL- 2.19.\\n1. The estimated probability of improvement is:\\nˆπ(gum bacteria) =\\nexp(−4.8792 + 0.0258 × gum bacteria)\\n1 + exp(−4.8792 + 0.0258 × gum bacteria).\\nHence, ˆπ(33) = 0 .01748.\\n36Chapter 2 LOGISTIC REGRESSION\\n2. For ˆπ(gum bacteria) = 0 .5 we know that:\\nˆπ(gum) = exp( ˆα + ˆβx)\\n1 + exp( ˆα + ˆβx)\\n= 0.5 (2.39)\\ngum bacteria = −ˆα/ ˆβ = 4.8792/0.0258 = 189 .116. (2.40)\\n3. The estimated odds ratio are given by:\\nexp( ˆβ) = exp(0 .0258) = 1 .0504. (2.41)\\n4. A 99% conﬁdence interval for β is calculated as follows:\\nˆβ ± z0.005 × ASE( ˆβ) = (2.42)\\n0.0258 ± 2.576 × 0.0194 (2.43)\\n= (−0.00077, 0.9917). (2.44)\\nTherefore, a 99% conﬁdence interval for the true odds ratio exp(β) is given by:\\n(exp(−0.00077), exp(0.9917)) = (0 .99923, 2.6958). (2.45)\\n\\x04\\nSOL-23 \\uf14b CH.SOL- 2.20.\\n1. The sample odds ratio is:\\nˆθ = 130 × 6833\\n60 × 6778 = 2.1842. (2.46)\\n372.3. SOLUTIONS\\n2. The estimated standard error for log\\n(\\nˆθ\\n)\\nis:\\nˆσ\\n(\\nlog ˆθ\\n)\\n=\\n√\\n1\\n60 + 1\\n6833 + 1\\n130 + 1\\n6778 = 0.1570. (2.47)\\n3. According to previous sections, the 95% CI for the true log odds ratio is:\\n0.7812 ± 1.96 × 0.1570 = (0 .4734, 1.0889). (2.48)\\nCorrespondingly, the 95% CI for the true odds ratio is:\\n(e0.4734, e1.0889) = (1 .6060, 2.9710). (2.49)\\n\\x04\\n2.3.5 The Logit Function and Entropy\\nSOL-24 \\uf14b CH.SOL- 2.21.\\n1. The entropy (Fig. 2.13) has a maximum value of log2(2) for probability p = 1/2, which\\nis the most chaotic distribution. A lower entropy is a more predictable outcome, with\\nzero providing full certainty.\\n2. The derivative of the entropy with respect to p yields the negative of the logit func-\\ntion:\\ndH(p)\\ndp = −logit(p). (2.50)\\nNote: The curious reader is encouraged to rigorously prove this claim.\\n\\x04\\n2.3.6 Python, PyTorch, CPP\\nSOL-25 \\uf14b CH.SOL- 2.22.\\n38Chapter 2 LOGISTIC REGRESSION\\nFIGURE 2.13: Binary entropy .\\n1. During inference, the purpose of inner_product is to multiply the vector of logistic re-\\ngression coefﬁcients with the vector of the input which we like to evaluate, e.g., calculate\\nthe probability and binary class.\\n2. The line hypo(x) > 0.5f is commonly used for the evaluation of binary classiﬁcation\\nwherein probability values above 0.5 (i.e., a threshold) are regarded as TRUE whereas\\nvalues below 0.5 are regarded as F ALSE.\\n3. The term θ (theta) stands for the logistic regression coefﬁcients which were evaluated\\nduring training.\\n4. The output is as follows:\\n1 > inner_product=-0.5\\n2 > prob=0.377541\\n3 > hypo=0\\nFIGURE 2.14: Logistic regression in C++\\n\\x04\\nSOL-26 \\uf14b CH.SOL- 2.23.\\n392.3. SOLUTIONS\\nBecause the second dimension of lin is 7, and the ﬁrst dimension of data is 3, the result-\\ning matrix has a shape of torch.Size([3, 7]) .\\n\\x04\\nSOL-27 \\uf14b CH.SOL- 2.24.\\nIdeally, you should be able to recognize these functions immediately upon a request from\\nthe interviewer.\\n1. A softmax function.\\n2. A sigmoid function.\\n3. A derivative of a sigmoid function.\\n\\x04\\nSOL-28 \\uf14b CH.SOL- 2.25.\\nThe function implemented in Fig. 2.10 is the binary cross-entropy function. \\x04\\nSOL-29 \\uf14b CH.SOL- 2.26.\\n1. All the methods are variations of the sigmoid function.\\n2. In Python, approximately 1.797e + 308 holds the largest possible valve for a ﬂoating\\npoint variable. The logarithm of which is evaluated at 709.78. If you try to execute the\\nfollowing expression in Python, it will result in inf : np.log(1.8e + 308).\\n3. I would use Ver003 because of its stability. Note: Can you entail why is this method\\nmore stable than the others?\\n\\x04\\n40CHAPTER\\n3\\nPROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAnyone who considers arithmetical methods of producing random digits is, of\\ncourse, in a state of sin.\\n— John von Neumann (1903-1957)\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nThe Beta-Binomial distribution . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 773.1. INTRODUCTION\\n3.1 Introduction\\nT\\nHE Bayesian school of thought has permeated ﬁelds such as mechanical\\nstatistics, classical probability , and ﬁnancial mathematics [ 13]. In tandem,\\nthe subject matter itself has gained attraction, particularly in the ﬁeld of\\nBML. It is not surprising then, that several new Python based probabilistic\\nprogramming libraries such as PyMc3 and Stan [ 11] have emerged and have become\\nwidely adopted by the machine learning community .\\nThis chapter aims to introduce the Bayesian paradigm and apply Bayesian infer-\\nences in a variety of problems. In particular, the reader will be introduced with real-\\nlife examples of conditional probability and also discover one of the most important\\nresults in Bayesian statistics: that the family of beta distributions is conjugate to a bi-\\nnomial likelihood . It should be stressed that Bayesian inference is a subject matter\\nthat students evidently ﬁnd hard to grasp, since it heavily relies on rigorous probab-\\nilistic interpretations of data. Speciﬁcally , several obstacles hamper with the prospect\\nof learning Bayesian statistics:\\n1. Students typically undergo merely basic introduction to classical probability and\\nstatistics. Nonetheless, what follows requires a very solid grounding in these\\nﬁelds.\\n2. Many courses and resources that address Bayesian learning do not cover essen-\\ntial concepts.\\n3. A strong comprehension of Bayesian methods involves numerical training and\\nsophistication levels that go beyond ﬁrst year calculus.\\nConclusively , this chapter may be much harder to understand than other chapters.\\nThus, we strongly urge the readers to thoroughly solve the following questions and\\nverify their grasp of the mathematical concepts in the basis of the solutions [ 8].\\n3.2 Problems\\n3.2.1 Expectation and Variance\\nPRB-30 \\uf059 CH.PRB- 3.1.\\nDeﬁne what is meant by a Bernoulli trial.\\n42Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPRB-31 \\uf059 CH.PRB- 3.2.\\nThe binomial distribution is often used to model the probability that k out of a group of n\\nobjects bare a speciﬁc characteristic. Deﬁne what is meant by a binomial random variable\\nX.\\nPRB-32 \\uf059 CH.PRB- 3.3.\\nWhat does the following shorthand stand for?\\nX ∼ Binomial(n, p ) (3.1)\\nPRB-33 \\uf059 CH.PRB- 3.4.\\nFind the probability mass function (PMF) of the following random variable:\\nX ∼ Binomial(n, p ) (3.2)\\nPRB-34 \\uf059 CH.PRB- 3.5.\\nAnswer the following questions:\\n1. Deﬁne what is meant by (mathematical) expectation.\\n2. Deﬁne what is meant by variance.\\n3. Derive the expectation and variance of a the binomial random variable X ∼ Binomial(n, p )\\nin terms of p and n.\\nPRB-35 \\uf059 CH.PRB- 3.6.\\nProton therapy (PT) is a widely adopted form of treatment for many types of cancer [ 6].\\nA PT device which was not properly calibrated is used to treat a patient with pancreatic\\ncancer (Fig. 3.1). As a result, a PT beam randomly shoots 200 particles independently and\\ncorrectly hits cancerous cells with a probability of 0.1.\\n433.2. PROBLEMS\\nFIGURE 3.1: Histopathology for pancreatic cancer cells.\\n1. Find the statistical distribution of the number of correct hits on cancerous cells in\\nthe described experiment. What are the expectation and variance of the corresponding\\nrandom variable?\\n2. A radiologist using the device claims he was able to hit exactly 60 cancerous cells.\\nHow likely is it that he is wrong?\\n3.2.2 Conditional Probability\\nPRB-36 \\uf059 CH.PRB- 3.7.\\nGiven two events A and B in probability space H, which occur with probabilities P (A)\\nand P (B), respectively:\\n1. Deﬁne the conditional probability of A given B. Mind singular cases.\\n2. Annotate each part of the conditional probability formulae.\\n3. Draw an instance of Venn diagram, depicting the intersection of the events A and B.\\nAssume that A ⋃ B = H.\\nPRB-37 \\uf059 CH.PRB- 3.8.\\nBayesian inference amalgamates data information in the likelihood function with known\\nprior information. This is done by conditioning the prior on the likelihood using the Bayes\\nformulae. Assume two events A and B in probability space H, which occur with probabilities\\n44Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nP (A) and P (B), respectively. Given that A ⋃ B = H, state the Bayes formulae for this case,\\ninterpret its components and annotate them.\\nPRB-38 \\uf059 CH.PRB- 3.9.\\nDeﬁne the terms likelihood and log-likelihood of a discrete random variable X given\\na ﬁxed parameter of interest γ. Give a practical example of such scenario and derive its\\nlikelihood and log-likelihood.\\nPRB-39 \\uf059 CH.PRB- 3.10.\\nDeﬁne the term prior distribution of a likelihood parameter γ in the continuous case.\\nPRB-40 \\uf059 CH.PRB- 3.11.\\nShow the relationship between the prior, posterior and likelihood probabilities.\\nPRB-41 \\uf059 CH.PRB- 3.12.\\nIn a Bayesian context, if a ﬁrst experiment is conducted, and then another experiment is\\nfollowed, what does the posterior become for the next experiment?\\nPRB-42 \\uf059 CH.PRB- 3.13.\\nWhat is the condition under which two events A and B are said to be statistically\\nindependent?\\n3.2.3 Bayes Rule\\nPRB-43 \\uf059 CH.PRB- 3.14.\\nIn an experiment conducted in the ﬁeld of particle physics (Fig. 3.2), a certain particle\\nmay be in two distinct equally probable quantum states: integer spin or half-integer spin.\\nIt is well-known that particles with integer spin are bosons, while particles with half-integer\\nspin are fermions [ 4].\\n453.2. PROBLEMS\\nFIGURE 3.2: Bosons and fermions: particles with half-integer spin are fermions.\\nA physicist is observing two such particles, while at least one of which is in a half-integer\\nstate. What is the probability that both particles are fermions?\\nPRB-44 \\uf059 CH.PRB- 3.15.\\nDuring pregnancy, the Placenta Chorion T est [1] is commonly used for the diagnosis of\\nhereditary diseases (Fig. 3.3). The test has a probability of 0.95 of being correct whether or\\nnot a hereditary disease is present.\\n46Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.3: Foetal surface of the placenta\\nIt is known that 1% of pregnancies result in hereditary diseases. Calculate the probability\\nof a test indicating that a hereditary disease is present.\\nPRB-45 \\uf059 CH.PRB- 3.16.\\nThe Dercum disease [ 3] is an extremely rare disorder of multiple painful tissue growths.\\nIn a population in which the ratio of females to males is equal, 5% of females and 0.25% of\\nmales have the Dercum disease (Fig. 3.4).\\nFIGURE 3.4: The Dercum disease\\nA person is chosen at random and that person has the Dercum disease. Calculate the\\nprobability that the person is female.\\nPRB-46 \\uf059 CH.PRB- 3.17.\\nThere are numerous fraudulent binary options websites scattered around the Internet,\\nand for every site that shuts down, new ones are sprouted like mushrooms. A fraudulent AI\\n473.2. PROBLEMS\\nbased stock-market prediction algorithm utilized at the New Y ork Stock Exchange, (Fig. 3.6)\\ncan correctly predict if a certain binary option [ 7] shifts states from 0 to 1 or the other way\\naround, with 85% certainty.\\nFIGURE 3.5: The New York Stock Exchange.\\nA ﬁnancial engineer has created a portfolio consisting twice as many state-1 options then\\nstate-0 options. A stock option is selected at random and is determined by said algorithm to\\nbe in the state of 1. What is the probability that the prediction made by the AI is correct?\\nPRB-47 \\uf059 CH.PRB- 3.18.\\nIn an experiment conducted by a hedge fund to determine if monkeys (Fig. 3.6) can\\noutperform humans in selecting better stock market portfolios, 0.05 of humans and 1 out of\\n15 monkeys could correctly predict stock market trends correctly.\\n48Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.6: Hedge funds and monkeys.\\nFrom an equally probable pool of humans and monkeys an “expert” is chosen at ran-\\ndom. When tested, that expert was correct in predicting the stock market shift. What is the\\nprobability that the expert is a human?\\nPRB-48 \\uf059 CH.PRB- 3.19.\\nDuring the cold war, the U.S.A developed a speech to text (STT) algorithm that could\\ntheoretically detect the hidden dialects of Russian sleeper agents. These agents (Fig. 3.7),\\nwere trained to speak English in Russia and subsequently sent to the US to gather intelli-\\ngence. The FBI was able to apprehend ten such hidden Russian spies [ 9] and accused them\\nof being \"sleeper\" agents.\\nFIGURE 3.7: Dialect detection.\\n493.2. PROBLEMS\\nThe Algorithm relied on the acoustic properties of Russian pronunciation of the word\\n(v-o-k-s-a-l) which was borrowed from English V-a-u-x-h-a-l-l. It was alleged that it is im-\\npossible for Russians to completely hide their accent and hence when a Russian would\\nsay V-a-u-x-h-a-l-l, the algorithm would yield the text \"v-o-k-s-a-l\". T o test the algorithm\\nat a diplomatic gathering where 20% of participants are Sleeper agents and the rest Americ-\\nans, a data scientist randomly chooses a person and asks him to say V-a-u-x-h-a-l-l. A single\\nletter is then chosen randomly from the word that was generated by the algorithm, which\\nis observed to be an \"l\". What is the probability that the person is indeed a Russian sleeper\\nagent?\\nPRB-49 \\uf059 CH.PRB- 3.20.\\nDuring World War II, forces on both sides of the war relied on encrypted communica-\\ntions. The main encryption scheme used by the German military was an Enigma machine\\n[5], which was employed extensively by Nazi Germany. Statistically, the Enigma machine\\nsent the symbols X and Z Fig. ( 3.8) according to the following probabilities:\\nP (X) = 2\\n9 (3.3)\\nP (Z) = 7\\n9 (3.4)\\nFIGURE 3.8: The Morse telegraph code.\\nIn one incident, the German military sent encoded messages while the British army used\\ncountermeasures to deliberately tamper with the transmission. Assume that as a result of the\\nBritish countermeasures, an X is erroneously received as a Z (and mutatis mutandis) with a\\n50Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nprobability 1\\n7. If a recipient in the German military received a Z, what is the probability that\\na Z was actually transmitted by the sender?\\n3.2.4 Maximum Likelihood Estimation\\nPRB-50 \\uf059 CH.PRB- 3.21.\\nWhat is likelihood function of the independent identically distributed (i.i.d) random\\nvariables:\\nX1, · · · , Xn where Xi ∼ binomial(n, p ), ∀i ∈ [1, n],\\nand where p is the parameter of interest?\\nPRB-51 \\uf059 CH.PRB- 3.22.\\nHow can we derive the maximum likelihood estimator (MLE) of the i.i.d samples\\nX1, · · · , Xn introduced in Q. 3.21?\\nPRB-52 \\uf059 CH.PRB- 3.23.\\nWhat is the relationship between the likelihood function and the log-likelihood function?\\nPRB-53 \\uf059 CH.PRB- 3.24.\\nDescribe how to analytically ﬁnd the MLE of a likelihood function?\\nPRB-54 \\uf059 CH.PRB- 3.25.\\nWhat is the term used to describe the ﬁrst derivative of the log-likelihood function?\\nPRB-55 \\uf059 CH.PRB- 3.26.\\nDeﬁne the term Fisher information.\\n3.2.5 Fisher Information\\n513.2. PROBLEMS\\nPRB-56 \\uf059 CH.PRB- 3.27.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history [ 2] with a death tool far exceeding all\\npast outbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976\\nin Sudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 3.9: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the center for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ | y) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y, γ ∈ [0, 1], y = 1, 2, . . . , n (3.5)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ,\\nthe proportion of infected humans in the entire population. The expectation and variance of\\nthe binomial distribution are:\\nE(y|γ, n) = nγ, V (y|γ, n) = nγ(1 − γ) (3.6)\\nAnswer the following; for the likelihood function of the form Lx(γ):\\n1. Find the log-likelihood function lx(γ) = ln Lx(γ).\\n52Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. Find the gradient of lx(γ).\\n3. Find the Hessian matrix H(γ).\\n4. Find the Fisher information I(γ).\\n5. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\nPRB-57 \\uf059 CH.PRB- 3.28.\\nIn this question, you are going to derive the Fisher information function for several\\ndistributions. Given a probability density function (PDF) f (X|γ), you are provided with\\nthe following deﬁnitions:\\n1. The natural logarithm of the PDF ln f (X|γ) = Φ(X|γ).\\n2. The ﬁrst partial derivative Φ′(X|γ).\\n3. The second partial derivative Φ′′(X|γ).\\n4. The Fisher Information for a continuous random variable:\\nI(γ) = −Eγ\\n[\\nΦ′(X|γ)2\\n]\\n. (3.7)\\nFind the Fisher Information I(γ) for the following distributions:\\n1. The Bernoulli Distribution X ∼ B(1, γ).\\n2. The Poisson Distribution X ∼ P oiss(θ).\\nPRB-58 \\uf059 CH.PRB- 3.29.\\n1. True or False: The Fisher Information is used to compute the Cramer-Rao bound on\\nthe variance of any unbiased maximum likelihood estimator.\\n2. True or False: The Fisher Information matrix is also the Hessian of the symmetrized\\nKL divergence.\\n533.2. PROBLEMS\\n3.2.6 Posterior & prior predictive distributions\\nPRB-59 \\uf059 CH.PRB- 3.30.\\nIn chapter 3 we discussed the notion of a prior and a posterior distribution.\\n1. Deﬁne the term posterior distribution.\\n2. Deﬁne the term prior predictive distribution.\\nPRB-60 \\uf059 CH.PRB- 3.31.\\nLet y be the number of successes in 5 independent trials, where the probability of success\\nis θ in each trial. Suppose your prior distribution for θ is as follows: P (θ = 1 /2) = 0 .25,\\nP (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y) after observing y.\\n2. Derive the prior predictive distribution for y.\\n3.2.7 Conjugate priors\\nPRB-61 \\uf059 CH.PRB- 3.32.\\nIn chapter 3 we discussed the notion of a prior and a posterior.\\n1. Deﬁne the term conjugate prior.\\n2. Deﬁne the term non-informative prior.\\nThe Beta-Binomial distribution\\nPRB-62 \\uf059 CH.PRB- 3.33.\\nThe Binomial distribution was discussed extensively in chapter 3. Here, we are going to\\nshow one of the most important results in Bayesian machine learning. Prove that the family\\nof beta distributions is conjugate to a binomial likelihood , so that if a prior is in that\\n54Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nfamily then so is the posterior. That is, show that:\\nx ∼ Ber(γ), γ ∼ B (α, β) ⇒ γ|x ∼ B (α′, β′) (3.8)\\nFor instance, for h heads and t tails, the posterior is:\\nB(h + α, t + β) (3.9)\\n3.2.8 Bayesian Deep Learning\\nPRB-63 \\uf059 CH.PRB- 3.34.\\nA recently published paper presents a new layer for a new Bayesian neural network\\n(BNN). The layer behaves as follows. During the feed-forward operation, each of the hidden\\nneurons Hn , n ∈ 1, 2 in the neural network (Fig. 3.10) may, or may not ﬁre independently\\nof each other according to a known prior distribution.\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 3.10: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ binomial(n, γ ) random variable\\nand ﬁres with a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U nif orm(0, γ) random variable\\nand ﬁres with a probability of γ.\\nPRB-64 \\uf059 CH.PRB- 3.35.\\nY our colleague, a veteran of the Deep Learning industry, comes up with an idea for for\\n553.2. PROBLEMS\\na BNN layer entitled OnOffLayer. He suggests that each neuron will stay on (the other\\nstate is off) following the distribution f (x) = e−x for x > 0 and f (x) = 0 otherwise\\n(Fig. 3.11). X indicates the time in seconds the neuron stays on . In a BNN, 200 such\\nneurons are activated independently in said OnOffLayer. The OnOffLayer is set to off (e.g.\\nnot active) only if at least 150 of the neurons are shut down . Find the probability that\\nthe OnOffLayer will be active for at least 20 seconds without being shut down.\\non offtime = f (x) = e−x\\nFIGURE 3.11: OnOffLayer in a BNN model.\\nPRB-65 \\uf059 CH.PRB- 3.36.\\nA Dropout layer [12] (Fig. 3.12) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 3.12: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [10], a Dropout layer is declared as follows ( 3.1):\\n56Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 3.1: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 3.1) indicates that the probability of zeroing an\\nelement is 0.2.\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 3.13: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 3.12). Here, for illustration purposes, all two\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\nY ou are interested in the proportionθ of dropped-out neurons. Assume that the chance of\\ndrop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the posterior\\nof θ.\\nPRB-66 \\uf059 CH.PRB- 3.37.\\nA new data scientist in your team, who was formerly a Quantum Physicist, suggests\\nthe following procedure for a Dropout layer entitled QuantumDrop which is based on\\nQuantum principles and the Maxwell Boltzmann distribution. In the Maxwell-Boltzmann\\n573.2. PROBLEMS\\ndistribution, the likelihood of ﬁnding a particle with a particular velocity v is provided by:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.10)\\n0 1 000 2 000 3 000 4 000 5 000\\n0\\n2\\n4\\n·10−4\\nv in m·s−1\\nP (v)\\nHelium\\nFIGURE 3.14: The Maxwell-Boltzmann distribution.\\nIn the suggested QuantumDrop layer ( 3.15), each of the neurons behaves like a molecule\\nand is distributed according to the Maxwell-Boltzmann distribution and ﬁres only when\\nthe most probable speed is reached . This speed is the velocity associated with the highest\\npoint in the Maxwell distribution ( 3.14). Using calculus, brain power and some mathem-\\natical manipulation, ﬁnd the most likely value (speed) at which the neuron will ﬁre .\\noff firedneuron − f ires\\nFIGURE 3.15: A QuantumDrop layer.\\n58Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3.3 Solutions\\n3.3.1 Expectation and Variance\\nSOL-30 \\uf14b CH.SOL- 3.1.\\nThe notion of a Bernoulli trial refers to an experiment with two dichotomous binary out-\\ncomes; success (x = 1), and failure (x = 0). \\x04\\nSOL-31 \\uf14b CH.SOL- 3.2.\\nA binomial random variable X = k represents k successes in n mutually independent\\nBernoulli trials. \\x04\\nSOL-32 \\uf14b CH.SOL- 3.3.\\nThe shorthand X ∼ Binomial(n, p ) indicates that the random variable X has the bi-\\nnomial distribution (Fig. 3.16). The positive integer parameter n indicates the number of\\nBernoulli trials and the real parameter p, 0 < p < 1 holds the probability of success in each of\\nthese trials.\\n0 10 20 30 40 50\\n0,0\\n0,2\\n0,4\\np(x = k) =\\n( n\\nk\\n)\\n· pk · (1 − p)n−k\\nx\\np(x)\\nn = 50, p = 0.3\\nn = 50, p = 0.7\\nn = 50, p = 0.9\\nFIGURE 3.16: The binomial distribution.\\n\\x04\\nSOL-33 \\uf14b CH.SOL- 3.4.\\n593.3. SOLUTIONS\\nThe random variable X ∼ Binomial(n, p ) has the following PMF:\\nP (X = k) =\\n(\\nn\\nk\\n)\\npk (1 − p)n−k ; k = 0, 1, 2, . . . , n. (3.11)\\n\\x04\\nSOL-34 \\uf14b CH.SOL- 3.5.\\nThe answers below regard a discrete random variable. The curious reader is encouraged to\\nexpend them to the continuous case.\\n1. For a random variable X with probability mass function P (X = k) and a set of out-\\ncomes K, the expected value of X is deﬁned as:\\nE[X] :=\\n∑\\nk∈K\\nkP (X = k). (3.12)\\nNote: The expectation of X may also be denoted by µX.\\n2. The variance of X is deﬁned as:\\nVar[X] := E\\n[\\n(X − E[X])2\\n]\\n. (3.13)\\nNote: The variance of X may also be denoted by σ2\\nX, while σX itself denotes the stand-\\nard deviation of X.\\n3. The population mean and variance of a binomial random variable with parameters n\\nand p are:\\nE[X] = np V [X] = np(1 − p) (3.14)\\nNote: Why is this solution intuitive? What information theory-related phenomenon\\noccurs when p = 1/2?\\n\\x04\\nSOL-35 \\uf14b CH.SOL- 3.6.\\n60Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1. This scenario describes an experiment that is repeated 200 times independently with a\\nsuccess probability of 0.1. Thus, if the random variable X denotes the number of times\\nsuccess was obtained, then it is best characterized by the binomial distribution with\\nparameters n = 200 and p = 0.1. Formally:\\nX ∼ Binomial(200, 0.1). (3.15)\\nThe expectation of X is given by:\\nx = E(x) = 200 × 0.1 = 20 , (3.16)\\nand its respective variance is:\\nV ar = 200 × 0.10(1 − 0.10) = 18 .0. (3.17)\\n2. Here we propose two distinguished methods to answer the question.\\nPrimarily, the straightforward solution is to employ the deﬁnition of the binomial dis-\\ntribution and substitute the value of X in it. Namely:\\nP (X = 60; n = 200, p = 0.1)\\n=\\n(\\n200\\n60\\n)\\n0.160 (1 − 0.1)200−60\\n=≈ 2.7 × e−15.\\n(3.18)\\nThis leads to an extremely high probability that the radiologist is mistaken.\\nThe following approach is longer and more advanced, but grants the reader with insights\\nand intuition regarding the results. T o derive how wrong the radiologist is, we can\\nemploy an approximation by considering the standard normal distribution. In statistics,\\nthe Z-score allows us to understand how far from the mean is a data point in units of\\nstandard deviation, thus revealing how likely it is to occur (Fig. 3.17).\\n613.3. SOLUTIONS\\nZ-score\\nz =\\nData point\\nx − µ\\nExpectation\\nσ\\nStandard dev .\\n. (3.19)\\nFIGURE 3.17: Z-score\\nTherefore, the probability of correctly hitting 60 cells is:\\nP (X ≥ 60) = P (Z ≥ 60 − 20√\\n18.0 ) = P (Z ≥ 9.428) ≈ 0. (3.20)\\nAgain, the outcome',\n",
              " ' extremely high probability that the radiologist is mistaken.\\nThe following approach is longer and more advanced, but grants the reader with insights\\nand intuition regarding the results. T o derive how wrong the radiologist is, we can\\nemploy an approximation by considering the standard normal distribution. In statistics,\\nthe Z-score allows us to understand how far from the mean is a data point in units of\\nstandard deviation, thus revealing how likely it is to occur (Fig. 3.17).\\n613.3. SOLUTIONS\\nZ-score\\nz =\\nData point\\nx − µ\\nExpectation\\nσ\\nStandard dev .\\n. (3.19)\\nFIGURE 3.17: Z-score\\nTherefore, the probability of correctly hitting 60 cells is:\\nP (X ≥ 60) = P (Z ≥ 60 − 20√\\n18.0 ) = P (Z ≥ 9.428) ≈ 0. (3.20)\\nAgain, the outcome shows the likelihood that the radiologist was wrong approaches 1.\\nNote: Why is the relation depicted in Fig. 3.17 deduces that Z is a standard Gaussian?\\nUnder what terms is this conclusion valid? Why does eq. (3.20) employs the cumulative\\ndistribution function and not the probability mass function?\\n\\x04\\n3.3.2 Conditional Probability\\nSOL-36 \\uf14b CH.SOL- 3.7.\\n1. For two events A and B with P (B) > 0, the conditional probability of A given that\\nB has occurred is deﬁned as:\\nP (A|B) = P (A ∩ B)\\nP (B) . (3.21)\\nIt is easy to note that if P (B) = 0 , this relation is not deﬁned mathematically. In this\\ncase, P (A|B) = P (A ∩ B) = P (A).\\n2. The annotated probabilities are displayed in Fig. 3.18:\\n62Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nA given B\\nP (A|B) =\\nA and B\\nP (A ∩ B)\\nP (B)\\nB only\\n. (3.22)\\nFIGURE 3.18: Conditional probability\\n3. An example of a diagram depicting the intersected events A and B is displayed in Fig.\\n3.19:\\nA B\\nH\\nFIGURE 3.19: V enn diagram of the intersected events A and B in probability space H\\n\\x04\\nSOL-37 \\uf14b CH.SOL- 3.8.\\nThe Bayes formulae reads:\\nP (A|B) = P (B|A)P (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac), (3.23)\\nwhere P (Ac) is the complementary probability of P (A). The interpretation of the elements in\\n633.3. SOLUTIONS\\nBayes formulae is as follows:\\nposterior probability = likelihood of the data × prior probability\\nnormalization constant . (3.24)\\nNote: What is the important role of the normalization constant? Analyze the cases where\\nP (B) → 0 and P (B) → 1. The annotated probabilities are displayed in (Fig. 3.20):\\nPosterior\\nP (A|B) =\\nLikelihood\\nP (B|A)\\nPrior\\nP (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac)\\nB only\\n. (3.25)\\nFIGURE 3.20: Annotated components of the Bayes formula (eq. 3.23)\\n\\x04\\nSOL-38 \\uf14b CH.SOL- 3.9.\\nGiven X as a discrete randomly distributed variable and given γ as the parameter of\\ninterest, the likelihood and the log-likelihood of X given γ follows respectively:\\nLγ(X = x) = p(X = x|γ) (3.26)\\nℓγ(X = x) = ln ( p(X = x|γ)) (3.27)\\nThe term likelihood can be intuitively understood from this deﬁnition; it deduces how likely is\\nto obtain a value x when a prior information is given regarding its distribution, namely the\\nparameter γ. For example, let us consider a biased coin toss with ph = γ. Then:\\nLγ(X = “h′′) = p(X = “h′′|γ) = γ. (3.28)\\nℓγ(X = “h′′) = ln ( p(X = “h′′|γ)) = ln ( γ) . (3.29)\\n64Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nNote: The likelihood function may also follow continuous distributions such as the normal\\ndistribution. In the latter, it is recommended and often obligatory to employ the log-likelihood.\\nWhy? We encourage the reader to modify the above to the continuous case of normal distribu-\\ntion and derive the answer. \\x04\\nSOL-39 \\uf14b CH.SOL- 3.10.\\nThe continuous prior distribution, f (Γ = γ) represents what is known about the probab-\\nility of the value γ before the experiment has commenced. It is termed as being subjective,\\nand therefore may vary considerably between researchers. By proceeding the previous example,\\nf (Γ = 0.8) holds the probability of randomly ﬂipping a coin that yields “heads” with chance\\nof 80% of times. \\x04\\nSOL-40 \\uf14b CH.SOL- 3.11.\\nThe essence of Bayesian analysis is to draw inference of unknown quantities or quantiles\\nfrom the posterior distribution p(Γ = γ|X = x), which is traditionally derived from prior\\nbeliefs and data information. Bayesian statistical conclusions about chances to obtain the para-\\nmeter Γ = γ or unobserved values of random variable X = x, are made in terms of prob-\\nability statements. These probability statements are conditional on the observed values of X,\\nwhich is denoted as p(Γ = γ|X = x), called posterior distributions of parameter γ. Bayesian\\nanalysis is a practical method for making inferences from data and prior beliefs using probab-\\nility models for quantities we observe and for quantities which we wish to learn. Bayes rule\\nprovides a relationship of this form:\\nposterior ∝ p(x|γ)p(γ) ∝ data given prior × chance of prior . (3.30)\\n\\x04\\nSOL-41 \\uf14b CH.SOL- 3.12.\\nThe posterior density summarizes what is known about the parameter of interest γ after\\nthe data is observed. In Bayesian statistics, the posterior density p(Γ = γ|X = x) becomes\\nthe prior for this next experiment. This is part of the well-known Bayesian updating mech-\\nanism wherein we update our knowledge to reﬂect the actual distribution of data that we\\nobserved. T o summarize, from the perspective of Bayes Theorem, we update the prior distri-\\nbution to a posterior distribution after seeing the data. \\x04\\n653.3. SOLUTIONS\\nSOL-42 \\uf14b CH.SOL- 3.13.\\nTwo events A and B are statistically independent if (and only if):\\nP (A ∩ B) = P (A)P (B). (3.31)\\nNote: Use conditional probability and rationalize this outcome. How does this property be-\\ncome extremely useful in practical researches that consider likelihood of normally distributed\\nfeatures? \\x04\\n3.3.3 Bayes Rule\\nSOL-43 \\uf14b CH.SOL- 3.14.\\nLet γ stand for the number of half-integer spin states, and given the prior knowledge that\\nboth states are equally probable:\\nP (γ = 2|γ ≥ 1) (3.32)\\n= P (γ = 2, γ ≥ 1)\\nP (γ ≥ 1) (3.33)\\n= P (γ = 2)\\n1 − P (γ = 0) = 1/4\\n1 − 1/4 = 1\\n3 (3.34)\\nNote: Under what statistical property do the above relations hold? \\x04\\nSOL-44 \\uf14b CH.SOL- 3.15.\\nLet event A indicate present hereditary-disease and let event B to hold a positive test result.\\nThe calculated probabilities are presented in T able 3.1. We were asked to ﬁnd the probability\\nof a test indicating that hereditary-disease is present, namely P (B). According to the law of\\ntotal probability:\\nP (B) = P (B|A) ∗ P (A) + P (B|A) ∗ P (A)\\n= [0.95 ∗ 0.01] + [0.05 ∗ 0.99] = 0 .059 (3.35)\\nNote: In terms of performance evaluation, P (B|A) is often referred to as the probability of\\n66Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPROBABILITY EXPLANATION\\nP(A)= 0.01 The probability of hereditary-disease.\\nP(A)=1-0.01=.99 The probability of no hereditary-disease.\\nP(B|A)=0.95 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is NOT present [Ã].\\nP(B|B)=1-0.95=.05 The probability that the test will yield a positive result [B]\\nif hereditary-disease is NOT present [Ã] (probability of false\\nalarm).\\nP(B|A)=0.95 The probability that the test will yield a positive result [B] if\\nhereditary-disease is present [A] (probability of detection).\\nP(B|A)=1-0.95=.05 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is present [A].\\nTABLE 3.1: Probability values of hereditary-disease detection.\\ndetection and P (B|A) is considered the probability of false alarm. Notice that these measures\\ndo not, neither logically nor mathematically, combine to probability of 1. \\x04\\nSOL-45 \\uf14b CH.SOL- 3.16.\\nWe ﬁrst enumerate the probabilities one by one:\\nP (Dercum|f emale) = 0 .05, (3.36)\\nP (Dercum|male) = 0 .0025, (3.37)\\nP (male) = P (f emale) = 0 .5. (3.38)\\nWe are asked to ﬁnd P (f emale|Dercum). Using Bayes Rule:\\nP (f emale|Dercum) = P (Dercum|f emale)P (f emale)\\nP (Dercum) . (3.39)\\n673.3. SOLUTIONS\\nHowever we are missing the term P (Dercum). T o ﬁnd it, we apply the Law of T otal Probab-\\nility:\\nP (Dercum) = P (Dercum|f emale)P (f emale)\\n+P (Dercum|male)P (male)\\n=\\n0.05 · 0.5 + 0.0025 · 0.5 = 0 .02625.\\nAnd ﬁnally, returning to eq. ( 3.39):\\nP (f emale|Dercum) = 0.05 · 0.5\\n0.02625 ≈ 0.9524 (3.40)\\nNote: How could this result be reached with one mathematical equation? \\x04\\nSOL-46 \\uf14b CH.SOL- 3.17.\\nIn order to solve this problem, we introduce the following events:\\n1. AI: the AI predicts that the state of the stock option is 1.\\n2. State1: the state of the stock option is 1.\\n3. State0: the state of the stock option is 0.\\nA direct application of Bayes formulae yields:\\nP (State1|AI) = (3.41)\\nP (AI|State1)P (State1)\\nP (AI|State1)P (State1)+P (AI|State0)P (State0) (3.42)\\n= 0.85·2/3\\n0.85·2/3+0.15·1/3 ≈ 0.9189.\\n\\x04\\nSOL-47 \\uf14b CH.SOL- 3.18. In order to solve this problem, we introduce the following events:\\n1. H: a human.\\n68Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. M : a monkey.\\n3. C: a correct prediction.\\nBy employing Bayes theorem and the Law of T otal probability:\\nP (H|C) = P (H ∩ C)\\nP (C)\\n= P (C|H)P (H)\\nP (C|H)P (H) + P (C|M )P (M )\\n=\\n1\\n20 · 1\\n2\\n1\\n20 · 1\\n2 + 1\\n15 · 1\\n2\\n≈ 0.42.\\n(3.43)\\nNote: If something seems off in this outcome, do not worry - it is a positive sign for\\nunderstanding of conditional probability. \\x04\\nSOL-48 \\uf14b CH.SOL- 3.19.\\nIn order to solve this problem, we introduce the following events:\\n1. RU S: a Russian sleeper agent is speaking.\\n2. AM : an American is speaking.\\n3. L: the TTS system generates an “l”.\\nWe are asked to ﬁnd the value of P (RU S|L). Using Bayes Theorem we can write:\\nP (RU S|L) = P (L|RU S)P (RU S)\\nP (L) . (3.44)\\nWe were told that the Russians consist 1/5 of the attendees at the gathering, therefore:\\nP (RU S) = 1\\n5. (3.45)\\n693.3. SOLUTIONS\\nAdditionally, because \"v-o-k-s-a-l\" has a single l out of a total of six letters:\\nP (L|RU S) = 1\\n6. (3.46)\\nAdditionally, because \"V-a-u-x-h-a-l-l\" has two l’s out of a total of eight letters:\\nP (L|AM ) = 2\\n8. (3.47)\\nAn application of the Law of T otal Probability yields:\\nP (L) = P (AM )P (L|AM ) + P (RU S)P (L|RU S) (3.48)\\n=\\n( 4\\n5\\n) ( 2\\n8\\n)\\n+\\n( 1\\n5\\n) ( 1\\n6\\n)\\n= 7\\n30.\\nUsing Bayes Theorem we can write:\\nP (RU S|L) =\\n1\\n5\\n(\\n1\\n6\\n)\\n7\\n30\\n= 1\\n7. (3.49)\\nNote: What is the letter by which the algorithm is most likely to discover a Russian sleeper\\nagent? \\x04\\nSOL-49 \\uf14b CH.SOL- 3.20.\\nWe are given that:\\nP (X is erroneously received as a Z ) = 1 /7. Using Bayes Theorem we can write:\\nP (Z trans |Z received ) =\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received ) . (3.50)\\n70Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAn application of the Law of T otal Probability yields:\\nP (Z received ) =\\nP (Z received |Z trans )P (Z trans )\\n+P (Z received |X trans )P (X trans )\\n= 6\\n7 · 7\\n9 + 1\\n7 · 2\\n9\\n= 44\\n63.\\nSo, using Bayes Rule, we have that\\nP (Z trans |Z received )\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received )\\n=\\n6\\n7\\n7\\n9\\n44\\n63\\n= 44\\n63 = 0.95.\\n(3.51)\\n\\x04\\n3.3.4 Maximum Likelihood Estimation\\nSOL-50 \\uf14b CH.SOL- 3.21.\\nFor the set of i.i.d samples X1, · · · , Xn, the likelihood function is the product of the\\nprobability functions:\\nL(p) = p(X1 = x1; p)p(X2 = x2; p) · · ·p(Xn = xn; p)\\n=\\nn∏\\ni=1\\n(\\nn\\nxi\\n)\\npxi(1 − p)n−xi. (3.52)\\nNote: What is the distribution of X n when X is a Bernoulli distributed random variable?\\n\\x04\\n713.3. SOLUTIONS\\nSOL-51 \\uf14b CH.SOL- 3.22.\\nThe maximum likelihood estimator (MLE) of p is the value of all possible p values that\\nmaximizes L(p). Namely, the p value that renders the set of measurements X1, · · · , Xn as the\\nmost likely. Formally:\\nˆp = arg max0≤p≤1L(p) (3.53)\\nNote: The curious student is highly encouraged to derive ˆp from L(p). Notice that L(p) can\\nbe extremely simpliﬁed. \\x04\\nSOL-52 \\uf14b CH.SOL- 3.23.\\nThe log-likelihood is the logarithm of the likelihood function. Intuitively, maximizing\\nthe likelihood function L(γ) is equivalent to maximizing ln L(γ) in terms of ﬁnding the MLE\\nˆγ, since ln is a monotonically increasing function. Often, we maximize ln(f (γ)) instead of\\nthe f (γ). A common example is when L(γ) is comprised of normally distribution random\\nvariables.\\nFormally, if X1, · · · , Xn are i.i.d, each with probability mass function (PMF) of fXi(xi | γ),\\nthen\\nf (γ) =\\nn∏\\ni=1\\nfXi(xi | γ), (3.54)\\nln(f (γ)) =\\nn∑\\ni=1\\nln fXi(xi | γ). (3.55)\\n\\x04\\nSOL-53 \\uf14b CH.SOL- 3.24.\\nThe general procedure for ﬁnding the MLE, given that the likelihood function is differen-\\ntiable, is as follows:\\n1. Start by differentiating the log-likelihood function ln (L(γ)) with respect to a parameter\\nof interest γ.\\n2. Equate the result to zero.\\n72Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3. Solve the equation to ﬁnd ˆγ that holds:\\n∂ ln L(ˆγ | x1, · · ·xn)\\n∂γ = 0 (3.56)\\n4. Compute the second derivative to verify that you indeed have a maximum rather than\\na minimum.\\n\\x04\\nSOL-54 \\uf14b CH.SOL- 3.25.\\nThe ﬁrst derivative of the log-likelihood function is commonly known as the Fisher score\\nfunction, and is deﬁned as:\\nu(γ) = ∂ ln L(γ | x1, · · ·xn)\\n∂γ (3.57)\\n\\x04\\nSOL-55 \\uf14b CH.SOL- 3.26.\\nFisher information, is the term used to describe the expected value of the second derivat-\\nives (the curvature) of the log-likelihood function, and is deﬁned by:\\nI(γ) = −E\\n[\\n∂2 ln L(γ | x1, · · ·xn)\\n∂γ2\\n]\\n(3.58)\\n\\x04\\n3.3.5 Fisher Information\\nSOL-56 \\uf14b CH.SOL- 3.27.\\n1. Given L(γ):\\nln L(γ) = ln\\n(\\nny\\n)\\n+ y ∗ ln(γ) + (n − y) ln(1 − γ). (3.59)\\n733.3. SOLUTIONS\\n2. T o ﬁnd the gradient, we differentiate once:\\ng(γ) = yγ −1 − (n − y)(1 − γ)−1 =\\n(γ(1 − γ))−1y − n(1 − γ)−1. (3.60)\\n3. The Hessian is generated by differentiating g(γ):\\nH(γ) = −yγ −2 − (n − y)(1 − γ)−2 (3.61)\\n4. The Fisher information is calculated as follows:\\nI(γ) = −E(H(γ)) = n\\nγ(1 − γ), (3.62)\\nsince:\\nE(y|γ, n) = n ∗ γ (3.63)\\n5. Equating the gradient to zero and solving for our parameter γ, we get:\\nˆγ = y\\nn (3.64)\\nIn our case this equates to: 300/10000 = 0 .03. Regarding the error, there is a close\\nrelationship between the variance of γ and the Fisher information, as the former is the\\ninverse of the latter:\\nvar(γ) = [ I(γ)]−1\\nV (γ) = γ(1 − γ)\\nn\\n(3.65)\\nPlugging the numbers from our question:\\nˆV (ˆγ) = 0.03(1 − 0.03)\\n10000 = 2.9 × 10−7. (3.66)\\n74Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nStatistically, the standard error that we are asked to ﬁnd is the square root of eq. 3.66\\nwhich equals 5.3 × 10−4. Note: What desired property is revealed in this experiment?\\nAt was cost could we ensure a low standard error?\\n\\x04\\nSOL-57 \\uf14b CH.SOL- 3.28.\\nThe Fisher Information for the distributions is as follows:\\n1. Bernoulli:\\nΦ(x|γ) = x log γ + (1 − x) log(1 − γ), (3.67)\\nΦ′(x|γ) = x\\nγ − 1 − x\\n1 − γ , (3.68)\\nΦ′′(x|γ) = − x\\nγ2 − 1 − x\\n(1 − γ)2 , (3.69)\\nI(γ) = −Eγ\\n[\\nX(1 − γ)2 + (1 − X)γ2\\nγ2(1 − γ)2\\n]\\n= 1\\nγ(1 − γ). (3.70)\\n2. Poisson:\\nλ(x|θ) = x log θ − log x! − θ,\\nλ′(x|θ) = x − θ\\nθ ,\\nλ′′(x|θ) = − x\\nθ2 ,\\nI(θ) = −Eθ\\n[\\n(X − θ)2\\nθ2\\n]\\n= 1\\nθ .\\n(3.71)\\n\\x04\\nSOL-58 \\uf14b CH.SOL- 3.29.\\n753.3. SOLUTIONS\\n1. T rue.\\n2. T rue.\\n\\x04\\n3.3.6 Posterior & prior predictive distributions\\nSOL-59 \\uf14b CH.SOL- 3.30.\\n1. Given a sample of the form x = ( x1, · · · , xn) drawn from a density p(θ; x) and θ is\\nrandomly generated according to a prior density of p(θ). Then the posterior density is\\ndeﬁned by:\\np(θ|x) = p(θ; x)p(θ)\\np(x) . (3.72)\\n2. The prior predictive density is:\\np(x) =\\n∫\\nθ∈Θ p(θ; x)p(θ)dθ (3.73)\\n\\x04\\nSOL-60 \\uf14b CH.SOL- 3.31.\\n1. The posterior p(θ|y) ∝ p(y|θ)p(θ) is:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3\\n( 5\\ny\\n)\\n(1/2)y(1/2)5−y0.25, θ = 1/2( 5\\ny\\n)\\n(1/6)y(5/6)5−y0.5, θ = 1/6( 5\\ny\\n)\\n(1/4)y(3/4)5−y0.25, θ = 1/4\\n0, otherwise\\n2. The prior predictive distribution p(y):\\n(\\n5\\ny\\n)\\n((1/2)y(1/2)5−y0.25 (3.74)\\n76Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n+\\n(1/6)y(5/6)5−y0.5 + (1/4)y(3/4)5−y0.25). (3.75)\\n\\x04\\n3.3.7 Conjugate priors\\nSOL-61 \\uf14b CH.SOL- 3.32.\\n1. A class F of prior distributions is said to form a conjugate family if the posterior density\\nis in F for all each sample, whenever the prior density is in F.\\n2. Often we would like a prior that favours no particular values of the parameter over\\nothers. Bayesian analysis requires prior information, however sometimes there is no\\nparticularly useful information before data is collected. In these situations, priors with\\n“no information” are expected. Such priors are called non-informative priors.\\n\\x04\\nSOL-62 \\uf14b CH.SOL- 3.33.\\nIf x ∼ B(n, γ) so\\np(x|γ) ∝ γx(1 − γ)n−x\\nand the prior for γ is B(α, β) so\\np(γ) ∝ γα−1(1 − γ)β−1\\nthen the posterior is\\nγ|x ∼ B (α + x, β + n − x)\\nIt is immediately clear the family of beta distributions is conjugate to a\\nbinomial likelihood.\\n\\x04\\n3.3.8 Bayesian Deep Learning\\n773.3. SOLUTIONS\\nSOL-63 \\uf14b CH.SOL- 3.34.\\n1. The hidden neuron is distributed according to:\\nX ∼ binomial(n, γ ) random variable and ﬁres with a probability of γ. There are 100\\nneurons and only 20 are ﬁred.\\nP (x = 20|θ) =\\n\\uf8eb\\n\\uf8ed 100\\n20\\n\\uf8f6\\n\\uf8f8 θ20(1 − θ)80 (3.76)\\n2. The hidden neuron is distributed according to:\\nX unif orm(0, γ) random variable and ﬁres with a probability of γ.\\nThe uniform distribution is, of course, a very simple case:\\nf (x; a, b) = 1\\nb − a for a ≤ x ≤ b (3.77)\\nTherefore:\\nf (x|γ) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0 if γ < x or x < 0\\n1/γ if 0 ≤ x ≤ θ\\n(3.78)\\n\\x04\\nSOL-64 \\uf14b CH.SOL- 3.35.\\nThe provided distribution is from the exponential family. Therefore, a single neuron be-\\ncomes inactive with a probability of:\\np = P (X < 20) =\\n∫ 20\\n0\\ne−x dx = 1 − e−20. (3.79)\\nThe OnOffLayer is off only if at least 150 out of 200 neurons are off. Therefore, this may be\\nrepresented as a Binomial distribution and the probability for the layer to be off is:\\nV =\\n∑\\nn≥150\\n\\uf8eb\\n\\uf8ed 200\\nn\\n\\uf8f6\\n\\uf8f8 ˜pn(1 − ˜p)200−n (3.80)\\n78Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nHence, the probability of the layer being active for at least 20 seconds is 1 minus this value:\\n[1 − V ]. (3.81)\\n\\x04\\nSOL-65 \\uf14b CH.SOL- 3.36.\\nThe observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (3.82)\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (3.83)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (3.84)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (3.85)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(3.86)\\n\\x04\\nSOL-66 \\uf14b CH.SOL- 3.37.\\nNeurons are dropped whenever their value (or the equivalent quantum term- speed) reach\\n79REFERENCES\\nthe most likely value:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.87)\\nFrom calculus, we know that in order to maximize a function, we have to equate its ﬁrst\\nderivative to zero:\\nd\\ndv n(v) = 0 (3.88)\\nThe constants can be taken out as follows:\\nd\\ndv v2e− mv2\\n2kT = 0 (3.89)\\nApplying the chain rule from calculus:\\n2ve− mv2\\n2kT + v2\\n(\\n− m\\n2kT 2v\\n)\\ne− mv2\\n2kT = 0 (3.90)\\nWe notice that several terms cancel out:\\nv2 m\\n2kT = 1 (3.91)\\nNow the quadratic equation can be solved yielding:\\nvmost_probable =\\n√\\n2kT\\nm\\n(3.92)\\nTherefore, this is the most probable value at which the dropout layer will ﬁre.\\n\\x04\\nReferences\\n[1] M. Barati and P . ‘Comparison of complications of chorionic villus sampling and\\namniocentesis’. In: 5.4 (2012), pp. 241–244 (cit. on p. 46).\\n[2] J. D. e. a. Bell BP Damon IK. ‘Overview, Control Strategies, and Lessons Learned\\nin the CDC Response to the 20142016 Ebola Epidemic.’ In: Morbidity and Mortal-\\nity Weekly Report 65.3 (2016), pp. 4–11 (cit. on p. 52).\\n80Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n[3] J. C. Cook and G. P . Gross. Adiposis Dolorosa (Dercum, Anders Disease) . StatPearls\\n[Internet], 2019 (cit. on p. 47).\\n[4] G. Ecker. Particles, Field, From Quantum Mechanics to the Standard Model of Particle\\nPhysics. Springer., 2019 (cit. on p. 45).\\n[5] K. Gaj and A. Orlowski. ‘Facts and Myths of Enigma: Breaking Stereotypes’. In:\\nInternational Conference on the Theory and Applications of Cryptographic T echniques .\\n2003 (cit. on p. 50).\\n[6] B. Gottschalk. ‘Techniques of Proton Radiotherapy: Transport Theory’. In: arXiv\\n(2012) (cit. on p. 43).\\n[7] T. S. O. of Investor Education and Advocacy. Binary options and Fraud (cit. on\\np. 48).\\n[8] E. T. Jaynes. Probability Theory as Logic . Ed. by P . F. Fougère. Maximum-Entropy\\nand Bayesian Methods. Kluwer, Dordrecht, 1990 (cit. on p. 42).\\n[9] D. o. J. National Security Division. Conspiracy to Act as Unregistered Agents of a\\nForeign Government. 2010 (cit. on p. 49).\\n[10] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on p. 56).\\n[11] J. Salvatier, T. V . Wiecki and C. Fonnesbeck. ‘Probabilistic programming in Py-\\nthon using PyMC3’. In: PeerJ Computer Science 2 (Jan. 2016), e55 (cit. on p. 42).\\n[12] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 56).\\n[13] E. B. Starikov. ‘Bayesian Statistical Mechanics: Entropy Enthalpy Compensation\\nand Universal Equation of State at the Tip of Pen’. In: Frontiers in Physics 6 (2018),\\np. 2 (cit. on p. 42).\\n81REFERENCES\\n82HIGH SCHOOL\\nPART IIICHAPTER\\n4\\nINFORMATION THEORY\\nA basic idea in information theory is that information can be treated very much\\nlike a physical quantity, such as mass or energy.\\n— Claude Shannon, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 87\\nShannon\\'s Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen\\'s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 101\\nShannon\\'s Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\nKullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen\\'s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1184.1. INTRODUCTION\\n4.1 Introduction\\nI\\nNDUCTIVE inference, is the problem of reasoning under conditions of in-\\ncomplete information, or uncertainty. According to Shannon’s theory [ 2],\\ninformation and uncertainty are two sides of the same coin: the more uncer-\\ntainty there is, the more information we gain by removing the uncertainty .\\nEntropy plays central roles in many scientiﬁc realms ranging from physics and statist-\\nics to data science and economics. A basic problem in information theory is encoding\\nlarge quantities of information [ 2].\\nShannon’s discovery of the fundamental laws of data compression and transmis-\\nsion marked the birth of information theory . In his fundamental paper of 1948, “ A\\nMathematical Theory of Communication ” [4], Shannon proposed a measure of the uncer-\\ntainty associated with a random memory-less source, called Entropy.\\nH(X) H(Y )\\nH(Z)\\nH(Y |X)\\nH(Z|XY )\\nI(X; Z|Y )\\nFIGURE 4.1: Mutual information\\nEntropy ﬁrst emerged in thermodynamics in the 18 th century by\\nCarnot, [1] in his pioneering work on steam entitled “ Reﬂection on the Motive Power of\\nFire” (Fig. 4.2). Subsequently it appeared in statistical mechanics where it was viewed\\nas a measure of disorder. However, it was Boltzmann ( 4.30) who found the connection\\nbetween entropy and probability , and the notion of information as used by Shannon is\\na generalization of the notion of entropy . Shannon’s entropy shares some instinct with\\nBoltzmann’s entropy , and likewise the mathematics developed in information theory\\nis highly relevant in statistical mechanics.\\n86Chapter 4 INFORMATION THEORY\\nFIGURE 4.2: Reﬂection on the motive power of ﬁre.\\nThe majority of candidates I interview fail to come up with an answer to the fol-\\nlowing question: what is the entropy of tossing a non-biased coin? Surprisingly , even after\\nI explicitly provide them with Shannon’s formulae for calculating entropy ( 4.4), many\\nare still unable to calculate simple logarithms. The purpose of this chapter is to present\\nthe aspiring data scientist with some of the most signiﬁcant notions of entropy and\\nto elucidate its relationship to probability . Therefore, it is primarily focused on basic\\nquantities in information theory such as entropy , cross-entropy , conditional entropy ,\\nmutual information and Kullback-Leibler divergence, also known as relative entropy .\\nIt does not however, discuss more advanced topics such as the concept of ’active in-\\nformation’ introduced by Bohm and Hiley [ 3].\\n4.2 Problems\\n4.2.1 Logarithms in Information Theory\\nIt is important to note that all numerical calculations in this chapter use the binary\\nlogarithm log2. This speciﬁc logarithm produces units of bits, the commonly used units\\nof information in the ﬁeld on information theory .\\n874.2. PROBLEMS\\nPRB-67 \\uf059 CH.PRB- 4.1.\\nRun the following Python code ( 4.3) in a Python interpreter. What are the results?\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n5\\n6 print (math.log10(1.0/0.98)) # Common log (base 10)\\n7 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n8\\n9 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n10 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\nFIGURE 4.3: Natural ( ln), binary (log2) and common ( log10) logarithms.\\nPRB-68 \\uf059 CH.PRB- 4.2.\\nThe three basic laws of logarithms:\\n1. First law\\nlog A + log B = log AB. (4.1)\\nCompute the following expression:\\nlog10 3 + log10 4.\\n2. Second law\\nlog An = n log A. (4.2)\\n88Chapter 4 INFORMATION THEORY\\nCompute the following expression:\\nlog2 46.\\n3. Third law\\nlog A − log B = log A\\nB . (4.3)\\nTherefore, subtracting log B from log A results in log A\\nB .\\nCompute the following expression:\\nloge 15 − loge 3.\\n4.2.2 Shannon\\'s Entropy\\nPRB-69 \\uf059 CH.PRB- 4.3.\\nWrite Shannon\\'s famous general formulae for uncertainty.\\nPRB-70 \\uf059 CH.PRB- 4.4.\\nChoose exactly one, and only one answer.\\n1. For an event which is certain to happen, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N ), N being the number of possible events\\n894.2. PROBLEMS\\n2. For N equiprobable events, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N )\\nPRB-71 \\uf059 CH.PRB- 4.5.\\nShannon found that entropy was the only function satisfying three natural properties.\\nEnumerate these properties.\\nPRB-72 \\uf059 CH.PRB- 4.6.\\nIn information theory, minus the logarithm of the probability of a symbol (essentially\\nthe number of bits required to represent it efﬁciently in a binary code) is deﬁned to be the\\ninformation conveyed by transmitting that symbol. In this context, the entropy can be\\ninterpreted as the expected information conveyed by transmitting a single symbol from an\\nalphabet in which the symbols occur with the probabilities πk.\\nMark the correct answer : Information is a/an [decrease/increase] in uncertainty.\\nPRB-73 \\uf059 CH.PRB- 4.7.\\nClaud Shannon\\'s paper “A mathematical theory of communication” [ 4], marked the\\nbirth of information theory. Published in 1948, it has become since the Magna Carta of the\\ninformation age. Describe in your own words what is meant by the term Shannon bit.\\nPRB-74 \\uf059 CH.PRB- 4.8.\\nWith respect to the notion of surprise in the context of information theory:\\n1. Deﬁne what it actually meant by being surprised.\\n90Chapter 4 INFORMATION THEORY\\n2. Describe how it is related to the likelihood of an event happening.\\n3. True or False: The less likely the occurrence of an event, the smaller information it\\nconveys.\\nPRB-75 \\uf059 CH.PRB- 4.9.\\nAssume a source of signals that transmits a given message a with probability Pa. Assume\\nfurther that the message is encoded into an ordered series of ones and zeros (a bit string) and\\nthat a receiver has a decoder that converts the bit string back into its respective message.\\nShannon devised a formulae that describes the size that the mean length of the bit string can\\nbe compressed to. Write the formulae.\\nPRB-76 \\uf059 CH.PRB- 4.10.\\nAnswer the following questions:\\n1. Assume a source that provides a constant stream of N equally likely symbols\\n{x1, x2, . . . , xN }. What does Shannon\\'s formulae ( 4.4) reduce to in this particular\\ncase?\\n2. Assume that each equiprobable pixel in a monochrome image that is fed to a DL classi-\\nﬁcation pipeline, can have values ranging from 0 to 255. Find the entropy in bits.\\nPRB-77 \\uf059 CH.PRB- 4.11.\\nGiven Shannon\\'s famous general formulae for uncertainty ( 4.4):\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.4)\\n1. Plot a graph of the curve of probability vs. uncertainty.\\n2. Complete the sentence: The curve is [symmetrical/asymmetrical].\\n914.2. PROBLEMS\\n3. Complete the sentence: The curve rises to a [minimum/maximum] when the two\\nsymbols are equally likely ( Pa = 0.5).\\nPRB-78 \\uf059 CH.PRB- 4',\n",
              " 'e ( 4.4) reduce to in this particular\\ncase?\\n2. Assume that each equiprobable pixel in a monochrome image that is fed to a DL classi-\\nﬁcation pipeline, can have values ranging from 0 to 255. Find the entropy in bits.\\nPRB-77 \\uf059 CH.PRB- 4.11.\\nGiven Shannon\\'s famous general formulae for uncertainty ( 4.4):\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.4)\\n1. Plot a graph of the curve of probability vs. uncertainty.\\n2. Complete the sentence: The curve is [symmetrical/asymmetrical].\\n914.2. PROBLEMS\\n3. Complete the sentence: The curve rises to a [minimum/maximum] when the two\\nsymbols are equally likely ( Pa = 0.5).\\nPRB-78 \\uf059 CH.PRB- 4.12.\\nAssume we are provided with biased coin for which the event ‘heads’ is assigned probab-\\nility p, and ‘tails’ - a probability of 1 − p. Using (4.4), the respective entropy is:\\nH(p) = −p log p − (1 − p) log (1 − p) . (4.5)\\nTherefore, H ≥ 0 and the maximum possible uncertainty is attained when p = 1 /2, is\\nHmax = log 2 2.\\nGiven the above formulation, describe a helpful property of the entropy that follows from\\nthe concavity of the logarithmic function.\\nPRB-79 \\uf059 CH.PRB- 4.13.\\nTrue or False: Given random variables X, Y and Z where Y = X + Z then:\\nH(X, Y ) = H(X, Z). (4.6)\\nPRB-80 \\uf059 CH.PRB- 4.14.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n92Chapter 4 INFORMATION THEORY\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh)+ p(xt) = 1 , what is formulae\\nfor the average surprise?\\n6. What is the value of the average surprise in bits?\\n4.2.3 Kullback-Leibler Divergence (KLD)\\nPRB-81 \\uf059 CH.PRB- 4.15.\\nWrite the formulae for the Kullback-Leibler divergence between two discrete probability\\ndensity functions P and Q.\\nPRB-82 \\uf059 CH.PRB- 4.16.\\nDescribe one intuitive interpretation of the KL-divergence with respect to bits.\\nPRB-83 \\uf059 CH.PRB- 4.17.\\n1. True or False: The KL-divergence is not a symmetric measure of similarity, i.e.:\\nDKL(P ∥Q) ̸= D KL(Q∥P ).\\n2. True or False: The KL-divergence satisﬁes the triangle inequality.\\n3. True or False: The KL-divergence is not a distance metric.\\n4. True or False: In information theory, KLD is regarded as a measure of the informa-\\ntion gained when probability distribution Q is used to approximate a true probability\\ndistribution P .\\n5. True or False: The units of KL-divergence are units of information.\\n6. True or False: The KLD is always non-negative, namely:\\nDKL(P ∥Q) ≥ 0.\\n934.2. PROBLEMS\\n.\\n7. True or False: In a decision tree, high information gain indicates that adding a split\\nto the decision tree results in a less accurate model.\\nPRB-84 \\uf059 CH.PRB- 4.18.\\nGiven two distributions f1 and f2 and their respective joint distribution f , write the\\nformulae for the mutual information of f1 and f2.\\nPRB-85 \\uf059 CH.PRB- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem.\\n4.2.4 Classification and Information Gain\\nPRB-86 \\uf059 CH.PRB- 4.20.\\nThere are several measures by which one can determine how to optimally split attributes\\nin a decision tree. List the three most commonly used measures and write their formulae.\\nPRB-87 \\uf059 CH.PRB- 4.21.\\nComplete the sentence: In a decision tree, the attribute by which we choose to split is\\nthe one with [minimum/maximum] information gain.\\nPRB-88 \\uf059 CH.PRB- 4.22.\\nT o study factors affecting the decision of a frog to jump (or not), a deep learning re-\\nsearcher from a Brazilian rain-forest, collects data pertaining to several independent binary\\nco-variates.\\n94Chapter 4 INFORMATION THEORY\\nFIGURE 4.4: A Frog in its natural habitat. Photo taken by my son.\\nThe binary response variable Jump indicates whether a jump was observed. Referring to\\nT able (4.1), each row indicates the observed values, columns denote features and rows denote\\nlabelled instances while class label ( Jump) denotes whether the frog had jumped.\\nObservation Green Rain Jump\\nx1 1 0 +\\nx2 1 1 +\\nx3 1 0 +\\nx4 1 1 +\\nx5 1 0 +\\nx6 0 1 +\\nx7 0 0 −\\nx8 0 1 −\\nTABLE 4.1: Decision trees and frogs.\\nWithout explicitly determining the information gain values for each of the three attrib-\\nutes, which attribute should be chosen as the attribute by which the decision tree should be\\nﬁrst partitioned? e.g which attribute has the highest predictive power regarding the decision\\nof the frog (Fig. 4.4) to jump.\\n954.2. PROBLEMS\\nPRB-89 \\uf059 CH.PRB- 4.23.\\nThis question discusses the link between binary classiﬁcation, information gain and de-\\ncision trees. Recent research [ 5] suggests that Cannabis (Fig. 4.5), and Cannabinoids ad-\\nministration in particular may reduce the size of malignant tumours in rodents. The data\\n(T able9.2) comprises a training set of feature vectors with corresponding class labels which\\na researcher intents classifying using a decision tree.\\nFIGURE 4.5: Cannabis\\nT o study factors affecting tumour shrinkage, the deep learning researcher collects data\\nregrading two independent binary variables; θ1 (T/F) indicating whether the rodent is a fe-\\nmale, and θ2 (T/F) indicating whether the rodent was administrated with Cannabinoids. The\\nbinary response variable, γ, indicates whether tumour shrinkage was observed (e.g. shrink-\\nage=+, no shrinkage=-). Referring to T able ( 9.2), each row indicates the observed values,\\ncolumns (θi) denote features and class label ( γ) denotes whether shrinkage was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 4.2: Decision trees and Cannabinoids administration\\n96Chapter 4 INFORMATION THEORY\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\nPRB-90 \\uf059 CH.PRB- 4.24.\\nT o study factors affecting the expansion of stars, a physicist is provided with data re-\\ngrading two independent variables; θ1 (T/F) indicating whether a star is dense, and θ2 (T/F)\\nindicating whether a star is adjacent to a black-hole. He is told that the binary response vari-\\nable, γ, indicates whether expansion was observed.\\ne.g.:\\nexpansion=+, no expansion=-. Referring to table ( 4.3), each row indicates the observed val-\\nues, columns (θi) denote features and class label (γ) denotes whether expansion was observed.\\nγ (expansion) θ1 (dense) θ2 (black-hole)\\n+ F T\\n+ T T\\n+ T T\\n- F T\\n+ T F\\n- F F\\n- F F\\nTABLE 4.3: Decision trees and star expansion.\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (expansion)\\nbefore splitting.\\n2. Using log2 and the provided dataset, calculate the information gain of H(γ|θ1).\\n974.2. PROBLEMS\\n3. Using log2 and the provided dataset, calculate the information gain of H(γ|θ2).\\nPRB-91 \\uf059 CH.PRB- 4.25.\\nT o study factors affecting tumour shrinkage in humans, a deep learning researcher is\\nprovided with data regrading two independent variables; θ1 (S/M/L) indicating whether the\\ntumour is small(S), medium(M) or large(L), and θ2 (T/F) indicating whether the tumour\\nhas undergone radiation therapy. He is told that the binary response variable, γ, indicates\\nwhether tumour shrinkage was observed (e.g. shrinkage=+, no shrinkage=-).\\nReferring to table ( 4.4), each row indicates the observed values, columns ( θi) denote\\nfeatures and class label ( γ) denotes whether shrinkage was observed.\\nγ (shrinkage) θ1 θ2\\n- S F\\n+ S T\\n- M F\\n+ M T\\n+ H F\\n+ H T\\nTABLE 4.4: Decision trees and radiation therapy .\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (shrinkage).\\n2. Using log2 and the provided dataset, calculate the entropy of H(γ|θ1).\\n3. Using log2 and the provided dataset, calculate the entropy of H(γ|θ2).\\n4. True or false: We should split on a speciﬁc variable that minimizes the information\\ngain, therefore we should split on θ2 (radiation therapy).\\n4.2.5 Mutual Information\\nPRB-92 \\uf059 CH.PRB- 4.26.\\n98Chapter 4 INFORMATION THEORY\\nShannon described a communications system consisting ﬁve elements (4.6), two of which\\nare the source S and the destination D.\\nSourse S Trans\\nT\\nChannel\\nCH\\nReceiver\\nR\\nDest\\nD\\nMESSAGE\\nSIGNAL\\nSIGNAL\\nMESSAGE\\nFIGURE 4.6: Shannon\\'s ﬁve element communications system.\\n1. Draw a Venn diagram depicting the relationship between the entropies of the source\\nH(S) and of the destination H(D).\\n2. Annotate the part termed equivocation.\\n3. Annotate the part termed noise.\\n4. Annotate the part termed mutual information.\\n5. Write the formulae for mutual information.\\nPRB-93 \\uf059 CH.PRB- 4.27.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\n994.2. PROBLEMS\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\nPRB-94 \\uf059 CH.PRB- 4.28.\\nComplete the sentence: Mutual information is a Shannon entropy-based measure of\\ndependence between random variables. The mutual information between X and Z can be\\nunderstood as the (a) [___] of the (b) [___] in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.7)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X.\\n4.2.6 Mechanical Statistics\\nSome books have a tendency of sweeping \"unseen\" problems under the rug. We will\\nnot do that here. This subsection may look intimidating and for a good reason; it\\ninvolves equations that, unless you are a physicists, you have probably never en-\\ncountered before. Nevertheless, the ability to cope with new concepts lies at the heart\\nof every job interview.\\nFor some of the questions, you may need these constants:\\nPHYSICAL CONSTANTS\\nk Boltzmanns constant 1.381 × 10−23 J K−1\\nc Speed of light in vacum 2.998 × 108m s−1\\nh Planck’s constant 6.626 × 10−34 J s\\nPRB-95 \\uf059 CH.PRB- 4.29.\\nWhat is the expression for the Boltzmann probability distribution?\\nPRB-96 \\uf059 CH.PRB- 4.30.\\nInformation theory, quantum physics and thermodynamics are closely interconnected.\\nThere are several equivalent formulations for the second law of thermodynamics. One ap-\\nproach to describing uncertainty stems from Boltzmanns fundamental work on entropy in\\n100Chapter 4 INFORMATION THEORY\\nstatistical mechanics. Describe what is meant by Boltzmanns entropy.\\nPRB-97 \\uf059 CH.PRB- 4.31.\\nFrom Boltzmanns perspective, what is the entropy of an octahedral dice ( 4.7)?\\nFIGURE 4.7: An octahedral dice.\\n4.2.7 Jensen\\'s inequality\\nPRB-98 \\uf059 CH.PRB- 4.32.\\n1. Deﬁne the term concave function.\\n2. Deﬁne the term convex function.\\n3. State Jensen\\'s inequality and its implications.\\nPRB-99 \\uf059 CH.PRB- 4.33.\\nTrue or False: Using Jensen\\'s inequality, it is possible to show that the KL divergence\\nis always greater or equal to zero.\\n4.3 Solutions\\n4.3.1 Logarithms in Information Theory\\n1014.3. SOLUTIONS\\nSOL-67 \\uf14b CH.SOL- 4.1.\\nNumerical results (4.8) are provided using Python interpreter version 3.6.\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 > 0.02020270731751947\\n5 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n6 > 3.912023005428146\\n7 print (math.log10(1.0/0.98)) # Common log (base 10)\\n8 > 0.008773924307505152\\n9 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n10 > 1.6989700043360187\\n11 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n12 > 0.02914634565951651\\n13 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n14 > 5.643856189774724\\nFIGURE 4.8: Logarithms in information theory .\\n\\x04\\nSOL-68 \\uf14b CH.SOL- 4.2.\\nThe logarithm base is explicitly written in each solution.\\n1.\\nlog10 3 + log10 4 = log 10(3 × 4) = log 10 12.\\n2.\\nlog2 46 = 6 log2 4.\\n3.\\nloge 15 − loge 3 = log e\\n15\\n3 = log e 5.\\n102Chapter 4 INFORMATION THEORY\\n\\x04\\n4.3.2 Shannon\\'s Entropy\\nSOL-69 \\uf14b CH.SOL- 4.3.\\nShannons famous general formulae for uncertainty is:\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.8)\\n\\x04\\nSOL-70 \\uf14b CH.SOL- 4.4.\\n1. No information is conveyed by an event which is a-priori known to occur for certain\\n(Pa = 1), therefore the entropy is 0.\\n2. Equiprobable events mean that Pi = 1 /N ∀i ∈ [1, N]. Therefore for N equally-likely\\nevents, the entropy is log2(N ).\\n\\x04\\nSOL-71 \\uf14b CH.SOL- 4.5.\\nThe three properties are as follows:\\n1. H(X) is always non-negative, since information cannot be lost.\\n2. The uniform distribution maximizes H(X), since it also maximizes uncertainty.\\n3. The additivity property which relates the sum of entropies of two independent events.\\nFor instance, in thermodynamics, the total entropy of two isolated systems which co-\\nexist in equilibrium is the sum of the entropies of each system in isolation.\\n\\x04\\n1034.3. SOLUTIONS\\nSOL-72 \\uf14b CH.SOL- 4.6.\\nInformation is an [increase] in uncertainty. \\x04\\nSOL-73 \\uf14b CH.SOL- 4.7.\\nThe Shannon bit has two distinctive states; it is either 0 or 1, but never both at the same\\ntime. Shannon devised an experiment in which there is a question whose only two possible\\nanswers were equally likely to happen .\\nHe then deﬁned one bit as the amount of information gained (or alternatively, the amount\\nof entropy removed) once an answer to the question has been learned. He then continued to\\nstate that when the a-priori probability of any one possible answer is higher than the other, the\\nanswer would have conveyed less than one bit of information. \\x04\\nSOL-74 \\uf14b CH.SOL- 4.8.\\nThe notion of surprise is directly related to the likelihood of an event happening. Mathem-\\natically is it inversely proportional to the probability of that event.\\nAccordingly, learning that a high-probability event has taken place, for instance the sun rising,\\nis much less of a surprise and gives less information than learning that a low-probability\\nevent, for instance, rain in a hot summer day, has taken place. Therefore, the less likely the\\noccurrence of an event, the greater information it conveys.\\nIn the case where an event is a-priori known to occur for certain ( Pa = 1 ), then no inform-\\nation is conveyed by it. On the other hand, an extremely intermittent event conveys a lot of\\ninformation as it surprises us and informs us that a very improbable state exists. Therefore,\\nthe statement in part 3 is false.\\n\\x04\\nSOL-75 \\uf14b CH.SOL- 4.9.\\nThis quantity ISh, represented in the formulae is called the Shannon information of the\\nsource:\\nISh = −\\n∑\\na\\npa log2 pa. (4.9)\\nIt refers to the mean length in bits, per message, into which the messages can be compressed\\n104Chapter 4 INFORMATION THEORY\\nto. It is then possible for a communications channel to transmit ISh bits per message with a\\ncapacity of ISh. \\x04\\nSOL-76 \\uf14b CH.SOL- 4.10.\\n1. For N equiprobable events it holds that Pi = 1 /N, ∀i ∈ [1, N]. Therefore if we substi-\\ntute this into Shannon\\'s equation we get:\\nHequiprobable = −\\nN∑\\ni=1\\n1\\nN log2\\n1\\nN . (4.10)\\nSince N does not depend on i, we can pull it out of the sum:\\nHequiprobable = −( 1\\nN log2\\n1\\nN )\\nN∑\\ni=1\\n1 (4.11)\\n= −\\n( 1\\nN log2\\n1\\nN\\n)\\nN\\n= − log2\\n1\\nN (4.12)\\n= log 2 N.\\nIt can be shown that for a given number of symbols (i.e., N is ﬁxed) the uncertainty H\\nhas its largest value only when the symbols are equally probable.\\n2. The probability for each pixel to be assigned a value in the given range is:\\npi = 1/256. (4.13)\\nTherefore the entropy is:\\nH = −(256)(1/256)(−8) = 8 [bits/symbol]. (4.14)\\n\\x04\\nSOL-77 \\uf14b CH.SOL- 4.11.\\n1054.3. SOLUTIONS\\nRefer to Fig. 4.9 for the corresponding illustration of the graph, where information is\\nshown as a function of p. It is equal to 0 for p = 0 and for p = 1. This is reasonable because for\\nsuch values of p the outcome is certain, so no information is gained by learning the outcome.\\nThe entropy in maximal uncertainty equals to 1 bit for p = 0 .5. Thus, the information gain\\nis maximal when the probabilities of two possible events are equal. Furthermore, for the entire\\nrange of probabilities between p = 0.4 and p = 0.6 the information is close to 1 bit. \\x04\\nFIGURE 4.9: H vs. Probability\\nSOL-78 \\uf14b CH.SOL- 4.12.\\nAn important set of properties of the entropy follows from the concavity of the entropy,\\nwhich follows from the concavity of the logarithm. Suppose that in an experiment, we cannot\\ndecide whether the actual probability of ‘heads’ is p1 or p2. We may decide to assign probability\\nq to the ﬁrst alternative and probability 1 − q to the second. The actual probability of ‘heads’\\nthen is the mixture qp1 + (1 − q)p2. The corresponding entropies satisfy the inequality:\\nS (qp1 + (1 − q)p2) ≥ qS (p1) + (1 − q) S (p2) , (4.15)\\n106Chapter 4 INFORMATION THEORY\\nThese probabilities, are equal in the extreme cases where p1 = p2, or q = 0, or q = 1. \\x04\\nSOL-79 \\uf14b CH.SOL- 4.13.\\nGiven (X, Y ), we can determine X and Z = Y − X. Conversely, given (X, Z), we can\\ndetermine X and Y = X + Z. Hence, H(X, Y ) = H(X, Z) due to the existence of this\\nbijection. \\x04\\nSOL-80 \\uf14b CH.SOL- 4.14.\\nThe solution and numerical calculations are provided using log2.\\n1. We can predict ‘heads’ for each ﬂip with an accuracy of p(xh) = 98 %.\\n2. According to Fig. ( 4.10), if the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is log2(1/0.98) [bits] .\\n1 import math\\n2 import numpy\\n3 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n4 > 0.02914634565951651\\n5 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n6 > 5.643856189774724\\nFIGURE 4.10: Shannon information gain for a biased coin toss.\\n3. Likewise, if the result of the coin toss is ‘tails’, the amount of Shannon information\\ngained is log2(1/0.02) [bits] .\\n4. It is always true that the more information is associated with an outcome, the more\\nsurprising it is.\\n5. The formulae for the average surprise is:\\nH(x) = p(xh) log 1\\np(xh) + p(xt) log 1\\np(xt). (4.16)\\n1074.3. SOLUTIONS\\n6. The value of the average surprise in bits is ( 4.11):\\nH(x) = [0 .98 × 0.0291] + [0.02 × 5.643] (4.17)\\n= 0.1414 [bits].\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4 print (\"binaryEntropy(p) is:{}\\nbits\".format(binaryEntropy(0.98)))↪→\\n5 > binaryEntropy(p) is:0.1414 bits\\nFIGURE 4.11: Average surprise\\n\\x04\\n4.3.3 Kullback-Leibler Divergence\\nSOL-81 \\uf14b CH.SOL- 4.15.\\nFor discrete probability distributions P and Q, the Kullback-Leibler divergence from P\\nto Q, the KLD is deﬁned as:\\nD(P ∥ Q) =\\n∑\\nx\\nP (x) log P (x)\\nQ(x) (4.18)\\n= EP\\n[\\nlog 1\\nQ(x) − log 1\\nP (x)\\n]\\n= HP (Q)\\ued19 \\ued18\\ued17 \\ued1a\\nCross Entropy\\n− H(P )\\ued19 \\ued18\\ued17 \\ued1a\\nEntropy\\n.\\n\\x04\\n108Chapter 4 INFORMATION THEORY\\nSOL-82 \\uf14b CH.SOL- 4.16.\\nOne interpretation is the following: the KL-divergence indicates the average number of\\nadditional bits required for transmission of values x ∈ X which are distributed according\\nto P (x), but we erroneously encoded them according to distribution Q(x). This makes sense\\nsince you have to “pay” for additional bits to compensate for not knowing the true distribution,\\nthus using a code that was optimized according to other distribution. This is one of the reason\\nthat the KL-divergence is also known as relative entropy. Formally, the cross entropy has an\\ninformation interpretation quantifying how many bits are wasted by using the wrong code:\\nHP (Q) =\\n∑\\nx\\nP (x)\\ued19 \\ued18\\ued17 \\ued1a\\nSending P\\ncode for Q\\n\\ued17 \\ued1a\\ued19 \\ued18\\nlog 1\\nQ(x) . (4.19)\\n\\x04\\nSOL-83 \\uf14b CH.SOL- 4.17.\\n1. True KLD is a non-symmetric measure, i.e. D(P ∥ Q) ̸= D(Q ∥ P ).\\n2. False KLD does not satisfy the triangle inequality.\\n3. True KLD is not a distance metric.\\n4. True KLD is regarded as a measure of the information gain. Notice that, however, KLD\\nis the amount of information lost.\\n5. True The units of KL divergence are units of information (bits, nats, etc.).\\n6. True KLD is a non-negative measure.\\n7. True Performing splitting based on highly informative event usually leads to low model\\ngeneralization and a less accurate one as well.\\n\\x04\\nSOL-84 \\uf14b CH.SOL- 4.18.\\n1094.3. SOLUTIONS\\nFormally, mutual information attempts to measure how correlated two variables are with\\neach other:\\nI(X; Y ) =\\n∑\\nx,y\\nP (x, y) log P (x, y)\\nP (x)P (y) (4.20)\\n= E\\n[\\nlog 1\\nP (x) + log 1\\nP (y) − log 1\\nP (x, y)\\n]\\n= H(X) + H(Y ) − H(X, Y ).\\nRegarding the question at hand, given two distributions f1 and f2 and their joint distri-\\nbution f , the mutual information of f1 and f2 is deﬁned as I(f1, f2) = H(f, f1f2). If the\\ntwo distributions are independent, i.e. f = f1 · f2, the mutual information will vanish. This\\nconcept has been widely used as a similarity measure in image analysis. \\x04\\nSOL-85 \\uf14b CH.SOL- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem. \\x04\\n4.3.4 Classification and Information Gain\\nSOL-86 \\uf14b CH.SOL- 4.20.\\nThe three most widely used methods are:\\n1.\\nEntropy (t) = −\\nc−1∑\\ni=0\\np(i) log2 p(i). (4.21)\\n2.\\n1 −\\nc−1∑\\ni=0\\n[p(i)]2 (4.22)\\n110Chapter 4 INFORMATION THEORY\\n3.\\nClassiﬁcation error (t) = 1 − max\\ni\\n[p(i)]. (4.23)\\n\\x04\\nSOL-87 \\uf14b CH.SOL- 4.21.\\nIn a decision tree, the attribute by which we choose to split is the one with [maximum]\\ninformation gain. \\x04\\nSOL-88 \\uf14b CH.SOL- 4.22.\\nIt is clear that the entropy will be decreased more by ﬁrst splitting on Green rather than\\non Rain.\\nFIGURE 4.12: First split.\\n\\x04\\nSOL-89 \\uf14b CH.SOL- 4.23.\\n1. Information gain is the expected reduction in entropy caused by partitioning values in\\na dataset according to a given attribute.\\n2. A decision tree learning algorithm chooses the next attribute to partition the currently\\nselected node, by ﬁrst computing the information gain from the entropy, for instance,\\nas a splitting criterion.\\n3. There are 3 positive examples corresponding to Shrinkage=+, and 2 negative examples\\n1114.3. SOLUTIONS\\ncorresponding to Shrinkage=-. Using the formulae:\\nH(Y ) = −\\nk∑\\ni=1\\nP (Y = yi) log2 P (Y = yi) (4.24)\\nand the probabilities:\\nP (γ = +) = 3\\n5 , (4.25)\\nP (γ = −) = 2\\n5 , (4.26)\\nthe overall entropy before splitting is ( 4.13):\\nEorig = −(3/5) log(3/5) − (2/5) log(2/5)\\n= H(γ) ≈ 0.97095[bits/symbol]. (4.27)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is: 0.97095 bits\\nFIGURE 4.13: Entropy before splitting.\\n4. If we split on θ1, (4.5) the relative shrinkage frequency is:\\n112Chapter 4 INFORMATION THEORY\\nTotal θ1 = T θ1 = F\\n+ 3 0\\n- 1 1\\nTABLE 4.5: Splitting on θ1.\\nT o compute the information gain (IG) based on feature θ1, we must ﬁrst compute the\\nentropy of γ after a split based on θ1, H(γ|θ1):\\nH(γ|θ1)\\n= −\\nv∑\\nj=1\\n[ k∑\\ni=1\\nP (γ = γi|θ1 = θj) log2 P (γ = γi|θ1 = θj)\\n]\\nP (θ1 = θj).\\nTherefore, using the data for the the relative shrinkage frequency ( 4.5), the information\\ngain after splitting on θ1 is:\\nEθ1=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.8112,\\nEθ1=F = −0\\n1 log 0\\n1 − 1\\n1 log 1\\n1 = 0.0.\\n(4.28)\\nNow we know that P (θ1 = T ) = 4/5 and P (θ1 = F ) = 1/5 , therefore:\\n∆ = Eorig − (4/5) Eθ1=T − (1/5) Eθ1=F\\n= 0.97095 − (4/5) ∗ 0.8112 − (1/5) ∗ (0.0)\\n=≈ 0.32198 [bits/symbol].\\n(4.29)\\n\\x04\\nSOL-90 \\uf14b CH.SOL- 4.24.\\nThere are 4 positive examples corresponding to Expansion=+, and 3 negative examples\\n1134.3. SOLUTIONS\\ncorresponding to Expansion=-.\\n1. The overall entropy before splitting is ( 4.14):\\nEorig = −(4/7) log(4/7) − (3/7) log(3/7)\\n= 0.9852281 [bits/symbol]. (4.30)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is:0.9852281 bits\\nFIGURE 4.14: Entropy before splitting.\\n2. If we split on θ1, (4.6) the relative star expansion frequency is:\\nTotal θ1 = T θ1 = F\\n+ 3 1\\n- 0 3\\nTABLE 4.6: Splitting on θ1.\\nTherefore, the information gain after splitting on A is:\\nEθ1=T = −3\\n3 log 3\\n3 − 0\\n3 log 0\\n3 = 0.0,\\nEθ1=F = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.81127.\\n(4.31)\\n114Chapter 4 INFORMATION THEORY\\nNow we know that P (θ1 = T ) = 3/7 and P (θ1 = F ) = 4/7 , therefore:\\n∆ = Eorig − (3/7) Eθ1=T − (4/7) Eθ1=F\\n= 0.98522 − (3/7) ∗ 0.0 − (4/7) ∗ (0.81127)\\n= 0.52163 [bits/symbol].\\n(4.32)\\n3. If we split on θ2, (4.7) the relative star expansion frequency is:\\nTotal θ2 = T θ2 = F\\n+ 3 1\\n- 1 2\\nTABLE 4.7: Splitting on θ2.\\nThe information gain after splitting on B is:\\nEθ2=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.0.8112,\\nEθ2=F = −1\\n3 log 1\\n3 − 2\\n3 log 2\\n3 = 0.9182.\\n(4.33)\\nNow we know that P (θ2 = T ) = 4/7 and P (θ2 = F ) = 3/7 , therefore:\\n∆ = Eorig − (4/7) Eθ2=T − (3/7) Eθ2=F\\n= 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol].\\n∆ = 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol]. (4.34)\\n\\x04\\n1154.3. SOLUTIONS\\nSOL-91 \\uf14b CH.SOL- 4.25.\\n1.\\nH(γ) = −\\n( 2\\n6 log2\\n2\\n6 + 4\\n6 log2\\n4\\n6\\n)\\nH(γ) = −\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n≈ 0.92 [bits/symbol].\\n(4.35)\\n2.\\nH(γ|θ1) = −1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n−\\n1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n− 1\\n3 (1 log2 1) .\\nH(γ|θ1) = 1\\n3(1) + 1\\n3(1) + 1\\n3 (0).\\nH(γ|θ1) = 2\\n3 ≈ 0.66[bits/symbol].\\n(4.36)\\n3.\\nH(γ|θ2) = −1\\n2\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n− 1\\n2 (1 log2 1) .\\nH(γ|θ2) = 1\\n2\\n(\\nlog2 3 − 2\\n3\\n)\\n.\\nH(γ|θ2) = 1\\n2 log2 3 − 1\\n3 ≈ 0.46 [bits/symbol].\\n(4.37)\\n4. False.\\n\\x04\\n4.3.5 Mutual Information\\nSOL-92 \\uf14b CH.SOL- 4.26.\\n1. The diagram is depicted in Fig. 4.15.\\n116Chapter 4 INFORMATION THEORY\\nE N\\nH(S) H(D)\\nFIGURE 4.15: Mutual Information between H(S) & H(D).\\n2. Equivocation is annotated by E.\\n3. Noise is annotated by N .\\n4. The intersection (shaded area) in (4.15) corresponds to mutual information of the source\\nH(S) and of the destination H(D).\\n5. The formulae for mutual information is:\\nH(S; D) = H(S) − E = H(D) − N. (4.38)\\n\\x04\\nSOL-93 \\uf14b CH.SOL- 4.27.\\nThe relative entropy D(p||q) is the measure of difference between two distributions. It\\ncan also be expressed like a measure of the inefﬁciency of assuming that the distribution is q\\nwhen the true distribution is p. \\x04\\nSOL-94 \\uf14b CH.SOL- 4.28.\\nMutual information is a Shannon entropy-based measure of dependence between random\\nvariables. The mutual information between X and Z can be understood as the reduction of\\n1174.3. SOLUTIONS\\nthe uncertainty in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.39)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X. \\x04\\n4.3.6 Mechanical Statistics\\nSOL-95 \\uf14b CH.SOL- 4.29.\\nIs this question valuable? \\x04\\nSOL-96 \\uf14b CH.SOL- 4.30.\\nBoltzmann related the degree of disorder of the state of a physical system to the logarithm\\nof its probability. If, for example, the system has n non-interacting and identical particles,\\neach capable of existing in each of K equally likely states, the leading term in the logarithm of\\nthe probability of ﬁnding the system in a conﬁguration with n1 particles in state 1, n2 in state\\n2, etc, is given by the Boltzmann entropy Hπ = − ∑K\\n1 πi log(πi), where πi = ni/n. \\x04\\nSOL-97 \\uf14b CH.SOL- 4.31.\\nThere are 8 equiprobable events in each roll of the dice, therefore:\\nH = −\\n8∑\\ni=1\\n1\\n8 log2\\n1\\n8 = 3 [bits] . (4.40)\\n\\x04\\n4.3.7 Jensen\\'s inequality\\nSOL-98 \\uf14b CH.SOL- 4.32.\\n1. A function f is concave in the range [a, b] if f φ2 is negative in the range [a, b].\\n2. A function f is convex in the range [a, b] if f φ2 is positive in the range [a, b].\\n118Chapter 4 INFORMATION THEORY\\n3. The following inequality was published by J.L. Jensen in 1906:\\n(Jensen’s Inequality)Let f be a function convex up on (a, b). Then for any n ≥ 2\\nnumbers xi ∈ (a, b):\\nf\\n( ∑n\\ni=1 xi\\nn\\n)\\n≤\\n∑n\\ni=1 f (xi)\\nn ,\\nand that the equality is attained if and only if f is linear or all xi are equal.\\nFor a convex down function, the sign of the inequality changes to ≥.\\nJensen’s inequality states that if f is convex in the range [a, b], then:\\nf (a) + f (b)\\n2 ≥ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b. Jensen’s inequality states that if f is concave in the\\nrange [a, b], then:\\nf (a) + f (b)\\n2 ≤ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b.\\n\\x04\\nSOL-99 \\uf14b CH.SOL- 4.33.\\nTrue The non-negativity of KLD can be proved using Jensen\\'s inequality. \\x04\\nReferences\\n[1] S. Carnot. Reﬂections on the Motive Power of Fire: And Other Papers on the Second\\nLaw of Thermodynamics . Dover books on physics. Dover Publications, 2012 (cit.\\non p. 86).\\n[2] T. M. Cover and J. A. Thomas. Elements of Information Theory . John Wiley and\\nSons, Inc., 2006 (cit. on p. 86).\\n[3] B. J. Hiley. ‘From the Heisenberg Picture to Bohm: a New Perspective on Active\\nInformation and its relation to Shannon Information’. In: Proc. Conf. Quantum\\nTheory: reconsideration of foundations (2002), pp. 141–162 (cit. on p. 87).\\n119REFERENCES\\n[4] C. Shannon. ‘A mathematical theory of communication’. In: Bell System T echnical\\nJournal 27 (1948), pp. 379–423 (cit. on pp. 86, 90).\\n[5] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 96).\\n120CHAPTER\\n5\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . .',\n",
              " ' . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1465.1. INTRODUCTION\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 155\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n5.1 Introduction\\nC\\nALCULUS is the mathematics of change; the differentiation of a function is\\nkey to almost every domain in the scientiﬁc and engineering realms and\\ncalculus is also very much central to DL. A standard curriculum of ﬁrst year\\ncalculus includes topics such as limits, differentiation, the derivative, Taylor\\nseries, integration, and the integral. Many aspiring data scientists who lack a relevant\\nmathematical background and are shifting careers, hope to easily enter the ﬁeld but\\nfrequently encounter a mental barricade.\\n122Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nf (x) f ′(x)\\nsin(x) cos(x)\\ncos(x) − sin(x)\\nlog(x) 1\\nx\\nex ex\\nThanks to the rapid advances in processing power and the proliferation of GPUs,\\nit is possible to lend the burden of computation to a computer with high efﬁciency\\nand precision. For instance, extremely fast implementations of backpropagation, the\\ngradient descent algorithm, and automatic differentiation (AD) [5] brought artiﬁcial in-\\ntelligence from a mere concept to reality .\\nCalculus is frequently taught in a way that is very burdensome to the student,\\ntherefore I tried incorporating the writing of Python code snippets into the learning\\nprocess and the usage of:\\nDAGs (Directed Acyclic Graphs). Gradient descent is the essence of optimization in\\ndeep learning, which requires efﬁcient access to ﬁrst and second order derivatives that\\nAD frameworks provide. While older AD frameworks were written in C++ ([ 4]), the\\nnewer ones are Python-based such as Autograd ([ 10]) and JAX ([ 3], [1]).\\nDerivatives are also crucial in graphics applications. For example, in a render-\\ning technique entitled global illumination, photons bounce in a synthetically generated\\nscene while their direction and colour has to be determined using derivatives based\\non the speciﬁc material each photon hits. In ray tracing algorithms, the colour of the\\npixels is determined by tracing the trajectory the photons travel from the eye of the\\nobserver through a synthetic 3D scene.\\nA function is usually represented by a DAG. For instance, one commonly used\\nform is to represent intermediate values as nodes and operations as arcs ( 5.2). One\\nother commonly used form is to represent not only the values but also the operations\\nas nodes ( 5.11).\\nThe ﬁrst representation of a function by a DAG goes back to [ 7].\\n1235.2. PROBLEMS\\nx\\ny\\nk\\nf (a)\\nf (b)\\na bc\\nFIGURE 5.1: Intermediate value theorem\\nManual differentiation is tedious and error-prone and practically unusable for real-\\ntime graphics applications wherein numerous successive derivatives have to be re-\\npeatedly calculated. Symbolic differentiation on the other hand, is a computer based\\nmethod that uses a collection of differentiation rules to analytically calculate an exact\\nderivative of a function resulting in a purely symbolic derivatives. Many symbolic\\ndifferentiation libraries utilize what is known as operator-overloading ([9]) for both the\\nforward and reverse forms of differentiation, albeit they are not quite as fast as AD.\\n5.2 Problems\\n5.2.1 AD, Gradient descent & Backpropagation\\nAD [5] is the application of the chain rule to functions by computers in order to auto-\\nmatically compute derivatives. AD plays a signiﬁcant role in training deep learning\\nalgorithms and in order to understand AD you need a solid grounding in Calculus. As\\nopposed to numerical differentiation, AD is a procedure for establishing exact deriv-\\natives without any truncation errors. AD breaks a computer program into a series of\\nfundamental mathematical operations, and the gradient or Hessian of the computer\\nprogram is found by successive application of the chain rule ( 5.1) to it’s elementary\\nconstituents.\\n124Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nFor instance, in the C++ programming language, two techniques ([ 4]) are com-\\nmonly utilized in transforming a program that calculates numerical values of a func-\\ntion into a program which calculates numerical values for derivatives of that function;\\n(1) an operator overloading approach and (2) systematic source code transformation.\\n∂\\n∂t f (g(t))\\n⏐⏐⏐⏐⏐\\nt=t0\\n=\\n\\uf8eb\\n\\uf8ed ∂\\n∂s f (s)\\n⏐⏐⏐⏐⏐\\ns=g(t0)\\n\\uf8f6\\n\\uf8f8\\n(\\n∂\\n∂t g(t)\\n⏐⏐⏐⏐⏐\\nt=t0\\n)\\n(5.1)\\nOne notable feature of AD is that the values of the derivatives produced by apply-\\ning AD, as opposed to numerical differentiation (ﬁnite difference formulas), are exact\\nand accurate. Two variants of AD are widely adopted by the scientiﬁc community: the\\nforward mode or the reverse mode where the underlying distinction between them is\\nthe order in which the chain rule is being utilized. The forward mode, also entitled\\ntangent mode, propagates derivatives from the dependent towards the independent\\nvariables, whereas the reverse or adjoint mode does exactly the opposite. AD makes\\nheavy use of a concept known as dual numbers (DN) ﬁrst introduced by Clifford ([ 2]).\\nx1 v1 v2 f\\n(x)2\\nln(1 + v1)\\nexp(v1)\\nv2 + 1\\nFIGURE 5.2: A Computation graph with intermediate values as nodes and operations as\\narcs.\\n5.2.2 Numerical differentiation\\nPRB-100 \\uf059 CH.PRB- 5.1.\\n1. Write the formulae for the ﬁnite difference rule used in numerical differentiation.\\n2. What is the main problem with this formulae?\\n1255.2. PROBLEMS\\n3. Indicate one problem with software tools which utilize numerical differentiation and\\nsuccessive operations on ﬂoating point numbers.\\nPRB-101 \\uf059 CH.PRB- 5.2.\\n1. Given a function f (x) and a point a, deﬁne the instantaneous rate of change of\\nf (x) at a.\\n2. What other commonly used alternative name does the instantaneous rate of change\\nhave?\\n3. Given a function f (x) and a point a, deﬁne the tangent line of f (x) at a.\\n5.2.3 Directed Acyclic Graphs\\nThere are two possible ways to traverse a DAG (Directed Acyclic Graph). One\\nmethod is simple. Start at the bottom and go through all nodes to the top of the com-\\nputational tree. That is nothing else than passing the corresponding computation se-\\nquence top down. Based on this method, the so called forward mode or of AD was\\ndeveloped [ 8]. In contrast to this forward mode the reverse mode was ﬁrst used by\\nSpeelpenning [ 13] who passed the underlying graph top down and propagated the\\ngradient backwards.\\nPRB-102 \\uf059 CH.PRB- 5.3.\\n1. State the deﬁnition of the derivative f (c) of a function f (x) at x = c.\\n2. With respect to the DAG depicted in 5.3:\\n126Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx √x\\n1\\n/\\ng(x)\\nFIGURE 5.3: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.3 and ﬁnd the function g(x) it represents.\\n(b) Using the deﬁnition of the derivative, ﬁnd g′(9).\\nPRB-103 \\uf059 CH.PRB- 5.4.\\n1. With respect to the expression graph depicted in 5.4, traverse the graph and ﬁnd the\\nfunction g(x) it represents.\\nx\\n**2\\n2\\n*\\n-\\n+\\n1\\ng(x)\\nFIGURE 5.4: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n2. Using the deﬁnition of the derivative ﬁnd the derivative of g(x).\\n5.2.4 The chain rule\\nPRB-104 \\uf059 CH.PRB- 5.5.\\n1275.2. PROBLEMS\\n1. The chain rule is key concept in differentiation. Deﬁne it.\\n2. Elaborate how the chain rule is utilized in the context of neural networks.\\n5.2.5 Taylor series expansion\\nThe idea behind a Taylor series is that if you know a function and all its derivatives\\nat one point x = a, you can approximate the function at other points near a. As an\\nexample, take f (x) = √x. You can use Taylor series to approximate\\n√\\n10 by knowing\\nf (9) and all the derivatives f ′(9), f ′′(9).\\nThe MacLaurin series ( 5.2) is a special case of Taylor series when f (0), f ′(0) are\\nknown:\\nf (x) = f (0) + xf ′(0) + x2\\n2! f ′′(0) + x3\\n3! f ′′′(0) + · · · =\\n∞∑\\np=0\\nxp\\np! f (p)(0) (5.2)\\nFor instance, the Maclaurin expansion of cos(x) is:\\nf (x) = cos x, f ′(x) = − sin x,\\nf ′′(x) = − cos x, f ′′′(x) = sin x (5.3)\\nWhen evaluated at 0 results in:\\ncos x = 1 − x2\\n2! + x4\\n4! − x6\\n6! + · · · (5.4)\\nPRB-105 \\uf059 CH.PRB- 5.6.\\nFind the T aylor series expansion for:\\n1.\\n1\\n1 − x (5.5)\\n128Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2.\\nex (5.6)\\n3.\\nsin(x) (5.7)\\n4.\\ncos(x) (5.8)\\nPRB-106 \\uf059 CH.PRB- 5.7.\\nFind the T aylor series expansion for:\\nlog(x) (5.9)\\nPRB-107 \\uf059 CH.PRB- 5.8.\\nFind the T aylor series expansion centered at x = −3 for:\\nf (x) = 5 x2 − 11x + 1 (5.10)\\nPRB-108 \\uf059 CH.PRB- 5.9.\\nFind the 101th degree T aylor polynomial centered at x = 0 for:\\nf (x) = cos( x) (5.11)\\nPRB-109 \\uf059 CH.PRB- 5.10.\\nAt x = 1, compute the ﬁrst 7 terms of the T aylor series expansion of:\\nf (x) = ln 3 x. (5.12)\\n1295.2. PROBLEMS\\n5.2.6 Limits and continuity\\nTheorem 1 (L’Hopital’s rule) .\\n[limx→a\\nf (x)\\ng(x) = limx→a\\nf ′(x)\\ng′(x) ]. (5.13)\\nPRB-110 \\uf059 CH.PRB- 5.11.\\nFind the following limits:\\n1. lim\\nx→3\\nex3\\n− e27\\n3x − 9\\n2. lim\\nx→0\\nex2\\n− x − 1\\n3 cos x − x − 3\\n3. limx→∞\\nx − ln x\\n100√x + 4\\n5.2.7 Partial derivatives\\nPRB-111 \\uf059 CH.PRB- 5.12.\\n1. True or false: When applying a partial derivative, there are two variables considered\\nconstants - the dependent and independent variable.\\n2. Given g(x, y), ﬁnd its partial derivative with respect to x:\\ng(x, y) = x2y + yx + 8y. (5.14)\\nPRB-112 \\uf059 CH.PRB- 5.13.\\n130Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe gradient of a two-dimensional function is given by\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j (5.15)\\n1. Find the gradient of the function:\\nf (x, y) = xy2 − y2 + x3 (5.16)\\n2. Given the function:\\ng(x, y) = x2y = xy2 − y − 1, (5.17)\\nevaluate it at (−1, 0), directed at (1, 1).\\nPRB-113 \\uf059 CH.PRB- 5.14.\\nFind the partial derivatives of:\\nf (x, y) = 3 sin 2(x − y) (5.18)\\nPRB-114 \\uf059 CH.PRB- 5.15.\\nFind the partial derivatives of:\\nz = 2 sin(x) sin(y) (5.19)\\n5.2.8 Optimization\\nPRB-115 \\uf059 CH.PRB- 5.16.\\nConsider f (x) = x2 + 1\\n(x + 2)2 .\\n1. Where is f (x) well deﬁned?\\n1315.2. PROBLEMS\\n2. Where is f (x) increasing and decreasing?\\n3. Where is f (x) reaching minimum and maximum values.\\nPRB-116 \\uf059 CH.PRB- 5.17.\\nConsider f (x) = 2 x3 − x.\\n1. Derive f (x) and conclude on its behavior.\\n2. Derive once again and discuss the concavity of the function f (x).\\nPRB-117 \\uf059 CH.PRB- 5.18.\\nConsider the function\\nf (x, y) = 2 x2 − xy + y2,\\nand ﬁnd maximum, minimum, and saddle points.\\n5.2.9 The Gradient descent algorithm\\nPRB-118 \\uf059 CH.PRB- 5.19.\\nThe gradient descent algorithm can be utilized for the minimization of convex functions.\\nStationary points are required in order to minimize a convex function. A very simple ap-\\nproach for ﬁnding stationary points is to start at an arbitrary point, and move along the\\ngradient at that point towards the next point, and repeat until converging to a stationary\\npoint.\\n1. What is the term used to describe the vector of all partial derivatives for a function\\nf (x)?\\n2. Complete the sentence: when searching for a minima, if the derivative is positive, the\\nfunction is increasing/decreasing.\\n132Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n3. The function x2 as depicted in 5.5, has a derivative of f ′(x) = 2 x. Evaluated at x =\\n−1, the derivative equals f ′(x = −1) = −2. At x = −1, the function is decreasing\\nas x gets larger. We will happen if we wish to ﬁnd a minima using gradient descent,\\nand increase (decrease) x by the size of the gradient , and then again repeatedly keep\\njumping?\\n4. How this phenomena can be alleviated?\\n5. True or False: The gradient descent algorithm is guaranteed to ﬁnd a local minimum\\nif the learning rate is correctly decreased and a ﬁnite local minimum exists.\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−1,0\\n1,0\\n2,0\\n3,0\\n4,0\\nx = −1\\nx\\ny\\nx2\\nFIGURE 5.5: x2 Function\\nPRB-119 \\uf059 CH.PRB- 5.20.\\n1. Is the data linearly separable?\\nX1 X2 Y\\n1 1 +\\n12 12 −\\n4 5 −\\n12 12 +\\n(5.20)\\n1335.2. PROBLEMS\\n2. What is loss function for linear regression?\\n3. What is the gradient descent algorithm to minimize a function f (x)?\\n5.2.10 The Backpropagation algorithm\\nThe most important, expensive and hard to implement part of any hardware realiz-\\nation of ANNs is the non-linear activation function of a neuron. Commonly applied\\nactivation functions are the sigmoid and the hyperbolic tangent. In the most used\\nlearning algorithm in present day applications, back-propagation, the derivatives of\\nthe sigmoid function are needed when back propagating the errors.\\nThe backpropagation algorithm looks for the minimum of the error function in\\nweight space using the method of gradient descent.\\nPRB-120 \\uf059 CH.PRB- 5.21.\\n1. During the training of an ANN, a sigmoid layer applies the sigmoid function to every\\nelement in the forward pass, while in the backward pass the chain rule is being util-\\nized as part of the backpropagation algorithm. With respect to the backpropagation\\nalgorithm, given a sigmoid σ(x) = ex\\n1+ex activation function, and a J as the cost func-\\ntion, annotate each part of equation (5.21):\\ndZ = dJ\\ndσ(x)\\ndσ(x)\\ndx = dA · σ(x) ·\\n(\\n1 − σ(x)\\n)\\n(5.21)\\n2. Code snippet 5.6 provides a pure Python-based (e.g. not using Autograd) implement-\\nation of the forward pass for the sigmoid function. Complete the backward pass that\\ndirectly computes the analytical gradients.\\n134Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5 def backward(self, grad):\\n6 grad_input = [???]\\n7 return grad_input\\nFIGURE 5.6: Forward pass for the sigmoid function.\\nPRB-121 \\uf059 CH.PRB- 5.22.\\nThis question deals with the effect of customized transfer functions. Consider a neural\\nnetwork with hidden units that use x3 and output units that use sin(2x) as transfer func-\\ntions. Using the chain rule, starting from ∂E/∂yk, derive the formulas for the weight updates\\n∆wjk and ∆wij. Notice - do not include partial derivatives in your ﬁnal answer.\\n5.2.11 Feed forward neural networks\\nUnderstanding the inner-workings of Feed Forward Neural Networks (FFNN) is\\ncrucial to the understanding of other, more advanced Neural Networks such as CNN’s.\\nA Neural Network (NN) is an interconnected assembly of simple processing\\nelements, units or nodes, whose functionality is loosely based on the animal\\nneuron. The processing ability of the network is stored in the inter-unit\\nconnection strengths, or weights, obtained by a process of adaptation to, or\\nlearning from, a set of training patterns. [ 6]\\nThe Backpropagation Algorithm is the most widely used learning algorithm for\\nFFNN. Backpropagation is a training method that uses the Generalized Delta Rule . Its\\nbasic idea is to perform a gradient descent on the total squared error of the network\\noutput, considered as a function of the weights. It was ﬁrst described by Werbos and\\nmade popular by Rumelhart’s, Hinton’s and Williams’ paper [ 12].\\n1355.2. PROBLEMS\\n5.2.12 Activation functions, Autograd/JAX\\nActivation functions, and most commonly the sigmoid activation function, are\\nheavily used for the construction of NNs. We utilize Autograd ([ 10]) and the recently\\npublished JAX ([ 1]) library to learn about the relationship between activation func-\\ntions and the Backpropagation algorithm.\\nUsing a logistic, or sigmoid, activation function has some beneﬁts in being able\\nto easily take derivatives and then interpret them using a logistic regression model.\\nAutograd is a core module in PyTorch ([ 11]) and adds inherit support for automatic\\ndifferentiation for all operations on tensors and functions. Moreover, one can imple-\\nment his own custom Autograd function by sub classing the autograd F unction and\\nimplementing the forward and backward passes which operate on PyTorch tensors.\\nPyTorch provides a simple syntax ( 5.7) which is transparent to both CPU/GPU sup-\\nport.\\nimport torch\\nfrom torch.autograd import Function\\nclass DLFunction(Function):\\n@staticmethod\\ndef forward(ctx, input):\\n...\\n@staticmethod\\ndef backward(ctx, grad_output):\\n...\\nFIGURE 5.7: PyTorch syntax for autograd.\\nPRB-122 \\uf059 CH.PRB- 5.23.\\n1. True or false:In Autograd, if any input tensor of an operation has requires_grad=T rue,\\nthe computation will be tracked. After computing the backward pass, a gradient w.r.t.\\nthis tensor is accumulated into .grad attribute\\n136Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. True or false: In Autograd, multiple calls to backward will sum up previously com-\\nputed gradients if they are not zeroed.\\nPRB-123 \\uf059 CH.PRB- 5.24.\\nY our friend, a veteran of the DL community wants to use logistic regression and im-\\nplement custom activation functions using Autograd. Logistic regression is used when the\\nvariable y that we want to predict can only take on discrete values (i.e. classiﬁcation). Con-\\nsidering a binary classiﬁcation problem (y = 0 or y = 1) ( 5.8), the hypothesis function could\\nbe deﬁned so that it is bounded between [0, 1] in which we use some form of logistic function,\\nsuch as the sigmoid function. Other, more efﬁcient functions exist such as the ReLU (Rec-\\ntiﬁed Linear Unit) which we discussed later. Note: The weights in ( 5.8) are only meant for\\nillustration purposes and are not part of the solution.\\nxn\\nx2\\nx1\\n1\\n∑\\nwn\\nw2\\nw1\\nw0\\n0\\n1\\n0\\n1\\nSummation Activation\\nyk =f(netk)\\ninputs weights\\nFIGURE 5.8: A typical binary classiﬁcation problem.\\n1. Given the sigmoid function: g(x) = 1\\n1+e−z what is the expression for the corresponding\\nhypothesis in logistic regression?\\n2. What is the decision boundary?\\n3. What does hΘ(x) = 0 .8 mean?\\n4. Using an Autograd based Python program, implement both the forward and backward\\npass for the sigmoid activation function and evaluate it’s derivative at x = 1\\n1375.2. PROBLEMS\\n5. Using an Autograd based Python program, implement both the forward and backward\\npass for the ReLU activation function and evaluate it’s derivative at x = 1\\nPRB-124 \\uf059 CH.PRB- 5.25.\\nFor real values, −1 < x < 1 the hyperbolic tangent function is deﬁned as:\\ntanh−1 x = 1\\n2 [ln(1 + x) − ln(1 − x)] (5.22)\\nOn the other hand, the artanh function, which returns the inverse hyperbolic tangent of\\nits argument x, is implemented in numpy as arctanh().\\nIts derivative is given by:\\n(arctanh(x))′ = 1\\n1 − x2 (5.23)\\nY our friend, a veteran of the DL community wants to implement a custom activation\\nfunction for the arctanh function using Autograd. Help him in realize the method.\\n1. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n2. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the forward pass for the arctanh function in Python.\\n3. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the backward pass for the arctanh function in Python.\\n4. Name the class ArtanhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\n5.2.13 Dual numbers in AD\\nDual numbers (DN) are analogous to complex numbers and augment real numbers\\n138Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nwith a dual element by adjoining an inﬁnitesimal element d, for which d2 = 0.\\nPRB-125 \\uf059 CH.PRB- 5.26.\\n1. Explain how AD uses ﬂoating point numerical rather than symbolic expressions.\\n2. Explain the notion of DN as introduced by ([ 2]).\\n3. What arithmetic operations are possible on DN?.\\n4. Explain the relationship between a T aylor series and DN.\\nPRB-126 \\uf059 CH.PRB- 5.27.\\n1. Expand the following function using DN:\\nsin(x + ˙xd) (5.24)\\n2. With respect to the expression graph depicted in 5.9:\\nx\\n3\\n* +\\n2\\ng(x)\\nFIGURE 5.9: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.9 and ﬁnd the function g(x) it represents.\\n(b) Expand the function g(x) using DN.\\n3. Show that the general identity :\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.25)\\n1395.2. PROBLEMS\\nholds in this particular case too.\\n4. Using the derived DN, evaluate the function g(x) at x = 2.\\n5. Using an Autograd based Python program implement the function and evaluate it’s\\nderivative at x = 2.\\nPRB-127 \\uf059 CH.PRB- 5.28.\\nWith respect to the expression graph depicted in 5.10:\\nx\\n**2\\n5\\n*\\n*\\n+\\n14\\ng(x)\\nFIGURE 5.10: An expression graph for g(x). Constants are shown in gray , crossed-out\\nsince derivatives should not be propagated to constant operands.\\n1. T raverse the graph5.10 and ﬁnd the function g(x) it represents.\\n2. Expand the function g(x) using DN.\\n3. Using the derived DN, evaluate the function g(x) at x = 5.\\n4. Using an AutoGrad based Python program implement the function and evaluate it’s\\nderivative at x = 5.\\n5.2.14 Forward mode AD\\nPRB-128 \\uf059 CH.PRB- 5.29.\\n140Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nWhen differentiating a function using forward-mode AD, the computation of such an\\nexpression can be computed from its corresponding directed a-cyclical graph by propagating\\nthe numerical values.\\n1. Find the function, g(A, B, C) represented by the expression graph in 5.11.\\nA\\nB\\nC\\nln\\n+* g (A, B, C))\\nFIGURE 5.11: A computation graph for g(x)\\n2. Find the partial derivatives for the function g(x).\\nPRB-129 \\uf059 CH.PRB- 5.30.\\nAnswer the following given that a computational graph of a function has N inputs and\\nM outputs.\\n1. True or False?:\\n(a) Forward and reverse mode AD always yield the same result.\\n(b) In reverse mode AD there are fewer operations (time) and less space for interme-\\ndiates (memory).\\n(c) The cost for forward mode grows with N.\\n(d) The cost for reverse mode grows with M.\\nPRB-130 \\uf059 CH.PRB- 5.31.\\n1415.2. PROBLEMS\\n1. T ransform the source code in code snippet 5.1 into a function g(x1, x2).\\nCODE 5.1: A function, g(x1, x2) in the C programming language.\\n1 float g( float x1 , float x2) {\\n2 float v1, v2, v3 , v4 , v5;\\n3 v1=x1;\\n4 v2=x2;\\n5 v3 = v1 * v2;\\n6 v4 = ln (v1 );\\n7 v5 = v3 + v4;\\n8 return v5;\\n9 }\\n2. T ransform the functiong(x1, x2) into an expression graph.\\n3. Find the partial derivatives for the function g(x1, x2).\\n5.2.15 Forward mode AD table construction\\nPRB-131 \\uf059 CH.PRB- 5.32.\\n1. Given the function:\\nf (x1, x2) = x1x2 + ln (x1) (5.26)\\nand the graph 5.1, annotate each vertex (edge) of the graph with the partial derivatives\\nthat would be propagated in forward mode AD.\\n2. T ransform the graph into a table that computes the function:\\ng(x1, x2) evaluated at (x1; x2) = ( e2; π) using forward-mode AD.\\n3. Write and run a Python code snippet to prove your results are correct.\\n4. Describe the role of seed values in forward-mode AD.\\n142Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n5. T ransform the graph into a table that computes the derivative of g(x1, x2) evalu-\\nated at (x1; x2) = ( e2; π) using forward-mode AD for x1 as the chosen independent\\nvariable.\\n6. Write and run a Python code snippet to prove your results are correct.\\n5.2.16 Symbolic differentiation\\nIn this section, we introduce the basic functionality of the SymPy (SYMbolic Python)\\nlibrary commonly used for symbolic mathematics as a means to deepen your under-\\nstanding in both Python and calculus. If you are using Sympy in a Jupyter notebook\\nin Google Colab (e.g. https://colab.research.google.com/) then rendering\\nsympy equations requires MathJax to be available within each cell output. The follow-\\ning is a hook function that will make this possible:\\nCODE 5.2: Sympy in Google Colab\\n1 from IPython.display import Math, HTML\\n2 def enable_sympy_in_cell():\\n3 display(HTML(\"<script\\nsrc=\\'https://cdnjs.cloudflare.com/ajax/libs/\"↪→\\n4 \"mathjax/2.7.3/latest.js?config=default\\'>\\n5 </script>\"))\\n6 get_ipython().events.register(\\'pre_run_cell\\' ,\\nenable_sympy_in_cell)↪→\\nAfter successfully registering this hook, SymPy rendering ( 5.3) will work correctly:\\nCODE 5.3: Rendering Sympy in Google Colab\\n1 import sympy\\n2 from sympy import *\\n3 init_printing()\\n4 x, y, z = symbols(\\'x y z\\' )\\n5 Integral(sqrt(1/x), (x, 0, oo))\\n1435.2. PROBLEMS\\nIt is also recommended to use the latest version of Sympy:\\nCODE 5.4: Updating Sympy\\n> pip install --upgrade sympy\\n5.2.17 Simple differentiation\\nPRB-132 \\uf059 CH.PRB- 5.33.\\nAnswer the following questions:\\n1. Which differentiation method is inherently prone to rounding errors?\\n2. Deﬁne the term symbolic differentiation.\\nPRB-133 \\uf059 CH.PRB- 5.34.\\nAnswer the following questions:\\n1. Implement the sigmoid function σ(x) = 1\\n1+e−x symbolically using a Python based\\nSymPy program.\\n2. Differentiate the sigmoid function using SymPy and compare it with the analytical\\nderivation σ′(x) = σ(x)(1 − σ(x)).\\n3. Using SymPy, evaluate the gradient of the sigmoid function at x = 0.\\n4. Using SymPy, plot the resulting gradient of the sigmoid function.\\n5.2.18 The Beta-Binomial model\\nPRB-134 \\uf059 CH.PRB- 5.35.\\n144Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nY ou will most likely not be given such a long programming task during a face-to-face\\ninterview. Nevertheless, an extensive home programming assignment is typically given at\\nmany of the start-ups I am familiar with. Y ou should allocate around approximately four to\\nsix hours to completely answer all questions in this problem.\\nWe discussed the Beta-Binomial model extensively in chapter 3. Recall that the Beta-\\nBinomial distribution is frequently used in Bayesian statistics to model the number of suc-\\ncesses in n trials. We now employ SymPy to do the same; demonstrate computationally how\\na prior distribution is updated to develop into a posterior distribution after observing the\\ndata via the relationship of the Beta-Binomial distribution.\\nProvided the probability of success, the number of successes after n trials follows a bino-\\nmial distribution. Note that the beta distribution is a conjugate prior for the parameter of\\nthe binomial distribution. In this case, the likelihood function is binomial, and a beta prior\\ndistribution yields a beta posterior distribution.\\nRecall that for the Beta-Binomial distribution the following relationships exist:\\nPrior of θ Beta(a,b)\\nLikelihood binomial (n, θ)\\nPosterior of θ Beta (a + x, b + n − x)\\nPosterior Mean (a + x)/(a + b + n − x)\\n(5.27)\\n1. Likelihood: The starting point for our inference problem is the Likelihood, the prob-\\nability of the observed data. Find the Likelihood function symbolically using sympy.\\nConvert the SymPy representation to a purely Numpy based callable function with a\\nLambda expression. Evaluate the Likelihood function at θ = 0 .5 with 50 successful\\ntrials out of 100.\\n2. Prior: The Beta Distribution. Deﬁne the Beta distribution which will act as our prior\\ndistribution symbolically using sympy. Convert the SymPy representation to a purely\\nNumpy based callable function. Evaluate the Beta Distribution at θ : 0.5, a : 2, b : 7\\n3. Plot the Beta distribution, using the Numpy based function.\\n4. Posterior: Find the posterior distribution by multiplying our Beta prior by the Bi-\\nnomial Likelihood symbolically using sympy. Convert the SymPy representation to\\n1455.3. SOLUTIONS\\na purely Numpy based callable function. Evaluate the Posterior Distribution at θ :\\n0.5, a : 2, b : 7\\n5. Plot the posterior distribution, using the Numpy based function.\\n6. Show that the posterior distribution has the same functional dependence on θ as the\\nprior, and it is just another Beta distribution.\\n7. Given:\\nPrior : Beta(θ|a = 2, b = 7) = 56 θ (−θ + 1)6 and:\\nLikelihood : Bin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47 ﬁnd the resulting posterior\\ndistribution and plot it.\\n5.3 Solutions\\n5.3.1 Algorithmic differentiation, Gradient descent\\n5.3.2 Numerical differentiation\\nSOL-100 \\uf14b CH.SOL- 5.1.\\n1. The formulae is:\\nf ′(x) ≈ f (x + h) − f (x)\\nh . (5.28)\\n2. The main problem with this formulae is that it suffers from numerical instability for\\nsmall values of h.\\n3. In some numerical software systems, the number\\n√\\n2 may be represented as the a ﬂoat-\\ning point number ≈ 1.414213562. Therefore, the result of:\\nf loat\\n( √\\n(2)\\n)\\n∗ f loat\\n( √\\n(2)\\n)\\nmay equal ≈ 2.000000446.\\n\\x04\\nSOL-101 \\uf14b CH.SOL- 5.2.\\n146Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The instantaneous rate of change equals:\\nlim\\nh→0\\nf (a + h) − f (a)\\na + h − a . (5.29)\\n2. The instantaneous rate of change of f (x) at a is also commonly known as the tangent\\nline of f (x) at a.\\n3. Given a function f (x) and a point a, the tangent (Fig. 5.12) line of f (x) at a is a line\\nthat touches f (a) but does not cross f (x) (sufﬁciently close to a).\\nFIGURE 5.12: A Tangent line\\n\\x04\\n5.3.3 Directed Acyclic Graphs\\nSOL-102 \\uf14b CH.SOL- 5.3.\\n1475.3. SOLUTIONS\\n1. The deﬁnition is:\\nf ′(c) = lim\\nh→0\\nf (c + h) − f (c)\\nh .\\n2. If we traverse the graph 5.3 from left to right we derive the following function:\\ng(x) = 1√x . (5.30)\\nf ′(9) = lim\\nh→0\\n1/\\n√\\n9 + h − 1/\\n√\\n9\\nh\\n= lim\\nh→0\\n√\\n9 −\\n√\\n9 + h√\\n9 ·\\n√\\n9 + h · h\\n= lim\\nh→0\\n(3 −\\n√\\n9 + h)(3 +\\n√\\n9 + h)\\n3\\n√\\n9 + h · (3 +\\n√\\n9 + h) · h\\n= lim\\nh→0\\n9 − (9 + h)\\n9\\n√\\n9 + h · h + 3 · (9 + h) · h\\n= − 1\\n9 · 3 + 3 · 9\\n= − 1\\n54\\n\\x04\\nSOL-103 \\uf14b CH.SOL- 5.4.\\n1. The function g(x) = 2 x2 − x + 1 represents the expression graph depicted in 5.4.\\n148Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. By the deﬁnition:\\nf ′(x) = lim\\nh→0\\nf (x + h) − f (x)\\nx + h − x\\n= lim\\nh→0\\n2(x + h)2 − (x + h) + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2(x2 + 2xh + h2) − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2x2 + 4xh + 2h2 − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n4xh + 2h2 − h\\nh\\n= lim\\nh→0\\n4x + 2h − 1\\n= 4x − 1.\\n(5.31)\\nf (x) = 2 x2 − x + 1\\nf ′(x) = 4 x − 1\\n\\x04\\n5.3.4 The chain rule\\nSOL-104 \\uf14b CH.SOL- 5.5.\\n1. The chain rule states that the partial derivative of E = E(x, y) with respect to x can be\\ncalculated via another variable y = y(x), as follows:\\n∂E\\n∂x = ∂E\\n∂y · ∂y\\n∂x (5.',\n",
              " ' + 4xh + 2h2 − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n4xh + 2h2 − h\\nh\\n= lim\\nh→0\\n4x + 2h − 1\\n= 4x − 1.\\n(5.31)\\nf (x) = 2 x2 − x + 1\\nf ′(x) = 4 x − 1\\n\\x04\\n5.3.4 The chain rule\\nSOL-104 \\uf14b CH.SOL- 5.5.\\n1. The chain rule states that the partial derivative of E = E(x, y) with respect to x can be\\ncalculated via another variable y = y(x), as follows:\\n∂E\\n∂x = ∂E\\n∂y · ∂y\\n∂x (5.32)\\n2. For instance, the chain rule [ 8] is applied in neural networks to calculate the change in\\n1495.3. SOLUTIONS\\nits weights resulting from tuning the cost function. This derivative is calculated via a\\nchain of partial derivatives (e.g. of the activation functions).\\n\\x04\\n5.3.5 Taylor series expansion\\nSOL-105 \\uf14b CH.SOL- 5.6.\\n1.\\n1\\n1 − x =\\n∞∑\\nn=0\\nxn = 1 + x + x2 + x3\\n(when −1 < x < 1) (5.33)\\n2.\\nex =\\n∞∑\\nn=0\\nxn\\nn! = 1 + x + x2\\n2! + x3\\n3! + · · · (5.34)\\n3.\\nsin x =\\n∞∑\\nn=0\\n(−1)n\\n(2n + 1)! x2n+1 = x − x3\\n3! + x5\\n5! − · · · (5.35)\\n4.\\ncos x =\\n∞∑\\nn=0\\n(−1)n\\n(2n)! x2n = 1 − x2\\n2! + x4\\n4! − · · · (5.36)\\n\\x04\\nSOL-106 \\uf14b CH.SOL- 5.7.\\n150Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nlog x =\\n∞∑\\nn=1\\n(−1)n+1 (x − 1)n\\nn = (x − 1) − (x − 1)2\\n2 +\\n(x − 1)3\\n3 − (x − 1)4\\n4 + · · ·\\n(5.37)\\n\\x04\\nSOL-107 \\uf14b CH.SOL- 5.8.\\nIn this case, all derivatives can be computed:\\nf 0(x) = 5 x2 − 11x + 1,\\nf 0(−3) = 79 ,\\nf 1(x) = 10 x − 11,\\nf 1(−3) = −41,\\nf 2(x) = 10 ,\\nf 2(−3) = 10 ,\\nf n(x) = 0, ∀n ≥ 3.\\n(5.38)\\n\\x04\\nSOL-108 \\uf14b CH.SOL- 5.9.\\nThe immediate answer is 1. Refer to eq. 5.36 to verify this logical consequence. \\x04\\nSOL-109 \\uf14b CH.SOL- 5.10.\\nBy employing eq. 5.37, one can substitute x by 3 − x and generate the ﬁrst 7 terms of the\\nx-dependable outcome before assigning the point x = 1.\\n\\x04\\n5.3.6 Limits and continuity\\nSOL-110 \\uf14b CH.SOL- 5.11.\\n1515.3. SOLUTIONS\\n1. With an indeterminate form 0/0, L’Hopital’s rule holds. We look at\\nlim\\nx→3\\n3x2ex3\\n3 = 9e27,\\nwhich equals to the original limit.\\n2. Again, we yield 0/0 at interim, so we look at the ﬁrst order derivative\\nlim\\nx→0\\n2xex − 1\\n−3 sin x − 1 = 1.\\nThe original limit is also equal to 1.\\n3. This time, the intermediate form is of ∞/∞ and L’Hopital applies as well. The quotient\\nof the derivatives is\\n1 − 1\\nx\\n0.01x−99/100 = 100(x − 1)x1/99\\nAs x → ∞, this goes to ∞, so the original limit is equal to ∞ also.\\n\\x04\\n5.3.7 Partial derivatives\\nSOL-111 \\uf14b CH.SOL- 5.12.\\n1. T rue.\\n2. By treating y as constant, one can derive that\\n∂g\\n∂x = 2xy + y. (5.39)\\n\\x04\\nSOL-112 \\uf14b CH.SOL- 5.13.\\n152Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1.\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j\\n=\\n(\\ny2 + 3x2\\n)\\ni + (2xy − 2y) j\\n(5.40)\\n2. It can be shown that ∇g(x, y) = (2 xy + y2) i + (x2 + 2xy − 1) j at (−1, 0) equals\\n(0, 0). According to the deﬁnition of directional derivative:\\n(0, 0) · (1, 1)\\n|(1, 1)| = 0 (5.41)\\n\\x04\\nSOL-113 \\uf14b CH.SOL- 5.14.\\n∂f\\n∂x = 6 sin(x − y) cos(x − y)\\n∂f\\n∂y = −6 sin(x − y) cos(x − y)\\n(5.42)\\n\\x04\\nSOL-114 \\uf14b CH.SOL- 5.15.\\n∂z\\n∂x = 2 cos x sin y\\n∂z\\n∂y = 2 sin x cos y\\n(5.43)\\n\\x04\\n5.3.8 Optimization\\nSOL-115 \\uf14b CH.SOL- 5.16.\\n1535.3. SOLUTIONS\\n1. The function is only deﬁned where x ̸= −2, in the domain of:\\n(−∞, −2) ∪ (−2, +∞).\\n2. By a simple quotient-based derivation:\\nf ′(x) = 2(x + 2)(2x − 1)\\n(x + 2)4 . (5.44)\\nNamely, expect for the ill-deﬁned x = −2, the critical point of x = 0 .5 should be\\nconsidered. For x > 0.5, the derivative is positive and the function increases, in contrast\\nto x < 0.5.\\n3. The requested coordinate is (0.5, 0.2).\\n\\x04\\nSOL-116 \\uf14b CH.SOL- 5.17.\\n1. f ′(x) = 6 x2 − 1, which entails the behavior of the function changes around the points\\nx = ± 1√\\n6. The derivative is negative between x = − 1√\\n6 and x = 1√\\n6, i.e., it decreases\\nin the domain, and increases otherwise.\\n2. The second derivative is f ′′(x) = 12 x, which means the function is concave for negative\\nx values and convex otherwise.\\n\\x04\\nSOL-117 \\uf14b CH.SOL- 5.18.\\nThe function should be derived according to each variable separately and be equated to 0,\\nas follows:\\nfx(x, y) = 4 x − y = 0 , f y(x, y) = −y + 2y = 0 .\\nSo, the solution to these equations yield the coordinate (0, 0), and f (0, 0) = 0 .\\nLet us derive the second order derivative, as follows:\\n∂2f\\n∂x2 (x, y) = 4 , ∂2f\\n∂y2 (x, y) = 2 , ∂2f\\n∂x∂y (x, y) = −1 ,\\n154Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nAlso, the following relation exists:\\nD(x, y) = ∂2f\\n∂x2\\n∂2f\\n∂y2 −\\n(\\n∂2f\\n∂x∂y\\n) 2\\n= 7 ,\\nThus, the critical point (0, 0) is a minimum. \\x04\\n5.3.9 The Gradient descent algorithm\\nSOL-118 \\uf14b CH.SOL- 5.19.\\n1. It is the gradient of a function which is mathematically represented by:\\n∇f (x, y) =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\n∂f (x,y)\\n∂x\\n∂f (x,y)\\n∂y\\n\\uf8f6\\n\\uf8f7\\uf8f8 (5.45)\\n2. Increasing.\\n3. We will keep jumping between the same two points without ever reaching a minima.\\n4. This phenomena can be alleviated by using a learning rate or step size . For instance,\\nx+ = 2 ∗ η where η is a learning rate with small value such as η = 0.25.\\n5. T rue.\\n\\x04\\nSOL-119 \\uf14b CH.SOL- 5.20.\\n1. The point (12,12) has two classes, so the classes cannot be separated by any line.\\n2.\\nJ(θ) = 1\\n2m\\nm∑\\ni=1\\n(ˆyi − yi)2\\n(5.46)\\n1555.3. SOLUTIONS\\n3. Simple but fundamental algorithm for minimizing f . Just repeatedly move in the direc-\\ntion of the negative gradient\\n(a) Start with initial guess θ(0), step size η\\n(b) For k = 1, 2, 3, . . .:\\ni. Compute the gradient ∇f (θ(k−1))\\nii. Check if gradient is close to zero; is so stop, otherwise continue\\niii. Update θ(k) = θ(k−1) − η∇f (θ(k−1))\\n(c) Return ﬁnal θ(k) as approximate solution θ∗\\n\\x04\\n5.3.10 The Backpropagation algorithm\\nSOL-120 \\uf14b CH.SOL- 5.21.\\n1. The annotated parts of equation (5.21) appear in (5.47):\\nσ(x) = ex\\n1 + ex = The Sigmoid activation function\\nσ(x) ·\\n(\\n1 − σ(x)\\n)\\nThe deriviative of the Sigmoid activation function =\\n1Z = The input\\ndZ = The error introduced by input Z.\\nA = The output\\ndA = The error introduced by output A.\\n(5.47)\\n2. Code snippet 5.13 provides an implementation of both the forward and backward passes\\nfor the sigmoid function.\\n156Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5\\n6 def backward(self, grad):\\n7 grad_input = self.x*(1-self.x) * grad\\n8 return grad_input\\nFIGURE 5.13: Forward and backward passes for the sigmoid activation function in pure\\nPython.\\n\\x04\\nSOL-121 \\uf14b CH.SOL- 5.22.\\nThe key concept in this question is merely understanding that the transfer function and\\nits derivatives are changing compared to traditional activation functions, namely:\\n∂E\\n∂yk\\n= (yk − dk) (5.48)\\n∂E\\n∂netk\\n= ∂E\\n∂yk\\n· ∂yk\\n∂netk\\n= (yk − dk) · 2 cos(2netk) (5.49)\\n∆wjk = −η ∂E\\n∂wjk\\n= −η ∂E\\n∂netk\\n· ∂netk\\n∂wjk\\n= −η · (yk − dk) · 2 cos(2netk) · yj (5.50)\\n∂E\\n∂yj\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\n· ∂netk\\n∂yj\\n)\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\nwjk\\n)\\n(5.51)\\n∂E\\n∂netj\\n= ∂E\\n∂yj\\n· ∂yj\\n∂netj\\n= ∂E\\n∂yj\\n· 3net2\\nj (5.52)\\n1575.3. SOLUTIONS\\n∆wij = −η ∂E\\n∂wij\\n= −η ∂E\\n∂netj\\n· ∂netj\\n∂wij\\n= −η · (∑\\nk [(yk − dk) · 2 cos(2netk) · wjk]) · 3net2\\nj · yi\\n(5.53)\\n\\x04\\n5.3.11 Feed forward neural networks\\n5.3.12 Activation functions, Autograd/JAX\\nSOL-122 \\uf14b CH.SOL- 5.23.\\n1. T rue.\\n2. T rue.\\n\\x04\\nSOL-123 \\uf14b CH.SOL- 5.24.\\nThe answers are as follows:\\n1. hΘ(x) = g(ΘT x) = 1\\n1+e−Θ\\nT\\nx\\n.\\n2. The decision boundary for the logistic sigmoid function is where hΘ(x) = 0 .5 (values\\nless than 0.5 mean false, values equal to or more than 0.5 mean true).\\n3. That there is a 80% chance that the instance is of the corresponding class, therefore:\\n• hΘ(x) = g(Θ0 + Θ1x1 + Θ2x2). We can predict y = 1 if x0 + x1 + x2 ≥ 0.\\n4. The code snippet in 5.14 implements the function using Autograd.\\n158Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 from torch.autograd import Function\\n2 class Sigmoid(Function):\\n3 @staticmethod\\n4 def forward(ctx, x):\\n5 output = 1 / (1 + torch.exp(-x))\\n6 ctx.save_for_backward(output)\\n7 return output\\n8\\n9 @staticmethod\\n10 def backward(ctx, grad_output):\\n11 output, = ctx.saved_tensors\\n12 grad_x = output * (1 - output) * grad_output\\n13 return grad_x\\nFIGURE 5.14: Forward and backward for the sigmoid function in Autograd.\\n5. The code snippet in 5.15 implements the function using Autograd.\\n1595.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ReLU(torch.autograd.Function):\\n3 @staticmethod\\n4 def forward(ctx, input):\\n5 ctx.save_for_backward(input)\\n6 return input.clamp(min=0)\\n7\\n8 @staticmethod\\n9 def backward(ctx, grad_output):\\n10 input, = ctx.saved_tensors\\n11 grad_input = grad_output.clone()\\n12 grad_input[input < 0] = 0\\n13 return grad_input\\nFIGURE 5.15: Forward and backward for the ReLU function in Autograd.\\n\\x04\\nSOL-124 \\uf14b CH.SOL- 5.25. The answers are as follows:\\n1. Code snippet 5.16 implements the forward pass using pure Python.\\n160Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n3 requires_grad=True)).type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 arctanh_values = np.arctanh(xT_np)\\n7 print (\"Numpy:\", arctanh_values)\\n8 > Numpy: [[ 0.38842311 0.1944129 0.64900533]]\\nFIGURE 5.16: Forward pass for equation ( 5.23) using pure Python.\\n2. Code snippet 5.17 implements the forward pass using Autograd.\\n1 import torch\\n2 from torch.autograd import Function\\n3 class ArtanhFunction(Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward(x)\\n7 r = (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5)\\n8 return r\\nFIGURE 5.17: Forward pass for equation ( 5.23).\\n3. Code snippet 5.18 implements the backward pass using Autograd.\\n1615.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ArtanhFunction(Function):\\n3 @staticmethod\\n4 input, = ctx.saved_tensors\\n5 out= grad_output / (1 - input ** 2)\\n6 print (\"backward:{}\".format(out))\\n7 return out\\nFIGURE 5.18: Backward pass for equation ( 5.23).\\n4. Code snippet 5.19 veriﬁes the correctness of the implementation using gradcheck.\\n1 import numpy as np\\n2\\n3 xT =\\ntorch.abs(torch.tensor([[0.11,0.19,0.57]],requires_grad=True))↪→\\n4 .type(torch.DoubleTensor)\\n5 arctanh_values_torch = arctanhPyTorch(xT)\\n6 print (\"Torch:\", arctanh_values_torch)\\n7 from torch.autograd import gradcheck, Variable\\n8 f = ArtanhFunction.apply\\n9 test=gradcheck(lambda t: f(t), xT)\\n10 print(test)\\n11\\n12 > PyTorch version: 1.7.0\\n13 > Torch: tensor([[ 0.3884, 0.1944, 0.6490]], dtype =torch.float64,\\n14 > grad_fn=<ArtanhFunctionBackward>)\\n15 > backward:tensor([[1.1586, 1.0383,1.4838]], dtype =torch.float64,\\n16 grad_fn=<CopyBackwards>)\\nFIGURE 5.19: Invoking arctanh using gradcheck\\n162Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n\\x04\\n5.3.13 Dual numbers in AD\\nSOL-125 \\uf14b CH.SOL- 5.26.\\nThe answers are as follows:\\n1. The procedure of AD is to use verbatim text of a computer program which calculates\\na numerical value and to transform it into the text of a computer program called the\\ntransformed program which calculates the desired derivative values. The transformed\\ncomputer program carries out these derivative calculations by repeated use of the chain\\nrule however applied to actual ﬂoating point values rather than to a symbolic rep-\\nresentation.\\n2. Dual numbers extend all numbers by adding a second component x ↦→ x + ˙xd where\\nx + ˙x is the dual part.\\n3. The following arithmetic operations are possible on DN:\\n(a) d2 = 0\\n(b) (x + ˙xd) + (y + ˙yd) = x + y + ( ˙x + ˙y)d\\n(c) −(x + ˙xd) = −x − ˙xd\\n(d) 1\\nx+ ˙xd = 1\\nx − ˙x\\nx2 d\\n4. For f (x + ˙xd) the T aylor series expansion is:\\nf (x + ˙xd) = f (x) + f ′(x)\\n1! ˙xd + . . .0 (5.54)\\nThe immediate and important result is that all higher-order terms (n >= 2) disappear\\nwhich provides closed-form mathematical expression that represents a function and its\\nderivative.\\n\\x04\\nSOL-126 \\uf14b CH.SOL- 5.27.\\n1635.3. SOLUTIONS\\nThe answers are as follows:\\n1.\\nsin(x + ˙xd) = sin( x) + cos(x) ˙xd (5.55)\\n2. If we traverse the graph 5.9 from left to right we drive the following simple function:\\ng(x) = 3 ∗ x + 2 (5.56)\\n3. We know that:\\ng(x) = 3 ∗ x + 2 (5.57)\\ng′(x) = 3 (5.58)\\nNow if we expand the function using DN:\\ng(x + ˙xd) = 3 ∗ (x + ˙xd) + 2 = (5.59)\\n3 ∗ x + 3 ∗ ( ˙xd) + 2 (5.60)\\nRearranging:\\n3 ∗ x + 2 + 3 ∗ ( ˙xd) (5.61)\\nBut since g(x) = 3 ∗ x + 2 then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.62)\\n4. Evaluating the function g(x) at x = 2 using DN we get:\\ng(x = 2) = (3 ∗ 2 + 2) + (3) ˙xd = (5.63)\\n8 + (3) ˙xd (5.64)\\n5. The code snippet in 5.20 implements the function using Autograd.\\n164Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([2.0], dtype =float)\\n4 def f1(x):\\n5 return 3*x + 2\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 8.0\\n8 print(grad_f1(x)) # > 3.0\\nFIGURE 5.20: Autograd\\n\\x04\\nSOL-127 \\uf14b CH.SOL- 5.28. The answers are as follows:\\n1. If we traverse the graph 5.9 from left to right we drive the following function:\\ng(x) = 5 ∗ x2 + 4 ∗ x + 1 (5.65)\\n2. We know that:\\ng(x1) = 5 ∗ x2 + 4 ∗ x + 1 (5.66)\\ng′(x1) = 10 ∗ x1 + 4 (5.67)\\nNow if we expand the function using DN we get:\\ng(x + ˙xd) = 5 ∗ (x + ˙xd)2 + 4 ∗ (x + ˙xd) + 1 = (5.68)\\n5 ∗ (x2 + 2 ∗ x + ˙xd + ( ˙xd)2) + 4 ∗ x + 4 ∗ ( ˙xd) + 1 (5.69)\\n1655.3. SOLUTIONS\\nHowever by deﬁnition (d2) = 0 and therefore that term vanishes. Rearranging the\\nterms:\\n(5 ∗ x2 + 4 ∗ x + 1) + (10 ∗ x + 4) ˙xd (5.70)\\nBut since g(x) = (5 ∗ x2 + 4 ∗ x + 1) then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.71)\\n3. Evaluating the function g(x) at x = 5 using DN we get:\\ng(x = 4) = (5 ∗ 52 + 4 ∗ 5 + 1) + (10 ∗ 5 + 4) ˙xd =\\n146 + (54) ˙xd (5.72)\\n4. The code snippet in 5.21 implements the function using Autograd.\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([5.0], dtype =float)\\n4 def f1(x):\\n5 return 5*x**2 + 4*x +1\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 146.0\\n8 print(grad_f1(x)) # > 54.0\\nFIGURE 5.21: Autograd\\n\\x04\\n5.3.14 Forward mode AD\\nSOL-128 \\uf14b CH.SOL- 5.29.\\nThe answers are as follows:\\n166Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The function g(x) represented by the expression graph in 5.11 is:\\ng(x) = A + B ∗ ln(C) (5.73)\\n2. For a logarithmic function:\\nd\\ndx ln(x) = 1\\nx (5.74)\\nTherefore, the partial derivatives for the function g(x) are:\\n∂f\\n∂A = 1\\n∂f\\n∂B = ln(C)\\n∂f\\n∂C = B ∗ 1\\nC\\n(5.75)\\n\\x04\\nSOL-129 \\uf14b CH.SOL- 5.30. The answers are as follows:\\n1. T rue. Both directions yield the exact same results.\\n2. T rue. Reverse mode is more efﬁcient than forward mode AD (why?).\\n3. T rue.\\n4. T rue.\\n\\x04\\nSOL-130 \\uf14b CH.SOL- 5.31.\\nThe answers are as follows:\\n1675.3. SOLUTIONS\\n1. The function is\\nf (x1, x2) = x1x2 + ln (x1) (5.76)\\n2. The graph associated with the forward mode AD is as follows:\\nx1\\nx2\\n*\\n+\\nln\\nf (x1, x2)\\nFIGURE 5.22: A Computation graph for g(x1, x2) in 5.1\\n3. The partial derivatives are:\\n∂f\\n∂x1\\n= x2 − 1\\n(x1)\\n∂f\\n∂x2\\n= x1\\n(5.77)\\n\\x04\\n5.3.15 Forward mode AD table construction\\nSOL-131 \\uf14b CH.SOL- 5.32.\\nThe answers are as follows:\\n1. The graph with the intermediate values is depicted in ( 5.23)\\n168Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx1\\nx2\\n*\\n+\\nln\\ng(x1, x2)\\nv1\\nv2\\nv1 v4\\nv3\\nv5\\nFIGURE 5.23: A derivative graph for g(x1, x2) in 5.1\\n2. Forward mode AD for g (x1, x2) = ln ( x1) + x1x2 evaluated at (x1, x2) = ( e2, π).\\nForward-mode function evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\nv1 = ln v−1 = ln (e2) = 2\\nv2 = v−1 × v0 = e2 × π = 23.2134\\nv3 = v1 + v2 2 + 23.2134 = 25 .2134\\nf = v3 =≈ 25.2134\\nTABLE 5.1: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n3. The following Python code ( 5.24) proves that the numerical results are correct:\\n1695.3. SOLUTIONS\\n1 import math\\n2 print (math.log(math.e*math.e) + math.e*math.e*math.pi)\\n3 > 25.2134^^I\\nFIGURE 5.24: Python code- AD of the function g(x1, x2)\\n4. Seed values indicate the values by which the dependent and independent variables are\\ninitialized to before being propagated in a computation graph. For instance:\\n˙v1 = ∂x1\\n∂x1\\n= 1\\n˙v2 = ∂x2\\n∂x1\\n= 0\\nTherefore we set ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n5. Here we construct a table for the forward-mode AD for the derivative of f (x1, x2) =\\nln (x1) + x1x2 evaluated at (x1, x2) = ( e2, π) while setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.. In\\nforward-mode AD a derivative is called a tangent.\\nIn the derivation that follows, note that mathematically using manual differentiation:\\nd\\ndx1\\n[ln(x) + x2x]\\n= d\\ndx1\\n[ln(x1)] + x2 · d\\ndx1\\n[x1]\\n= 1\\nx1\\n+ x2 · 1\\n= 1\\nx1\\n+ x2\\nand also since d\\ndx ln(x) = 1\\nx then ˙v1 = 1\\nv−1\\n∗ ˙v−1 = ˙v−1/v−1 = 1\\ne2 ∗ 1 = 1 /e2.\\n170Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nForward-mode AD derivative evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\n˙v−1 = ˙x1 = 1\\n˙v0 = ˙x2 = 0\\n˙v1 = ˙v−1/v−1 = 1/e2\\n˙v2 = ˙v−1 × v0 + ˙v0 ×\\nv−1 = 1 × π + 0 ×\\ne2 = π\\n˙v4 = ˙v1 + ˙v2 = 1/e2 +\\nπ\\n˙f = ˙v4 = 1 /e2 +\\nπ =≈ 3.2769\\nTABLE 5.3: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute ∂y\\n∂x1\\n.\\n6. The following Python code ( 5.25) proves that the numerical results are correct:\\n1715.3. SOLUTIONS\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 import math\\n4\\n5 x1 = math.e* math.e\\n6 x2 = math.pi\\n7\\n8 def f1(x1,x2):\\n9 return (np.log(x1) + x1*x2)\\n10\\n11 grad_f1 = grad(f1)\\n12\\n13 print(f1(x1,x2)) # > 25.2134\\n14 print(grad_f1(x1,x2)) # > 3.2769\\nFIGURE 5.25: Python code- AD of the function g(x1, x2)\\n\\x04\\n5.3.16 Symbolic differentiation\\n5.3.17 Simple differentiation\\nSOL-132 \\uf14b CH.SOL- 5.33.\\nThe answers are as follows:\\n1. Approximate methods such as numerical differentiation suffer from numerical instabil-\\nity and truncation errors.\\n2. In symbolic differentiation, a symbolic expression for the derivative of a function is\\ncalculated. This approach is quite slow and requires symbols parsing and manipulation.\\nFor example, the number\\n√\\n2 is represented in SymPy as the object Pow(2,1/2). Since\\nSymPy employees exact representations Pow(2,1/2)*Pow(2,1/2) will always equal 2.\\n\\x04\\n172Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nSOL-133 \\uf14b CH.SOL- 5.34.\\n1. First:\\n1 import sympy\\n2 sympy.init_printing()\\n3 from sympy import Symbol\\n4 from sympy import diff, exp, sin, sqrt\\n5 y = Symbol(\\'y\\' )\\n6 y = sympy.Symbol(\"y\")\\n7 sigmoid = 1/(1+sympy.exp(-y))^^I\\nFIGURE 5.26: Sigmoid in SymPy\\n2. Second:\\n1 sig_der=sym.diff(sigmoid, y)\\nFIGURE 5.27: Sigmoid gradient in SymPy\\n3. Third:\\n1 sig_der.evalf(subs={y:0})\\n2 > 0.25\\nFIGURE 5.28: Sigmoid gradient in SymPy\\n1735.3. SOLUTIONS\\n4. The plot is depicted in 5.29.\\n1 p = sym.plot(sig_der);\\n10.0\\n 7.5\\n 5.0\\n 2.5\\n 0.0 2.5 5.0 7.5 10.0\\ny\\n0.00\\n0.05\\n0.10\\n0.15\\n0.20\\n0.25f(y)\\nFIGURE 5.29: SymPy gradient of the Sigmoid() function\\n\\x04\\n5.3.18 The Beta-Binomial model\\nSOL-134 \\uf14b CH.SOL- 5.35.\\nT o correctly render the generated LaT eX in this problem, we import and conﬁgure several\\nlibraries as depicted in 5.30.\\n174Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 import scipy.stats as st\\n3 import matplotlib.pyplot as plt\\n4 import sympy as sp\\n5 sp.interactive.printing.\\n6 init_printing(use_latex=True)\\n7 from IPython.display import display, Math, Latex\\n8 maths = lambda s: display(Math(s))\\n9 latex = lambda s: display(Latex(s)) ^^I\\nFIGURE 5.30: SymPy imports\\n1. The Likelihood function can be created as follows. Note the speciﬁc details of generating\\nthe Factorial function in SymPy.\\n1755.3. SOLUTIONS\\n1 n = sp.Symbol(\\'n\\' , integer =True, positive =True)\\n2 r = sp.Symbol(\\'r\\' , integer =True, positive =True)\\n3 theta = sp.Symbol(\\'theta\\' )\\n4 # Create the function symbolically\\n5 from sympy import factorial\\n6 cNkSym= (factorial(n))/ (factorial(r) *factorial(n-r))\\n7 cNkSym.evalf()\\n8 binomSym= cNkSym*((theta **r)*(1-theta)**(n-r))\\n9 binomSym.evalf()\\n10 #Convert it to a Numpy-callable function\\n11 binomLambda = sp.Lambda((theta,r,n), binomSym)\\n12 maths(r\"\\\\operatorname{Bin}(r|n,\\\\theta) = \" )\\n13 display (binomLambda .expr)\\n14 #Evaluating the SymPy version results in:\\n15 > binomSym.subs({theta:0.5,r:50,n:100})\\n16 #Evaluating the pure Numpy version results in:\\n17 > binomLambda(0.5,50,100)= 0.07958923\\nFIGURE 5.31: Likelihood function using SymPy\\nThe Symbolic representation results in the following LaT eX:\\nBin(r|n, θ) = θr (−θ + 1)n−r n!\\nr! (n − r)! (5.78)\\n2. The Beta distribution can be created as follows.\\n176Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 #mu = sp.Symbol(\\'mu\\', integer=False, positive=True)\\n4 # Create the function symbolically\\n5 G = sp.gamma\\n6 # The normalisation factor\\n7 BetaNormSym = G(a + b)/(G(a)*G(b))\\n8 # The functional form\\n9 BetaFSym = theta**(a-1) * (1-theta)**(b-1)\\n10 BetaSym=BetaNormSym * BetaFSym\\n11 BetaSym.evalf() # this works\\n12 # Turn Beta into a function\\n13 BetaLambda = sp.Lambda((theta,a,b), BetaNormSym * BetaFSym)\\n14 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) = \" )\\n15 display(BetaSym)\\n16 #Evaluating the SymPy version results in:\\n17 > BetaLambda(0.5,2,7)=0.4375\\n18 #Evaluating the pure Numpy version results in:\\n19 > BetaSym.subs({theta:0.5,a:2,b:7})=0.4375\\nFIGURE 5.32: Beta distribution using SymPy\\nThe result is:\\nBeta(θ|a, b) = θa−1Γ(a + b)\\nΓ(a)Γ(b) (−θ + 1)b−1 (5.79)\\n3. The plot is depicted in 5.33.\\n1775.3. SOLUTIONS\\n1 %pylab inline\\n2 mus = arange(0,1,.01)\\n3 # Plot for various values of a and b\\n4 for ab in [(.1,.1),(.5,.5),(2,20),(2,3), ( 1,1)]:\\n5 plot(mus, vectorize(BetaLambda)(mus, *ab), label =\"a=%s b=%s\" % ab)\\n6 legend(loc=0)\\n7 xlabel(r\"$\\\\theta$\", size =22)\\nFIGURE 5.33: A plot of the Beta distribution\\n4. We can ﬁnd the posterior distribution by multiplying our Beta prior by the Binomial\\nLikelihood.\\n178Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 BetaBinSym=BetaSym * binomSym\\n4 # Turn Beta-bin into a function\\n5 BetaBinLambda = sp.Lambda((theta,a,b,n,r), BetaBinSym)\\n6 BetaBinSym=BetaBinSym.powsimp()\\n7 display(BetaBinSym)\\n8 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) \\\\times\\n\\\\operatorname{Bin}(r|n,\\\\theta) \\\\propto %s\" %\\nsp.latex(BetaBinSym))\\n↪→\\n↪→\\n9 > BetaBinSym.subs({theta:0.5,a:2,b:7,n:10,r:3})= 0.051269\\n10 > BetaBinLambda ( 0.5,2,7, 10,3)= 0.051269\\nFIGURE 5.34: A plot of the Beta distribution\\nThe result is:\\nBeta(θ|a, b) × Bin(r|n, θ) ∝\\nθa+r−1 (−θ + 1)b+n−r−1 n!\\nr! (n − r)!Γ(a)Γ(b) Γ(a + b)\\nSo the posterior distribution has the same functional dependence on θ as the prior, it is\\njust another Beta distribution.\\n5. Mathematically, the relationship is as follows:\\n1795.3. SOLUTIONS\\nPrior :\\nBeta(θ|a = 2, b = 7)\\n= 56θ (−θ + 1)6\\nLikelihood :\\nBin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47\\nPosterior(normalised) :\\nBeta(θ|2, 7) × Bin(3|50, θ) = 1097600 θ4 (−θ + 1)53\\n(5.80)\\n180Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 prior = BetaLambda(theta,2,7)\\n2 maths(\"\\\\mathbf{Prior}:\\\\operatorname{Beta}(\\\\theta|a=2,b=7) = %s\" %\\nsp.latex(prior))↪→\\n3 likelihood = binomLambda(theta,3,50) # = binomLambda(0.5,3,10)\\n4 maths(\"\\\\mathbf{Likelihood}: \\\\operatorname{Bin}(r=3|n=6, \\\\theta) =\\n%s\" % sp.latex(likelihood))↪→\\n5 posterior = prior * likelihood\\n6 posterior=posterior.powsimp()\\n7 maths(r\"\\\\mathbf{Posterior\\n(normalised)}:\\\\operatorname{Beta}(\\\\theta|2,7) \\\\times\\n\\\\operatorname{Bin}(3|50,\\\\theta)=%s\"\\n↪→\\n↪→\\n8 posterior.subs({theta:0.5})\\n9 plt.plot(mus, (sp .lambdify(theta,posterior))(mus), \\'r\\' )\\n10 xlabel(\"$\\\\\\\\theta$\", size =22)\\nFIGURE 5.35: A plot of the Posterior with the provided data samples.\\n\\x04\\nReferences\\n[1] J. Bradbury et al. JAX: composable transformations of NumPy programs. 2018 (cit. on\\npp. 123, 136).\\n181REFERENCES\\n[2] W. K. Clifford. ‘Preliminary Sketch of Bi-quaternions’. In: Proceedings of the Lon-\\ndon Mathematical Society 4 (1873), pp. 381–95 (cit. on pp. 125, 139).\\n[3] R. Frostig et al. JAX: Autograd and XLA . 2018 (cit. on p. 123).\\n[4] A. Griewank, D. Juedes and J. Utke. ‘Algorithm 755; ADOL-C: a package for the\\nautomatic differentiation of algorithms written in C/C++’. In: ACM T ransactions\\non Mathematical Software 22.2 (June 1996), pp. 131–167 (cit. on pp. 123, 125).\\n[5] A. Griewank and A. Walther. Evaluating Derivatives: Principles and T echniques\\nof Algorithmic Differentiation . Second. USA: Society for Industrial and Applied\\nMathematics, 2008 (cit. on pp. 123, 124).\\n[6] K. Gurney. An Introduction to Neural Networks . 1 Gunpowder Square, London\\nEC4A 3DE, UK: UCL Press, 1998 (cit. on p. 135).\\n[7] L. V . Kantorovich. ‘On a mathematical symbolism convenient for performing\\nmachine calculations’. In: Dokl. Akad. Nauk SSSR . V ol. 113. 4. 1957, pp. 738–741\\n(cit. on p. 123).\\n[8] G. Kedem. ‘Automatic differentiation of computer programs’. In: ACM T ransac-\\ntions on Mathematical Software (TOMS) 6.2 (1980), pp. 150–165 (cit. on pp. 126,\\n149).\\n[9] S. Laue. On the Equivalence of Forward Mode Automatic Differentiation and Symbolic\\nDifferentiation. 2019. arXiv: 1904.02990 [cs.SC] (cit. on p. 124).\\n[10] D. Maclaurin, D. Duvenaud and R. P . Adams. ‘Autograd: Effortless gradients in\\nnumpy’. In: ICML 2015 AutoML Workshop . V ol. 238. 2015 (cit. on pp. 123, 136).\\n[11] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: (2017) (cit. on p. 136).\\n[12] D. Rumelhart, G. Hinton and R. Williams. ‘Learning representations by back\\npropagating errors’. In: Nature 323 (1986), pp. 533–536 (cit. on p. 135).\\n[13] B. Speelpenning. Compiling fast partial derivatives of functions given by algorithms .\\nTech. rep. Illinois Univ Urbana Dept of Computer Science, 1980 (cit. on p. 126).\\n182BACHELORS\\nPART IVCHAPTER\\n6\\nDEEP LEARNING: NN ENSEMBLES\\nThe saddest aspect of life right now is that gathers knowledge faster than society\\n',\n",
              " 'ML 2015 AutoML Workshop . V ol. 238. 2015 (cit. on pp. 123, 136).\\n[11] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: (2017) (cit. on p. 136).\\n[12] D. Rumelhart, G. Hinton and R. Williams. ‘Learning representations by back\\npropagating errors’. In: Nature 323 (1986), pp. 533–536 (cit. on p. 135).\\n[13] B. Speelpenning. Compiling fast partial derivatives of functions given by algorithms .\\nTech. rep. Illinois Univ Urbana Dept of Computer Science, 1980 (cit. on p. 126).\\n182BACHELORS\\nPART IVCHAPTER\\n6\\nDEEP LEARNING: NN ENSEMBLES\\nThe saddest aspect of life right now is that gathers knowledge faster than society\\ngathers wisdom.\\n— Isaac Asimov\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 2026.1. INTRODUCTION\\n6.1 Introduction\\nI\\nNtuition and practice demonstrate that a poor or an inferior choice may\\nbe altogether prevented merely by motivating a group (or an ensemble)\\nof people with diverse perspectives to make a mutually acceptable choice.\\nLikewise, in many cases, neural network ensembles signiﬁcantly improve\\nthe generalization ability of single-model based AI systems [ 5, 11]. Shortly follow-\\ning the foundation of Kaggle, research in the ﬁeld had started blooming; not only\\nbecause researchers are advocating and using advanced ensembling approaches in\\nalmost every competition, but also by the empirical success of the top winning mod-\\nels. Though the whole process of training ensembles typically involves the utilization\\nof dozens of GPUs and prolonged training periods, ensembling approaches enhance\\nthe predictive power of a single model. Though ensembling obviously has a signiﬁc-\\nant impact on the performance of AI systems in general, research shows its effect is\\nparticularly dramatic in the ﬁeld of neural networks [ Russakovsky_2015, 1, 4, 7, 13].\\nTherefore, while we could examine combinations of any type of learning algorithms,\\nthe focus of this chapter is the combination of neural networks.\\n6.2 Problems\\n6.2.1 Bagging, Boosting and Stacking\\nPRB-135 \\uf059 CH.PRB- 6.1.\\nMark all the approaches which can be utilized to boost a single model performance:\\n(i) Majority Voting\\n(ii) Using K-identical base-learning algorithms\\n(iii) Using K-different base-learning algorithms\\n(iv) Using K-different data-folds\\n(v) Using K-different random number seeds\\n(vi) A combination of all the above approaches\\n186Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nPRB-136 \\uf059 CH.PRB- 6.2.\\nAn argument erupts between two senior data-scientists regarding the choice of an ap-\\nproach for training of a very small medical corpus. One suggest that bagging is superior\\nwhile the other suggests stacking. Which technique, bagging or stacking, in your opinion is\\nsuperior? Explain in detail.\\n(i) Stacking since each classier is trained on all of the available data.\\n(ii) Bagging since we can combine as many classiﬁers as we want by training each on a\\ndifferent sub-set of the training corpus.\\nPRB-137 \\uf059 CH.PRB- 6.3.\\nComplete the sentence: A random forest is a type of a decision tree which utilizes [bag-\\nging/boosting]\\nPRB-138 \\uf059 CH.PRB- 6.4.\\nThe algorithm depicted in Fig. 6.1 was found in an old book about ensembling. Name the\\nalgorithm.\\n1876.2. PROBLEMS\\nAlgorithm 1: Algo 1\\nData: A set of training data, Q with N elements has been established\\nwhile K times do\\nCreate a random subset of N ′ data by sampling from Q containing the N\\nsamples;\\nN ′ < N ;\\nExecute algorithm Algo 2;\\nReturn all N ′ back to Q\\nAlgorithm 2: Algo 2\\nChoose a learner hm;\\nwhile K times do\\nPick a training set and train with hm;\\nFIGURE 6.1: A speciﬁc ensembling approach\\nPRB-139 \\uf059 CH.PRB- 6.5.\\nFig. 6.2 depicts a part of a speciﬁc ensembling approach applied to the models x1, x2...xk.\\nIn your opinion, which approach is being utilized?\\nGenerelizerx3\\nx2\\nx1\\n...\\nxk\\nBase Learners\\nf\\n?\\nFIGURE 6.2: A speciﬁc ensembling approach\\n(i) Bootstrap aggregation\\n(ii) Snapshot ensembling\\n(iii) Stacking\\n188Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n(iv) Classical committee machines\\nPRB-140 \\uf059 CH.PRB- 6.6.\\nConsider training corpus consisting of balls which are glued together as triangles, each\\nof which has either 1, 3, 6, 10, 15, 21, 28, 36, or 45 balls.\\n1. We draw several samples from this corpus as presented in Fig. 6.3 wherein each sample\\nis equiprobable. What type of sampling approach is being utilized here?\\nFIGURE 6.3: Sampling approaches\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n2. Two samples are drawn one after the other. In which of the following cases is the\\ncovariance between the two samples equals zero?\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n3. During training, the corpus sampled with replacement and is divided into several\\nfolds as presented in Fig. 6.4.\\nT1:\\nT2:\\nT3:\\nT4:\\nFIGURE 6.4: Sampling approaches\\n1896.2. PROBLEMS\\nIf 10 balls glued together is a sample event that we know is hard to correctly classify,\\nthen it is impossible that we are using:\\n(i) Bagging\\n(ii) Boosting\\n6.2.2 Approaches for Combining Predictors\\nPRB-141 \\uf059 CH.PRB- 6.7.\\nThere are several methods by which the outputs of base classiﬁers can be combined to\\nyield a single prediction. Fig. 6.5 depicts part of a speciﬁc ensembling approach applied to\\nseveral CNN model predictions for a labelled data-set. Which approach is being utilized?\\n(i) Majority voting for binary classiﬁcation\\n(ii) Weighted majority voting for binary classiﬁcation\\n(iii) Majority voting for class probabilities\\n(iv) Weighted majority class probabilities\\n(v) An algebraic weighted average for class probabilities\\n(vi) An adaptive weighted majority voting for combining multiple classiﬁers\\n190Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 l = []\\n2 for i,f in enumerate(filelist):\\n3 temp = pd.read_csv(f)\\n4 l.append(temp)\\n5 arr = np.stack(l,axis=-1)\\n6 avg_results = pd.DataFrame(arr[:,:-1,:].mean(axis=2))\\n7 avg_results[\\'image\\' ] = l[0][\\'image\\' ]\\n8 avg_results.columns = l[0].columns\\nFIGURE 6.5: PyTorch code snippet for an ensemble\\nPRB-142 \\uf059 CH.PRB- 6.8.\\nRead the paper Neural Network Ensembles [3] and then complete the sentence: If the\\naverage error rate for a speciﬁc instance in the corpus is less than [...]% and the respective\\nclassiﬁers in the ensemble produce independent [...], then when the number of classiﬁers\\ncombined approaches inﬁnity, the expected error can be diminished to zero.\\nPRB-143 \\uf059 CH.PRB- 6.9.\\nTrue or false: A perfect ensemble comprises of highly correct classiﬁers that differ as\\nmuch as possible.\\nPRB-144 \\uf059 CH.PRB- 6.10.\\nTrue or false: In bagging, we re-sample the training corpus with replacement and there-\\nfore this may lead to some instances being represented numerous times while other instances\\nnot to be represented at all.\\n6.2.3 Monolithic and Heterogeneous Ensembling\\nPRB-145 \\uf059 CH.PRB- 6.11.\\n1916.2. PROBLEMS\\n1. True or false: T raining an ensemble of a single monolithic architecture results in\\nlower model diversity and possibly decreased model prediction accuracy.\\n2. True or false: The generalization accuracy of an ensemble increases with the number\\nof well-trained models it consists of.\\n3. True or false: Bootstrap aggregation (or bagging), refers to a process wherein a CNN\\nensemble is being trained using a random subset of the training corpus.\\n4. True or false: Bagging assumes that if the single predictors have independent errors,\\nthen a majority vote of their outputs should be better than the individual predictions.\\nPRB-146 \\uf059 CH.PRB- 6.12.\\nRefer to the papers: Dropout as a Bayesian Approximation [2] and Can Y ou Trust\\nY our Model’s Uncertainty? [12] and answer the following question: Do deep ensembles\\nachieve a better performance on out-of-distribution uncertainty benchmarks compared with\\nMonte-Carlo (MC)-dropout?\\nPRB-147 \\uf059 CH.PRB- 6.13.\\n1. In a transfer-learning experiment conducted by a researcher, a number of ImageNet-\\npretrained CNN classiﬁers, selected from T able 6.1 are trained on ﬁve different folds\\ndrawn from the same corpus. Their outputs are fused together producing a composite\\nmachine. Ensembles of these convolutional neural networks architectures have been\\nextensively studies an evaluated in various ensembling approaches [ 4, 9]. Is it likely\\nthat the composite machine will produce a prediction with higher accuracy than that\\nof any individual classiﬁer? Explain why.\\n192Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nCNN Model Classes Image Size Top-1 accuracy\\nResNet152 1000 224 78.428\\nDPN98 1000 224 79.224\\nSeNet154 1000 224 81.304\\nSeResneXT101 1000 224 80.236\\nDenseNet161 1000 224 77.560\\nInceptionV4 1000 299 80.062\\nTABLE 6.1: ImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches.\\n2. True or False: In a classiﬁcation task, the result of ensembling is always superior.\\n3. True or False: In an ensemble, we want differently trained models converge to differ-\\nent local minima.\\nPRB-148 \\uf059 CH.PRB- 6.14.\\nIn committee machines, mark all the combiners that do not make direct use of the input:\\n(i) A mixture of experts\\n(ii) Bagging\\n(iii) Ensemble averaging\\n(iv) Boosting\\nPRB-149 \\uf059 CH.PRB- 6.15.\\nTrue or False: Considering a binary classiﬁcation problem ( y = 0 or y = 1 ), ensemble\\naveraging, wherein the outputs of individual models are linearly combined to produce a fused\\noutput is a form of a static committee machine.\\n1936.2. PROBLEMS\\nMn\\nM2\\nM1\\n∑\\nwn\\nw2\\nw1\\n0\\n1\\n0\\n1\\nFIGURE 6.6: A typical binary classiﬁcation problem.\\nPRB-150 \\uf059 CH.PRB- 6.16.\\nTrue or false: When using a single model, the risk of overﬁtting the data increases when\\nthe number of adjustable parameters is large compared to cardinality (i.e., size of the set) of\\nthe training corpus.\\nPRB-151 \\uf059 CH.PRB- 6.17.\\nTrue or false:If we have a committee of K trained models and the errors are uncorrelated,\\nthen by averaging them the average error of a model is reduced by a factor of K.\\n6.2.4 Ensemble Learning\\nPRB-152 \\uf059 CH.PRB- 6.18.\\n1. Deﬁne ensemble learning in the context of machine learning.\\n2. Provide examples of ensemble methods in classical machine-learning.\\n3. True or false: Ensemble methods usually have stronger generalization ability.\\n4. Complete the sentence: Bagging is variance/bias reduction scheme while boosting\\nreduced variance/bias.\\n194Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n6.2.5 Snapshot Ensembling\\nPRB-153 \\uf059 CH.PRB- 6.19.\\nY our colleague, a well-known expert in ensembling methods, writes the following pseudo\\ncode in Python shown in Fig. 6.7 for the training of a neural network. This runs inside a\\nstandard loop in each training and validation step.\\n1 import torchvision.models as models\\n2 ...\\n3 models = [\\'resnext\\' ]\\n4 for m in models:\\n5 train ...\\n6 compute VAL loss ...\\n7 amend LR ...\\n8 if (val_acc > 90.0):\\n9 saveModel()\\nFIGURE 6.7: PyTorch code snippet for an ensemble\\n1. What type of ensembling can be used with this approach? Explain in detail.\\n2. What is the main advantage of snapshot ensembling? What are the disadvantages, if\\nany?\\nPRB-154 \\uf059 CH.PRB- 6.20.\\nAssume further that your colleague amends the code as follows in Fig. 6.8.\\n1956.2. PROBLEMS\\n1 import torchvision.models as models\\n2 import random\\n3 import np\\n4 ...\\n5 models = [\\'resnext\\' ]\\n6 for m in models:\\n7 train ...\\n8 compute loss ...\\n9 amend LR ...\\n10 manualSeed= draw a new random number\\n11 random.seed(manualSeed)\\n12 np.random.seed(manualSeed)\\n13 torch.manual_seed(manualSeed)\\n14 if (val_acc > 90.0):\\n15 saveModel()\\nFIGURE 6.8: PyTorch code snippet for an ensemble\\nExplain in detail what would be the possible effects of adding lines 10-13.\\n6.2.6 Multi-model Ensembling\\nPRB-155 \\uf059 CH.PRB- 6.21.\\n1. Assume your colleague, a veteran in DL and an expert in ensembling methods writes\\nthe following Pseudo code shown in Fig. 6.9 for the training of several neural networks.\\nThis code snippet is executed inside a standard loop in each and every training/valida-\\ntion epoch.\\n196Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 import torchvision.models as models\\n2 ...\\n3 models = [\\'resnext\\' ,\\'vgg\\' ,\\'dense\\' ]\\n4 for m in models:\\n5 train ...\\n6 compute loss /acc ...\\n7 if (val_acc > 90.0):\\n8 saveModel()\\nFIGURE 6.9: PyTorch code snippet for an ensemble\\nWhat type of ensembling is being utilized in this approach? Explain in detail.\\n2. Name one method by which NN models may be combined to yield a single prediction.\\n6.2.7 Learning-rate Schedules in Ensembling\\nPRB-156 \\uf059 CH.PRB- 6.22.\\n1. Referring to Fig. ( 6.10) which depicts a speciﬁc learning rate schedule, describe the\\nbasic notion behind its mechanism.\\n1976.3. SOLUTIONS\\n1\\n0,5\\n1\\nx\\ny\\nFIGURE 6.10: A learning rate schedule.\\n2. Explain how cyclic learning rates [10] can be effective for the training of convolutional\\nneural networks such as the ones in the code snippet of Fig. 6.10.\\n3. Explain how a cyclic cosine annealing schedule as proposed by Loshchilov [ 10] and\\n[13] is used to converge to multiple local minima.\\n6.3 Solutions\\n6.3.1 Bagging, Boosting and Stacking\\nSOL-135 \\uf14b CH.SOL- 6.1.\\nAll the presented options are correct. \\x04\\nSOL-136 \\uf14b CH.SOL- 6.2.\\nThe correct choice would be stacking. In cases where the given corpus is small, we would\\nmost likely prefer training our models on the full data-set. \\x04\\nSOL-137 \\uf14b CH.SOL- 6.3.\\nA random forest is a type of a decision tree which utilizes bagging. \\x04\\n198Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-138 \\uf14b CH.SOL- 6.4.\\nThe presented algorithm is a classic bagging. \\x04\\nSOL-139 \\uf14b CH.SOL- 6.5.\\nThe approach which is depicted is the ﬁrst phase of stacking. In stacking, we ﬁrst (phase\\n0) predict using several base learners and then use a generalizer (phase 1) that learns on top\\nof the base learners predictions. \\x04\\nSOL-140 \\uf14b CH.SOL- 6.6.\\n1. Sampling with replacement\\n2. Sampling without replacement\\n3. This may be mostly a result of bagging, since in boosting we would have expected miss-\\ncorrectly classiﬁed observations to repeatedly appear in subsequent samples.\\n\\x04\\n6.3.2 Approaches for Combining Predictors\\nSOL-141 \\uf14b CH.SOL- 6.7.\\nAn Algebraic weighted average for class probabilities. \\x04\\nSOL-142 \\uf14b CH.SOL- 6.8.\\nThis is true, [ 3] provides a mathematical proof. \\x04\\nSOL-143 \\uf14b CH.SOL- 6.9.\\nThis is true. For extension, see instance [ 8]. \\x04\\nSOL-144 \\uf14b CH.SOL- 6.10.\\nThis is true. In a bagging approach, we ﬁrst randomly draw (with replacement), K ex-\\n1996.3. SOLUTIONS\\namples where K is the size of the original training corpus therefore leading to an imbalanced\\nrepresentation of the instances. \\x04\\n6.3.3 Monolithic and Heterogeneous Ensembling\\nSOL-145 \\uf14b CH.SOL- 6.11.\\n1. True Due to their lack of diversity, an ensemble of monolithic architectures tends to\\nperform worse than an heterogeneous ensemble.\\n2. True This has be consistently demonstrated in [ 11, 5].\\n3. True In [6] there is a discussion about both using the whole corpus and a subset much\\nlike in bagging.\\n4. True The total error decreases with the addition of predictors to the ensemble.\\n\\x04\\nSOL-146 \\uf14b CH.SOL- 6.12.\\nY es, they do. \\x04\\nSOL-147 \\uf14b CH.SOL- 6.13.\\n1. Y es, it is very likely, especially if their errors are independent.\\n2. True It may be proven that ensembles of models perform at least as good as each of the\\nensemble members it consists of.\\n3. True Different local minima add to the diversiﬁcation of the models.\\n\\x04\\nSOL-148 \\uf14b CH.SOL- 6.14.\\nBoosting is the only one that does not. \\x04\\n200Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-149 \\uf14b CH.SOL- 6.15.\\nFalse By deﬁnition, static committee machines use only the output of the single predict-\\nors. \\x04\\nSOL-150 \\uf14b CH.SOL- 6.16.\\nTrue \\x04\\nSOL-151 \\uf14b CH.SOL- 6.17.\\nFalse Though this may be theoretically true, in practice the errors are rarely uncorrelated\\nand therefore the actual error can not be reduced by a factor of K. \\x04\\n6.3.4 Ensemble Learning\\nSOL-152 \\uf14b CH.SOL- 6.18.\\n1. Ensemble learning is an excellent machine learning idea which displays noticeable bene-\\nﬁts in many applications, one such notable example is the widespread use of ensembles\\nin Kaggle competitions. In an ensemble several individual models (for instance Res-\\nNet18 and VGG16) which were trained on the same corpus, work in tandem and during\\ninference, their predictions are fused by a pre-deﬁned strategy to yield a single predic-\\ntion.\\n2. In classical machine learning Ensemble methods usually refer to bagging, boosting and\\nthe linear combination of regression or classiﬁcation models.\\n3. True The stronger generalization ability stems from the voting power of diverse models\\nwhich are joined together.\\n4. Bagging is variance reduction scheme while boosting reduced bias.\\n\\x04\\n6.3.5 Snapshot Ensembling\\n2016.3. SOLUTIONS\\nSOL-153 \\uf14b CH.SOL- 6.19.\\n1. Since only a single model ie being utilized, this type of ensembling is known as snap-\\nshot ensembling. Using this approach, during the training of a neural network and\\nin each epoch, a snapshot, e.g. the weights of a trained instance of a model (a PTH\\nﬁle in PyT orch nomenclature) are persisted into permanent storage whenever a certain\\nperformance metrics, such as accuracy or loss is being surpassed. Therefore the name\\n“snapshot”; weights of the neural network are being snapshot at speciﬁc instances in\\ntime. After several such epochs the top-5 performing Snapshots which converged to\\nlocal minima [4] are combined as part of an ensemble to yield a single prediction.\\n2. Advantages: during a single training cycle, many model instances may be collected.\\nDisadvantages: inherent lack of diversity by virtue of the fact that the same models is\\nbeing repeatedly used.\\n\\x04\\nSOL-154 \\uf14b CH.SOL- 6.20.\\nChanging the random seed at each iteration/epoch, helps in introducing variation which\\nmay contribute to diversifying the trained neural network models. \\x04\\n6.3.6 Multi-model Ensembling\\nSOL-155 \\uf14b CH.SOL- 6.21.\\n1. Multi-model ensembling.\\n2. Both averaging and majority voting.\\n\\x04\\n6.3.7 Learning-rate Schedules in Ensembling\\nSOL-156 \\uf14b CH.SOL- 6.22.\\n202Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1. Capturing the best model of each training cycle allows to obtain multiple models settled\\non various local optima from cycle to cycle at the cost of training a single mode\\n2. The approach is based on the non-convex nature of neural networks and the ability to\\nconverge and escape from local minima using a speciﬁc schedule to adjust the learning\\nrate during training.\\n3. Instead of monotonically decreasing the learning rate, this method lets the learning rate\\ncyclically vary between reasonable boundary values.\\n\\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 186).\\n[2] Y . Gal and Z. Ghahramani. ‘Dropout as a Bayesian approximation’. In: arXiv\\npreprint arXiv:1506.02157 (2015) (cit. on p. 192).\\n[3] L. K. Hansen and P . Salamon. ‘Neural Network Ensembles’. In: IEEE T rans. Pat-\\ntern Anal. Mach. Intell. 12 (1990), pp. 993–1001 (cit. on pp. 191, 199).\\n[4] G. Huang et al. ‘Snapshot ensembles: Train 1, get M for free. arXiv 2017’. In:\\narXiv preprint arXiv:1704.00109 () (cit. on pp. 186, 192, 202).\\n[5] J. Huggins, T. Campbell and T. Broderick. ‘Coresets for scalable Bayesian logistic\\nregression’. In: Advances in Neural Information Processing Systems . 2016, pp. 4080–\\n4088 (cit. on pp. 186, 200).\\n[6] C. Ju, A. Bibaut and M. van der Laan. ‘The relative performance of ensemble\\nmethods with deep convolutional neural networks for image classiﬁcation’. In:\\nJournal of Applied Statistics 45.15 (2018), pp. 2800–2818 (cit. on p. 200).\\n[7] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on p. 186).\\n[8] A. Krogh and J. V edelsby. ‘Neural Network Ensembles, Cross Validation, and\\nActive Learning’. In: NIPS. 1994 (cit. on p. 199).\\n[9] S. Lee et al. ‘Stochastic multiple choice learning for training diverse deep en-\\nsembles’. In: Advances in Neural Information Processing Systems . 2016, pp. 2119–\\n2127 (cit. on p. 192).\\n203REFERENCES\\n[10] I. Loshchilov and F. Hutter. ‘Sgdr: Stochastic gradient descent with warm re-\\nstarts’. In: arXiv preprint arXiv:1608.03983 (2016) (cit. on p. 198).\\n[11] P . Oshiro et al.(2012)Oshiro and Baranauskas. ‘How many trees in a random\\nforest?’ In: International Workshop on Machine Learning and Data Mining in Pattern\\nRecognition. 2012 (cit. on pp. 186, 200).\\n[12] Y . Ovadia et al. ‘Can you trust your model’s uncertainty? Evaluating predict-\\nive uncertainty under dataset shift’. In: Advances in Neural Information Processing\\nSystems. 2019, p. 13991 (cit. on p. 192).\\n[13] L. N. Smith. ‘Cyclical learning rates for training neural networks’. In: 2017 IEEE\\nWinter Conference on Applications of Computer Vision (WACV). IEEE. 2017, pp. 464–\\n472 (cit. on pp. 186, 198).\\n204CHAPTER\\n7\\nDEEP LEARNING: CNN FEATURE EXTRACTION\\nWhat goes up must come down.\\n— Isaac Newton\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\\nNeural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\n7.1 Introduction\\nT\\nHE extraction of an n-dimensional feature vector (FV) or an embedding from\\none (or more) layers of a pre-trained CNN, is termed feature extraction (FE).\\nUsually , FE works by ﬁrst removing the last fully connected (FC) layer from\\na CNN and then treating the remaining layers of the CNN as a ﬁxed FE. As\\nexempliﬁed in Fig. ( 7.1) and Fig. ( 7.2), applying this method to the ResNet34 archi-\\ntecture, the resulting FV consists of 512 ﬂoating point values. Likewise, applying the\\nsame logic on the ResNet152 architecture, the resulting FV has 2048 ﬂoating point ele-\\nments.7.2. PROBLEMS\\n1 2 3 4 · · · k = 512\\nA ﬁxed k-element FV .\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nActual values of a normalized k-element FV .\\nFIGURE 7.1: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depicted is\\nthe ResNet CNN architecture with 34 layers.\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.2: PyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed).\\nThe premise behind FE is that CNNs which were originally trained on the Im-\\nageNet Large Scale Visual Recognition Competition [ 7], can be adapted and used (for\\ninstance in a classiﬁcation task) on a completely different (target) domain without any\\nadditional training of the CNN layers. The power of a CNN to do so lies in its ability\\nto generalize well beyond the original data-set it was trained on, therefore FE on a\\nnew target data-set involves no training and requires only inference.\\n7.2 Problems\\n7.2.1 CNN as Fixed Feature Extractor\\nBefore attempting the problems in this chapter you are highly encouraged to read the\\nfollowing papers [ 1, 3, 7]. In many DL job interviews, you will be presented with a\\npaper you have never seen before and subsequently be asked questions about it; so\\nreading these references would be an excellent simulation of this real-life task.\\n206Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-157 \\uf059 CH.PRB- 7.1.\\nTrue or False: While AlexNet [ 4] used 11 × 11 sized ﬁlters, the main novelty presented\\nin the VGG [ 8] architecture was utilizing ﬁlters with much smaller spatial extent, sized\\n3 × 3.\\nPRB-158 \\uf059 CH.PRB- 7.2.\\nTrue or False : Unlike CNN architectures such as AlexNet or VGG, ResNet does not\\nhave any hidden FC layers.\\nPRB-159 \\uf059 CH.PRB- 7.3.\\nAssuming the VGG-Net has 138, 357, 544 ﬂoating point parameters, what is the phys-\\nical size in Mega-Bytes (MB) required for persisting a trained instance of VGG-Net on\\npermanent storage?\\nPRB-160 \\uf059 CH.PRB- 7.4.\\nTrue or False : Most attempts at researching image representation using FE, focused\\nsolely on reusing the activations obtained from layers close to the output of the CNN, and\\nmore speciﬁcally the fully-connected layers.\\nPRB-161 \\uf059 CH.PRB- 7.5.\\nTrue or False: FE in the context of deep learning is particularly useful when the target\\nproblem does not include enough labeled data to successfully train CNN that generalizes\\nwell.\\nPRB-162 \\uf059 CH.PRB- 7.6.\\nWhy is a CNN trained on the ImageNet dataset [ 7] a good candidate for a source prob-\\nlem?\\nPRB-163 \\uf059 CH.PRB- 7.7.\\n2077.2. PROBLEMS\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of [...] layers.\\n2. It consists of [...] convolutional and 3 [...] layers.\\n3. The input image size is [...].\\n4. The number of input channels is [...].\\n5. Every image has it’s mean RGB value [subtracted / added].\\n6. Each convolutional layer has a [small/large] kernel sized [...].\\n7. The number of pixels for padding and stride is [...].\\n8. There are 5 [...] layers having a kernel size of [...] and a stride of [...] pixels.\\n9. For non-linearity a [rectiﬁed linear unit (ReLU [ 5])/sigmoid] is used.\\n10. The [...] FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of [...] features.\\n12. The last FC layer has only [...] features.\\n13. The last FC layer is terminated by a [...] activation layer.\\n14. Dropout [is / is not] being used between the FC layers.\\nPRB-164 \\uf059 CH.PRB- 7.8.\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture [ 8] for the classiﬁcation of pancreatic cancer. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with\\nit by utilizing the same logic. In Fig. ( 9.7) three different classes of pancreatic cancer are\\ndisplayed: A, B and C, curated from a dataset of 4K Whole Slide Images (WSI) labeled by\\na board certiﬁed pathologist. Y our task is to use FE to correctly classify the images in the\\ndataset.\\n208Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nFIGURE 7.3: A dataset of 4K histopathology WSI from three severity classes: A, B and C.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture [ 8]. As de-\\npicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters),\\nlearnable parameters (weights,biases), and FV size are presented.\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 7.1: Incomplete listing of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4K images from the dataset, how can\\nyou now classify the images into their respective categories?\\n2097.2. PROBLEMS\\nPRB-165 \\uf059 CH.PRB- 7.9.\\nStill referring to T able ( 9.3), a data scientist suggests using the output layer of the\\nVGG19 CNN as a ﬁxed FE. What is the main advantage of using this layer over using\\nfor instance, the f c7 layer? (Hint: think about an ensemble of feature extractors)\\nPRB-166 \\uf059 CH.PRB- 7.10.\\nStill referring to T able (9.3) and also to the code snippet in Fig. ( 7.4), which represents a\\nnew CNN derived from the VGG19 CNN:\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=[???])\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = [???]\\n11 self.classifier = torch.nn.Sequential([???])\\n12 self.num_feats = [???]\\n13\\n14 def forward(self, x):\\n15 f = self.features(x)\\n16 f = f.view(f.size(0), -1)\\n17 f = [???]\\n18 print (f.data.size())\\n19 return f\\nFIGURE 7.4: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n210Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. Complete line 6; what should be the value of pretrained ?\\n2. Complete line 10; what should be the value of self.features ?\\n3. Complete line 12; what should be the value of self.num_feats ?\\n4. Complete line 17; what should be the value of f ?\\nPRB-167 \\uf059 CH.PRB- 7.11.\\nWe are still referring to T able ( 9.3) and using the skeleton code provided in Fig. ( 7.5)\\nto derive a new CNN entitled ResNetBottom from the ResNet34 CNN, to extract a 512-\\ndimensional FV for a given input image. Complete the code as follows:\\n1. The value of self.features in line 7.\\n2. The forward method in line 11.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7\\n8 def forward(self, x):\\n9 x = [???]\\n10 x = x.view(x.size(0), -1)\\n11 return x\\nFIGURE 7.5: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\n2117.2. PROBLEMS\\nPRB-168 \\uf059 CH.PRB- 7.12.\\nStill referring to T able (9.3), the PyT orch based pseudo code snippet in Fig. (7.6) returns\\nthe 512-dimensional FV from the modiﬁed ResNet34 CNN, given a 3-channel RGB image\\nas an input.\\n1 import torchvision.models as models\\n2 from torchvision import transforms\\n3 ...\\n4\\n5 test_trans = transforms.Compose([\\n6 transforms.Resize(imgnet_size),\\n7 transforms.ToTensor(),\\n8 transforms.Normalize([0.485, 0.456, 0.406],\\n9 [0.229, 0.224, 0.225])])\\n10\\n11 def ResNet34FE(image, model):\\n12 f=None\\n13 image = test_trans(image)\\n14 image = Variable(image, requires_grad =False).cuda()\\n15 image= image.cuda()\\n16 f = model(image)\\n17 f = f.view(f.size(1), -1)\\n18 print (\"Size : {}\" .format(f.shape))\\n19 f = f.view(f.size(1),-1)\\n20 print (\"Size : {}\" .format(f.shape))\\n21 f =f.cpu().detach().numpy()[0]\\n22 print (\"Size : {}\" .format(f.shape))\\n23 return f\\nFIGURE 7.6: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\nAnswer the following questions regarding the code in Fig. ( 7.6):\\n212Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. What is the purpose of test_trans in line 5?\\n2. Why is the parameter requires_grad set to False in line 14?\\n3. What is the purpose of f.cpu() in line 23?\\n4. What is the purpose of detach() in line 23?\\n5. What is the purpose of numpy()[0] in line 23?\\n7.2.2 Fine-tuning CNNs\\nPRB-169 \\uf059 CH.PRB- 7.13.\\nDeﬁne the term ﬁne-tuning (FT) of an ImageNet pre-trained CNN .\\nPRB-170 \\uf059 CH.PRB- 7.14.\\nDescribe three different methods by which one can ﬁne-tune an ImageNet pre-trained\\nCNN.\\nPRB-171 \\uf059 CH.PRB- 7.15.\\nMelanoma is a lethal form of malignant skin cancer, frequently misdiagnosed as a benign\\nskin lesion or even left completely undiagnosed.\\nIn the United States alone, melanoma accounts for an estimated 6, 750 deaths per annum\\n[6]. With a 5-year survival rate of 98%, early diagnosis and treatment is now more likely\\nand possibly the most suitable means for melanoma related death reduction. Dermoscopy\\nimages, shown in Fig. ( 7.7) are widely used in the detection and diagnosis of skin lesions.\\nDermatologists, relying on personal experience, are involved in a laborious task of manually\\nsearching dermoscopy images for lesions.\\nTherefore, there is a very real need for automated analysis tools, providing assistance to\\nclinicians screening for skin metastases. In this question, you are tasked with addressing\\nsome of the fundamental issues DL researchers face when building deep learning pipelines.\\nAs suggested in [ 3], you are going to use ImageNet pre-trained CNN to resolve a classiﬁca-\\ntion task.\\n2137.2. PROBLEMS\\nFIGURE 7.7: Skin lesion categories. An exemplary visualization of melanoma.\\n1. Given that the skin lesions fall into seven distinct categories, and you are training us-\\ning cross-entropy loss, how should the classes be represented so that a typical PyT orch\\ntraining loop will successfully converge?\\n2. Suggest several data augmentation techniques to augment the data.\\n3. Write a code snippet in PyT orch to adapt the CNN so that it can predict 7 classes\\ninstead of the original source size of 1000.\\n4. In order to ﬁne tune our CNN, the (original) output layer with 1000 classes was\\nremoved and the CNN was adjusted so that the (new) classiﬁcation layer comprised\\nseven softmax neurons emitting posterior probabilities of class membership for each\\nlesion type.\\n7.2.3 Neural style transfer, NST\\nBefore attempting the problems in the section, you are strongly recommended to read\\nthe paper: “A Neural Algorithm of Artistic Style ” [2].\\nPRB-172 �',\n",
              " '.\\n1. Given that the skin lesions fall into seven distinct categories, and you are training us-\\ning cross-entropy loss, how should the classes be represented so that a typical PyT orch\\ntraining loop will successfully converge?\\n2. Suggest several data augmentation techniques to augment the data.\\n3. Write a code snippet in PyT orch to adapt the CNN so that it can predict 7 classes\\ninstead of the original source size of 1000.\\n4. In order to ﬁne tune our CNN, the (original) output layer with 1000 classes was\\nremoved and the CNN was adjusted so that the (new) classiﬁcation layer comprised\\nseven softmax neurons emitting posterior probabilities of class membership for each\\nlesion type.\\n7.2.3 Neural style transfer, NST\\nBefore attempting the problems in the section, you are strongly recommended to read\\nthe paper: “A Neural Algorithm of Artistic Style ” [2].\\nPRB-172 \\uf059 CH.PRB- 7.16.\\nBrieﬂy describe how neural style transfer (NST) [ 2] works.\\nPRB-173 \\uf059 CH.PRB- 7.17.\\nComplete the sentence : When using the VGG-19 CNN [ 8] for neural-style transfer,\\nthere different images are involved. Namely they are: [...], [...] and [...].\\n214Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-174 \\uf059 CH.PRB- 7.18.\\nRefer to Fig. 7.8 and answer the following questions:\\nFIGURE 7.8: Artistic style transfer using the style of Francis Picabia’s Udnie painting.\\n1. Which loss is being utilized during the training process?\\n2. Brieﬂy describe the use of activations in the training process.\\nPRB-175 \\uf059 CH.PRB- 7.19.\\nStill referring to Fig. 7.8:\\n1. How are the activations utilized in comparing the content of the content image to the\\ncontent of the combined image?.\\n2. How are the activations utilized in comparing the style of the content image to the\\n2157.3. SOLUTIONS\\nstyle of the combined image?.\\nPRB-176 \\uf059 CH.PRB- 7.20.\\nStill referring to Fig. 7.8. For a new style transfer algorithm, a data scientist extracts a\\nfeature vector from an image using a pre-trained ResNet34 CNN ( 7.9).\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.9: PyTorch declaration for a pre-trained ResNet34 CNN.\\nHe then deﬁnes the cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and :\\nv = {v1, v2, . . . , vN }\\nas:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures thecosine of the angle between\\nthe vectors irrespective of their magnitude. It is calculated as the dot product of two numeric\\nvectors, and is normalized by the product of the length of the vectors.\\nAnswer the following questions:\\n1. Deﬁne the term Gram matrix.\\n2. Explain in detail how vector similarity is utilised in the calculation of the Gram mat-\\nrix during the training of NST.\\n7.3 Solutions\\n7.3.1 CNN as Fixed Feature Extractor\\n216Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nSOL-157 \\uf14b CH.SOL- 7.1.\\nT rue. The increased depth in VGG-Net was made possible using smaller ﬁlters without\\nsubstantially increasing the number of learnable parameters. Albeit an unwanted side effect\\nof the usage of smaller ﬁlters is the increase in the number of ﬁlters per-layer. \\x04\\nSOL-158 \\uf14b CH.SOL- 7.2.\\nT rue. The ResNet architecture terminates with a global average pooling layer followed\\nby a K-way FC layer with a softmax activation function, where K is the number of classes\\n(ImageNet has 1000 classes). Therefore, the ResNet has no hidden FC layers. \\x04\\nSOL-159 \\uf14b CH.SOL- 7.3. Note that 1bit = 0.000000125 MB, therefore:\\n138, 357544 × 32 = 4427441408 bits = 553.430176 MB. (7.1)\\n\\x04\\nSOL-160 \\uf14b CH.SOL- 7.4.\\nT rue. There are dozens of published papers supporting this claim. Y ou are encouraged to\\nsearch them on Arxiv or Google Scholar. \\x04\\nSOL-161 \\uf14b CH.SOL- 7.5.\\nT rue. One of the major hurdles of training a medical AI system is the lack of annotated\\ndata. Therefore, extensive research is conducted to exploit ways for FE and transfer learning,\\ne.g., in the application of ImageNet trained CNNs, to target datasets in which labeled data is\\nscarce. \\x04\\nSOL-162 \\uf14b CH.SOL- 7.6.\\nThere are two main reasons why this is possible:\\n1. The huge number of images inside the ImageNet dataset ensures a CNN model that gen-\\neralizes to additional domains, like the histopathology domain, which is substantially\\ndifferent from the original domain the model was trained one (e.g., cats and dogs).\\n2177.3. SOLUTIONS\\n2. A massive array of disparate visual patterns is produced by an ImageNet trained CNN,\\nsince it consists of 1, 000 different groups.\\n\\x04\\nSOL-163 \\uf14b CH.SOL- 7.7.\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of 19 layers.\\n2. It consists of 5 convolutional and 3 FC layers.\\n3. The input image size is 244 , the default size most ImageNet trained CNNs work on.\\n4. The number of input channels is 3 .\\n5. Every image has its mean RGB value subtracted . (why?)\\n6. Each convolutional layer has a small kernel sized 3 × 3 . (why?)\\n7. The number of pixels for padding and stride is the same and equals 1 .\\n8. There are 5 convolutional layers having a kernel size of 2 × 2 and a stride of 2 pixels.\\n9. For non-linearity a rectiﬁed linear unit (ReLU [ 5]) is used.\\n10. The 3 FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of 4096 features.\\n12. The last FC layer has only 1000 features.\\n13. The last FC layer is terminated by a softmax activation layer.\\n14. Dropout is being used between the FC layers.\\n\\x04\\nSOL-164 \\uf14b CH.SOL- 7.8.\\n218Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. One or more layers of the VGG19 CNN are selected for extraction and a new CNN\\nis designed on top of it. Thus, during inference our target layers are extracted and\\nnot the original softmax layer. Subsequently, we iterate and run inference over all\\nthe images in our pancreatic cancer data-set, extract the features, and persist them to\\npermanent storage such as a solid-state drive (SSD) device. Ultimately, each image has\\na corresponding FV .\\n2. Regarding the VGG19 CNN, there are numerous ways of extracting and combining\\nfeatures from different layers. Of course, these different layers, e.g., the FC, conv4_3,\\nand fc7 layer may be combined together to form a larger feature vector. T o determine\\nwhich method works best, you shall have to experiment on your data-set; there is no way\\nof a-priory determining the optimal combination of layers. Here are several examples:\\n(a) Accessing the last FC layer resulting in a 1000-D FV . The output is the score for\\neach of the 1000 classes of the ImageNet data-set.\\n(b) Removing the last FC layer leaves the fc7 layer, resulting in a 4096-D FV .\\n(c) Directly accessing the conv4_3 layer results in a 512-D FV .\\n3. Once the FVs are extracted, we can train any linear classiﬁer such as an SVM or\\nsoftmax classiﬁer on the FV data-set, and not on the original images.\\n\\x04\\nSOL-165 \\uf14b CH.SOL- 7.9.\\nOne beneﬁt of using the FC layer is that other ImageNet CNNs can be used in tandem\\nwith the VGG19 to create an ensemble since they all produce the same 1000-D sized FV . \\x04\\nSOL-166 \\uf14b CH.SOL- 7.10. The full code is presented in Fig. ( 7.10).\\n2197.3. SOLUTIONS\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=True)\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = original_model.features\\n11 self.classifier = torch.nn.Sequential(\\n12 (*list(original_model.classifier.\\n13 children())[:-1]))\\n14 self.num_feats = 4096\\n15\\n16 def forward(self, x):\\n17 f = self.features(x)\\n18 f = f.view(f.size(0), -1) # (1, 4096) -> (4096,)\\n19 f = self.classifier(f)\\n20 print (f.data.size())\\n21 return f\\nFIGURE 7.10: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n1. The value of the parameter pretrained should be T rue in order to instruct PyT orch to\\nload an ImageNet trained weights.\\n2. The value of self.features should be original_model.features . This is because we like to\\nretain the layers of the original classiﬁer (original_model).\\n3. The value of self.num_feats should be 4096 . (Why?)\\n4. The value of f should be self.classiﬁer(f) since our newly created CNN has to be in-\\nvoked to generate the FV .\\n220Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n\\x04\\nSOL-167 \\uf14b CH.SOL- 7.11.\\n1. Line number 7 in Fig. ( 7.11) takes care of extracting the the correct 512-D FV .\\n2. Line number 11 in Fig. ( 7.11) extracts the correct 512-D FV by creating a sequential\\nmodule on top of the existing features.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7 def forward(self, x):\\n8 x = [???]\\n9 x = x.view(x.size(0), -1)\\n10 return x\\nFIGURE 7.11: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n\\x04\\nSOL-168 \\uf14b CH.SOL- 7.12.\\n1. T ransforms are incorporated into deep learning pipelines in order to apply one or more\\noperations on images which are represented as tensors. Different transforms are usu-\\nally utilized during training and inference. For instance, during training we can use a\\ntransform to augment our data-set, while during inference our transform may be lim-\\nited only to normalizing an image. PyT orch allows the use of transforms either during\\ntraining or inference. The purpose of test_trans in line 5 is to normalize the data.\\n2217.3. SOLUTIONS\\n2. The parameter requires_grad is set to False in line 14 since during inference the com-\\nputation of gradients is obsolete.\\n3. The purpose of f.cpu() in line 11 is to move a tensor that was allocated on the GPU\\nto the CPU. This may be required if we want to apply a CPU-based method from the\\nPython numpy package on a T ensor that does not live in the CPU.\\n4. detach() in line 23 returns a newly created tensor without affecting the current tensor.\\nIt also detaches the output from the current computational graph, hence no gradient is\\nbackpropagated for this speciﬁc variable.\\n5. The purpose of numpy()[0] in line 23 is to convert the variable (an array) to a numpy\\ncompatible variable and also to retrieve the ﬁrst element of the array.\\n\\x04\\n7.3.2 Fine-tuning CNNs\\nSOL-169 \\uf14b CH.SOL- 7.13.\\nThe term ﬁne-tuning (FT) of an ImageNet pre-trained CNN refers to the method by which\\none or more of the weights of the CNN are re-trained on a new target data-set, which may or\\nmay-not have similarities with the ImageNet data-set. \\x04\\nSOL-170 \\uf14b CH.SOL- 7.14. The three methods are as follows:\\n1. Replacing and re-training only the classiﬁer (usually the FC layer) of the ImageNet\\npre-trained CNN, on a target data-set.\\n2. FT all of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n3. FT part of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n\\x04\\nSOL-171 \\uf14b CH.SOL- 7.15.\\n222Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The categories have to be represented numerically. One such option is presented in Code\\n(7.1).\\n1 \\'MEL\\' : 0, \\'NV\\' : 1, \\'BCC\\' : 2, \\'AKIEC\\' : 3, \\'BKL\\' : 4, \\'DF\\' : 5,\\n\\'VASC\\' : 6↪→\\nCODE 7.1: The seven categories of skin lesions.\\n2. Several possible augmentations are presented in Code ( 7.2). It is usually, that by trial\\nand error one ﬁnds the best possible augmentation for a target data-set. However, meth-\\nods such as AutoAugment may render the manual selection of augmentations obsolete.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\n6 if brightness != 0:\\n7 self.transforms.append(PILBrightness())\\n8 if contrast != 0:\\n9 self.transforms.append(PILContrast())\\n10 if colorbalance != 0:\\n11 self.transforms.append(PILColorBalance())\\n12 if sharpness != 0:\\n13 self.transforms.append(PILSharpness())\\nCODE 7.2: Pseudeo code for augmentations.\\n3. In contrast to the ResNet CNN which ends by an FC layer, the ImageNet pre-trained\\nDPN CNN family, in this case the pretrainedmodels.dpn107, terminated by a Conv2d\\n2237.3. SOLUTIONS\\nlayer and hence must be adapted accordingly if one wishes to change the number fo\\nclasses from the 1000 (ImageNet) classes to our skin lession classiﬁcation problem (7\\nclasses). Line 7 in Code ( 7.3) demonstrated this idiom.\\n1 import torch\\n2 class Dpn107Finetune(nn.Module):\\n3 def __init__(self, num_classes: int, net_kwards):\\n4 super().__init__()\\n5 self.net = pretrainedmodels.dpn107(**net_kwards)\\n6 self.net.__name__= str (self.net)\\n7 self.net.classifier = torch.nn.Conv2d(2688,\\nnum_classes,kernel_size=1)↪→\\n8 print(self.net)\\nCODE 7.3: Change between 1000 classes to 7 classes for the ImageNet pre-trained DPN\\nCNN family .\\n\\x04\\n7.3.3 Neural style transfer\\nSOL-172 \\uf14b CH.SOL- 7.16.\\nThe images are: a content image, a style image and lastly a combined image. \\x04\\nSOL-173 \\uf14b CH.SOL- 7.17.\\nThe algorithm presented in the paper suggests how to combine the content a ﬁrst image\\nwith the style of a second image to generate a third, stylized image using CNNs.\\n\\x04\\nSOL-174 \\uf14b CH.SOL- 7.18.\\nThe answers are as follows:\\n224Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The training pipeline uses a combined loss which consists of a weighted average of the\\nstyle loss and the content loss.\\n2. Different CNN layers at different levels are utilized to capture both ﬁne-grained styl-\\nistic details as well as larger stylistic features.\\n\\x04\\nSOL-175 \\uf14b CH.SOL- 7.19.\\n1. The content loss is the mean square error (MSE) calculated as the difference between\\nthe CNN activations of the last convolutional layer of both the content image and the\\nstyle images.\\n2. The style loss amalgamates the losses of several layers together. For each layer, the gram\\nmatrix (see 7.2) for the activations at that layer is obtained for both the style and the\\ncombined images. Then, just like in the content loss, the MSE of the Gram matrices is\\ncalculated.\\n\\x04\\nSOL-176 \\uf14b CH.SOL- 7.20.\\nFor each feature map, a feature vector is extracted. The gram matrix captures the correl-\\nation between these feature vectors which is then being used in the loss function. Provided a\\nlist of feature vectors extracted from the images, u1, . . . , uk ∈ Rn, the Gram matrix is deﬁned\\nas: \\uf8eb\\n\\uf8ec\\uf8ec\\uf8ec\\uf8ed\\nu1 · u1 . . . u 1 · uk\\n... . . . ...\\nuk · u1 . . . u k · uk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f7\\uf8f8 (7.2)\\nThe Gram matrix \\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 206).\\n225REFERENCES\\n[2] L. A. Gatys, A. S. Ecker and M. Bethge. A Neural Algorithm of Artistic Style . 2015.\\narXiv: 1508.06576 [cs.CV] (cit. on p. 214).\\n[3] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on pp. 206, 213).\\n[4] A. Krizhevsky. One weird trick for parallelizing convolutional neural networks . 2014.\\narXiv: 1404.5997 [cs.NE] (cit. on p. 207).\\n[5] V . Nair and G. E. Hinton. ‘Rectiﬁed Linear Units Improve Restricted Boltzmann\\nMachines’. In: ICML 10 . Madison, WI, USA: Omnipress, 2010, pp. 807–814 (cit.\\non pp. 208, 218).\\n[6] A. J. R. L. Siegel K. D. Miller. ‘Cancer statistics 2016’. In: CA: a cancer journal for\\nclinicians 66,1 (2016), pp. 7–30 (cit. on p. 213).\\n[7] Russakovsky. ‘ImageNet Large Scale Visual Recognition Challenge’. In: Journal\\nof Computer Vision 115.3 (Apr. 2015), pp. 211–252 (cit. on pp. 206, 207).\\n[8] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 207–209, 214).\\n226CHAPTER\\n8\\nDEEP LEARNING\\nIt is the weight, not numbers of experiments that is to be regarded.\\n— Isaac Newton.\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 234\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 235\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 236\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 239\\nConvolution and correlation in python . . . . . . . . . . . . . . 240\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 241\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 244\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 246The Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 247\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 248\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 249\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 251\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 251\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 253\\nSigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 260\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 268\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 273\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 274\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 276\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 280\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 283\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 284\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\n228Chapter 8 DEEP LEARNING\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 286\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 291\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 291\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 292\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 293\\nConvolution and correlation in python . . . . . . . . . . . . . . 294\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 295\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 297\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 299\\nThe Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 300\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 301\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 301\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 304\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 305\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 306\\n229Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 318\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 324\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 324\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 326\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 326\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 327\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 328\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 329\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 331\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333\\n230Chapter 8 DEEP LEARNING\\n8.1 Introduction\\nI\\nT was Alex Krizhevsky who ﬁrst demonstrated that a convolutional neural\\nnetwork (CNN) can be effectively trained on the ImageNet large scale visual\\nrecognition challenge. A CNN automatically provides some degree of trans-\\nlation and assumes that we wish to learn ﬁlters, in a data-driven fashion, as\\na means to extract features describing the inputs. CNNs are applied to numerous com-\\nputer vision, imaging, and computer graphics tasks as in [ 24], [ 23], [ 15], [ 5]. Further-\\nmore, they have become extremely popular, and novel architectures and algorithms\\nare continually popping up overnight.\\n8.2 Problems\\n8.2.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nPRB-177 \\uf059 CH.PRB- 8.1.\\nFig (8.1) depicts two different cross-validation approaches. Name them.\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\nTRAIN VAL\\nFIGURE 8.1: Two CV approaches\\n2318.2. PROBLEMS\\nPRB-178 \\uf059 CH.PRB- 8.2.\\n1. What is the purpose of the following Python code snippet 8.2 ?\\n1 skf = StratifiedKFold(y, n_folds =5, random_state =989,\\nshuffle=True)↪→\\nFIGURE 8.2: Stratiﬁed K-fold\\n2. Explain the beneﬁts of using the K-fold cross validation approach.\\n3. Explain the beneﬁts of using the Stratiﬁed K-fold cross validation approach.\\n4. State the difference between K-fold cross validation and stratiﬁed cross validation.\\n5. Explain in your own words what is meant by “We adopted a 5-fold cross-validation\\napproach to estimate the testing error of the model”.\\nK-Fold CV\\nPRB-179 \\uf059 CH.PRB- 8.3.\\nT rue or False: In a K-fold CV approach, the testing set is completely excluded from the\\nprocess and only the training and validation sets are involved in this approach.\\nPRB-180 \\uf059 CH.PRB- 8.4.\\nT rue or False: In a K-fold CV approach, the ﬁnal test error is:\\nCV (k) = 1\\nk\\nk∑\\ni=1\\nMSEi (8.1)\\n232Chapter 8 DEEP LEARNING\\nPRB-181 \\uf059 CH.PRB- 8.5.\\nMark all the correct choices regarding a cross-validation approach:\\n(i) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted.\\n(ii) A 5-fold cross-validation approach results in 1 model instance being ﬁtted over and\\nover again 5 times.\\n(iii) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted\\nover and over again 5 times.\\n(iv) Uses K-different data-folds.\\nPRB-182 \\uf059 CH.PRB- 8.6.\\nMark all the correct choices regarding the approach that should be taken to compute the\\nperformance of K-fold cross-validation:\\n(i) We compute the cross-validation performance as the arithmetic mean over the K per-\\nformance estimates from the validation sets.\\n(ii) We compute the cross-validation performance as the best one over the K performance\\nestimates from the validation sets.\\nStratification\\nPRB-183 \\uf059 CH.PRB- 8.7.\\nA data-scientist who is interested in classifying cross sections of histopathology image\\nslices (8.3) decides to adopt a cross-validation approach he once read about in a book. Name\\nthe approach from the following options:\\n2338.2. PROBLEMS\\n1st\\n2nd\\n3rd\\nK-fold CV\\nVAL FOLD TRAIN FOLD\\nFIGURE 8.3: A speciﬁc CV approach\\n(i) 3-fold CV\\n(ii) 3-fold CV with stratiﬁcation\\n(iii) A (repeated) 3-fold CV\\nLOOCV\\nPRB-184 \\uf059 CH.PRB- 8.8.\\n1. T rue or false: The leave-one-out cross-validation (LOOCV) approach is a sub-case of\\nk-fold cross-validation wherein K equals N , the sample size.\\n2. T rue or false: It is always possible to ﬁnd an optimal value n, K = n in K-fold\\ncross-validation.\\n8.2.2 Convolution and correlation\\nThe convolution operator\\nPRB-185 \\uf059 CH.PRB- 8.9.\\nEquation 8.2 is commonly used in image processing:\\n(f ∗ g)(t) =\\n∫ ∞\\n−∞\\nf (τ )g(t − τ )dτ (8.2)\\n234Chapter 8 DEEP LEARNING\\n1. What does equation 8.2 represent?\\n2. What does g(t) represent?\\nPRB-186 \\uf059 CH.PRB- 8.10.\\nA data-scientist assumes that:\\ni A convolution operation is both linear and shift invariant.\\nii A convolution operation is just like correlation, except that we ﬂip over the ﬁlter before\\napplying the correlation operator.\\niii The convolution operation reaches a maximum, only in cases where the ﬁlter is mostly\\nsimilar to a speciﬁc section of the input signal.\\nIs he right in assuming so? Explain in detail the meaning of these statements.\\nThe correlation operator\\nPRB-187 \\uf059 CH.PRB- 8.11.\\nMark the correct choice(s):\\n1. The cross-correlation operator is used to ﬁnd the location where two different signals\\nare most similar.\\n2. The autocorrelation operator is used to ﬁnd when a signal is similar to a delayed ver-\\nsion of itself.\\nPRB-188 \\uf059 CH.PRB- 8.12.\\nA data-scientist provides you with a formulae for a discrete 2D convolution operation\\n(8.3):\\nf (x, y) ∗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf (m, n)h(x − m, y − n) (8.3)\\n2358.2. PROBLEMS\\nUsing only (8.3), write the equivalent 2D correlation operation.\\nPadding and stride\\nRecommended reading : “A guide to convolution arithmetic for deep learning ” by Vincent\\nDumoulin and Francesco Visin (2016) [ 22].\\nPRB-189 \\uf059 CH.PRB- 8.13.\\nWhen designing a convolutional neural network layer, one must also deﬁne how the ﬁlter\\nor kernel slides through the input signal. This is controlled by what is known as the stride\\nand padding parameters or modes. The two most commonly used padding approached in\\nconvolutions are the V ALIDand the SAME modes. Given an input stride of 1:\\n1. Deﬁne SAME\\n2. Deﬁne V ALID\\nPRB-190 \\uf059 CH.PRB- 8.14.\\nTrue or False: A valid convolution is a type of convolution operation that does not use\\nany padding on the input.\\nPRB-191 \\uf059 CH.PRB- 8.15.\\nY ou are provided with aK × K input signal and a θ × θ ﬁlter. The signal is subjected to\\nthe valid padding mode convolution. What are the resulting dimensions?\\narr = [\\n0 ... 0\\n0 ... 0\\n0 ... 0\\n] (8.4)\\nPRB-192 \\uf059 CH.PRB- 8.16.\\nAs depicted in ( 8.4), a ﬁlter is applied to a ×3 input signal. Identify the correct choice\\ngiven a stride of 1 and Same padding mode.\\n236Chapter 8 DEEP LEARNING\\nFIGURE 8.4: A padding approach\\n',\n",
              " ' V ALID\\nPRB-190 \\uf059 CH.PRB- 8.14.\\nTrue or False: A valid convolution is a type of convolution operation that does not use\\nany padding on the input.\\nPRB-191 \\uf059 CH.PRB- 8.15.\\nY ou are provided with aK × K input signal and a θ × θ ﬁlter. The signal is subjected to\\nthe valid padding mode convolution. What are the resulting dimensions?\\narr = [\\n0 ... 0\\n0 ... 0\\n0 ... 0\\n] (8.4)\\nPRB-192 \\uf059 CH.PRB- 8.16.\\nAs depicted in ( 8.4), a ﬁlter is applied to a ×3 input signal. Identify the correct choice\\ngiven a stride of 1 and Same padding mode.\\n236Chapter 8 DEEP LEARNING\\nFIGURE 8.4: A padding approach\\nPRB-193 \\uf059 CH.PRB- 8.17.\\nAs depicted in in ( 8.5), a ﬁlter is applied to a 3 × 3 input signal, mark the correct choices\\ngiven a stride of 1.\\n(i) A represents a V ALID convolution and B represents a SAME convolution\\n(ii) A represents a SAME convolution and B represents a V ALID convolution\\n(iii) Both A and B represent a V ALID convolution\\n(iv) Both A and B represent a SAME convolution\\n2378.2. PROBLEMS\\nFIGURE 8.5: A padding approach\\nPRB-194 \\uf059 CH.PRB- 8.18.\\nIn this question we discuss the two most commonly used padding approaches in convo-\\nlutions; V ALIDand SAME . Fig.8.6 presents python code for generating an input signal\\narr001 and a convolution kernel f ilter001. The input signal, arr001 is ﬁrst initialized to\\nall zeros as follows:\\narr001 = [\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n] (8.5)\\n1. Without actually executing the code, determine what would be the resulting shape of\\nthe convolve2d() operation.\\n2. Manually compute the result of convolving the input signal with the provided ﬁlter.\\n3. Elaborate why the size of the resulting convolutions is smaller than the size of the\\ninput signal.\\n238Chapter 8 DEEP LEARNING\\n1 import numpy\\n2 import scipy.signal\\n3\\n4 arr01 = numpy.zeros((6, 6),dtype=float)\\n5 print (arr01)\\n6 arr01[:,:3] = 3.0\\n7 arr01[:,3:] = 1.0\\n8\\n9 filter001 = numpy.zeros((3, 3), dtype =float)\\n10 filter001[:,0] = 2.0\\n11 filter001[:,2] = -2.0\\n12\\n13 output = scipy.signal.convolve2d(arr01, filter, mode =\\'valid\\' )\\nFIGURE 8.6: Convolution and correlation in python\\nKernels and filters\\nPRB-195 \\uf059 CH.PRB- 8.19.\\nEquation 8.6 is the discrete equivalent of equation 8.2 which is frequently used in image\\nprocessing:\\n(y ∗ k)[i, j] =\\n∑\\nn\\n∑\\nm\\ny[i − n, j − m]k[n, m] (8.6)\\n1. Given the following discrete kernel in the X direction, what would be the equivalent Y\\ndirection?\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 1\\n−1 1\\n\\uf8f9\\n\\uf8fb (8.7)\\n2. Identify the discrete convolution kernel presented in ( 8.7).\\n2398.2. PROBLEMS\\nFIGURE 8.7: A 3 by 3 convolution kernel\\nPRB-196 \\uf059 CH.PRB- 8.20.\\nGiven an image of size w × h, and a kernel with width K, how many multiplications and\\nadditions are required to convolve the image?\\nConvolution and correlation in python\\nPRB-197 \\uf059 CH.PRB- 8.21.\\nFig.8.8 presents two built-in Python functions for the convolution and correlation oper-\\nators.\\n1 import nympy as np\\n2 np.convolve(A,B,\"full\") # for convolution\\n3 np.correlate(A,B,\"full\") # for cross correlation\\nFIGURE 8.8: Convolution and correlation in python\\n1. Implement the convolution operation from scratch in Python. Compare it with the\\n240Chapter 8 DEEP LEARNING\\nbuilt-in numpy equivalent.\\n2. Implement the correlation operation using the implementation of the convolution op-\\neration. Compare it with the built-in numpy equivalent.\\nSeparable convolutions\\nPRB-198 \\uf059 CH.PRB- 8.22.\\nThe Gaussian distribution in the 1D and 2D is shown in Equations 8.8 and 8.9.\\nG(x) = 1√\\n2πσ e− x2\\n2σ2 (8.8)\\nG(x, y) = 1\\n2πσ 2 e− x2+y2\\n2σ2 (8.9)\\nThe Gaussian ﬁlter, is an operator that is used to blur images and remove detail and\\nnoise while acting like a low-pass ﬁlter. This is similar to the way a mean ﬁlter works, but\\nthe Gaussian ﬁlter uses a different kernel. This kernel is represented with a Gaussian bell\\nshaped bump.\\nAnswer the following questions:\\n1. Can 8.8 be used directly on a 2D image?\\n2. Can 8.9 be used directly on a 2D image?\\n3. Is the Gaussian ﬁlter separable? if so, what are the advantages of separable ﬁlters.\\n8.2.3 Similarity measures\\nImage, text similarity\\nPRB-199 \\uf059 CH.PRB- 8.23.\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n2418.2. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 8.9: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\n1 void xxx(std::vector<float>& arr) {\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nAn unknown algorithm in C++11\\nFIGURE 8.10: listing\\nWhich results in this vector ( 8.11):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 8.11: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n242Chapter 8 DEEP LEARNING\\nPRB-200 \\uf059 CH.PRB- 8.24.\\nFurther to the above, the scientist then applies the following algorithm:\\nAlgorithm 3: Algo 1\\nData: Two vectors v1 and v2 are provided\\nApply algorithm xxx on the two vectors\\nRun algorithm 2\\nAlgorithm 4: Algo 2\\n1 float algo2(const std::vector<float>& v1, const\\nstd::vector<float>& v2){↪→\\n2 double mul = 0;\\n3 for (size_t i = 0; i < v1.size(); ++i){\\n4 mul += v1[i] * v2[i];\\n5 }\\n6 if (mul < 0) {\\n7 return 0;\\n8 }\\n9 return mul;\\n10 }\\nFIGURE 8.12: An unknown algorithm\\n1. Name the algorithm algo2 that he used and explain in detail what he used it for.\\n2. Write the mathematical formulae behind it.\\n3. What are the minimum and maximum values it can return?\\n4. An alternative similarity measures between two vectors is:\\nsimeuc(v1, v2) = −||v1 − v2||. (8.10)\\nName the measure.\\n2438.2. PROBLEMS\\nJacard similarity\\nPRB-201 \\uf059 CH.PRB- 8.25.\\n1. What is the formulae for the Jaccard similarity [ 12] of two sets?:\\n2. Explain the formulae in plain words.\\n3. Find the Jacard similarity given the sets depicted in ( 8.13)\\nFIGURE 8.13: Jaccard similarity .\\n4. Compute the Jaccard similarity of each pair of the following sets:\\ni 12, 14, 16, 18.\\nii 11, 12, 13, 14, 15.\\niii 11, 16, 17.\\nThe Kullback-Leibler Distance\\nPRB-202 \\uf059 CH.PRB- 8.26.\\nIn this problem, you have to actually read 4 different papers, so you will probably not\\nencounter such a question during an interview, however reading academic papers is an ex-\\ncellent skill to master for becoming a DL researcher.\\nRead the following papers which discuss aspects of the Kullback-Leibler divergence:\\ni Bennet [2]\\n244Chapter 8 DEEP LEARNING\\nii Ziv [29]\\niii Bigi [3]\\niv Jensen [1]\\nThe Kullback-Leibler divergence, which was discussed thoroughly in chap 4 is a meas-\\nure of how different two probability distribution are. As noted, the KL divergence of the\\nprobability distributions P , Q on a set X is deﬁned as shown in Equation 8.11.\\nDKL(P ||Q) =\\n∑\\nx∈X\\nP (x)log P (x)\\nQ(x) (8.11)\\nNote however that since KL divergence is a non-symmetric information theoretical meas-\\nure of distance of P from Q, then it is not strictly a distance metric. During the past years,\\nvarious KL based distance measures (rather than divergence based) have been introduced in\\nthe literature generalizing this measure.\\nName each of the following KL based distances:\\nDKLD 1(P ||Q) = DKL(P ||Q) + DKL(Q||P ) (8.12)\\nDKLD 2(P ||Q) =\\n∑\\nx∈X\\n(P (x) − Q(x))log P (x)\\nQ(x) (8.13)\\nDKLD 3(P ||Q) = 1\\n2\\n[\\nDKL\\n(\\nP ||P + Q\\n2\\n)\\n+ DKL\\n(\\nQ||P + Q\\n2\\n)]\\n(8.14)\\nDKLD 4(P ||Q) = max (DKL(P ||Q) + DKL(Q||P )) (8.15)\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nPRB-203 \\uf059 CH.PRB- 8.27.\\nWhat is the goal of hashing? Draw a simple HashMap of keys and values. Explain what\\nis a collision and the notion of buckets. Explain what is the goal of MinHash.\\n2458.2. PROBLEMS\\nPRB-204 \\uf059 CH.PRB- 8.28.\\nWhat is Locality Sensitive Hashing or LSH?\\nPRB-205 \\uf059 CH.PRB- 8.29.\\nComplete the sentence : LSH main goal is to [...] the probability of a colliding, for\\nsimilar items in a corpus.\\n8.2.4 Perceptrons\\nThe Single Layer Perceptron\\nPRB-206 \\uf059 CH.PRB- 8.30.\\n1. complete the sentence : In a single-layer feed-forward NN, there are [...] input(s)\\nand [...]. output layer(s) and no [...] connections at all.\\nPRB-207 \\uf059 CH.PRB- 8.31.\\nIn its simplest form, a perceptron (8.16) accepts only a binary input and emits a binary\\noutput. The output, can be evaluated as follows:\\noutput =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0, if ∑\\nj wjxj + b ≤ 0,\\n1, if\\n∑\\nj wjxj + b > 0\\n. (8.16)\\nWhere weights are denoted by wj and biases are denoted by b. Answer the following ques-\\ntions:\\n1. T rue or False: If such a perceptron is trained using a labelled corpus, for each parti-\\ncipating neuron the values wj and b are learned automatically.\\n2. T rue or False: If we instead use a new perceptron (sigmoidial) deﬁned as follows:\\nσ(wx + b) (8.17)\\n246Chapter 8 DEEP LEARNING\\nwhere σ is the sigmoid function:\\nσ(z) = 1\\n1 + e−z . (8.18)\\nThen the new perceptron can process inputs ranging between 0 and 1 and emit output\\nranging between 0 and 1.\\n3. Write the cost function associated with the sigmoidial neuron.\\n4. If we want to train the perceptron in order to obtain the best possible weights and\\nbiases, which mathematical equation do we have to solve?\\n5. Complete the sentence: T o solve this mathematical equation, we have to apply [...]\\n6. What does the following equation stands for?\\n∇C = 1\\nn\\n∑\\nx\\n∇Cx (8.19)\\nWhere:\\nCx = 1\\n2∥y(x) − a(x, w, b)∥2 (8.20)\\n7. Complete the sentence: Due to the time-consuming nature of computing gradients for\\neach entry in the training corpus, modern DL libraries utilize a technique that gauges\\nthe gradient by ﬁrst randomly sampling a subset from the training corpus, and then\\naveraging only this subset in every epoch. This approach is known as [...]. The actual\\nnumber of randomly chosen samples in each epoch is termed [...]. The gradient itself\\nis obtained by an algorithm known as [...].\\nThe Multi Layer Perceptron\\nPRB-208 \\uf059 CH.PRB- 8.32.\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\n2478.2. PROBLEMS\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 8.14: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the value resulting from the application the sum operator?\\n3. Verify the correctness of your results using PyT orch.\\nActivation functions in perceptrons\\nPRB-209 \\uf059 CH.PRB- 8.33.\\nThe following questions refer to the MLP depicted in ( 8.15).\\n1. Further to the above, the ReLU non-linear activation function g(z) = max {0, z} is\\napplied ( 8.15) to the output of the linear transformation. What is the value of the\\noutput (out2) now?\\nx1\\nH1\\nx2\\ng(x1, x2)\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1 out2\\n0.001\\nInputs Hidden ActivationSum\\nFIGURE 8.15: Several nodes in a MLP .\\n248Chapter 8 DEEP LEARNING\\n2. Conﬁrm your manual calculation using PyT orch tensors.\\nBack-propagation in perceptrons\\nPRB-210 \\uf059 CH.PRB- 8.34.\\nY our co-worker, an postgraduate student at M.I.T, suggests using the following activa-\\ntion functions in a MLP . Which ones can never be back-propagated and why?\\ni\\nf (x) = |x| (8.21)\\nii\\nf (x) = x (8.22)\\niii\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx sin(1/x) if x ̸= 0\\n0 if x = 0\\n(8.23)\\niv\\nf (x) =\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f3\\nx2 x > 0\\n−x x < 0\\n0 x = 0\\n(8.24)\\nPRB-211 \\uf059 CH.PRB- 8.35.\\nY ou are provided with the following MLP as depicted in 8.16.\\n2498.2. PROBLEMS\\nθ0\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nγ2\\nFIGURE 8.16: A basic MLP\\nThe ReLU non-linear activation function g(z) = max {0, z} is applied to the hidden\\nlayers H1...H3 and the bias term equals 0.001.\\nAt a certain point in time it has the following values 8.17 all of which are belong to the\\ntype torch.F loatT ensor:\\n1 import torch\\n2 x= torch.tensor([0.9,0.7]) # Input\\n3 w= torch.tensor([\\n4 [-0.3,0.15],\\n5 [0.32,-0.91],\\n6 [0.37,0.47],\\n7 ]) # Weights\\n8 B= torch.tensor([0.002]) # Bias\\nFIGURE 8.17: MLP operations.\\n1. Using Python, calculate the output of the MLP at the hidden layers H1...H3.\\n2. Further to the above, you discover that at a certain point in time that the weights\\nbetween the hidden layers and the output layers γ1 have the following values:\\n1 w1= torch.tensor([\\n2 [0.15,-0.46,0.59],\\n3 [0.10,0.32,-0.79],\\n4 )\\n250Chapter 8 DEEP LEARNING\\nWhat is the value observed at the output nodes γ1..γ2?\\n3. Assume now that a Softmax activation is applied to the output. What are the resulting\\nvalues?\\n4. Assume now that a cross-entropy loss is applied to the output of the Softmax.\\nL = −\\n∑\\ni\\nˆyi log (yi) (8.25)\\nWhat are the resulting values?\\nThe theory of perceptrons\\nPRB-212 \\uf059 CH.PRB- 8.36. If someone is quoted saying:\\nMLP networks are universal function approximators.\\nWhat does he mean?\\nPRB-213 \\uf059 CH.PRB- 8.37.\\nT rue or False: the output of a perceptron is 0 or 1.\\nPRB-214 \\uf059 CH.PRB- 8.38.\\nT rue or False: A multi-layer perceptron falls under the category of supervised machine\\nlearning.\\nPRB-215 \\uf059 CH.PRB- 8.39.\\nT rue or False: The accuracy of a perceptron is calculated as the number of correctly\\nclassiﬁed samples divided by the total number of incorrectly classiﬁed samples.\\nLearning logical gates\\n2518.2. PROBLEMS\\nPRB-216 \\uf059 CH.PRB- 8.40.\\nThe following questions refer to the SLP depicted in ( 8.18). The weights in the SLP are\\nw1 = 1 and w2 = 1 respectively. There is a single hidden node, H1. The bias term, B1 equals\\n−2.5.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1 =\\n1\\nw2 =\\n1\\nout1\\n−2.5\\nInputs\\nHidden\\nSum\\nFIGURE 8.18: A single layer perceptron.\\n1. Assuming the inputs to the SLP in ( 8.18) are\\ni x1 = 0.0 and x2 = 0.0\\nii x1 = 0.0 and x2 = 1.0\\niii x1 = 1.0 and x2 = 0.0\\niv x1 = 1.0 and x2 = 1.0\\nWhat is the value resulting from the application the sum operator?\\n2. Repeat the above, assuming now that the bias term B1 was amended and equals −0.25.\\n3. Deﬁne what is the perceptron learning rule.\\n4. What was the most crucial difference between Rosenblatt’s original algorithm and\\nHinton’s fundamental papers of 1986:\\n“Learning representations by back-propagating errors ” [22]\\nand 2012:\\n“ImageNet Classiﬁcation with Deep Convolutional Neural Networks ” [18]?\\n5. The AND logic gate [ 7] is deﬁned by the following table ( 8.19):\\n252Chapter 8 DEEP LEARNING\\nx1 x2 y\\n1 1 1\\n1 0 0\\n0 1 0\\n0 0 0\\nFIGURE 8.19: Logical AND gate\\nCan a perceptron with only two inputs and a single output function as an AND logic\\ngate? If so, ﬁnd the weights and the threshold and demonstrate the correctness of your\\nanswer using a truth table.\\n8.2.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\nPRB-217 \\uf059 CH.PRB- 8.41.\\nThe Sigmoid sc(x) = 1\\n1+e−cx , also commonly known as the logistic function (Fig. 8.20),\\nis widely used in binary classiﬁcation and as a neuron activation function in artiﬁcial neural\\nnetworks. Typically, during the training of an ANN, a Sigmoid layer applies the Sigmoid\\nfunction to elements in the forward pass, while in the backward pass the chain rule is be-\\ning utilized as part of the backpropagation algorithm. In 8.20 the constant c was selected\\narbitrarily as 2 and 5 respectively.\\n2538.2. PROBLEMS\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−2x\\nσ(x) = 1\\n1+e−5x\\nσ(x) = 1\\n1+2−1.5x\\nFIGURE 8.20: Examples of two sigmoid functions and an approximation.\\nDigital hardware implementations of the sigmoid function do exist but they are expens-\\nive to compute and therefore several approximation methods were introduced by the research\\ncommunity. The method by [ 10] uses the following formulas to approximate the exponential\\nfunction:\\nex ≈ Ex(x) ≈ 21.44x (8.26)\\nBased on this formulation, one can calculate the sigmoid function as:\\nSigmoid (x) ≈ 1\\n1 + 2−1.44x ≈ 1\\n1 + 2−1.5x (8.27)\\n1. Code snippet 8.21 provides a pure C++ based (e.g. not using Autograd) implementa-\\ntion of the forward pass for the Sigmoid function. Implement the backward pass that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19] style tensors.\\n254Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001( const torch::Tensor & x ){\\n5 torch::Tensor sig = 1.0 / (1.0 + torch::exp(( -x)));\\n6 return sig;\\n7 }\\nFIGURE 8.21: Forward pass for the Sigmoid function using Libtorch\\n2. Code snippet 8.22 provides a skeleton for printing the values of the sigmoid and its\\nderivative for a range of values contained in the vector v. Complete the code (lines 7-8)\\nso that the values are printed.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 ...\\n8 ...\\n9 }\\n10 }\\n.\\nFIGURE 8.22: Evaluation of the sigmoid and its derivative using Libtorch\\n3. Manually derive the derivative of eq. 8.27, e.g:\\nd\\ndx\\n[ 1\\n1 + 2−1.5x\\n]\\n(8.28)\\n2558.2. PROBLEMS\\n4. Implement both the forward pass for the Sigmoid function approximation eq. 8.27 that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19].\\n5. Print the values of the Sigmoid function and the Sigmoid function approximation eq.\\n8.27 for the following vector:\\nv = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] (8.29)\\nTanh\\nPRB-218 \\uf059 CH.PRB- 8.42.\\nThe Hyperbolic tangent nonlinearity, or the tanh function (Fig. 8.23), is a widely used\\nneuron activation function in artiﬁcial neural networks:\\nftanh (x) = sinh(x)\\ncosh(x) = ex − e−x\\nex + e−x (8.30)\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−4,0\\n−2,0\\n2,0\\n4,0\\nx\\nyσ(x) = 4 ∗ tanh x\\n4\\nσ(x) = tanh x\\n4\\nFIGURE 8.23: Examples of two tanh functions.\\n1. Manually derive the derivative of the tanh function.\\n256Chapter 8 DEEP LEARNING\\n2. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n3. Use the PyT orch based torch.autograd.F unction class to write a custom Function\\nthat implements the forward and backward passes for the tanh function in Python.\\n4. Name the class T anhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\nPRB-219 \\uf059 CH.PRB- 8.43.\\nThe code snippet in 8.24 makes use of the tanh function.\\n1 import torch\\n2\\n3 nn001 = nn.Sequential(\\n4 nn.Linear(200, 512),\\n5 nn.Tanh(),\\n6 nn.Linear(512, 512),\\n7 nn.Tanh(),\\n8 nn.Linear(512, 10),\\n9 nn.LogSoftmax(dim=1)\\n10 )\\nFIGURE 8.24: A simple NN based on tanh in PyTorch.\\n1. What type of a neural network does nn001 in 8.24 represent?\\n2. How many hidden layers does the layer entitles nn001 have?\\nPRB-220 \\uf059 CH.PRB- 8.44.\\n2578.2. PROBLEMS\\nY our friend, a veteran of the DL community claims that MLPs based on tanh activation\\nfunction, have a symmetry around 0 and consequently cannot be saturated. Saturation, so\\nhe claims is a phenomenon typical of the top hidden layers in sigmoid based MLPs. Is he\\nright or wrong?\\nPRB-221 \\uf059 CH.PRB- 8.45.\\nIf we initialize the weights of a tanh based NN, which of the following approaches will\\nlead to the vanishing gradients problem?.\\ni Using the normal distribution, with parameter initialization method as suggested by\\nKaiming [14].\\nii Using the uniform distribution, with parameter initialization method as suggested by\\nXavier Glorot [9].\\niii Initialize all parameters to a constant zero value.\\nPRB-222 \\uf059 CH.PRB- 8.46.\\nY ou friend, who is experimenting with the tanh activation function designed a small\\nCNN with only one hidden layer and a linear output ( 8.25):\\nFIGURE 8.25: A small CNN composed of tanh blocks.\\nHe initialized all the weights and biases (biases not shown for brevity) to zero. What is\\nthe most signiﬁcant design ﬂaw in his architecture?\\nHint: think about back-propagation.\\nReLU\\nPRB-223 \\uf059 CH.PRB- 8.47.\\n258Chapter 8 DEEP LEARNING\\nThe rectiﬁed linear unit, or ReLU g(z) = max {0, z} is the default for many CNN archi-\\ntectures. It is deﬁned by the following function:\\nfReLU(x) = max(0 , x) (8.31)\\nOr:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.32)\\n1. In what sense is the ReLU better than traditional sigmoidal activation functions?\\nPRB-224 \\uf059 CH.PRB- 8.48.\\nY ou are experimenting with the ReLU activation function, and you design a small CNN\\n(8.26) which accepts an RGB image as an input. Each CNN kernel is denoted by w.\\nFIGURE 8.26: A small CNN composed of ReLU blocks.\\nWhat is the shape of the resulting tensor W ?\\nPRB-225 \\uf059 CH.PRB- 8.49.\\nName the following activation function where a ∈ (0, 1):\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx if x > 0\\nax otherwise\\n(8.33)\\nSwish\\n2598.2. PROBLEMS\\nPRB-226 \\uf059 CH.PRB- 8.50.\\nIn many interviews, you will be given a paper that you have never encountered before,\\nand be required to read and subsequently discuss it. Please read Searching for Activation\\nFunctions [21] before attempting the questions in this question.\\n1. In [21], researchers employed an automatic pipeline for searching what exactly?\\n2. What types of functions did the researchers include in their search space?\\n3. What were the main ﬁndings of their research and why were the results surprising?\\n4. Write the formulae for the Swish activation function.\\n5. Plot the Swish activation function.\\n8.2.6 Performance Metrics\\nComparing different machine learning models, tuning hyper parameters and learn-\\ning rates, ﬁnding optimal augmentations, are all important steps in ML research. Typ-\\nically our goal is to ﬁnd the best model with the lowest errors on both the training\\nand validation sets. To do so we need to be able to measure the performance of each\\napproach/model/parameter setting etc. and compare those measures. For valuable\\nreference, read: “Evaluating Learning Algorithms: A Classiﬁcation Perspective ” [22]\\nConfusion matrix, precision, recall\\nPRB-227 \\uf059 CH.PRB- 8.51.\\nY ou design a binary classiﬁer for detecting the presence of malfunctioning temperature\\nsensors. Non-malfunctioning (N) devices are the majority class in the training corpus. While\\nrunning inference on an unseen test-set, you discover that the Confusion Metrics (CM) has\\nthe following values 8.27:\\n260Chapter 8 DEEP LEARNING\\nPredicted\\nP N\\nActual P 12 7\\nN 24 1009\\nFIGURE 8.27: A confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices.\\n1. Find: TP , TN, FP , FN and correctly label the numbers in table 8.27.\\n2. What is the accuracy of the model?\\n3. What is the precision of the model?\\n4. What is the recall of the model?\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\nFIGURE 8.28: Receiver Operating Characteristic curve.\\n2618.2. PROBLEMS\\nPRB-228 \\uf059 CH.PRB- 8.52.\\nComplete the following sentences:\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween [...] and [...].\\n2. It is a plot of [...] vs. the [...]. In place of [...], one could also use [...] which are essen-\\ntially {1 - ‘true negatives’ }.\\n3. A typical ROC curve has a concave shape with [...] as the beginning and [...] as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely con-\\nfused and cannot at all distinguish between the two classes, has an AUC of [...] which\\nis the [...] line in an ROC curve plot.\\nPRB-229 \\uf059 CH.PRB- 8.53.\\nThe code 8.30 and Figure 8.29 are the output from running XGBOOST for a binary\\nclassiﬁcation task.\\nFIGURE 8.29: RUC AUC\\n262Chapter 8 DEEP LEARNING\\n1 XGBClassifier(base_score=0.5, colsample_bylevel =1,\\ncolsample_bytree=0.5,↪→\\n2 gamma=0.017, learning_rate =0.15, max_delta_step =0, max_depth =9,\\n3 min_child_weight=3, missing =None, n_estimators =1000, nthread =-1,\\n4 objective=\\'binary:logistic\\' , reg_alpha =0, reg_lambda =1,\\n5 scale_pos_weight=1, seed =0, silent =1,\\nsubsample=0.9)shape:(316200, 6)↪→\\n6\\n7 >ROC AUC: 0.984439608912\\n8 >LOG LOSS: 0.0421598347226\\nFIGURE 8.30: XGBOOST for binary classiﬁcation.\\nHow would you describe the results of the classiﬁcation?.\\n8.2.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nPRB-230 \\uf059 CH.PRB- 8.54.\\nGiven an input of size of n × n, ﬁlters of size f × f and a stride of s with padding of p,\\nwhat is the output dimension?\\nPRB-231 \\uf059 CH.PRB- 8.55.\\nReferring the code snippet in Fig. ( 8.31), answer the following questions regarding the\\nVGG11 architecture [25]:\\n2638.2. PROBLEMS\\n1 import torchvision\\n2 import torch\\n3 def main():\\n4 vgg11 = torchvision.models.vgg11(pretrained=True)\\n5 vgg_layers = vgg11.features\\n6 for param in vgg_layers.parameters():\\n7 param.requires_grad = False\\n8\\n9 example = [torch.rand(1, 3, 224, 224),\\n10 torch.rand(1, 3, 512, 512),\\n11 torch.rand(1, 3, 704, 1024)]\\n12 vgg11.eval()\\n13 for e in example:\\n14 out=vgg_layers(e)\\n15 print(out.shape)\\n16 if __name__ == \"__main__\":\\n17 main()^^I^^I\\nFIGURE 8.31: CNN arithmetics on the VGG11 CNN model.\\n1. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the VGG11 CNN to the respective input.\\n2. Choose the correct option. The last layer of the VGG11 architecture is:\\ni Conv2d\\nii MaxPool2d\\niii ReLU\\nPRB-232 \\uf059 CH.PRB- 8.56.\\nStill referring the code snippet in Fig. ( 8.31), and speciﬁcally to line 7, the code is\\namended so that the line is replaced by the line:\\nvgg_layers=vgg11.features[:3] .\\n264Chapter 8 DEEP LEARNING\\n1. What type of block is now represented by the new line? Print it using PyT orch.\\n2. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the block:\\nvgg_layers=vgg11.features[:3] to the respective input.\\nPRB-233 \\uf059 CH.PRB- 8.57.\\nT able (8.1) presents an incomplete listing of the of the VGG11 architecture [ 25]. As\\ndepicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters) are\\npresented.\\nLayer #Filters\\nconv4_3 512\\nfc6 4,096\\nfc7 4,096\\noutput 1,000\\nTABLE 8.1: Incomplete listing of the VGG11 architecture.\\nComplete the missing parts regarding the dimensions and arithmetics of the VGG11\\nCNN architecture:\\n1. The VGG11 architecture consists of [...] convolutional layers.\\n2. Each convolutional layer is followed by a [...] activation function, and ﬁve [...] opera-\\ntions thus reducing the preceding feature map size by a factor of [...].\\n3. All convolutional layers have a [...] kernel.\\n4. The ﬁrst convolutional layer produces [...] channels.\\n5. Subsequently as the network deepens, the number of channels [...] after each [...] oper-\\nation until it reaches [...].\\n2658.2. PROBLEMS\\nDropout\\nPRB-234 \\uf059 CH.PRB- 8.58.\\nA Dropout layer [26] (Fig. 8.32) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 8.32: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [20], a Dropout layer is declared as follows ( 8.2):\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 8.2: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 8.2) indicates that the probability of zeroing an\\nelement is 0.2.\\n266Chapter 8 DEEP LEARNING\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 8.33: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 8.32). Here, for illustration purposes, all four\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\n1. Y ou are interested in the proportionθ of dropped-out neurons. Assume that the chance\\nof drop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the\\nposterior of θ.\\n2. Describe the similarities of dropout to bagging.\\nPRB-235 \\uf059 CH.PRB- 8.59.\\nA co-worker claims he discovered an equivalence theorem where, two consecutive Dro-\\npout layers [26] can be replaced and represented by a single Dropout layer 8.34.\\nFIGURE 8.34: Two consecutive Dropout layers\\nHi realized two consecutive layers in PyT orch [20], declared as follows ( 8.3):\\n2678.2. PROBLEMS\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Sequential(\\n4 nn.Conv2d(1024, 32),\\n5 nn.ReLU(),\\n6 nn.Dropout(p=P, inplace =True),\\n7 nn.Dropout(p=Q, inplace =True)\\n8 )\\nCODE 8.3: Consequtive dropout in PyTorch\\nWhere nn.Dropout(0.1) (Line #6 in 8.3) indicates that the probability of zeroing an\\nelement is 0.1.\\n1. What do you think about his idea, is he right or wrong?\\n2. Either prove that he is right or provide a single example that refutes his theorem.\\nConvolutional Layer\\nThe convolution layer is probably one of the most important layers in the theory and\\npractice of modern deep learning and computer vision in particular.\\nTo study the optimal number of convolutional layers for the classiﬁcation of two\\ndifferent types of the Ebola virus, a researcher designs a binary classiﬁcation pipeline\\nusing a small CNN with only a few layers ( 8.35):\\n268Chapter 8 DEEP LEARNING\\nFIGURE 8.35: A CNN based classiﬁcation system.\\nAnswer the following questions while referring to ( 8.35):\\nPRB-236 \\uf059 CH.PRB- 8.60.\\nIf he uses the following ﬁlter for the convolutional operation, what would be the resulting\\ntensor after the application of the convolutional layer?\\nFIGURE 8.36: A small ﬁlter for a CNN\\nPRB-237 \\uf059 CH.PRB- 8.61.\\nWhat would be the resulting tensor after the application of the ReLU layer ( 8.37)?\\n2698.2. PROBLEMS\\nFIGURE 8.37: The result of applying the ﬁlter.\\nPRB-238 \\uf059 CH.PRB- 8.62.\\nWhat would be the resulting tensor after the application of the MaxPool layer ( 8.78)?\\nPooling Layers\\nA pooling layer transforms the output of a convolutional layer, and neurons in a pool-\\ning layer accept the outputs of a number of adjacent feature maps and merge their\\noutputs into a single number.\\nMaxPooling\\nPRB-239 \\uf059 CH.PRB- 8.63.\\nThe following input 8.38 is subjected to a MaxPool2D(2,2) operation having 2 × 2 max-\\npooling ﬁlter with a stride of 2 and no padding at all.\\n270Chapter 8 DEEP LEARNING\\nFIGURE 8.38: Input to MaxPool2d operation.\\nAnswer the following questions:\\n1. What is the most common use of max-pooling layers?\\n2. What is the result of applying the MaxPool2d operation on the input?\\nPRB-240 \\uf059 CH.PRB- 8.64.\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and evaluate its behaviour during inference:\\n2718.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 8.4: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n272Chapter 8 DEEP LEARNING\\nFIGURE 8.39: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist',\n",
              " '.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 8.4: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n272Chapter 8 DEEP LEARNING\\nFIGURE 8.39: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet a second MaxPool2D(2,2).\\nWhat is the resulting tensor shape after running line 9? and line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\nBatch normalization, Gaussian PDF\\nRecommended readings for this topic are “ Batch Normalization: Accelerating Deep Net-\\nwork T raining by Reducing Internal Covariate Shift ” [16] and “ Delving deep into rectiﬁers:\\nSurpassing human-level performance on imagenet classiﬁcation ” [14].\\nA discussion of batch normalization (BN) would not be complete without a discus-\\nsion of the Gaussian normal distribution. Though it would be instructive to develop\\nthe forward and backwards functions for a BN operation from scratch, it would also\\nbe quite complex. As an alternative we discuss several aspects of the BN operation\\nwhile expanding on the Gaussian distribution.\\n2738.2. PROBLEMS\\nThe Gaussian distribution\\nPRB-241 \\uf059 CH.PRB- 8.65.\\n1. What is batch normalization?\\n2. The normal distribution is deﬁned as follows:\\nP (x) = 1\\nσ\\n√\\n2π e−(x−µ)2/2σ2\\n(8.34)\\nGenerally i.i.d. X ∼ N (µ, σ2) however BN uses the standard normal distribution.\\nWhat mean and variance does the standard normal distribution have?\\n3. What is the mathematical process of normalization?\\n4. Describe, how normalization works in BN.\\nPRB-242 \\uf059 CH.PRB- 8.66.\\nIn python, the probability density function for a normal distribution is given by 8.40:\\n1 import scipy\\n2 scipy.stats.norm.pdf(x, mu, sigma)\\nFIGURE 8.40: Normal distribution in Python.\\n1. Without using Scipy, implement the normal distribution from scratch in Python.\\n2. Assume, you want to back propagate on the normal distribution, and therefore you\\nneed the derivative. Using Scipy write a function for the derivative.\\nBN\\nPRB-243 \\uf059 CH.PRB- 8.67.\\n274Chapter 8 DEEP LEARNING\\nY our friend, a novice data scientist, uses an RGB image ( 8.41) which he then subjects to\\nBN as part of training a CNN.\\nFIGURE 8.41: A convolution and BN applied to an RGB image.\\n1. Help him understand, during BN, is the normalization applied pixel-wise or per colour\\nchannel?\\n2. In the PyT orch implementation, he made a silly mistake 8.42, help him identify it:\\n2758.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class BNl001(nn.Module):\\n4 def __init__(self):\\n5 super(BNl001, self).__init__()\\n6 self.cnn = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 64, kernel_size =3, padding =2),\\n8 )\\n9 self.math= torch.nn.Sequential(\\n10 torch.nn.BatchNorm2d(32),\\n11 torch.nn.PReLU(),\\n12 torch.nn.Dropout2d(0.05)\\n13 )\\n14 def forward(self, x):\\n15 ...\\nFIGURE 8.42: A mistake in a CNN\\nTheory of CNN design\\nPRB-244 \\uf059 CH.PRB- 8.68.\\nTrue or false: An activation function applied after a Dropout, is equivalent to an activ-\\nation function applied before a dropout.\\nPRB-245 \\uf059 CH.PRB- 8.69.\\nWhich of the following core building blocks may be used to construct CNNs? Choose all\\nthe options that apply:\\ni Pooling layers\\nii Convolutional layers\\niii Normalization layers\\niv Non-linear activation function\\n276Chapter 8 DEEP LEARNING\\nv Linear activation function\\nPRB-246 \\uf059 CH.PRB- 8.70.\\nY ou are designing a CNN which has a single BN layer. Which of the following core CNN\\ndesigns are valid? Choose all the options that apply:\\ni CONV → act → BN → Dropout → . . .\\nii CONV → act → Dropout → BN → . . .\\niii CONV → BN → act → Dropout → . . .\\niv BN → CONV → act → Dropout → . . .\\nv CONV → Dropout → BN → act → . . .\\nvi Dropout → CONV → BN → act → . . .\\nPRB-247 \\uf059 CH.PRB- 8.71.\\nThe following operator is known as the Hadamard product:\\nOUT = A ⊙ B (8.35)\\nWhere:\\n(A ⊙ B)i,j := (A)i,j(B)i,j (8.36)\\nA scientist, constructs a Dropout layer using the following algorithm:\\ni Assign a probability of p for zeroing the output of any neuron.\\nii Accept an input tensor T , having a shape S\\niii Generate a new tensor T ‘∈ {0, 1}S\\niv Assign each element in T ‘a randomly and independently sampled value from a Bernoulli\\ndistribution:\\nT ‘i ∼ B(1, p) (8.37)\\n2778.2. PROBLEMS\\nv Calculate the OU T tensor as follows:\\nOUT = T ‘⊙ T (8.38)\\nY ou are surprised to ﬁnd out that his last step is to multiply the output of a dropout layer\\nwith:\\n1\\n1 − p (8.39)\\nExplain what is the purpose of multiplying by the term 1\\n1−p .\\nPRB-248 \\uf059 CH.PRB- 8.72.\\nVisualized in (8.43) from a high-level view, is an MLP which implements a well-known\\nidiom in DL.\\nFIGURE 8.43: A CNN block\\n1. Name the idiom.\\n2. What can this type of layer learn?\\n3. A fellow data scientist suggests amending the architecture as follows ( 8.44)\\n278Chapter 8 DEEP LEARNING\\nFIGURE 8.44: A CNN block\\nName one disadvantage of this new architecture.\\n4. Name one CNN architecture where the input equals the output.\\nCNN residual blocks\\nPRB-249 \\uf059 CH.PRB- 8.73.\\nAnswer the following questions regarding residual networks ([ 13]).\\n1. Mathematically, the residual block may be represented by:\\ny = x + F(x) (8.40)\\nWhat is the function F?\\n2. In one sentence, what was the main idea behind deep residual networks (ResNets) as\\nintroduced in the original paper ([ 13])?\\nPRB-250 \\uf059 CH.PRB- 8.74.\\nY our friend was thinking about ResNet blocks, and tried to visualize them in ( 8.45).\\n2798.2. PROBLEMS\\nFIGURE 8.45: A resnet CNN block\\n1. Assuming a residual of the form y = x + F(x), complete the missing parts in Fig.\\n(8.45).\\n2. What does the symbol ⊕ denotes?\\n3. A fellow data scientist, who had coffee with you said that residual blocks may compute\\nthe identity function. Explain what he meant by that.\\n8.2.8 Training, hyperparameters\\nHyperparameter optimization\\nPRB-251 \\uf059 CH.PRB- 8.75.\\nA certain training pipeline for the classiﬁcation of large images (1024 x 1024) uses the\\nfollowing Hyperparameters (8.46):\\n280Chapter 8 DEEP LEARNING\\nHyperparameter Value\\nInitial learning rate 0.1\\nWeight decay 0.0001\\nMomentum 0.9\\nBatch size 1024\\n1 optimizer = optim.SGD(model.parameters(), lr =0.1,\\n2 momentum=0.9,\\n3 weight_decay=0.0001)\\n4 ...\\n5 trainLoader = torch.utils.data.DataLoader(\\n6 datasets.LARGE(\\'../data\\' , train =True, download =True,\\n7 transform=transforms.Compose([\\n8 transforms.ToTensor(),\\n9 ])),\\n10 batch\\\\_size=1024, shuffle =True)\\nFIGURE 8.46: Hyperparameters.\\nIn your opinion, what could possibly go wrong with this training pipeline?\\nPRB-252 \\uf059 CH.PRB- 8.76.\\nA junior data scientist in your team who is interested in Hyperparameter tuning, wrote\\nthe following code ( 8.5) for spiting his corpus into two distinct sets and ﬁtting an LR model:\\n2818.2. PROBLEMS\\n1 from sklearn.model_selection import train_test_split\\n2 dataset = datasets.load_iris()\\n3 X_train, X_test, y_train, y_test =\\n4 train_test_split(dataset.data, dataset .target, test_size =0.2)\\n5 clf = LogisticRegression(data_norm=12)\\n6 clf.fit(X_train, y_train)\\nCODE 8.5: Train and Validation split.\\nHe then evaluated the performance of the trained model on the Xtest set.\\n1. Explain why his methodology is far from perfect.\\n2. Help him resolve the problem by utilizing a difference splitting methodology.\\n3. Y our friend now amends the code an uses:\\n1 clf = GridSearchCV(method, params, scoring =\\'roc_auc\\' , cv =5)\\n2 clf.fit(train_X, train_y)\\nExplain why his new approach may work better.\\nPRB-253 \\uf059 CH.PRB- 8.77.\\nIn the context of Hyperparameter optimization, explain the difference between grid search\\nand random search.\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nPRB-254 \\uf059 CH.PRB- 8.78.\\n282Chapter 8 DEEP LEARNING\\nNon-invasive methods that forecast the existence of lung nodules ( 8.47), is a precursor\\nto lung cancer. Y et, in spite of acquisition standardization attempts, the manual detection of\\nlung nodules still remains predisposed to inter mechanical and observer variability. What is\\nmore, it is a highly laborious task.\\nFIGURE 8.47: Pulmonary nodules.\\nIn the majority of cases, the training data is manually labelled by radiologists who make\\nmistakes. Imagine you are working on a classiﬁcation problem and hire two radiologists for\\nlung cancer screening based on low-dose CT (LDCT). Y ou ask them to label the data, the\\nﬁrst radiologist labels only the training set and the second the validation set. Then you hire\\na third radiologist to label the test set.\\n1. Do you think there is a design ﬂow in the curation of the data sets?\\n2. A friend suggests that all there radiologists read all the scans and label them independ-\\nently thus creating a majority vote. What do you think about this idea?\\nValidation curve ACC\\nPRB-255 \\uf059 CH.PRB- 8.79.\\nAnswer the following questions regarding the validation curve visualized in ( 8.48):\\n2838.2. PROBLEMS\\n20 40 60 80 100\\n0,2\\n0,4\\n0,6\\n0,8\\nEPOCH\\nERR V ALID\\nTRAIN\\nFIGURE 8.48: A validation curve.\\n1. Describe in one sentence, what is a validation curve.\\n2. Which hyperparameter is being used in the curve?\\n3. Which well-known metric is being used in the curve? Which other metric is commonly\\nused?\\n4. Which positive phenomena happens when we train a NN longer?\\n5. Which negative phenomena happens when we train a NN longer than we should?\\n6. How this negative phenomena is reﬂected in 8.48?\\nValidation curve Loss\\nPRB-256 \\uf059 CH.PRB- 8.80.\\nRefer to the validation log-loss curve visualized in ( 8.49) and answer the following ques-\\ntions:\\n284Chapter 8 DEEP LEARNING\\nFIGURE 8.49: Log-loss function curve.\\n1. Name the phenomena that starts happening right after the marking by the letter E and\\ndescribe why it is happening.\\n2. Name three different weight initialization methods.\\n3. What is the main idea behind these methods?\\n4. Describe several ways how this phenomena can be alleviated.\\n5. Y our friend, a fellow data-scientist, inspects the code and sees the following Hyper-\\nparameters are being used:\\nHyperparameter Value\\nInitial LR 0.00001\\nMomentum 0.9\\nBatch size 1024\\nHe then tells you that the learning rate (LR) is constant and suggests amending the\\ntraining pipeline by adding the following code ( 8.50):\\n2858.2. PROBLEMS\\n1 scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt)\\nFIGURE 8.50: A problem with the log-loss curve.\\nWhat do you think about his idea?\\n6. Provide one reason against the use of the log-loss curve.\\nInference\\nPRB-257 \\uf059 CH.PRB- 8.81.\\nY ou ﬁnished training a face recognition algorithm, which uses a feature vector of 128\\nelements. During inference, you notice that the performance is not that good. A friend tells\\nyou that in computer vision faces are gathered in various poses and perspectives. He there-\\nfore suggests that during inference you would augment the incoming face ﬁve times, run\\ninference on each augmented image and then fuse the output probability distributions by\\naveraging.\\n1. Name the method he is suggesting.\\n2. Provide several examples of augmentation that you might use during inference.\\nPRB-258 \\uf059 CH.PRB- 8.82.\\nComplete the sentence: If the training loss is insigniﬁcant while the test loss is signiﬁc-\\nantly higher, the network has almost certainly learned features which are not present in an\\n[...] set. This phenomena is referred to as [...]\\n8.2.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nPRB-259 \\uf059 CH.PRB- 8.83.\\nWhat does the term stochastic in SGD actually mean? Does it use any random number\\n286Chapter 8 DEEP LEARNING\\ngenerator?\\nPRB-260 \\uf059 CH.PRB- 8.84.\\nExplain why in SGD, the number of epochs required to surpass a certain loss threshold\\nincreases as the batch size decreases?\\nMomentum\\nPRB-261 \\uf059 CH.PRB- 8.85.\\nHow does momentum work? Explain the role of exponential decay in the gradient descent\\nupdate rule.\\nPRB-262 \\uf059 CH.PRB- 8.86.\\nIn your training loop, you are using SGD and a logistic activation function which is\\nknown to suffer from the phenomenon of saturated units.\\n1. Explain the phenomenon.\\n2. Y ou switch to using the tanh activation instead of the logistic activation, in your\\nopinion does the phenomenon still exists?\\n3. In your opinion, is using the tanh function makes the SGD operation to converge\\nbetter?\\nPRB-263 \\uf059 CH.PRB- 8.87.\\nWhich of the following statements holds true?\\ni In stochastic gradient descent we ﬁrst calculate the gradient and only then adjust weights\\nfor each data point in the training set.\\nii In stochastic gradient descent, the gradient for a single sample is not so different from\\nthe actual gradient, so this gives a more stable value, and converges faster.\\niii SGD usually avoids the trap of poor local minima.\\n2878.2. PROBLEMS\\niv SGD usually requires more memory.\\nNorms, L1, L2\\nPRB-264 \\uf059 CH.PRB- 8.88.\\nAnswer the following questions regarding norms.\\n1. Which norm does the following equation represent?\\n|x1 − x2| + |y1 − y2| (8.41)\\n2. Which formulae does the following equation represent?\\n\\ued6a\\ued6b\\ued6b√\\nn∑\\ni=1\\n(xi − yi)2 (8.42)\\n3. When your read that someone penalized the L2 norm, was the euclidean or the Man-\\nhattan distance involved?\\n4. Compute both the Euclidean and Manhattan distance of the vectors:\\nx1 = [6 , 1, 4, 5] and x2 = [2 , 8, 3, −1].\\nPRB-265 \\uf059 CH.PRB- 8.89.\\nY ou are provided with a pure Python code implementation of the Manhattan distance\\nfunction (8.51):\\n1 from scipy import spatial\\n2 x1=[6,1,4,5]\\n3 x2=[2,8,3,-1]\\n4 cityblock = spatial.distance.cityblock(x1, x2)\\n5 print(\"Manhattan:\", cityblock)\\nFIGURE 8.51: Manhattan distance function.\\n288Chapter 8 DEEP LEARNING\\nIn many cases, and for large vectors in particular, it is better to use a GPU for imple-\\nmenting numerical computations. PyT orch has full support for GPU’s (and its my favourite\\nDL library ... ), use it to implement the Manhattan distance function on a GPU.\\nPRB-266 \\uf059 CH.PRB- 8.90.\\nY our friend is training a logistic regression model for a binary classiﬁcation problem\\nusing the L2 loss for optimization. Explain to him why this is a bad choice and which loss he\\nshould be using instead.\\n8.3 Solutions\\n8.3.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nSOL-177 \\uf14b CH.SOL- 8.1.\\nThe ﬁrst approach is a leave-one-out CV (LOOCV) and the second is a K-fold cross-\\nvalidation approach. \\x04\\nSOL-178 \\uf14b CH.SOL- 8.2.\\nCross Validation is a cornerstone in machine learning, allowing data scientists to take\\nfull gain of restricted training data. In classiﬁcation, effective cross validation is essential to\\nmaking the learning task efﬁcient and more accurate. A frequently used form of the technique\\nis identiﬁed as K-fold cross validation. Using this approach, the full data set is divided into K\\nrandomly selected folds, occasionally stratiﬁed, meaning that each fold has roughly the\\nsame class distribution as the overall data set . Subsequently, for each fold, all the other\\n(K − 1) folds are used for training, while the present fold is used for testing. This process\\nguarantees that sets used for testing, are not used by a classiﬁer that also saw it during\\ntraining.\\n\\x04\\nK-Fold CV\\n2898.3. SOLUTIONS\\nSOL-179 \\uf14b CH.SOL- 8.3.\\nT rue. We never utilize the test set during a K-fold CV process. \\x04\\nSOL-180 \\uf14b CH.SOL- 8.4.\\nT rue. This is the average of the individual errors of K estimates of the test error:\\nMSE1, . . . ,MSEk (8.43)\\n\\x04\\nSOL-181 \\uf14b CH.SOL- 8.5.\\nThe correct answer is: A 5-fold cross-validation approach results in 5-different model in-\\nstances being ﬁtted. It is a common misconception to think that in a K-fold approach the same\\nmodel instance is repeatedly used. We must create a new model instance in each fold. \\x04\\nSOL-182 \\uf14b CH.SOL- 8.6.\\nThe correct answer is: we compute the cross-validation performance as the arithmetic\\nmean over the K performance estimates from the validation sets. \\x04\\nStratification\\nSOL-183 \\uf14b CH.SOL- 8.7.\\nThe correct answer is: 3-fold CV . A k-fold cross-validation is a special case of cross-\\nvalidation where we iterate over a dataset set k times. In each round, we split the dataset\\ninto k parts: one part is used for validation, and the remaining k − 1 parts are merged into\\na training subset for model evaluation. Stratiﬁcation is used to balance the classes in the\\ntraining and validation splits in cases where the corpus is imbalanced. \\x04\\nLOOCV\\nSOL-184 \\uf14b CH.SOL- 8.8.\\n1. T rue: In (LOOCV) K = N the full sample size.\\n2. False: There is no way of a-priori ﬁnding an optimal value for K, and the relationship\\n290Chapter 8 DEEP LEARNING\\nbetween the actual sample size and the resulting accuracy is unknown.\\n\\x04\\n8.3.2 Convolution and correlation\\nThe convolution operator\\nSOL-185 \\uf14b CH.SOL- 8.9.\\n1. This is the deﬁnition of a convolution operation on the two signals f and g.\\n2. In image processing, the term g(t) represents a ﬁltering kernel.\\n\\x04\\nSOL-186 \\uf14b CH.SOL- 8.10.\\n1. T rue. These operations have two key features: they are shift invariant, and they are\\nlinear. Shift invariance means that we perform the same operation at every point in the\\nimage. Linearity means that this operation is linear, that is, we replace every pixel with\\na linear combination of its neighbours\\n2. T rue. See for instance Eq. (8.3).\\n3. T rue.\\n\\x04\\nThe correlation operator\\nSOL-187 \\uf14b CH.SOL- 8.11.\\n1. T rue.\\n2. T rue.\\n\\x04\\n2918.3. SOLUTIONS\\nSOL-188 \\uf14b CH.SOL- 8.12.\\nA convolution operation is just like correlation, except that we ﬂip over the ﬁlter both\\nhorizontally and vertically before correlating.\\nf (x, y) ⊗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf ∗(m, n)h(x + m, y + n) (8.44)\\n\\x04\\nPadding and stride\\nRecommended reading : “ A guide to convolution arithmetic for deep learning by Vincent\\nDumoulin and Francesco Visin (2016) ” [22].\\nSOL-189 \\uf14b CH.SOL- 8.13.\\n1. The Valid padding only uses values from the original input; however, when the data\\nresolution is not a multiple of the stride, some boundary values are ignored entirely in\\nthe feature calculation.\\n2. The Same padding ensures that every input value is included, but also adds zeros near\\nthe boundary which are not in the original input.\\n\\x04\\nSOL-190 \\uf14b CH.SOL- 8.14.\\nT rue. Contrast this with the two other types of convolution operations. \\x04\\nSOL-191 \\uf14b CH.SOL- 8.15.\\n⌊\\nK − θ\\nθ\\n⌋\\n+ 1 ×\\n⌊\\nn − θ\\nθ\\n⌋\\n+ 1 (8.45)\\n\\x04\\nSOL-192 \\uf14b CH.SOL- 8.16.\\n292Chapter 8 DEEP LEARNING\\nA is the correct choice. \\x04\\nSOL-193 \\uf14b CH.SOL- 8.17.\\nA represents the V ALID mode while B represents the SAME mode. \\x04\\nSOL-194 \\uf14b CH.SOL- 8.18.\\n1. The resulting output has a shape of 4 × 4.\\n2. Convolution operation\\n[[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]]\\n[[ 2. 0. -2.]\\n[ 2. 0. -2.]\\n[ 2. 0. -2.]]\\n3. By deﬁnition, convolutions in the valid mode, reduce the size of the resulting input\\ntensor.\\n[[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]]\\n\\x04\\nKernels and filters\\nSOL-195 \\uf14b CH.SOL- 8.19.\\n2938.3. SOLUTIONS\\n1. Flipping by 180 degrees we get:\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 −1\\n1 1\\n\\uf8f9\\n\\uf8fb (8.46)\\n2. The Sobel ﬁlter which is being frequently used for edge detection in classical computer\\nvision.\\n\\x04\\nSOL-196 \\uf14b CH.SOL- 8.20.\\nThe resulting complexity is given by:\\nK 2wh (8.47)\\n\\x04\\nConvolution and correlation in python\\nSOL-197 \\uf14b CH.SOL- 8.21.\\n1. Convolution operation:\\n294Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 def convolution(A,B):\\n3 l_A = np.size(A)\\n4 l_B = np.size(B)\\n5 C = np.zeros(l_A + l_B -1)\\n6\\n7 for m in np.arange(l_A):\\n8 for n in np.arange(l_B):\\n9 C[m+n] = C[m+n] + A[m]*B[n]\\n10\\n11 return C\\nFIGURE 8.52: Convolution and correlation in python\\n2. Correlation operation:\\n1 def crosscorrelation(A,B):\\n2 return convolution(np.conj(A),B[::-1])\\nFIGURE 8.53: Convolution and correlation in python\\n\\x04\\nSeparable convolutions\\nSOL-198 \\uf14b CH.SOL- 8.22.\\n1. No.Since images are usually stored as discrete pixel values one would have to use a\\ndiscrete approximation of the Gaussian function on the ﬁltering mask before performing\\nthe convolution.\\n2. No.\\n2958.3. SOLUTIONS\\n3. Y es it is separable, a factor that has great implications. For instance, separability means\\nthat a 2D convolution can be reduced to two consequent 1D convolutions reducing the\\ncomputational runtime from O (n2 m2) to O (n2 m).\\n\\x04\\n8.3.3 Similarity measures\\nImage, text similarity\\nSOL-199 \\uf14b CH.SOL- 8.23.\\nThe algorithm presented in ( 8.12) normalizes the input vector. This is usually done prior\\nto applying any other method to the vector or before persisting a vector to a database of FVs.\\n\\x04\\nSOL-200 \\uf14b CH.SOL- 8.24.\\n1. The algorithm presented in ( 8.1) is one of the most commonly used image similarity\\nmeasures and is entitled cosine similarity. It can be applied to any pair of images.\\n2. The mathematical formulae behind it is:\\nThe cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and v = {v1, v2, . . . , vN } is deﬁned as:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures the cosine of the angle\\nbetween the vectors irrespective of their magnitude. It is calculated as the dot product\\nof two numeric vectors, and is normalized by the product of the length of the vectors.\\n3. The minimum and maximum values it can return are 0 and 1 respectively. Thus, a\\ncosine similarity value which is close to 1 indicated a very high similarity while that\\nclose to 0 indicates a very low similarity.\\n4. It represents the negative distance in Euclidean space between the vectors.\\n296Chapter 8 DEEP LEARNING\\n\\x04\\nJacard similarity\\nSOL-201 \\uf14b CH.SOL- 8.25.\\n1. The general formulae for the Jaccard similarity of two sets is given as follows:\\nJ(A, B) = |A ∩ B|\\n|A ∪ B|\\n2. That is, the ratio of the size of the intersection of A and B to the size of their union.\\n3. The Jaccard similarity equals:\\n2\\n7\\n4. Given (8.13)\\nFor the three combinations of pairs above, we have\\nJ({11, 16, 17}, {12, 14, 16, 18}) = 1\\n6\\nJ({11, 12, 13, 14, 15}, {11, 16, 17}) = 1\\n7\\nJ({11, 12, 13, 14, 15}, {12, 14, 16, 18}) = 2\\n7\\n\\x04\\nThe Kullback-Leibler Distance\\nSOL-202 \\uf14b CH.SOL- 8.26.\\nEach KLD corresponds to the deﬁnition of:\\ni Jensen [1]\\n2978.3. SOLUTIONS\\nii Bennet [2]\\niii Bigi [3]\\niv Ziv [29]\\n\\x04\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nSOL-203 \\uf14b CH.SOL- 8.27.\\nA Hashing function ( 8.54) maps a value into a constant length string that can be com-\\npared with other hashed values.\\nFIGURE 8.54: The idea of hashing\\nThe idea behind hashing is that items are hashed into buckets, such that similar items\\nwill have a higher probability of hashing into the same buckets.\\nThe goal of MinHash is to compute the Jaccard similarity without actually computing the\\nintersection and union of the sets, which would be slower. The main idea behind MinHash\\nis to devise a signature scheme such that the probability that there is a match between the\\nsignatures of two sets, S1 and S2, is equal to the Jaccard measure [ 12].\\n\\x04\\n298Chapter 8 DEEP LEARNING\\nSOL-204 \\uf14b CH.SOL- 8.28.\\nLocality-Sensitive Hashing (LSH) is a method which is used for determining which items\\nin a given set are similar. Rather than using the naive approach of comparing all pairs of items\\nwithin a set, items are hashed into buckets, such that similar items will be more likely to hash\\ninto the same buckets.\\n\\x04\\nSOL-205 \\uf14b CH.SOL- 8.29.\\nMaximise.\\n\\x04\\n8.3.4 Perceptrons\\nThe Single Layer Perceptron\\nSOL-206 \\uf14b CH.SOL- 8.30.\\nAnswer: one, one, feedback.\\n\\x04\\nSOL-207 \\uf14b CH.SOL- 8.31.\\n1. T rue.\\n2. T rue.\\n3.\\nC(w, b) = 1\\n2n\\n∑\\nx\\n∥y(x) − a(x, w, b)∥2 (8.48)\\nwhere w denotes the collection of all weights in the network, b all the biases, n is the\\ntotal number of training inputs and a(x, w, b) is the vector of outputs from the network\\nwhich has weights w, biases b and the input x.\\n4.\\narg min\\nw,b\\nC(w, b). (8.49)\\n5. Gradient descent.\\n2998.3. SOLUTIONS\\n6. The gradient.\\n7. Stochastic gradient descent. Batch size. Back-propagation.\\n\\x04\\nThe Multi Layer Perceptron\\nSOL-208 \\uf14b CH.SOL- 8.32.\\n1. This operation is a dot product with the given weights. Therefore:\\nout = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 = −0.164 (8.50)\\n2. This operation (sum) is a dot product with the given weights and with the given bias\\nadded. Therefore:\\nout1 = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 + 0.001 = −0.165 (8.51)\\n3. Code snippet 8.55 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 # .type(torch.FloatTensor)\\n3 x= torch.tensor([0.9,0.7])\\n4 w= torch.tensor([-0.3,0.15])\\n5 B= torch.tensor([0.001])\\n6 print (torch.sum(x*w))\\n7 print (torch.sum(x*w) + B)\\nFIGURE 8.55: MLP operations.\\n\\x04\\n300Chapter 8 DEEP LEARNING\\nActivation functions in perceptrons\\nSOL-209 \\uf14b CH.SOL- 8.33.\\n1. Since by deﬁnition:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.52)\\nAnd the output of the linear sum operation was −0.164 then, the output out2 = 0 .\\n2. Code snippet 8.56 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 x= torch.tensor([0.9,0.7])\\n3 w= torch.tensor([-0.3,0.15])\\n4 B= torch.tensor([0.001])\\n5 print (torch.sum(x*w))\\n6 print (torch.sum(x*w) + B)\\n7 print (torch.relu(torch.sum(x*w + B)))\\nFIGURE 8.56: MLP operations.\\n\\x04\\nBack-propagation in perceptrons\\nSOL-210 \\uf14b CH.SOL- 8.34. The answers are as follows:\\n1. Non-differentiable at 0.\\n2. Non-differentiable at 0.\\n3018.3. SOLUTIONS\\n3. Even though for x ̸= 0:\\nf ′(x) = sin 1\\nx − 1\\nx cos 1\\nx, (8.53)\\nthe function is still non-differentiable at 0.\\n4. Non-differentiable at 0.\\n\\x04\\nSOL-211 \\uf14b CH.SOL- 8.35.\\n1. Fig 8.57 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 for i in range(0,w.size(0)):\\n2 print (torch.relu(torch.sum(x*w[i]) + B))\\n3 > tensor([0.])\\n4 > tensor([0.])\\n5 > tensor([0.6630])\\nFIGURE 8.57: MLP operations- values.\\n2. The values at each hidden layer are depicted in 8.58\\n302Chapter 8 DEEP LEARNING\\n0.0\\n0.0\\n0.6630\\nOutput\\nFIGURE 8.58: Hidden layer values, simple MLP .\\n3. Fig 8.59 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 x1= torch.tensor([0.0,0.0,0.6630])# Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 for i in range(0,w1.size(0)):\\n7 print (torch.sum(x1*w1[i]))\\n8 > tensor(0.3912)\\n9 > tensor(-0.5238)\\nFIGURE 8.59: MLP operations- values at the output.\\n4. We can apply the Softmax function like so 8.60:\\n3038.3. SOLUTIONS\\n1 x1= torch.tensor([0.0,0.0,0.6630]) # Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 out1 = torch.tensor([[torch.sum(x1*w1[0]).item()],\\n7 [torch.sum(x1*w1[1]).item()]])\\n8 print (out1)\\n9 yhat = torch.softmax(out1, dim =0)\\n10 print (yhat)\\n11 > tensor([[ 0.3912],\\n12 [-0.5238]])\\n13 > tensor([[0.7140],\\n14 [0.2860]])\\nFIGURE 8.60: MLP operations- Softmax.\\n5. For the cross-entropy loss, we use the Softmax values and calculate the result as follows:\\n−1.0 ∗ log(0.7140) − 0.0 ∗ log(0.2860) = 1 .31 (8.54)\\n\\x04\\nThe theory of perceptrons\\nSOL-212 \\uf14b CH.SOL- 8.36.\\nHe means that theoretically [ 6], a non-linear layer followed by a linear layer, can ap-\\nproximate any non-linear function with arbitrary accuracy, provided that there are enough\\nnon-linear neurons\\n\\x04\\nSOL-213 \\uf14b CH.SOL- 8.37. T rue \\x04\\nSOL-214 \\uf14b CH.SOL- 8.38. T rue \\x04\\n304Chapter 8 DEEP LEARNING\\nSOL-215 \\uf14b CH.SOL- 8.39.\\nFalse. Divided by the training samples, not the number of incorrectly classiﬁed samples. \\x04\\nLearning logical gates\\nSOL-216 \\uf14b CH.SOL- 8.40.\\n1. The values are presented in the following table ( 8.61):\\nBias = −2.5\\nInput Weighted sum Output\\n(0,0) -2.5 0\\n(0,1) -1.5 0\\n(1,0) -1.5 0\\n(1,1) -0.5 0\\nFIGURE 8.61: Logical AND: B=-2.5\\n2. The values are presented in the following table ( 8.62):\\nBias = −0.25\\nInput Weighted sum Output\\n(0,0) -0.25 0\\n(0,1) -0.75 0\\n(1,0) -0.75 0\\n(1,1) 1.75 1\\nFIGURE 8.62: Logical AND: B=-0.25\\n3. The perceptron learning rule is an algorithm that can automatically compute optimal\\nweights for the perceptron.\\n3058.3. SOLUTIONS\\n4. The main addition by [ 22] and [ 18] was the introduction of a differentiable activation\\nfunction.\\n5. if we select w1 = 1;w2 = 1 and threshold=1. We get:\\nx1 = 1, x2 = 1 :\\nn = 1 × 1 + 1 × 1 = 2 ,thus,y = 1\\nx1 = 1, x2 = −1 :\\nn = 1 × 1 + 1 × (−1) = 0 ,thus,y = −1\\nx1 = −1, x2 = 1 :\\nn = 1 × (−1) + 1 × 1 = 0 ,thus,y = −1\\nx1 = −1, x2 = −1 :\\nn = 1 × (−1) + 1 × (−1) = −2,thus,y = −1\\n(8.55)\\nOr summarized in a table ( 8.63):\\nAND gate\\nin1 in2 out\\n0 0 0\\n0 1 0\\n1 0 0\\n1 1 1\\nFIGURE 8.63: Logical AND gate\\n\\x04\\n8.3.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\n306Chapter 8 DEEP LEARNING\\nSOL-217 \\uf14b CH.SOL- 8.41.\\n1. Remember that the analytical derivative is of the sigmoid:\\nd\\ndxs(x) = d\\ndx((1 + e−x)−1) (8.56)\\nd\\ndxs(x) = −1((1 + e−x)(−1−1)) d\\ndx(1 + e−x) (8.57)\\nd\\ndxs(x) = −1((1 + e−x)(−2))( d\\ndx (1) + d\\ndx(e−x)) (8.58)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(0 + e−x( d\\ndx(−x))) (8.59)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(e−x)(−1) (8.60)\\nd\\ndx s(x) = ((1 + e−x)(−2))(e−x) (8.61)\\nd\\ndxs(x) = 1\\n(1 + e−x)2 (e−x) (8.62)\\nd\\ndxs(x) = (e−x)\\n(1 + e−x)2 (8.63)\\nCode snippet 8.64 provides a pure C++ based implementation of the backward pass that\\ndirectly computes the analytical gradients in C++.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001_d(torch ::Tensor & x) {\\n5 torch::Tensor s = sigmoid001(x);\\n6 return (1 - s) * s;\\n7 }\\nFIGURE 8.64: Backward pass for the Sigmoid function using Libtorch.\\n3078.3. SOLUTIONS\\n2. Code snippet 8.65 depicts one way of printing the values.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"\\n9 << sigmoid001_d (t0).data().detach().item().toFloat()\\n10 << \\'\\\\n\\' ;\\n11 }\\n12 }\\nFIGURE 8.65: Evaluation of the sigmoid and its derivative in C++ using Libtorch.\\n3. The manual derivative of eq. 8.27 is:\\n3 ln(2)×\\n[\\n2−1.5x\\n(2−1.5x + 1)2\\n]\\n(8.64)\\n4. The forward pass for the Sigmoid function approximation eq. 8.27 is presented in code\\nsnippet 8.66:\\n308Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 torch::Tensor sig_approx( const torch::Tensor & x ){\\n4 torch::Tensor sig = 1.0 / (1.0 + torch::pow(2,( -1.5*x)));\\n5 return sig;\\n6 }\\nFIGURE 8.66: Forward pass for the Sigmoid function approximation in C++ using Libtorch.\\n5. The values are 8.67: :\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"<< sig_approx (t0).data().detach().item().\\n9 toFloat()<<\\'\\\\',\n",
              " '5*x)));\\n5 return sig;\\n6 }\\nFIGURE 8.66: Forward pass for the Sigmoid function approximation in C++ using Libtorch.\\n5. The values are 8.67: :\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"<< sig_approx (t0).data().detach().item().\\n9 toFloat()<<\\'\\\\n\\' ;\\n10 }\\nFIGURE 8.67: Printing the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch.\\nAn the values are presented in T able 8.2:\\n3098.3. SOLUTIONS\\nValue Sig Approx\\n0 0.5 0.5\\n0.1 0.524979 0.52597\\n0.2 0.549834 0.5518\\n0.3 0.574443 0.577353\\n0.4 0.598688 0.602499\\n0.5 0.622459 0.627115\\n0.6 0.645656 0.65109\\n0.7 0.668188 0.674323\\n0.8 0.689974 0.69673\\n0.9 0.710949 0.71824\\n0.99 0.729088 0.736785\\nTABLE 8.2: Computed values for the Sigmoid and the Sigmoid approximation.\\n\\x04\\nTanh\\nSOL-218 \\uf14b CH.SOL- 8.42.\\nThe answers are as follows:\\n1. The derivative is:\\nftanh(x) = 1 − ftanh(x)2 (8.65)\\n2. Code snippet 8.68 implements the forward pass using pure Python.\\n310Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 xT =\\ntorch.abs(torch.tensor([[0.37,0.192,0.571]],requires_grad=True))↪→\\n3 .type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 tanh_values = np.tanh(xT_np)\\n7 print (\"Numpy:\", tanh_values)\\n8 > Numpy: [[ 0.35399172 0.18967498 0.51609329]]\\nFIGURE 8.68: Forward pass for tanh using pure Python.\\n3. In order to implement a PyT orch based torch.autograd.F unction function such as\\ntanh, we must provide both the forward and backward passes implementation. The\\nmechanism behind this idiom in PyT orch is via the use of a context, abbreviated ctx\\nwhich is like a state manager for automatic differentiation. The implementation is de-\\npicted in 8.69:\\n3118.3. SOLUTIONS\\n1 import torch\\n2\\n3 class TanhFunction(torch.autograd.Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward( x )\\n7 y = x.tanh()\\n8 return y\\n9\\n10 @staticmethod\\n11 def backward(ctx, grad_output):\\n12 input, = ctx.saved_tensors\\n13 dy_dx = 1 / (input.cosh() ** 2)\\n14 out = grad_output * dy_dx\\n15 print (\"backward:{}\".format(out))\\n16 return out\\nFIGURE 8.69: Tanh in PyTorch.\\n4. Code snippet 8.70 veriﬁes the correctness of the implementation using gradcheck.\\n312Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 import numpy as np\\n3 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n4 requires_grad=True))\\n5 .type(torch.DoubleTensor)\\n6 xT_np=xT.detach().cpu().numpy()\\n7 tanh_values = np.tanh(xT_np)\\n8 tanh_values_torch = tanhPyTorch(xT)\\n9 print (\"Torch:\", tanh_values_torch)\\n10 from torch.autograd import gradcheck, Variable\\n11 f = TanhFunction.apply\\n12 test=gradcheck(lambda t: f(t), xT)\\n13 print(test)\\n14 > PyTorch version: 1.7.0\\n15 > Torch: tensor([[ 0.3540, 0.1897, 0.5161]], dtype =torch.float64)\\n16 > backward:tensor([[0.8747, 0.9640, 0.7336]],dtype=torch.float64)\\nFIGURE 8.70: Invoking gradcheck on tanh.\\n\\x04\\nSOL-219 \\uf14b CH.SOL- 8.43.\\n1. The type of NN is a MultiLayer Perceptron or MLP .\\n2. There are two hidden layers.\\n\\x04\\nSOL-220 \\uf14b CH.SOL- 8.44.\\nHe is partially correct , see for example Understanding the difﬁculty of training deep\\nfeedforward neural networks [9]. \\x04\\n3138.3. SOLUTIONS\\nSOL-221 \\uf14b CH.SOL- 8.45.\\nInitialize all parameters to a constant zero value. When we apply the tanh function to an\\ninput which is very large, the output which is almost zero, will be propagated to the remaining\\npartial derivatives leading to the well known phenomenon.\\n\\x04\\nSOL-222 \\uf14b CH.SOL- 8.46.\\nDuring the back-propagation process, derivatives are calculated with respect to (W (1))\\nand also (W (2)). The design ﬂaw:\\ni Y our friend initialized all weights and biases to zero.\\nii Therefore any gradient with respect to (W (2)) would also be zero.\\niii Subsequently, (W (2)) will never be updated.\\niv This would inadvertently cause the derivative with respect to (W (1)) to be always zero.\\nv Finally, would also never be updated (W (1)).\\n\\x04\\nReLU\\nSOL-223 \\uf14b CH.SOL- 8.47.\\nThe ReLU function has the beneﬁt of not saturating for positive inputs since its derivative\\nis one for any positive value.\\n\\x04\\nSOL-224 \\uf14b CH.SOL- 8.48.\\nThe shape is:\\n3 × 3 × 3 × 16\\n\\x04\\nSOL-225 \\uf14b CH.SOL- 8.49.\\nThe activation function is a leaky ReLU which in some occasions may outperform the\\n314Chapter 8 DEEP LEARNING\\nReLU activation function. \\x04\\nSwish\\nSOL-226 \\uf14b CH.SOL- 8.50.\\n1. They intended to ﬁnd new better-performing activation functions.\\n2. They had a list of basic mathematical functions to choose from, for instance the expo-\\nnential families exp(), sin(), min and max.\\n3. Previous research found several activation function properties which were considered\\nvery useful. For instance, gradient preservation and non-monotonicity. However the\\nsurprising discovery was that the swish function violates both of these previously deemed\\nuseful properties.\\n4. The equation is:\\nf (x) = x · σ(x) (8.66)\\n5. The plot is 8.71\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n−1,0\\n−0,5\\n0,5\\n1,0\\nx\\nyx ∗ σ(x) = x ∗ 1\\n1+e−4x\\nFIGURE 8.71: A plot of the Swish activation function.\\n\\x04\\n3158.3. SOLUTIONS\\n8.3.6 Performance Metrics\\nConfusion matrix, precision, recall\\nSOL-227 \\uf14b CH.SOL- 8.51.\\n1. The values are labelled inside 8.27:\\nPredicted\\nP N\\nTruth P TP=12 FN=7\\nN FP=24 TN=1009\\nFIGURE 8.72: TP , TN, FP , FN.\\n2.\\nacc = 12 + 1009\\n12 + 7 + 24 + 1009 = 0.97 (8.67)\\n3.\\nprec = 12\\n12 + 24 = 0.333 (8.68)\\n4.\\nrecall = 12\\n12 + 7 = 0.631 (8.69)\\n\\x04\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\n316Chapter 8 DEEP LEARNING\\nFIGURE 8.73: Receiver Operating Characteristic curve.\\nSOL-228 \\uf14b CH.SOL- 8.52.\\nROC allows to attest the relationship between sensitivity and speciﬁcity of a binary clas-\\nsiﬁer. Sensitivity or true positive rate measures the proportion of positives correctly classiﬁed;\\nspeciﬁcity or true negative rate measures the proportion of negatives correctly classiﬁed. Con-\\nventionally, the true positive rate tpr is plotted against the false positive rate fpr, which is one\\nminus true negative rate.\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween selectivity and sensitivity.\\n2. It is a plot of ‘true positives’ vs. the ‘true negatives’ . In place of ‘true negatives’ ,\\none could also use ‘false positives’ which are essentially 1 - ‘true negatives’ .\\n3. A typical ROC curve has a concave shape with (0,0) as the beginning and (1,1) as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely confused\\nand cannot at all distinguish between the two classes, has an AUC of 0.5, the ‘x = y’\\nline in an ROC curve plot.\\n3178.3. SOLUTIONS\\n\\x04\\nSOL-229 \\uf14b CH.SOL- 8.53.\\nThe ROC curve of an ideal classiﬁer (100% accuracy) has an AUC of 1, with 0.0 ‘false\\npositives’ and 1.0 ‘true positives’ . The ROC curve in our case, is almost ideal, which may\\nindicate over-ﬁtting of the XGBOOST classiﬁer to the training corpus. \\x04\\n8.3.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nSOL-230 \\uf14b CH.SOL- 8.54.\\nOutput dimension: L × L × M where L = n−f +2p\\ns + 1 \\x04\\nSOL-231 \\uf14b CH.SOL- 8.55.\\nThe answers are as follows:\\n1. Output dimensions:\\ni torch.Size([1, 512, 7, 7])\\nii torch.Size([1, 512, 16, 16])\\niii torch.Size([1, 512, 22, 40])\\n2. The layer is MaxPool2d.\\n\\x04\\nSOL-232 \\uf14b CH.SOL- 8.56.\\nThe answers are as follows:\\n1. A convolutional block 8.74.\\n318Chapter 8 DEEP LEARNING\\n1 Sequential(\\n2 (0): Conv2d( 3, 64, kernel_size =(3, 3), stride =(1, 1), padding =(1,\\n1))↪→\\n3 (1): ReLU(inplace =True)\\n4 (2): MaxPool2d(kernel_size =2, stride =2, padding =0, dilation =1,\\nceil_mode=False↪→\\n5 )\\nFIGURE 8.74: Convolutional block from the VGG11 architecture.\\n2. The shapes are as follows:\\ni torch.Size([1, 64, 112, 112])\\nii torch.Size([1, 64, 256, 256])\\niii torch.Size([1, 64, 352, 512])\\n\\x04\\nSOL-233 \\uf14b CH.SOL- 8.57.\\nThe VGG11 architecture contains seven convolutional layers, each followed by a ReLU\\nactivation function, and ﬁve max-polling operations, each reducing the respective feature\\nmap by a factor of 2. All convolutional layers have a 3 × 3 kernel. The ﬁrst convolutional\\nlayer produces 64 channels and subsequently, as the network deepens, the number of channels\\ndoubles after each max-pooling operation until it reaches 512. \\x04\\nDropout\\nSOL-234 \\uf14b CH.SOL- 8.58.\\n1. The observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (8.70)\\n3198.3. SOLUTIONS\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (8.71)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (8.72)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (8.73)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(8.74)\\n2. In dropout, in every training epoch, neurons are randomly pruned with probability\\nP = p sampled from a Bernoulli distribution. During inference, all the neurons are used\\nbut their output is multiplied by the a-priory probability P . This approach resembles to\\nsome degree the model averaging approach of bagging.\\n\\x04\\nSOL-235 \\uf14b CH.SOL- 8.59.\\nThe answers are as follows:\\n1. The idea is true and a solid one.\\n2. The idiom may be exempliﬁed as follows 8.75:\\n320Chapter 8 DEEP LEARNING\\nFIGURE 8.75: Equivalence of two consecutive dropout layers\\nThe probabilities add up by multiplication at each layer, resulting in a single dropout\\nlayer with probability:\\n1 − (1 − p)(1 − q) (8.75)\\n\\x04\\nConvolutional Layer\\nSOL-236 \\uf14b CH.SOL- 8.60.\\nThe result is ( 8.76):\\nFIGURE 8.76: The result of applying the ﬁlter.\\n\\x04\\n3218.3. SOLUTIONS\\nSOL-237 \\uf14b CH.SOL- 8.61.\\nThe result is ( 8.77):\\nFIGURE 8.77: The result of applying a ReLU activation.\\n\\x04\\nSOL-238 \\uf14b CH.SOL- 8.62.\\nThe result is ( 8.78):\\nFIGURE 8.78: The result of applying a MaxPool layer.\\n\\x04\\nPooling Layers\\nMaxPooling\\n322Chapter 8 DEEP LEARNING\\nSOL-239 \\uf14b CH.SOL- 8.63.\\nThe answers are as follows:\\n1. A max-pooling layer is most commonly used after a convolutional layer in order to\\nreduce the spatial size of CNN feature maps.\\n2. The result is 8.79:\\nFIGURE 8.79: Output of the MaxPool2d operation.\\n\\x04\\nSOL-240 \\uf14b CH.SOL- 8.64.\\n1. In MaxPool2D(2,2), the ﬁrst parameter is the size of the pooling operation and the\\nsecond is the stride of the pooling operation.\\n2. The BatchNorm2D operation does not change the shape of the tensor from the previous\\nlayer and therefore it is:\\ntorch.Size ([1, 32, 222, 222]).\\n3. During the training of a CNN we use model.train() so that Dropout layers are ﬁred.\\nHowever, in order to run inference, we would like to turn this ﬁring mechanism off,\\nand this is accomplished by model.eval() instructing the PyT orch computation graph\\nnot to activate dropout layers.\\n4. The resulting tensor shape is:\\ntorch.Size ([1, 32, 55, 55])\\nIf we reshape the tensor like in line 17 using:\\nx = x.view(x.size(0), −1)\\n3238.3. SOLUTIONS\\nThen the tensor shape becomes:\\ntorch.Size ([1, 96800])\\n5. Y es, you should agree with him, as depicted by the following plot 8.80:\\nFIGURE 8.80: A single MaxPool layer.\\n\\x04\\nBatch normalization, Gaussian PDF\\nThe Gaussian distribution\\nSOL-241 \\uf14b CH.SOL- 8.65.\\nThe answers are as follows:\\n1. BN is a method that normalizes the mean and variance of each of the elements during\\ntraining.\\n2. X ∼ N (0, 1) a mean of zero and a variance of one. The standard normal distribution\\noccurs when (σ)2 = 1 and µ = 0.\\n3. In order to normalize we:\\ni Step one is to subtract the mean to shift the distribution.\\nii Divide all the shifted values by their standard deviation (the square root of the\\nvariance).\\n4. In BN, the normalization is applied on an element by element basis. During training at\\neach epoch, every element in the batch has to be shifted and scaled so that it has a zero\\nmean and unit variance within the batch.\\n\\x04\\n324Chapter 8 DEEP LEARNING\\nSOL-242 \\uf14b CH.SOL- 8.66.\\n1. One possible realization is as follows 8.81:\\n1 from math import sqrt\\n2 import math\\n3 def normDist(x, mu, sigSqrt):\\n4 return (1 / sqrt(2 * math.pi * sigSqrt)) * math.e ** ((-0.5) *\\n(x - mu) ** 2 / sigSqrt)↪→\\nFIGURE 8.81: Normal distribution in Python: from scratch.\\n2. The derivative is given by 8.82:\\n1 scipy.stats.norm.pdf(x, mu, sigma) *(mu - x)/sigma**2\\nFIGURE 8.82: The derivative of a Normal distribution in Python.\\n\\x04\\nBN\\nSOL-243 \\uf14b CH.SOL- 8.67.\\n1. During training of a CNN, when a convolution is being followed by a BN layer, for\\neach of the three RGB channels a single separate mean and variance is being computed.\\n2. The mistake he made is using a BN with a batch size of 32, while the output from the\\nconvolutional layer is 64.\\n\\x04\\n3258.3. SOLUTIONS\\nTheory of CNN design\\nSOL-244 \\uf14b CH.SOL- 8.68.\\nT rue.\\n\\x04\\nSOL-245 \\uf14b CH.SOL- 8.69.\\nAll the options may be used to build a CNN. \\x04\\nSOL-246 \\uf14b CH.SOL- 8.70. While the original paper ([ 16]) suggests that BN layers be\\nused before an activation function, it is also possible to use BN after the activation function.\\nIn some cases, it actually leads to better results ([ 4]).\\n\\x04\\nSOL-247 \\uf14b CH.SOL- 8.71.\\nWhen dropout is enabled during the training process, in order to keep the expected output\\nat the same value, the output of a dropout layer must be multiplied with this term. Of course,\\nduring inference no dropout is taking place at all. \\x04\\nSOL-248 \\uf14b CH.SOL- 8.72.\\n1. The idiom is a bottleneck layer ([ 27]), which may act much like an autoencoder.\\n2. Reducing and then increasing the activations, may force the MLP to learn a more com-\\npressed representation.\\n3. The new architecture has far more connections and therefore it would be prone to over-\\nﬁtting.\\n4. Once such architecture is an autoencoder ([ 28]).\\n\\x04\\nCNN residual blocks\\nSOL-249 \\uf14b CH.SOL- 8.73.\\n326Chapter 8 DEEP LEARNING\\n1. The function F is the residual function.\\n2. The main idea was to add an identity connection which skips two layers all together.\\n\\x04\\nSOL-250 \\uf14b CH.SOL- 8.74.\\n1. The missing parts are visualized in ( 8.83).\\nFIGURE 8.83: A resnet CNN block\\n2. The symbol represents the addition operator.\\n3. Whenever F returns a zero, then the input X will reach the output without being\\nmodiﬁed. Therefore, the term identity function.\\n\\x04\\n8.3.8 Training, hyperparameters\\nHyperparameter optimization\\nSOL-251 \\uf14b CH.SOL- 8.75.\\nThe question states that image size is quite large, and the batch size is 1024, therefore it\\nmay fail to allocate memory on the GPU with an Out Of Memory (OOM) error message. This\\n3278.3. SOLUTIONS\\nis one of the most commonly faced errors when junior data-scientist start training models.\\n\\x04\\nSOL-252 \\uf14b CH.SOL- 8.76.\\n1. Since hs is tuning his Hyperparameters on the validation set, he would most probably\\noverﬁt to the validation set which he also used for evaluating the performance of the\\nmodel.\\n2. One way would be to amend the splitting, is by ﬁrst keeping a fraction of the training set\\naside, for instance 0.1, and then split the remaining .90 into a training and a validation\\nset, for instance 0.8 and 0.1.\\n3. His new approach uses GridSearchCV with 5-fold cross-validation to tune his Hyper-\\nparameters. Since he is using cross validation with ﬁve folds, his local CV metrics would\\nbetter reﬂect the performance on an unseen data set.\\n\\x04\\nSOL-253 \\uf14b CH.SOL- 8.77.\\nIn grid search, a set of pre-determined values is selected by a user for each dimension in\\nhis search space, and then thoroughly attempting each and every combination. Naturally, with\\nsuch a large search space the number of the required combinations that need to be evaluated\\nscale exponentially in the number of dimensions in the grid search.\\nIn random search the main difference is that the algorithm samples completely random\\npoints for each of the dimensions in the search space. Random search is usually faster and may\\neven produce better results.\\n\\x04\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nSOL-254 \\uf14b CH.SOL- 8.78.\\nThere is a potential for bias in certain settings such as this. If the whole training set\\nis labelled only by a single radiologist, it may be possible that his professional history would\\n328Chapter 8 DEEP LEARNING\\ninadvertently generate bias into the corpus. Even if we use the form of radiology report reading\\nknown as double reading it would not be necessarily true that the annotated scans would be\\ndevoid of bias or that the quality would be better [ 8].\\n\\x04\\nValidation curve ACC\\nSOL-255 \\uf14b CH.SOL- 8.79.\\nThe answers are as follows:\\n1. A validation curve displays on a single graph a chosen hyperparameter on the hori-\\nzontal axis and a chosen metric on the vertical axis.\\n2. The hyperparameter is the number of epochs\\n3. The quality metric is the error (1 -accuracy). Accuracy, error = (1`accuracy) or loss are\\ntypical quality metrics.\\n4. The longer the network is trained, the better it gets on the training set.\\n5. At some point the network is ﬁt too well to the training data and loses its capability to\\ngeneralize. While the classiﬁer is still improving on the training set, it gets worse on\\nthe validation and the test set.\\n6. At this point the quality curve of the training set and the validation set diverge.\\n\\x04\\nValidation curve Loss\\nSOL-256 \\uf14b CH.SOL- 8.80.\\nThe answers are as follows:\\n1. What we are witnessing is phenomena entitled a plateau. This may happen when the\\noptimization protocol can not improve the loss for several epochs.\\n2. There possible methods are:\\ni Constant\\nii Xavier/Glorot uniform\\n3298.3. SOLUTIONS\\niii Xavier/Glorot normal\\n3. Good initialization would optimally generate activations that produce initial gradients\\nthat are larger than zero. One idea is that the training process would converge faster if\\nunit variance is achieved ([ 16]). Moreover, weights should be selected carefully so that:\\ni They are large enough thus preventing gradients from decaying to zero.\\nii They are not too large causing activation functions to over saturate.\\n4. There are several ways to reduce the problem of plateaus:\\ni Add some type of regularization.\\nii In cases wherein the plateau happens right at the beginning, amend the way weights\\nare initialized.\\niii Amending the optimization algorithm altogether, for instance using SGD instead\\nof Adam and vice versa.\\n5. Since the initial LR is already very low, his suggestion may worsen the situation since\\nthe optimiser would not be able to jump off and escape the plateau.\\n6. In contrast to accuracy, Log loss has no upper bounds and therefore at times may be\\nmore difﬁcult to understand and to explain.\\n\\x04\\nInference\\nSOL-257 \\uf14b CH.SOL- 8.81.\\n1. Usually data augmentation, is a technique that is heavily used during training, espe-\\ncially for increasing the number of instances of minority classes. In this case, augment-\\nations are using during inference and this method is entitled T est Time Augmentation\\n(TTA).\\n2. Here are several image augmentation methods for TTA, with two augmentations shown\\nalso in PyT orch.\\n330Chapter 8 DEEP LEARNING\\nHorizontal ﬂip\\nV ertical ﬂip\\nRotation\\nScaling\\nCrops\\n1 transforms.HorizolntalFlip(p=1)(image)\\n2 transforms.VerticalFlip(p=1)(image)\\nFIGURE 8.84: Several image augmentation methods for TTA.\\n\\x04\\nSOL-258 \\uf14b CH.SOL- 8.82.\\ni Unseen\\nii Overﬁtting\\n\\x04\\n8.3.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nSOL-259 \\uf14b CH.SOL- 8.83.\\nThere is no relation to random number generation, the true meaning is the use of batches\\nduring the training process.\\n\\x04\\nSOL-260 \\uf14b CH.SOL- 8.84.\\nA larger batch size decreases the variance of the gradient estimation of SGD. Therefore, if\\nyour training loop uses larger batches, the model will converge faster. On the other hand, smal-\\n3318.3. SOLUTIONS\\nler batch sizes increase the variance, leading to the opposite phenomena; longer convergence\\ntimes.\\n\\x04\\nMomentum\\nSOL-261 \\uf14b CH.SOL- 8.85.\\nMomentum introduces an extra term which comprises a moving average which is used\\nin gradient descent update rule to exponentially decay the historical gradients Using such\\nterm has been demonstrated to accelerate the training process ([ 11]) requiring less epochs to\\nconverge.\\n\\x04\\nSOL-262 \\uf14b CH.SOL- 8.86.\\nThe answers are as follows:\\n1. The derivative of the logistic activation function is extremely small for either negtive or\\npositive large inputs.\\n2. The use of the tanh function does not alleviate the problem since we can scale and\\ntranslate the sigmoid function to represent the tanh function:\\ntanh(z) = 2 σ(2z) − 1 (8.76)\\nWhile the sigmoid function is centred around 0.5, the tanh activation is centred around\\nzero. Similar to the application of BN, centring the activations may aid the optimizer con-\\nverge faster. Note: there is no relation to SGD; the issue exists when using other optimization\\nfunctions as well. \\x04\\nSOL-263 \\uf14b CH.SOL- 8.87.\\nThe answers are as follows:\\ni T rue.\\nii False. In stochastic gradient descent, the gradient for a single sample is quite different\\n332Chapter 8 DEEP LEARNING\\nfrom the actual gradient, so this gives a more noisy value, and converges slower\\niii T rue.\\niv False. SGD requires less memory.\\n\\x04\\nNorms, L1, L2\\nSOL-264 \\uf14b CH.SOL- 8.88.\\n1. The L2 norm.\\n2. The Euclidean distance which is calculated as the square root of the sum of differences\\nbetween each point in a set of two points.\\n3. The Manhattan distance is an L1 norm (introduced by Hermann Minkowski) while the\\nEuclidean distance is an L2 norm.\\n4. The Manhattan distance is:\\n|6 − 2| + |1 − 8| + |4 − 3| + |5 − (−1)|\\n= 4 + 7 + 1 + 6 = 18 (8.77)\\n5. The Euclidean distance is:\\n√\\n(6 − 2)2 + (1 − 8)2 + (4 − 3)2 + (5 − (−1))2\\n=\\n√\\n102\\n(8.78)\\n\\x04\\nSOL-265 \\uf14b CH.SOL- 8.89.\\nThe PyT orch implementation is in ( 8.85). Note that we are allocating tensors on a GPU\\nbut ﬁrst they are created on a CPU using numpy. This is also always the interplay between\\nthe CPU and the GPU when training NN models. Note that this only work if you have GPU\\navailable; in case there is no GPU detected, the code has a fallback to the CPU.\\n333REFERENCES\\n1 %reset -f\\n2 import torch\\n3 import numpy\\n4\\n5 use_cuda = torch.cuda.is_available()\\n6 device = torch.device(\"cuda\" if use_cuda else \"cpu\")\\n7 print (device)\\n8 x1np=numpy.array([6,1,4,5])\\n9 x2np=numpy.array([2,8,3,-1])\\n10 x1t=torch.FloatTensor(x1np).to(device) # Move to GPU if available\\n11 x2t=torch.FloatTensor(x2np).to(device)\\n12 dist = torch.sqrt (torch .pow(x1t - x2t, 2).sum())\\n13 dist\\n14 >cuda\\n15 >tensor(10.0995, device =\\'cuda:0\\' )\\nFIGURE 8.85: Manhattan distance function in PyTorch.\\n\\x04\\nSOL-266 \\uf14b CH.SOL- 8.90.\\nThe L2 loss is suitable for a target, or a response variable that is continuous. On the other\\nhand, in a binary classiﬁcation problem using LR we would like the output to match either\\nzero or one and a natural candidate for a loss function is the binary cross-entropy loss. \\x04\\nReferences\\n[1] F. T. B. Fuglede. ‘Jensen-Shannon Divergence and Hilbert space embedding’. In:\\nIEEE Int Sym. Information Theory (2004) (cit. on pp. 245, 297).\\n[2] C. Bennett. ‘Information Distance’. In: IEEE T rans. Pattern Anal. Inform. Theory.\\n44:4 (1998), pp. 1407–1423 (cit. on pp. 244, 298).\\n[3] B. Bigi. ‘Using Kullback-Leibler Distance for Text Categorization’. In: In Pro-\\nceedings of the ECIR-2003, Lecture Notes in Computer Science, Springer-Verlag 2633\\n(2003), pp. 305–319 (cit. on pp. 245, 298).\\n334Chapter 8 DEEP LEARNING\\n[4] G. Chen. Rethinking the Usage of Batch Normalization and Dropout in the T raining of\\nDeep Neural Networks. 2019. arXiv: 1905.05928 [cs.LG] (cit. on p. 326).\\n[5] Y . S. Chen et al. ‘Deep photo enhancer: Unpaired learning for image enhance-\\nment from photographs with gans’. In: IEEE Conference on Computer Vision and\\nPattern Recognition. 2018, p. 6306 (cit. on p. 231).\\n[6] I. Ciuca and J. A. Ware. ‘Layered neural networks as universal approximators’.\\nIn: Computational Intelligence Theory and Applications . Ed. by B. Reusch. Berlin,\\nHeidelberg: Springer Berlin Heidelberg, 1997, pp. 411–415 (cit. on p. 304).\\n[7] T. Floyd. Digital Fundamentals. Prentice Hall, 2003 (cit. on p. 252).\\n[8] H. Geijer and M. Geijer. ‘Added value of double reading in diagnostic radi-\\nology ,a systematic review’. In: Insights into Imaging 9 (Mar. 2018). DOI : 10.1007/\\ns13244-018-0599-0 (cit. on pp. 282, 328, 329).\\n[9] X. Glorot and Y . Bengio. ‘Understanding the difﬁculty of training deep feedfor-\\nward neural networks’. In: Journal of Machine Learning Research - Proceedings T rack\\n9 (Jan. 2010), pp. 249–256 (cit. on pp. 258, 313).\\n[10] S. Gomar, M. Mirhassani and M. Ahmadi. ‘Precise digital implementations of\\nhyperbolic tanh and sigmoid function’. In: 2016 50th Asilomar Conference on Sig-\\nnals, Systems and Computers (2016) (cit. on p. 254).\\n[11] I. Goodfellow, Y . Bengio and A. Courville. Adaptive computation and machine\\nlearning. MIT Press, 2016 (cit. on p. 332).\\n[12] J. Gurmeet Singh Manku. ‘Detecting near-duplicates for web crawling’. In: Pro-\\nceedings of the 16th International Conference on World Wide Web (2007), p. 141 (cit.\\non pp. 244, 245, 298).\\n[13] K. He. Deep Residual Learning for Image Recognition . 2015. arXiv: 1512 . 03385\\n(cit. on p. 279).\\n[14] K. He et al. Delving Deep into Rectiﬁers: Surpassing Human-Level Performance on\\nImageNet Classiﬁcation. 2015. arXiv: 1502.01852 [cs.CV] (cit. on pp. 258, 273).\\n[15] A. Ignatov et al. ‘Dslr-quality photos on mobile devices with deep convolu-\\ntional networks’. In: IEEE International Conference on Computer Vision (ICCV) .\\n2017, pp. 3297–3305 (cit. on p. 231).\\n[16] S. Ioffe and C. Szegedy. ‘Batch Normalization’. In: CoRR abs/1502.03167 (2015).\\narXiv: 1502.03167 (cit. on pp. 273, 326, 330).\\n335REFERENCES\\n[17] R. Kohavi. ‘A Study of Cross-Validation and Bootstrap for Accuracy Estima-\\ntion and Model Selection’. In: Morgan Kaufmann, 1995, pp. 1137–1143 (cit. on\\npp. 231, 289).\\n[18] A. Krizhevsky , I. Sutskever and G. E. Hinton. ‘ImageNet Classiﬁcation with\\nDeep Convolutional Neural Networks’. In: Advances in Neural Information Pro-\\ncessing Systems . Ed. by F. Pereira et al. V ol. 25. Curran Associates, Inc., 2012,\\npp. 1097–1105 (cit. on pp. 252, 306).\\n[19] Libtorch: The PyT orch C++ frontend is a C++14 library for CPU and GPU tensor com-\\nputation. 2020 (cit. on pp. 254, 256).\\n[20] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on pp. 266, 267).\\n[21] P . Ramachandran.Searching for Activation Functions . 2017. arXiv: 1710.05941\\n[cs.NE] (cit. on p. 260).\\n[22] D. E. Rumelhart and G. E. Hinton. ‘Learning Representations by Back Propagat-\\ning Errors’. In: Neurocomputing: Foundations of Research . Cambridge, MA, USA:\\nMIT Press, 1988, pp. 696–699 (cit. on pp. 236, 252, 260, 292, 306).\\n[23] S. Sengupta et al. ‘Sfsnet: Learning shape, reﬂectance and illuminance of faces\\nin the wild’. In: Computer Vision and Pattern Regognition (CVPR) . 2018 (cit. on\\np. 231).\\n[24] Z. Shu, E. Yumer and S. Hadap. ‘Neural face editing with intrinsic image dis-\\nentangling’. In: Computer Vision and Pattern Recognition (CVPR) IEEE Conference .\\n2017, pp. 5444–5453 (cit. on p. 231).\\n[25] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 263, 265).\\n[26] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on pp. 266, 267).\\n[27] C. Szegedy et al. ‘Inception v4, Inception-ResNet and the Impact of Residual\\nConnections on Learning’. In: ICLR 2016 Workshop. 2016 (cit. on p. 326).\\n[28] P . Vincent et al. ‘Extracting and composing robust features with denoising au-\\ntoencoders’. In: Proceedings of the 25th international conference on Machine learning .\\n2008, pp. 1096–1103 (cit. on p. 326).\\n336Chapter 8 DEEP LEARNING\\n[29] J. Ziv and N. Merhav . ‘A measure of relative entropy between individual se-\\nquences with application to universal classiﬁcation’. In: IEEE T ransactions on In-\\nformation Theory 39(4) (1993), pp. 1270–1279 (cit. on pp. 245, 298).\\n337REFERENCES\\n338PRACTICE EXAM\\nPART VCHAPTER\\n9\\nJOB INTER VIEW MOCK EXAM\\nA man who dares to waste one hour of time has not discovered the value of life.\\n— Charles Darwin\\nContents\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nClassiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nStressful events, such as a job interview, prompt concern and anxiety (as they do for\\nvirtually every person), but it’s the lack of preparation that fuels unnecessary nervous-\\nness. Many perceive the interview as a potentially threatening event. Testing your\\nknowledge in AI using a mock exam, is an effective way to not only identifying your\\nweaknesses and to pinpointing the concepts and topics that need brushing up, but\\nalso to becoming more relaxed in similar situations. Remember that at the heart of job\\ninterview conﬁdence is feeling relaxed.\\nDoing this test early enough, gives you a head-start before the actual interview, so\\nthat you can target areas that require perfection. The exam includes questions from\\na wide variety of topics in AI, so that these areas are recognised and it would then\\nbe a case of solving all the problems in this book over a period of few months to be\\nproperly prepared. Do not worry even if you can not solve any of the problems in the\\nexam as some of them are quite difﬁcult.DEEP LEARNING JOB INTER VIEW MOCK EXAM\\nEXAM INSTRUCTIONS :\\nYOU SHOULD NOT SEARCH FOR SOLUTIONS ON THE WEB . M ORE GENERALLY , YOU\\nARE URGED TO TRY AND SOLVE THE PROBLEMS WITHOUT CONSULTING ANY REFER -\\nENCE MATERIAL , AS WOULD BE THE CASE IN A REAL JOB INTERVIEW .\\n9.0.1 Rules\\nREMARK: In order to receive credits, you must:\\ni Show all work neatly .\\nii A sheet of formulas and calculators are permitted but not notes or texts.\\niii Read the problems CAREFULLY\\niv Do not get STUCK at any problem (or in local minima ...) for too much time!\\nv After completing all problems, a double check is STRONGLY advised.\\nvi You have three hours to complete all questions.\\n342Chapter 9 JOB INTER VIEW MOCK EXAM\\n9.1 Problems\\n9.1.1 Perceptrons\\nPRB-267 \\uf059 CH.PRB- 9.1. [PERCEPTRONS]\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 9.1: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the resulting value from the application of the sum operator?\\n3. Using PyT orch tensors, verify the correctness of your answers.\\n9.1.2 CNN layers\\nPRB-268 \\uf059 CH.PRB- 9.2. [CNN LAYERS]\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and examine its behaviour during inference:\\n3439.1. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 9.',\n",
              " ' PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 9.1: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n344Chapter 9 JOB INTER VIEW MOCK EXAM\\nFIGURE 9.2: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet\\na second MaxPool2D(2,2). What is the resulting tensor shape after running line 9?\\nand line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\n9.1.3 Classification, Logistic regression\\nPRB-269 \\uf059 CH.PRB- 9.3. [CLASSIFICATION, LR]\\nT o study factors that affect the survivability of humans infected with COVID19 using\\nlogistic regression, a researcher considers the link between lung cancer and COVID19 as a\\n3459.1. PROBLEMS\\nplausible risk factor. The predictor variable is a count of removed pulmonary nodules (Fig.\\n9.3) in the lungs.\\nFIGURE 9.3: Pulmonary nodules.\\nThe response variable Y measures whether the patient shows any remission (as in the\\nmanifestations of a disease, e. g. yes=1, no=0) when the pulmonary nodules count shifts up\\nor down. The output from training a logistic regression classiﬁer is as follows:\\nStandard\\nParameter DF Estimate Error\\nIntercept 1 -4.8792 1.0732\\nPulmonary nodules 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of removed pulmonary nod-\\nules of a patient is 33.\\n2. Find out the removed pulmonary nodules count at which the estimated probability of\\nimprovement is 0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1, in the total\\nremoved pulmonary nodule count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total removed pulmonary nodule count. Remember that The most common\\nconﬁdence levels are 90%, 95%, 99%, and 99.9%.\\n346Chapter 9 JOB INTER VIEW MOCK EXAM\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 9.1: Common conﬁdence levels\\nT able9.1 lists the z values for these levels.\\n9.1.4 Information theory\\nPRB-270 \\uf059 CH.PRB- 9.4. [INFORMATION THEORY]\\nThis question discusses the link between binary classiﬁcation, information gain and\\ndecision trees. Recent research suggests that the co-existence of inﬂuenza (Fig. 9.4) and\\nCOVID19 virus may decrease the survivability of humans infected with the COVID 19\\nvirus. The data (T able 9.2) comprises a training set of feature vectors with corresponding\\nclass labels which a researcher intents classifying using a decision tree.\\nT o study factors affecting COVID19 eradication, the deep-learning researcher collects\\ndata regrading two independent binary variables; θ1 (T/F) indicating whether the patient is\\na female, and θ2 (T/F) indicating whether the human tested positive for the inﬂuenza virus.\\nThe binary response variable, γ, indicates whether eradication was observed (e.g. eradica-\\ntion=+, no eradication=-).\\n3479.1. PROBLEMS\\nFIGURE 9.4: The inﬂuenza virus.\\nReferring to T able ( 9.2), each row indicates the observed values, columns ( θi) denote\\nfeatures and rows (< θ i, γi >) denote labelled instances while class label ( γ) denotes whether\\neradication was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 9.2: Decision trees and the COVID19 virus.\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\n348Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-271 \\uf059 CH.PRB- 9.5.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh) + p(xt) = 1 , what is the\\nformula for the average surprise?\\n6. What is the value of the average surprise in bits?\\nPRB-272 \\uf059 CH.PRB- 9.6.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\n9.1.5 Feature extraction\\nPRB-273 \\uf059 CH.PRB- 9.7. [FEATURE EXTRACTION]\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n3499.1. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 9.5: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\nCODE 9.2: An unknown algorithm in C++11\\n1 void xxx(std::vector<float>& arr){\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nWhich results in this vector ( 9.6):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 9.6: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n350Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-274 \\uf059 CH.PRB- 9.8.\\n[FEATURE EXTRACTION]\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture for the classiﬁcation of the COVID19 pathogen. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with it\\nby utilizing the same logic.\\nIn (Fig. 9.7), 2 different classes of human cells are displayed; infected and not-infected,\\nwhich were curated from a dataset of 4K images labelled by a majority vote of two expert\\nvirologists. Y our task is to use FE to correctly classify the images in the dataset.\\nFIGURE 9.7: A dataset of human cells infected by the COVID19 pathogen.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture. As depicted,\\nfor each layer the number of ﬁlters (i. e. neurons with unique set of parameters), learnable\\nparameters (e. g. weights and biases), and FV size are presented.\\n3519.1. PROBLEMS\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 9.3: Incomplete listing of the of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4k images from the dataset, how can\\nyou now classify the images into their respective categories?\\n9.1.6 Bayesian deep learning\\nPRB-275 \\uf059 CH.PRB- 9.9. [BAYESIAN DEEP LEARNING]\\nA recently published paper presents a new layer for Bayesian neural networks (BNNs).\\nThe layer behaves as follows. During the feed-forward operation, each of the hidden neurons\\nHn , n ∈ { 1, 2, } in the neural network in (Fig. 9.8) may, or may not ﬁre, independently\\nof each other, according to a known prior distribution.\\n352Chapter 9 JOB INTER VIEW MOCK EXAM\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 9.8: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ B(n, γ ) random variable and ﬁres\\nwith a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U (0, γ) random variable and ﬁres\\nwith a probability of γ.\\nPRB-276 \\uf059 CH.PRB- 9.10.\\nDuring pregnancy, the Placenta Chorion T est is commonly used for the diagnosis of\\nhereditary diseases (Fig. 9.9).\\nFIGURE 9.9: Foetal surface of the placenta\\nAssume, that a new test entitled the Placenta COVID19 T est has the exact same proper-\\nties as the Placenta Chorion T est. The test has a probability of 0.95 of being correct whether\\nor not a COVID19 pathogen is present. It is known that 1/100 of pregnancies result in\\n3539.1. PROBLEMS\\nCOVID19 virus being passed to foetal cells. Calculate the probability of a test indicating\\nthat a COVID19 virus is present.\\nPRB-277 \\uf059 CH.PRB- 9.11.\\nA person who was unknowingly infected with the COVID19 pathogen takes a walk in\\na park crowded with people. Let y be the number of successful infections in 5 independent\\nsocial interactions or infection attempts (trials), where the probability of “success\" (infecting\\nsomeone else) is θ in each trial. Suppose your prior distribution for θ is as follows: P (θ =\\n1/2) = 0 .25, P (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y).\\n2. Derive the prior predictive distribution for y.\\nPRB-278 \\uf059 CH.PRB- 9.12.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history with a death tool far exceeding all past\\noutbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976 in\\nSudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 9.10: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the centre for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\n354Chapter 9 JOB INTER VIEW MOCK EXAM\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y,\\nγ ∈ [0, 1], y = 1, 2, . . . , n ,\\n(9.1)\\nwhere: \\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 = n!\\n(n − y)!y!. (9.2)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ, the\\nproportion of infected humans in the entire population.\\nThe expectation and variance of the binomial are:\\nE(y|γ, n) = nγ, , V (y|γ, n) = nγ(1 − γ). (9.3)\\nAnswer the following:\\n1. For the likelihood function of the form lx(γ) = log Lx(γ) what is the log-likelihood\\nfunction?\\n2. Find the log-likelihood function ln (L(γ))\\n3. Find the gradient vector g(γ)\\n4. Find the Hessian matrix H(γ)\\n5. Find the Fisher information I(γ)\\n6. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\n3559.1. PROBLEMS\\n356VOLUME TWO\\nPART VICHAPTER\\n10\\nVOLUME TWO - PLAN\\nNothing exists until it is measured.\\n— Niels Bohr, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nV ariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . 36110.1. INTRODUCTION\\nT ext to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\n10.1 Introduction\\nI\\nT is important at the outset to understand we could not possibly include\\neverything we wanted to include in the ﬁrst VOLUME of this series. While\\nthe ﬁrst volume is meant to introduce many of the core subjects in AI, the\\nsecond volume takes another step down that road and includes numerous,\\nmore advanced subjects. This is a short glimpse into the plan for VOLUME-2 of this\\nseries. This second volume focuses on more advanced topics in AI\\n10.2 AI system design\\n10.3 Advanced CNN topologies\\n10.4 1D CNN’s\\n10.5 3D CNN’s\\n10.6 Data augmentations\\n10.7 Object detection\\n10.8 Object segmentation\\n10.9 Semantic segmentation\\n10.10 Instance segmentation\\n10.11 Image classification\\n10.12 Image captioning\\n10.13 NLP\\n360Chapter 10 VOLUME TWO - PLAN\\n10.14 RNN\\n10.15 LSTM\\n10.16 GANs\\n10.17 Adversarial attacks and defences\\n10.18 Variational auto encoders\\n10.19 FCN\\n10.20 Seq2Seq\\n10.21 Monte carlo, ELBO, Re-parametrization\\n10.22 Text to speech\\n10.23 Speech to text\\n10.24 CRF\\n10.25 Quantum computing\\n10.26 RL\\n36110.26. RL\\n362List of Tables\\nTumour eradication statistics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\nCommon conﬁdence levels. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nTumour shrinkage in rats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nProbability values of hereditary-disease detection. . . . . . . . . . . . . . . . . 67\\nDecision trees and frogs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\\nDecision trees and Cannabinoids administration . . . . . . . . . . . . . . . . . 96\\nDecision trees and star expansion. . . . . . . . . . . . . . . . . . . . . . . . . . 97\\nDecision trees and radiation therapy . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nSplitting on θ2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . 169\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute\\n∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\\nImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches. . . 193\\nIncomplete listing of the VGG19 architecture . . . . . . . . . . . . . . . . . . . 209\\nIncomplete listing of the VGG11 architecture. . . . . . . . . . . . . . . . . . . . 265\\nComputed values for the Sigmoid and the Sigmoid approximation. . . . . . . 310\\nCommon conﬁdence levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nDecision trees and the COVID19 virus. . . . . . . . . . . . . . . . . . . . . . . . 348\\nIncomplete listing of the of the VGG19 architecture . . . . . . . . . . . . . . . . 352LIST OF TABLES\\n364List of Figures\\nExamples of two sigmoid functions. . . . . . . . . . . . . . . . . . . . . . . . . 15\\nPulmonary nodules (left) and breast cancer (right). . . . . . . . . . . . . . . . . 16\\nA multi-detector positron scanner used to locate tumours. . . . . . . . . . . . 18\\nA dental amalgam. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nA chain of spherical bacteria. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nCannabis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nLogistic regression in CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nA linear model in PyTorch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 25\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 26\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds vs. probability values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\nBinary entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nLogistic regression in C++ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nHistopathology for pancreatic cancer cells. . . . . . . . . . . . . . . . . . . . . 44\\nBosons and fermions: particles with half-integer spin are fermions. . . . . . . 46\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe Dercum disease . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe New York Stock Exchange. . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\nHedge funds and monkeys. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nDialect detection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nThe Morse telegraph code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nOnOffLayer in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 57\\nThe Maxwell-Boltzmann distribution. . . . . . . . . . . . . . . . . . . . . . . . 58\\nA QuantumDrop layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nThe binomial distribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nZ-score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62LIST OF FIGURES\\nConditional probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\nV enn diagram of the intersected events A and B in probability space H . . . . 63\\nAnnotated components of the Bayes formula (eq. 3.23) . . . . . . . . . . . . . . 64\\nMutual information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nReﬂection on the motive power of ﬁre. . . . . . . . . . . . . . . . . . . . . . . . 87\\nNatural (ln), binary (log2) and common ( log10) logarithms. . . . . . . . . . . . . 88\\nA Frog in its natural habitat. Photo taken by my son. . . . . . . . . . . . . . . . 95\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\\nShannon\\'s ﬁve element communications system. . . . . . . . . . . . . . . . . . 99\\nAn octahedral dice. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in information theory . . . . . . . . . . . . . . . . . . . . . . . . . . 102\\nH vs. Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\nShannon information gain for a biased coin toss. . . . . . . . . . . . . . . . . . 107\\nAverage surprise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nFirst split. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nMutual Information between H(S) & H(D). . . . . . . . . . . . . . . . . . . . . 117\\nIntermediate value theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nA Computation graph with intermediate values as nodes and operations as\\narcs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nx2 Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\\nForward pass for the sigmoid function. . . . . . . . . . . . . . . . . . . . . . . . 135\\nPyTorch syntax for autograd. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 137\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 139\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 140\\nA computation graph for g(x) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nA Tangent line . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\n366Chapter 10 LIST OF FIGURES\\nForward and backward passes for the sigmoid activation function in pure\\nPython. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\\nForward and backward for the sigmoid function in Autograd. . . . . . . . . . 159\\nForward and backward for the ReLU function in Autograd. . . . . . . . . . . . 160\\nForward pass for equation ( 5.23) using pure Python. . . . . . . . . . . . . . . . 161\\nForward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . . 161\\nBackward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nInvoking arctanh using gradcheck . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nA Computation graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . 168\\nA derivative graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . . . 169\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 170\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 172\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSymPy gradient of the Sigmoid() function . . . . . . . . . . . . . . . . . . . . . 174\\nSymPy imports . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\\nLikelihood function using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . 176\\nBeta distribution using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\nA plot of the Posterior with the provided data samples. . . . . . . . . . . . . . 181\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 191\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 194\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 195\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 196\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 197\\nA learning rate schedule. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\n367LIST OF FIGURES\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depic-\\nted is the ResNet CNN architecture with 34 layers. . . . . . . . . . . . . . 206\\nPyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 206\\nA dataset of 4K histopathology WSI from three severity classes: A, B and C. . 209\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\\nSkin lesion categories. An exemplary visualization of melanoma. . . . . . . . 214\\nArtistic style transfer using the style of Francis Picabia’s Udnie painting. . . . 215\\nPyTorch declaration for a pre-trained ResNet34 CNN. . . . . . . . . . . . . . . 216\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\\nTwo CV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nStratiﬁed K-fold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nA speciﬁc CV approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\nA padding approach . . . . . . . . . . . .',\n",
              " ' . . . . . . . . . . . . . . 221\\nTwo CV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nStratiﬁed K-fold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nA speciﬁc CV approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 239\\nA 3 by 3 convolution kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 240\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 242\\nlisting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nAn unknown algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\\nJaccard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nA basic MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\n368Chapter 10 LIST OF FIGURES\\nA single layer perceptron. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nExamples of two sigmoid functions and an approximation. . . . . . . . . . . . 254\\nForward pass for the Sigmoid function using Libtorch . . . . . . . . . . . . . . 255\\nEvaluation of the sigmoid and its derivative using Libtorch . . . . . . . . . . . 255\\nExamples of two tanh functions. . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nA simple NN based on tanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 257\\nA small CNN composed of tanh blocks. . . . . . . . . . . . . . . . . . . . . . . 258\\nA small CNN composed of ReLU blocks. . . . . . . . . . . . . . . . . . . . . . 259\\nA confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 261\\nRUC AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\\nXGBOOST for binary classiﬁcation. . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics on the VGG11 CNN model. . . . . . . . . . . . . . . . . . . . 264\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nTwo consecutive Dropout layers . . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nA CNN based classiﬁcation system. . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nA small ﬁlter for a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nInput to MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . . . . 271\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 273\\nNormal distribution in Python. . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nA convolution and BN applied to an RGB image. . . . . . . . . . . . . . . . . . 275\\nA mistake in a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\\nA validation curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog-loss function curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\\nA problem with the log-loss curve. . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nManhattan distance function. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\n369LIST OF FIGURES\\nThe idea of hashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301\\nMLP operations- values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\\nHidden layer values, simple MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- values at the output. . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- Softmax. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\\nLogical AND: B=-2.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND: B=-0.25 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nBackward pass for the Sigmoid function using Libtorch. . . . . . . . . . . . . . 307\\nEvaluation of the sigmoid and its derivative in C++ using Libtorch. . . . . . . 308\\nForward pass for the Sigmoid function approximation in C++ using Libtorch. 309\\nPrinting the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\\nForward pass for tanh using pure Python. . . . . . . . . . . . . . . . . . . . . . 311\\nTanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\\nInvoking gradcheck on tanh. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313\\nA plot of the Swish activation function. . . . . . . . . . . . . . . . . . . . . . . 315\\nTP , TN, FP , FN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 317\\nConvolutional block from the VGG11 architecture. . . . . . . . . . . . . . . . . 319\\nEquivalence of two consecutive dropout layers . . . . . . . . . . . . . . . . . . 321\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nThe result of applying a ReLU activation. . . . . . . . . . . . . . . . . . . . . . 322\\nThe result of applying a MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . 322\\nOutput of the MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . 323\\nA single MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324\\nNormal distribution in Python: from scratch. . . . . . . . . . . . . . . . . . . . 325\\nThe derivative of a Normal distribution in Python. . . . . . . . . . . . . . . . . 325\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nSeveral image augmentation methods for TTA. . . . . . . . . . . . . . . . . . . 331\\nManhattan distance function in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 334\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 345\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346\\n370Chapter 10 LIST OF FIGURES\\nThe inﬂuenza virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 350\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\\nA dataset of human cells infected by the COVID19 pathogen. . . . . . . . . . . 351\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354\\n371LIST OF FIGURES\\n372Alphabetical Index\\nA\\nA 2D convolution . . . . . . . . . . . . . . . . . .235\\nA 512 dimension embedding . . . . . . . 206\\nA mathematical theory of\\ncommunication . . . . . . . . . . . . . 90\\nA random forest . . . . . . . . . . . . . . . . . . . 187\\nACC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .329\\nAccuracy . . . . . . . . . . . . . . . . .251, 283, 329\\nActivation functions . 125, 135 ff., 139 ff.,\\n157 f., 160, 163, 165, 168, 248,\\n256, 301, 306\\nActivation layer . . . . . . . . . . . . . . .253, 306\\nAD . . . . . . . . . . . . . . . . .123 f., 137, 140, 166\\nAdam . . . . . . . . . . . . . . . . . . . . . . . . . . . . .330\\nAdditivity property . . . . . . . . . . . . . . . .103\\nAlexNet . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nAlgorithmic differentiation . . . .125, 135,\\n137, 139 ff., 146, 157 f., 160, 163,\\n165, 168\\nAlzheimer’s disease . . . . . . . . . . . . . . . . . 20\\nAmalgam ﬁllings . . . . . . . . . . . . . . . . . . . 18\\nAnalytical gradients . . . . . . . . . . . . . . . 134\\nAnalyze a paper . . . . . . . . . . . . . . . . . . . 260\\nAND logic gate . . . . . . . . . . . . . . . . . . . . 252\\nANN . . . . . . . . . . . . . . . . . . . . . . . . . . .15, 135\\nAnnotated probabilities . . . . . . . . . . . . .62\\nAnnotations . . . . . . . . . . . . . . . . . . . . . . .282\\nANNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\\nANOV A . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nApproaches for combining predictors\\n190, 199\\nArithmetic operations . . . . . . . . . 138, 163\\nArithmetical methods . . . . . . . . . . . . . . .41\\nArtiﬁcial neural networks . . . . . . . 12, 15\\nAUC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nAugmentation . . . . . . . . . . . . . . . . . . . . .222\\nAugmentations . . . . . . . . . . . . . . . . . . . . . . 8\\nAuto correlation . . . . . . . . . . . . . . .235, 291\\nAutoAugment . . . . . . . . . . . . . . . . . . . . .223\\nAutoencoder . . . . . . . . . . . . . . . . . .279, 326\\nAutoGrad . . . . . . . . . . . . . . . . . . . . .158, 173\\nAutograd124 f., 135–141, 157 f., 160, 163,\\n165, 168, 310\\nAutomatic differentiation . . . .123 f., 173\\nAveraging and majority voting . . . . .202\\nB\\nBack-propagation in perceptrons . . 249,\\n301\\nBack-propogation . . . . . . . . . . . . . . . . . .247\\nBackprop learning . . . . . . . . . . . . . . . . .134\\nBackprop learning rule . . . . . . . . . . . . 134\\nBackpropagation . . . . . . . . . 123, 134, 158\\nBackpropagation algorithm . . . 135, 156\\nBackward pass125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nBagging . . . . . . . . . . . . . .186, 189, 193, 198\\nBasic laws of logarithms . . . . . . . . . . . . 88\\nBatch normalization . . . . . . . . . . .273, 324\\nBatchNorm2D . . . . . . . . . . . . . . . . 271, 343\\nBayes formulae . . . . . . . . . . . . . . . . . .45, 64\\nBayes rule . . . . . . . . . . . . . 45, 47, 66, 353 f.ALPHABETICAL INDEX\\nBayes theorem . . . . 42, 46–50, 65 f., 68 ff.\\nBayesian . . . . . . . . . . . . . . . . . . . . . . . . . . . .77\\nBayesian analysis . . . . . . . . . . . . . . . .65, 77\\nBayesian approximation . . . . . . . . . . . 192\\nBayesian deep learning . . . . . 55, 77, 352\\nBayesian dropout . . . . . . . . . . . . . . . . . .352\\nBayesian inference . . . . . . . . . . . . . . .42, 45\\nBayesian machine learning . . . . . . . . . .54\\nBayesian neural networks . . . . . .55 f., 79\\nBayesian paradigm . . . . . . . . . . . . . . . . . 42\\nBayesian statistical conclusions . . . . . 65\\nBayesian statistics . . . . . . . . . . . . . . . 42, 65\\nBernoulli . . . . . . . . . . . . . . . . . . . . . . .75, 277\\nBernoulli distribution . . . . . . . . . . . . . . .53\\nBernoulli random variable . . . . . . . . . . 18\\nBernoulli trial . . . . . . . . . . . . . . 42 f., 59, 62\\nBeta binomial . . . . . . . . . . . . . . . . . . . . . .146\\nBeta binomial distribution . . . . . . . . .54 f.\\nBeta distribution . . . . . . . 42, 55, 146, 176\\nBeta prior . . . . . . . . . . . . . . . . . . . . . . . . . . .55\\nBias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .282\\nBiased coin . . . . . . . . . . . . . . . . . . . . .92, 349\\nBiased coin toss . . . . . . . . . . . . . . . . . 64, 92\\nBiases . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nBinary class . . . . . . . . . . . . . . . . . . . . . . . . .38\\nBinary classiﬁcation 12, 15, 96, 137, 190,\\n193 f., 246\\nBinary code . . . . . . . . . . . . . . . . . . . . . . . . .90\\nBinary logistic regression . . . . . . . . 14, 31\\nBinary options . . . . . . . . . . . . . . . . . . . . 48 f.\\nBinary response . . . . . . . . . . . . . . . . . . . . .14\\nBinary response variable . . . . . 19, 94, 97\\nBinomial . . . . . . . . . . . . . . . . . . . .43, 53, 354\\nBinomial distribution31, 43, 52 f., 55, 59,\\n78\\nBinomial likelihood . . . . . . . . . . . . 54, 178\\nBinomial random variable . . . . . 43, 59 f.\\nBlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .318\\nBN . . . . . . . . . . . . . . . . . . .273 f., 277, 324 ff.\\nBNN . . . . . . . . . . . . . . . . . . . . . . . . . . 55 f., 79\\nBNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nBohm and Hiley . . . . . . . . . . . . . . . . . . . . 87\\nBoltzmann . . . . . . . . . . . .58, 86, 100 f., 118\\nBoltzmann entropy . . . . . . . . . . . . . . . . 118\\nBoltzmann’s constant . . . . . . . . . . . . . . 100\\nBoltzmanns entropy . . . . . . . . . . . . . . . 101\\nBoosting . . . . . . . . .186, 189, 193, 198, 200\\nBootstrap aggregation . . . . . . . . .189, 192\\nBosons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nBosons and fermions . . . . . . . . . . . . . . . .46\\nBottleneck . . . . . . . . . . . . . . . . . . . . 279, 326\\nBrazilian rain forest . . . . . . . . . . . . . . . . .94\\nBreast cancer . . . . . . . . . . . . . . . . . . . . . . . 17\\nC\\nCalculus . . . . . . . . . . . . . . . . .80, 122 f., 143\\nCalculus in deep learning . . . . . . . . . . 123\\nCancer . . . . . . . . . . . . . . . . . . . . . .16, 43, 208\\nCannabinoids . . . . . . . . . . . . . . . . . . . . . . .96\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . .96\\nCDC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354\\nCE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nChain of spherical bacteria . . . . . . . . . . 20\\nChain rule . . . . . . . . . . . . . . . . . . . . . . . . .163\\nChaotic distribution . . . . . . . . . . . . . . . . 38\\nCI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .35\\nClass probabilities . . . . . . . . . . . . .190, 199\\nClassic bagging . . . . . . . . . . . . . . . . . . . .199\\nClassic logistic regression . . . . . . . . . . . 35\\nClassic normalization . . . . . . . . . . . . . . .29\\nClassical committee machines . . . . . .189\\nClassical machine learning . . . . . . . . . 201\\nClassical probability . . . . . . . . . . . . . . . . 42\\n374Chapter 10 ALPHABETICAL INDEX\\nClassiﬁcation . . . . . 32, 206, 208, 289, 345\\nClassiﬁcation and information gain . 94,\\n110\\nClaud Shannon . . . . . . . . . . . . . . . . . . . . .90\\nCM . . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nCNN . . . 8, 190, 192, 205 f., 216, 272, 274,\\n318, 326, 344, 349\\nCNN arithmetics . . . . . . . . . . . . . . . . . . 318\\nCNN as Fixed Feature Extractor . . . 206,\\n216\\nCNN classiﬁers . . . . . . . . . . . . . . . . . . . .192\\nCNN feature extraction . . . . . . . . . . . . 206\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . .343\\nCNN model predictions . . . . . . . . . . . 190\\nCNN parameters . . . . . . . . . . . . . . . . . . 207\\nCNN residual blocks . . . . . . . . . . . . . . .326\\nCoefﬁcients . . . . . . . . . . . . . . . . . . 12, 16, 27\\nCoffee consumption . . . . . . . . . . . . . . . . 36\\nCoin toss . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nCoin toss probabillity . . . . . . . . . . . . . . . 93\\nCommon conﬁdence levels . . . . . . . . . .21\\nComplementary probability . . . . . . . . .63\\nComputational graph . . . . . . . . . . . . . .140\\nComputational graphs . . 127, 140 f., 165,\\n168\\nConcave . . . . . . . . . . . . . . . . . . . . . . 154, 202\\nConcave and Convex functions . . . . 101\\nConcavity . . . . . . . . . . . . . . . . . . . . .106, 154\\nConcavity of the logarithm . . . . . . . . 106\\nConditional entropy . . . . . . . . . . . . . . . 118\\nConditional independence . . . . . . . . . . 66\\nConditional probability42, 44–50, 62, 69\\nConﬁdence intervals . . . . . . . . . . . . . . . . 37\\nConfusion matrics . . . . . . . . . . . . .261, 316\\nConfusion matrix . . . . . . . . . . . . . . . . . .316\\nConjugate prior . . . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . .54 f., 77\\nContent loss . . . . . . . . . . . . 214, 216, 224 f.\\nConv2D . . . . . . . . . . . . . . . . . . . . . . .271, 343\\nConv2d layer . . . . . . . . . . . . . . . . . . . . . .223\\nConv4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nConvex . . . . . . . . . . . . . . . . . . . . . . . 132, 202\\nConvex down function . . . . . . . . . . . . 119\\nConvex functions . . . . . . . . . . . . . . . . . .132\\nConvNet’s as ﬁxed feature extractors\\n206\\nConvolution . . . . . . . . . . . . . .234, 277, 291\\nConvolution and correlation in python\\n294\\nConvolution complexity . . . . . . . . . . . 240\\nConvolution layer . . . . . . . . . . . . .268, 321\\nConvolutional layer . . . . . . . . . 268, 321 f.\\nConvolutional neural network . . . . . . . 8\\nConvolutional neural networks192, 198\\nCorrelation . . . . . . . . . . . . . . . . . .234 f., 291\\nCost . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nCost function . . . . . . . . . . . . . . . . . . . . . .247\\nCovariance . . . . . . . . . . . . . . . . . . . . . . . .189\\nCovariates . . . . . . . . . . . . . . . . . . . . . . . . . .17\\nCOVID19 . . . . . . . . . . . . . . . . . . . . .345, 351\\nCPP 23 f., 38 f., 142 f., 168 f., 242 f., 254 f.,\\n307 ff.\\nCPP hypothesis . . . . . . . . . . . . . . . . . . . . .23\\nCPU . . . . . . . . . . . . . . . . . . . . . . . . . .222, 289\\nCPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\nCross correlation . . . . . . . . . . . . . .235, 291\\nCross entropy . . . . . . . . . . . . . . . . 25 f., 251\\nCross entropy loss . . . . . . . . . . . . .214, 251\\nCross validation . . . . . . . . . . 231, 289, 328\\nCross validation approaches . . .231, 289\\nCUDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . .289\\nCV . . . . . . . . . . . . . . . . . . . . . . . . . . . .231, 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . 289\\n375ALPHABETICAL INDEX\\nD\\nDAG . . . . . . . . . . . . . . . . .123, 126, 141, 168\\nData Science . . . . . . . . . . . . . . . . . . . . . . . . .4\\nDecision boundary . . . . . . . . . . . . . . . . . .14\\nDecision tree . . . 94 f., 97 f., 111, 187, 198\\nDecision trees . . . . . . . . . . . . . 94, 96 f., 348\\nDecision trees and cannabinoids\\nadministration . . . . . . . . . . . . . . 96\\nDeep Learning . . . . . . . . . . . . . . . . . . . . . . .4\\nDeep learning . . . . . 22, 77, 123, 196, 352\\nDeep Learning Job Interviews . . . . . . . . 6\\nDeep learning pipelines . . . . . . . . . . . .221\\nDental amalgam . . . . . . . . . . . . . . . . . . . .19\\nDercum disease . . . . . . . . . . . . . . . . . . . . .47\\nDifferentiation . . . . . . . . . .122, 143 f., 150\\nDifferentiation in deep learning . . . . 123\\nDirect derivation . . . . . . . . . . . . . . . . . . . .32\\nDirected Acyclic Graph . . . . . . . . . . . . 168\\nDirected acyclic graph . . . . . . . . . . . . . 141\\nDirected acyclic graphs . . . . . . . .126, 147\\nDirectional derivative . . . . . . . . . . . . . .131\\nDirectional derivatives . . . . . . . . . . . . .125\\nDistribution . . . . . . . . . . . . . . . . . . . . . . . . 45\\nDL . . . . . . . . . . . . . . 123, 196, 206, 221, 352\\nDL classiﬁcation pipeline . . . . . . . . . . . 91\\nDL job interviews . . . . . . . . . . . . . . . . . .206\\nDN . . . . . . . . . . . . . . . . . . . . . . . . . .138 f., 163\\nDouble reading . . . . . . . . . . . . . .282 f., 329\\nDPN CNN . . . . . . . . . . . . . . . . . . . . . . . . .223\\nDropout8, 57, 267 f., 277, 319 f., 326, 352\\nDropout as a bayesian approximation\\n192\\nDropout in PyTorch . . . . . . . . . . . . . . . . .56\\nDropout layer . . . . . . . . . . 57, 267 f., 319 f.\\nDropped out neurons . . . . . . . . . . . . . . . 57\\nDual numbers . . . . . . . . . .138 ff., 163, 165\\nDual numbers in AD . . . . . . . . . . 138, 163\\nE\\nEbola . . . . . . . . . . . . . . . . . . . . . . . . .53, 354 f.\\nEmbedding . . . . . . . . . . . . . . . . . . . . . . . .206\\nEncoded messages . . . . . . . . . . . . . . . . . .51\\nEncrypted communications . . . . . . . . . 50\\nEnigma machine . . . . . . . . . . . . . . . . . . . .50\\nEnsemble averaging . . . . . . . . . . . . . . . 193\\nEnsemble learning . . . . . . . .186, 194, 201\\nEnsemble methods . . . . . . . . . . . . 190, 195\\nEnsembling . . . . . .186 ff., 190, 194 f., 197\\nEntropy 22, 38, 86 f., 89, 93, 95, 97 f., 106,\\n108, 214, 349\\nEntry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .186\\nEpidemic . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nEquiprobable events . 90 f., 103, 105, 118\\nEquiprobable sample . . . . . . . . . . . . . . 189\\nEquivocation . . . . . . . . . . . . . . . . . . . . . . . 99\\nEradication . . . . . . . . . . . . . . . . . . . . . . . .347\\nEradication probabillity . . . . . . . . . . . . .18\\nEuclidean . . . . . . . . . . . . . . . . . . . . .288, 333\\nExpansion of stars . . . . . . . . . . . . . . . . . . 97\\nExpectation . . . . . . . . . . . . . . . . . . . . . . . . .62\\nExpectation and variance . . . . . . . . 42, 59\\nExplanatory variable . . . . . . . . . . . . . . . .17\\nExponential family . . . . . . . . . . . . . . . . . .78\\nF\\nFc7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nFeature extraction 214 f., 224 f., 349, 351\\nFeature vector . . . . . . . . . . . . . . . . .205, 350\\nFeature vectors . . . . . . . . . . . . . . . . . . . . . 96\\nFeed forward neural networks 135, 158\\nFermions . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nFFNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\n376Chapter 10 ALPHABETICAL INDEX\\nFiltering . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nFiltering kernel . . . . . . . . . . . . . . . . . . . . 234\\nFilters . . . . . . . . . . . . . . . . . . . . . . . . .239, 293\\nFinancial mathematics . . . . . . . . . . . . . . 42\\nFine tuning CNNs . . . . . . . . . . . . 213, 222\\nFinite difference rule . . . . . . . . . . 125, 147\\nFisher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nFisher information . . . . . . . . . 51, 53, 73 f.\\nFisher score . . . . . . . . . . . . . . . . . . . . . . . . .73\\nFliping . . . . . . . . . . . . . . . . . . . . . . . . . . . .294\\nForward mode . . . . . . . . . .131, 140 f., 168\\nForward mode AD . 140 f., 163, 166, 168\\nForward mode AD table construction\\n142, 168\\nForward pass . 125',\n",
              " ' . . 213, 222\\nFinite difference rule . . . . . . . . . . 125, 147\\nFisher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nFisher information . . . . . . . . . 51, 53, 73 f.\\nFisher score . . . . . . . . . . . . . . . . . . . . . . . . .73\\nFliping . . . . . . . . . . . . . . . . . . . . . . . . . . . .294\\nForward mode . . . . . . . . . .131, 140 f., 168\\nForward mode AD . 140 f., 163, 166, 168\\nForward mode AD table construction\\n142, 168\\nForward pass . 125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nG\\nGausiian distribution . . . . . . . . . .241, 295\\nGaussian . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nGaussian bell . . . . . . . . . . . . . . . . . . . . . .241\\nGaussian distribution . . . . . . . . . 274, 324\\nGaussian PDF . . . . . . . . . . . . . . . . . . . . . 324\\nGeneral concepts . . . . . . . . . . . . . . . . 12, 27\\nGeneralization . . . . . . . . . . . . . . . . 186, 206\\nGeneralized delta rule . . . . . . . . . . . . . 135\\ngeneralized linear models . . . . . . . . . . .14\\nGLM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\\nGLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\nGPU . . . . . . . . . . . . . . . . .222, 281, 289, 327\\nGPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\ngradcheck . . . . . . . . . . . . . . . . . . . . . . . . .310\\nGradient . . . . . . . . . . . . . . . . . . . . . .130, 247\\nGradient descent 123, 130, 146, 158, 247\\nGradient descent algorithm . . . . . . . . 132\\nGradient descent and backpropagation\\n124\\nGradients . . . . . . . . . . . . . . . . . . . . . . . . . .222\\nGram matrix . . . . . . . . . . . . . . . . . . . . . . .225\\nGrid search . . . . . . . . . . . . . . . . . . . 282, 328\\nGum bacteria . . . . . . . . . . . . . . . . . . . . . . .20\\nGUR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\nH\\nHereditary disease . . . . . . . . . . . . . . . . . .66\\nHereditary diseases . . . . . . . . . . . . . . . . .47\\nHessian . . . . . . . . . . . . . . . . . . . . . . . . . . . . .74\\nHessian matrix . . . . . . . . . . . . . . . . . . . . . 52\\nHeterogeneous ensembling . . . .191, 200\\nHidden layer . . . . . . . . . . . . . . . . . . .78, 248\\nHidden layers . . . . . . . . . . . . . . . . . . . . . 250\\nHidden node . . . . . . . . . . . . . 248, 252, 343\\nHinton . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nHistopathology . . . . . . . . . . . .43, 217, 351\\nHuang1704snapshot . . . . . . . . . . . . . . .202\\nHuman voice activity . . . . . . . . . . . . . . . 31\\nHyperbolic tangent . . . . . . . . . . . . . . . . 134\\nHyperbolig tangent . . . . . . . . . . . . . . . .138\\nHyperparameter optimization . . . . . 282,\\n327 f.\\nHyperparameters . . . . . . . . . . . . . . . . . .328\\nHypotheis . . . . . . . . . . . . . . . . . . . . . . . . . .16\\nI\\nIdeal classiﬁer . . . . . . . . . . . . . . . . .262, 317\\nIdentity connection . . . . . . . . . . . . . . . . 326\\nImage analysis . . . . . . . . . . . . . . . . . . . . .110\\nImage and text similarity . . . . . . . . . . 296\\nImage processing . . . . . . . . . . . . . . . . . .234\\nImageNet . . . . . . . . . . . . . . . . . .206 f., 222 f.\\nImageNet pre trained CNNs . . . . . . . 213\\n377ALPHABETICAL INDEX\\nImageNet pretrained CNN classiﬁers\\n192\\nImproper prior . . . . . . . . . . . . . . . . . . . . . 54\\nIndependent binary co variates . . . . . 94\\nIndependent events . . . . . . . . . . . . . . . . .45\\nIndependent variables . . . . . . . . . . .19, 97\\nIndividual predictions . . . . . . . . . . . . . 192\\nInductive inference . . . . . . . . . . . . . . . . . 86\\nInference . . . . . . . . . . . . . . . . . . . . . .286, 330\\nInformation gain . . . . . . . . . . 94–98, 106 f.\\nInformation gain values . . . . . . . . . . . . .95\\nInformation matrix . . . . . . . . . . . . . . . . . 53\\nInformation theory . . . . . . . 58, 86, 88–93,\\n98–101, 106, 347\\nInteractions . . . . . . . . . . . . . . . . . . . . . . . . .13\\nIntermediate value theorem . . . . . . . .124\\nIntersected events . . . . . . . . . . . . . . . . . . .63\\nIntroduction . . . .12, 42, 86, 122, 186, 205\\nJ\\nJacard similarity . . . . . . . . . . . . . . . . . . .297\\nJAX . . . . . . . . . . . . . . . . . . . . . . . . . . .136, 158\\nJensen . . . . . . . . . . . . . . . . . . . . . . . . 101, 119\\nJensen’s inequality . . . . . . . . . . . . 101, 118\\nJob Interview . . . . . . . . . . . . . . . . . . . . . . . . 4\\nJohn von Neumann . . . . . . . . . . . . . . . . . 41\\nJoint distribution . . . . . . . . . . . . . . . . . . 110\\nJupyter notebook . . . . . . . . . . . . . . . . . . 143\\nK\\nK Fold cross validation . . . . . . . . . . . . 289\\nK way FC layer . . . . . . . . . . . . . . . . . . . . 217\\nK-Fold cross validation . . . . . . . . . . . . 232\\nKaggle . . . . . . . . . . . . . . . . . . . . . . . .186, 201\\nKaggle competitions . . . . . . . . . . . . . . .201\\nKaiming . . . . . . . . . . . . . . . . . . . . . . . . . . .258\\nKernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nKernels . . . . . . . . . . . . . . . . . . . . . . . 239, 293\\nKL divergence . . . . . . . .53, 93, 100 f., 109\\nKLD . . . . . . . . . . . . . . . . . . . . . . .93, 119, 297\\nKullback Leibler . . . . . . . . . . . . . . . . . . .297\\nKullback Leibler divergence 87, 93, 108\\nL\\nL1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288, 333\\nL2 . . . . . . . . . . . . . . . . . . . . . . . . . . .288, 333 f.\\nLabelling and bias . . . . . . . . . . . . . . . . . 328\\nLaTeX . . . . . . . . . . . . . . . . . . . . . . . . .174, 176\\nLaw of total probability42, 46–50, 66–70\\nLaws of data compression . . . . . . . . . . 86\\nLDCT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nLeaky ReLU . . . . . . . . . . . . . . . . . . . . . . .259\\nLearning logical gates . . . . . . . . . . . . . .305\\nLearning rate schedules in ensembling\\n197, 202\\nLeave one out CV . . . . . . . . . . . . . . . . . .290\\nLeave-one-out CV . . . . . . . . . . . . . . . . . 234\\nLibtorch . . . . . . . . . . . . . .254 f., 257, 307 ff.\\nLikelihood . . . . . . . . . . . . . . . . . . . .44 f., 353\\nLikelihood function . . . 51, 53, 56, 73, 79\\nLikelihood parameter . . . . . . . . . . . . . . .45\\nLimits and continuity . . . . . . . . . 130, 151\\nLinear classiﬁers . . . . . . . . . . . . . . . . . . .219\\nLinear combination of regression . . 201\\nLinear decision boundary . . . . . . . . . . . 14\\nLinear logistic regression model . . . . . 33\\nLinear model in PyTorch . . . . . . . . . . . .24\\nLinear regression . . . . . . . . . . . . . . . . . . 133\\nLinear transformation . . . . . . . . . . . . . 343\\nLinearity . . . . . . . . . . . . . . . . . . . . . . . . . . 235\\nLink function . . . . . . . . . . . . . . . . . . . . . . .31\\nLocal minima . . . . . . . . . . . . . . . . . 198, 202\\n378Chapter 10 ALPHABETICAL INDEX\\nLog likelihood . . . . . . . . . . . . . . . . . . . . . .13\\nLog likelihood function . . 51, 53, 73, 355\\nLog loss . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog odds . . . . . . . . . . . . 13 f., 17 f., 20 f., 29\\nLogarithm . . . . . . . . . . . . . . . . . . . 35, 53, 72\\nLogarithmic function . . . . . . . . . . . . . . 166\\nLogarithms . . . . . . . . . . . .88 f., 101 ff., 172\\nLogarithms in information theory . . . 87\\nLogic gate . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical gates . . . . . . . . . . . . . . . . . .251, 305\\nLogistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogistic inverse . . . . . . . . . . . . . . . . . . . . .14\\nLogistic regression 12–16, 24 ff., 28 f., 31,\\n36, 137, 345\\n• Sigmoid . . . . . . . . . . . . . . . . . . . . . .253\\nLogistic regression classiﬁer . . . . . . . . .19\\nLogistic regression coefﬁcients . . . . . . 16\\nLogistic regression implementation23 f.\\nLogistic regression in C++ . . . . . . . . . . 39\\nLogistic regression in Python . . . . . . . 26\\nLogistic regression model . . . . . . . .27, 35\\nLogistic regression predictor variable12\\nLogistic regression threashold . . . . . . .39\\nLogistic response function . . . . . . . . . . 33\\nLogit . . . . . . . . . . . . . . . . . . . . . . . . . . . .14, 32\\nLogit equation . . . . . . . . . . . . . . . . . . . . . .16\\nLogit function . . . . . . . . . . . . . . . .14, 22, 31\\nLogit inverse . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogit transformation . . . . . . . . . . . . . . . .14\\nLogit value . . . . . . . . . . . . . . . . . . . . . . . . . 33\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . .234, 290\\nLoss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .334\\nLoss function . . . . . . . . . . . . . . . . . . . . . .133\\nLow model generalization . . . . . . . . . 109\\nLow standard error . . . . . . . . . . . . . . . . . 75\\nLower entropy . . . . . . . . . . . . . . . . . . . . . .38\\nLR . . . . . . . . . . . . . 16, 27, 33, 133, 137, 345\\nLR coefﬁcients . . . . . . . . . . . . . . . . . . . . . .16\\nLung cancer . . . . . . . . . . . . . . . . . . . .17, 282\\nM\\nM.Sc in Artiﬁcial Intelligence . . . . . . . . . 4\\nMachine learning . . . . . . 13 f., 25, 28, 316\\nMachine learning terminology . . . . . . 13\\nMacLaurin expansion . . . . . . . . . . . . . .128\\nMacLaurin series . . . . . . . . . . . . . . . . .128 f.\\nMagna Carta . . . . . . . . . . . . . . . . . . . . . . . .90\\nMajority voting . . . . . . . . . . .186, 190, 202\\nMalignant tumour . . . . . . . . . . . . . . . . . . 17\\nMalignant tumours . . . . . . . . . . . . . . . . . 96\\nManhattan . . . . . . . . . . . . . . . . . . . .288, 333\\nManual differentiation . . . . . . . . 124, 170\\nMaster’s programme in Artiﬁcial\\nIntelligence . . . . . . . . . . . . . . . . . . .4\\nMasters programme . . . . . . . . . . . . . . . . . 4\\nMathJax . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nMaximum likelihood estimatator . . . .73\\nMaximum likelihood estimation . 51, 71\\nMaxpool2D . . . . . . . . . . . . . . . . . . .271, 343\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxwell Boltzmann distribution . . . . 57\\nMaxwell distribution . . . . . . . . . . . . . . . 58\\nMean ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .241\\nMean square error . . . . . . . . . . . . . . . . . 225\\nMeasurement vector . . . . . . . . . . . . . . . . 16\\nMechanical statistics . . . . . . . 42, 100, 118\\nMedical AI . . . . . . . . . . . . . . . . . . . . . . . . 217\\nMelanoma . . . . . . . . . . . . . . . . . . . . . . . . .213\\nMigraine probabillity . . . . . . . . . . . . . . . 20\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . .298\\nML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .316\\nMLE . . . . . . . . . . . . . . . . . . .51, 53, 72 f., 355\\nMLP . . . . . . . . . . . . . . .246 ff., 252, 299, 343\\n379ALPHABETICAL INDEX\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . .332\\nMonolithic and heterogeneous\\nensembling . . . . . . . . . . . .191, 200\\nMonolithic architectures . . . . . . . . . . . 200\\nMonolithic ensembling . . . . . . . . . . . . 191\\nMonotonically increasing function . . 72\\nMonte Carlo dropout . . . . . . . . . . . . . . 192\\nMSE . . . . . . . . . . . . . . . . . . . . . .225, 288, 333\\nMulti class responses . . . . . . . . . . . . . . . 29\\nMulti Layer Perceptrons . . . . . . . . . . . 246\\nMulti layer perceptrons . . . . . . . . . . . . 299\\nMulti model ensembling . . . . . . 196, 202\\nMulticlass classiﬁcation . . . . . . . . . . . . . 12\\nMulticlass classiﬁcation problems . . . 12\\nMultivariable . . . . . . . . . . . . . . . . . . . . . . .12\\nMultivariable methods . . . . . . . . . . . . . .12\\nMutual information . . .86, 94, 98 ff., 110,\\n116\\nMutual information formulae . . . . . . 117\\nN\\nN dimensional feature vector . . . . . . 205\\nNatural logistic function . . . . . . . . . . . . 14\\nNatural logistic sigmoid . . . . . . . . . . . . 14\\nNegative log likelihood . . . . . . . . . . . . . 13\\nNeural network . . . . . . . . . . . . . . .195, 202\\nNeural network ensembles . . . . 186, 191\\nNeural networks . . 55, 57, 127, 135, 158,\\n186\\nNeural style transfer . . . . . . . . . . . . . 214 f.\\nNeuron activation function . . . . . . . . . 15\\nNew York stock exchange . . . . . . . . . . .48\\nNLL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .13\\nNN . . . . . . . . . . 55, 127, 135, 158, 186, 202\\nNN Layers . . . . . . . . . . . . . . . . . . . . . . . . 318\\nNoise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99\\nNon convex neural networks . . . . . . 203\\nNon informative prior . . . . . . . . . . . . . . 54\\nNon informative priors . . . . . . . . . . . . . 77\\nNon interacting identical particles . 118\\nNon linearity . . . . . . . . . . . . . . . . . . . . . .301\\nNon-differentiable . . . . . . . . . . . . . . . . .301\\nNon-linearity . . . . . . . . . . . . . . . . . . . . . .248\\nNonlinear layer . . . . . . . . . . . . . . . 253, 306\\nNormal distribution . . . . . . . . . . .274, 324\\nNormalization constant . . . . . . . . . . . . .64\\nNST . . . . . . . . . . . . . . . . . . . . . . . . . . . . .214 f.\\nNumerical Differentiation . . . . . . . . . .147\\nNumerical differentiation . . .124 ff., 146,\\n173\\nNumerical instability . . . . . . . . . . . . . . 146\\nNumpy . . . . . . . . . . . . . . . . . . . . . . . . . . . .221\\nO\\nOctahedral dice . . . . . . . . . . . . . . . . . . . .101\\nOdds . . . . . . . . . . . . . . . . . . . . . . . . . .12 f., 29\\nOdds of success in a binary response 14\\nOnOffLayer . . . . . . . . . . . . . . . . . . . . .56, 78\\nOOM . . . . . . . . . . . . . . . . . . . . . . . . .281, 327\\nOptimization . . . . . . . . . . . . . . . . . .131, 153\\nOptimization loss . . . . . . . . . . . . . . . . . .331\\nOrdinary predictors . . . . . . . . . . . . . . . . .28\\nOut of memory . . . . . . . . . . . . . . . 281, 327\\nOverﬁtting . . . . . . . . . . . . . . . . . .12, 27, 194\\nP\\nP value . . . . . . . . . . . . . . . . . . . . . . . . . . . . .36\\nPadding . . . . . . . . . . . . . . . . . . . . . . 236, 292\\nPancreactic cancer . . . . . . . . . . . . . . . . . . 43\\nPancreatic cancer classiﬁcation . . . . . 208\\nPartial derivative . . . . . . . . . . . . . . . . . . . 53\\nPartial derivatives . . . . . .130 ff., 142, 152\\n380Chapter 10 ALPHABETICAL INDEX\\nParticle physics . . . . . . . . . . . . . . . . . . . . .45\\nPDF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nPerceptron . . . . . . . . . . . . . . . . . . . .246, 299\\nPerceptron learning rule . . . . . . . . . . . 252\\nPerceptrons . . . . . . . . . .299, 301, 304, 343\\nPerformance metrics . . . . . . . . . . . . . . .316\\nPhysical constants . . . . . . . . . . . . . . . . . 100\\nPlacenta Chorion Test . . . . . . . . . . . . . .353\\nPlacenta chorion test . . . . . . . . . . . . . . 46 f.\\nPlanck’s constant . . . . . . . . . . . . . . . . . . 100\\nPlateau . . . . . . . . . . . . . . . . . . . . . . . . . . . .284\\nPMF . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43, 59\\nPoisson . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75\\nPoisson distribution . . . . . . . . . . . . . . . . 53\\nPooling Layer . . . . . . . . . . . . . . . . . . . . . 270\\nPooling layer . . . . . . . . . . . . . . . . . . . . . . 322\\nPosterior . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPosterior and prior predictive\\ndistributions . . . . . . . . . . . . . . . . 54\\nPosterior distribution . 54, 146, 180, 354\\nPosterior predictive distributions . . . 76\\nPre trained CNN . . . . . . . . . . . . . . . . . . 349\\nPre trained CNNs . . . . . . . . . . . . . . . . . .205\\nPre trained VGG19 CNN model . . . . 220\\nPrecision . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nPredictor variables . . . . . . . . . . . . . . . . . .28\\nPrior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPrior distribution . . . . . . . . . . . . . . . . . . . 45\\nPrior distributions . . . . . . . . . . . . . . . . . . 77\\nPrior predictive distribution . . . . 54, 354\\nProbabilistic programming . . . . . . . . . .42\\nProbability distribution . . . . . . . . . .13, 94\\nProbability mass function . . . . . . . .43, 60\\nProbability of failure . . . . . . . . . . . . . . . .28\\nProbability space . . . . . . . . . . . . . . . . . . . 44\\nProbability statements . . . . . . . . . . . . . . 65\\nProblems . . . . . . . . . . . . . . . . . .12, 186, 206\\nProton theraphy . . . . . . . . . . . . . . . . . . . . 43\\nProton therapy . . . . . . . . . . . . . . . . . . 16, 43\\nPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .16, 43\\nPulmonary nodules . . . . . . . . . . . 282, 345\\nPyMc3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nPython . 7, 23–27, 38 ff., 42, 56 f., 88, 102,\\n107 f., 112, 114, 123, 134, 136,\\n138, 140, 143 f., 157, 159 f., 163,\\n165 f., 170, 172 f., 175 ff., 179,\\n181, 191, 195–198, 202, 206,\\n210 f., 218, 221, 223 f., 232,\\n239 ff., 250 f., 256 f., 263 f., 266 ff.,\\n272, 282, 288, 294 f., 300–304,\\n312, 319 f., 330, 343 f., 349\\nPython coin toss . . . . . . . . . . . . . . . . . . . 108\\nPython interpreter . . . . . . . . . . . . . . . . . . 88\\nPyTorch . 7, 23–26, 38, 40, 56 f., 123, 134,\\n136, 138, 140, 143, 157, 159 f.,\\n163, 165 f., 170, 173, 176 f., 181,\\n191, 195 ff., 202, 206, 210 f., 218,\\n221, 223 f., 254–257, 267 f., 272,\\n288, 307 ff., 319 f., 343 f., 349\\nPytorch . . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nPyTorch code snippet for an ensemble\\n191\\nPyTorch sequential . . . . . . . . . . . . . . . . 257\\nPyTorch tanh . . . . . . . . . . . . . . . . . . . . . .257\\nQ\\nQuadratic equation . . . . . . . . . . . . . . . . . 80\\nQuantum drop . . . . . . . . . . . . . . . . . . . . . .57\\nQuantum physics . . . . . . . . . . . . . . . . . .100\\nQuantum states . . . . . . . . . . . . . . . . . . . . .45\\nQuantum term speed . . . . . . . . . . . . . . . 79\\n381ALPHABETICAL INDEX\\nR\\nRadiation therapy . . . . . . . . . . . . . . . 17, 98\\nRadiation therapy planning . . . . . . . . . 17\\nRadiology . . . . . . . . . . . . . . . . . . . . . . . . .282\\nRandom guess classiﬁer . . . . . . . 262, 317\\nRandom number seeds . . . . . . . . . . . . 186\\nRandom search . . . . . . . . . . . . . . . 282, 328\\nRecall . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic . . 261\\nReceiver operating characteristic . . . 316\\nRectiﬁcation . . . . . . . . . . . . . . . . . . . . . . .306\\nRelative entropy . . . . .98 f., 109, 117, 349\\nRelative maxima and minima . . . . . . 132\\nRelative risk . . . . . . . . . . . . . . . . . . . . . . . .34\\nRelative shrinkage frequency . . . . . . 112\\nRelative star expansion frequency . . 115\\nReLU . . . .248 f., 253, 258 f., 301, 306, 314\\nRendering sympy in Google colab . 143\\nResNet . . . . . . . . . . 205, 207, 211, 217, 223\\nResNet152 . . . . . . . . . . . . . . . . . . . . . . . . .205\\nResNet18 . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nResNet34 . . . . . . . . . . . . . . . . .205, 211, 349\\nResNet34 CNN . . . . . . . . . . . . . . . . . . . .211\\nResNetBottom . . . . . . . . . . . . . . . . . . . . .211\\nResNets . . . . . . . . . . . . . . . . . . . . . . . . . . .326\\nResponse variable . . . . . . . . . . 12 f., 17, 29\\nReversing probabilities . . . . . . . . . . . . . 47\\nROC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nROC AUC . . . . . . . . . . . . . . . . . . . . . . . . .316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . .261\\nRosenblatt . . . . . . . . . . . . . . . . . . . . . . . . .252\\nRR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34\\nRussakovsky . . . . . . . . . . . . . . . . . . . . . . 206\\nRussakovsky 2015 . . . . . . . . . . . . . . . . . 206\\nS\\nSaddle points . . . . . . . . . . . . . . . . . . . . . .155\\nSame padding . . . . . . . . . . . . 236, 238, 292\\nSample odds ratio . . . . . . . . . . . . . . . . . . 37\\nSampling approaches . . . . . . . . . . . . . .189\\nSampling with replacement . . . 189, 199\\nSampling without replacement 189, 199\\nSearch space . . . . . . . . . . . . . . . . . . 282, 328\\nSecond derivative test . . . . . . . . . . . . . 132\\nSeed values in AD . . . . . . . . . . . . .142, 170\\nSequential . . . . . . . . . . . . . . . . . . . . . . . . .221\\nSGD . . . . . . . . . . . . . . . . . . . . . .286 f., 330 ff.\\nShannon . . . . . . . 86 f., 89, 100, 103 f., 117\\nShannon bit . . . . . . . . . . . . . . . . . . . . . . . . .90\\nShannon’s famous general formulae\\n103\\nShannon’s general formulae . . . . . . . . 89\\nShift-invariance . . . . . . . . . . . . . . . . . . . .235\\nSigmoid . . . 15, 23, 32, 134, 137, 144, 160,\\n253, 306\\nSigmoid activation function . . . . 33, 137,\\n157 f., 160\\nSigmoid derivative . . . . . . . . . . . . . . . . . 15\\nSigmoid function . . . . . . . . . . . . . . . . . . 157\\nSigmoid gradient . . . . . . . . . . . . . .144, 173\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . 173\\nSigmoidal neuron . . . . . . . . . . . . . . . . . .247\\nSigmoidal perceptron . . . . . . . . . . . . . .246\\nSimilarity measures . . . . . . . . . . . . . . . .296\\nSimple differentiation . . . . . . . . . 144, 172\\nSingle Layer Perceptrons . . . . . . . . . . .246\\nSingle layer perceptrons . . . . . . . . . . . 299\\nSingle model based AI systems . . . . 186\\nSingle predictors . . . . . . . . . . . . . . . . . . .201\\nSkip connection . . . . . . . . . . . . . . . . . . . .326\\nSnapshot ensembling . . . 189 f., 195, 201\\n382Chapter 10 ALPHABETICAL INDEX\\nSobel ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .294\\nSoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nsoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . . .217\\nSoftmax activation . . . . . . . . . . . . . . . . .251\\nSoftmax activation function . . . . . . . . . 32\\nSoftmax derivation . . . . . . . . . . . . . . . . . 32\\nSoftmax function . . . . . . . . . . . . . . . . 32, 40\\nSoftmax layers . . . . . . . . . . . . . . . . . . . . . .29\\nSoftmax neurons . . . . . . . . . . . . . . . . . . .214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . .198\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . .49\\nSpeed of light in vacum . . . . . . . . . . . . 100\\nSperable convolutions . . . . . . . . .241, 295\\nSplitting criterion . . . . . . . . . . . . . . . . . .111\\nStacking . . . . . . . . . . . . . . . . . .186, 189, 198\\nStacking and bagging . . . . . . . . . . . . . .187\\nStan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nStandard deviation . . . . . . . . . . . . . . . . . 61\\nStar density . . . . . . . . . . . . . . . . . . . . . . . . .97\\nStar expansion . . . . . . . . . . . . . . . . . . . . .115\\nStatic committee machines . . . . . . . . . 201\\nStatistical distribution . . . . . . . . . . . . . . .44\\nStatistical independence . . . . . . . . . . . . 45\\nStatistical mechanics . . . . . . . . . . . . .11, 86\\nStochastic . . . . . . . . . . . . . . . . . . . . . . . . . .287\\nStochastic gradient descent . . . . 247, 331\\nStochastic gradient descent, SGD . . 286\\nStock markets . . . . . . . . . . . . . . . . . . . . . . .48\\nStocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .48\\nStratiﬁcation . . . . . . . . . . . . . . . . . . 233, 290\\nStratiﬁed K fold . . . . . . . . . . . . . . . . . . . 290\\nStratiﬁed K-Fold . . . . . . . . . . . . . . . . . . .233\\nStride . . . . . . . . . . . . . . . . . . . . 236, 292, 323\\nSTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\nStyle loss . . . . . . . . . . . . . . . 214, 216, 224 f.\\nStyle transfer . . . . . . . . . . . . . . 214 f., 224 f.\\nSupervised learning . . . . . . . . . . . . . . . . 28\\nSupervised machine learning . . . . . . . 12\\nSurprise . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nSwish . . . . . . . . . . . . .',\n",
              " ' . . . . . . . . . . . . . . . . . . . . 236, 292, 323\\nSTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\nStyle loss . . . . . . . . . . . . . . . 214, 216, 224 f.\\nStyle transfer . . . . . . . . . . . . . . 214 f., 224 f.\\nSupervised learning . . . . . . . . . . . . . . . . 28\\nSupervised machine learning . . . . . . . 12\\nSurprise . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . .260, 315\\nSymbolic differentiation . . . 123 f., 143 f.,\\n172 f.\\nSymPy . . . . . . . . .124, 143 f., 146, 173, 177\\nT\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310\\ntanh . . . . . . . . . . . . . . . . . . . . 253, 256 f., 306\\nTaylor series . . . . . . . . . . . . . . . . .122, 128 f.\\nTaylor series and dual numbers . . . . 163\\nTaylor series expansion . . . . . . 128 f., 150\\nTest set . . . . . . . . . . . . . . . . . . . . . . . . . . . .328\\nThe backpropagation algorithm . . . . 134\\nThe bayesian school of thought . . . . . 42\\nThe beta binomial model . . . . . . 144, 174\\nThe chain rule . . . . . . . . . . . . . . . . .127, 149\\nThe convolution operator . . . . . 234, 291\\nThe correlation operator . . . . . . .234, 291\\nThe gaussian distribution . . . . . . . . . . 324\\nThe gradient descent algorithm . . . . 155\\nThe gram matrix . . . . . . . . . . . . . . . . . . .225\\nThe hyperplane . . . . . . . . . . . . . . . . . 14, 31\\nThe Kullback Leibler distance . . . . . . 297\\nThe Likelihood function . . . . . . . . . . . 174\\nThe logit function and entropy . . . . . . 38\\nThe multi layer perceptron . . . . . . . . . 300\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . .32\\nThe sigmoid . . . . . . . . . . . . . . . . . . . . . . . . 15\\nThe sigmoid function . . . . . . . . . . . . . . . 29\\nThe theory of perceptrons . . . . . . . . . .304\\nTheory of CNN design . . . . . . . . . . . . .326\\nThermodynamics . . . . . . . . . . 86, 100, 103\\nTopologies . . . . . . . . . . . . . . . . . . . . . . . . .318\\nToxic mercury fumes . . . . . . . . . . . . . .18 f.\\n383ALPHABETICAL INDEX\\nTrain validation split . . . . . . . . . . . . . . .281\\nTraining corpus . . . . . . . . . . . . . . . 189, 200\\nTraining curve curve . . . . . . . . . . 283, 329\\nTraining hyperparameters . . . . . . . . . 327\\nTraining validation epoch . . . . . . . . . .196\\nTransformation . . . . . . . . . . . . . . . . . . . .222\\nTriangle inequality . . . . . . . . . . . . . . . . .109\\nTrue probability distribution . . . . . . . . 93\\nTruly understanding LR . . . . . . . . . 16, 33\\nTTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .69\\nTumors . . . . . . . . . . . . . . . . . . . . . . . . . . . . .98\\nTumour eradication . . . . . . . . . . . . . 17, 34\\nTumour shrinkage . . . . . . . . . . . . . . . . . .96\\nTumour shrinkage in rats . . . . . . . . . . . 22\\nTwo dimensional matrix . . . . . . . . . . . . 24\\nU\\nUncertainty . . . . . . . . . . . . . . . . . . . . . . .89 f.\\nUniversal function approximators . 251\\nV\\nValid padding . . . . . . . . . . . . 236, 238, 292\\nValidation curve . . . . . . . . . . . . . . 283, 329\\nValidation curve ACC . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . .329\\nValidation set . . . . . . . . . . . . . . . . . . . . . .328\\nVanilla linear regression . . . . . . . . . . . . .14\\nVanishing gradients . . . . . . . . . . . . . . . .258\\nVariance . . . . . . . . . . . .42 f., 59, 62, 74, 201\\nV enn diagram . . . . . . . . . . . . . . . . .44 f., 99\\nVGG . . . . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nVGG conv43 layer . . . . . . . . . . . . . . . . . 209\\nVGG fc7 layer . . . . . . . . . . . . . . . . . . . . . 209\\nVGG Net . . . . . . . . . . . . . . . . . . . . . .205, 216\\nVGG16 . . . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nVGG19 . . . . . . . . . . . . . . . . . . . 209, 221, 351\\nVGG19 architecture . . . . . . . . . . . . . . . .208\\nVGG19 CNN . . . . . . . . . . . . . 208, 218, 351\\nV oting power . . . . . . . . . . . . . . . . . . . . . .201\\nVumulative distribution . . . . . . . . . . . . .62\\nW\\nWald chi squared test . . . . . . . . . . . . . . . 28\\nWeight initialization247, 253, 258, 299 f.,\\n314\\nWest African ebola . . . . . . . . . . . . . . . . . .52\\nWSI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .208\\nWW2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .50\\nX\\nXavier . . . . . . . . . . . . . . . . . . . . . . . . 258, 330\\n384']"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunk_ques_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc4uBzLXBOhs",
        "outputId": "f772b479-2766-470c-9486-d9b1bc97bd33"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(chunk_ques_gen)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2WNZEiZBQG7",
        "outputId": "ef7fc7cf-a33e-464a-9683-ee7995338b2c"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "document_question_gen=[Document(page_content=t) for t in chunk_ques_gen]\n",
        "document_question_gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyumoXF7BTpJ",
        "outputId": "c5a3dfb7-b2ba-4c5d-c3d1-ef9dbc067f4d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content=\"SHLOMO KASHANI\\nDeep Learning Interviews is home to hundreds of fully-solved problems, \\nfrom a wide range of key topics in AI. It is designed to both rehearse \\ninterview or exam-specific topics and provide machine learning M.Sc./Ph.D. \\nstudents, and those awaiting an interview a well-organized overview of the \\nfield. The problems it poses are tough enough to cut your teeth on and to \\ndramatically improve your skills-but they’re framed within thought-\\nprovoking questions and engaging stories.\\nThat is what makes the volume so specifically valuable to students and job \\nseekers: it provides them with the ability to speak confidently and quickly on \\nany relevant topic, to answer technical questions clearly and correctly, and to \\nfully understand the purpose and meaning \\nof interview questions and \\nanswers. These are powerful, indispensable advantages to have when walking \\ninto the interview room.\\nThe book’s contents is a large inventory of numerous topics relevant to DL \\njob interviews and graduate-level exams. That places \\nthis work at the \\nforefront \\nof the growing trend in science to teach a core set of practical \\nmathematical and computational \\nskills. It is widely accepted that the \\ntraining of every computer scientist must include the fundamental theorems \\nof ML, and AI appears in the curriculum of \\nnearly every \\nuniversity. This \\nvolume is designed as an excellent reference for graduates of \\nsuch programs.\\nShlomo Kashani, Author. \\nwww.interviews.ai\\nDEEP LEARNING INTERVIEWS\\nDEEP LEARNING \\nINTERVIEWS\\nSHLOMO KASHANI deep learning interviews\\nAmir Ivry, Chief Editor.\\n    REAL-WORLD DEEP LEARNING INTERVIEW \\nPROBLEMS & SOLUTIONS\\n• Logistic Regression\\n• Information Theory\\n• Calculus\\n• Algorithmic Differentiation\\n• Bayesian Deep Learning\\n• Probabilistic Programming\\n• Ensemble Learning\\n• CNN Feature Extraction\\n• Deep Learning: Expanded Chapter\\nsecond editionSHLOMO KASHANI\\nDEEP LEARNING INTERVIEWS\\nBy Shlomo Kashani, M.Sc, QMUL, UK.\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nPublished by Shlomo Kashani, Tel-Aviv , ISRAEL.\\nVisit: http://www.interviews.ai\\nCopyright, 2020\\nThis book is protected by copyright.\\nNo part may be reproduced in any manner without written permission from the publisher.\\nPrinting version: VER . 26 TH OCTOBER 2021\\nPrinted in the United States of America.\\nLibrary of Congress Cataloging-in-Publication Data\\nA catalog record for this book is available from the Library of CongressCOPYRIGHT.\\n© 2016-2020 Shlomo Kashani, entropy@interviews.ai\\nA\\nLL RIGHTS RESERVED .The content contained within this book may not be\\nreproduced, duplicated or transmitted without direct written permission\\nfrom the author or the publisher. Under no circumstances will any blame\\nor legal responsibility be held against the publisher, or author, for any dam-\\nages, reparation, or monetary loss due to the information contained within this book.\\nEither directly or indirectly . This book is copyright protected. This book is only for\\npersonal use. You cannot amend, distribute, sell, use, quote or paraphrase any part, or\\nthe content within this book, without the consent of the author or publisher.\\nPlease note the information contained within this document is for educational and\\nentertainment purposes only . All effort has been executed to present accurate, up to\\ndate, and reliable, complete information. No warranties of any kind are declared or\\nimplied. Readers acknowledge that the author is not engaging in the rendering of\\nlegal, ﬁnancial, medical or professional advice. The content within this book has been\\nderived from various sources. Please consult a licensed professional before attempt-\\ning any techniques outlined in this book. By reading this document, the reader agrees\\nthat under no circumstances is the author responsible for any losses, direct or indirect,\\nwhich are incurred as a result of the use of information contained within this docu-\\nment, including, but not limited to errors, omissions, or inaccuracies.\\nNo part of this publication may be reproduced, stored in a retrieval system, or trans-\\nmitted in any form or by any means, electronic, mechanical, photocopying, record-\\ning, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976\\nUnited States Copyright Act, without the prior written permission of the Publisher.\\nLimit of Liability/Disclaimer of Warranty . While the publisher and author have used\\ntheir best efforts in preparing this book, they make no representations or warranties\\nwith respect to the accuracy or completeness of the contents of this book and spe-\\nciﬁcally disclaim any implied warranties of merchantability or ﬁtness for a particular\\npurpose. No warranty may be created or extended by sales representatives or writ-\\nten sales materials. The advice and strategies contained herein may not be suitable\\nfor your situation. You should consult with a professional where appropriate. Neitherthe publisher nor author shall be liable for any loss of proﬁt or any other commer-\\ncial damages, including but not limited to special, incidental, consequential, or other\\ndamages.\\nNotices. Knowledge and best practice in this ﬁeld are constantly changing. As new\\nresearch and experience broaden our understanding, changes in research methods,\\nprofessional practices, or medical treatment may become necessary . Practitioners and\\nresearchers must always rely on their own experience and knowledge in evaluating\\nand using any information, methods, compounds, or experiments described herein.\\nIn using such information or methods they should be mindful of their own safety and\\nthe safety of others, including parties for whom they have a professional responsibil-\\nity . To the fullest extent of the law, neither the Publisher nor the authors, contributors,\\nor editors, assume any liability for any injury and/or damage to persons or property\\nas a matter of products liability , negligence or otherwise, or from any use or operation\\nof any methods, products, instructions, or ideas contained in the material herein.FOREWORD.\\nWe will build a machine that will ﬂy.\\n— Joseph Michael Montgolﬁer, French Inventor/Aeronaut (1740-1810)\\nD\\nEEP learning interviews are technical, dense, and thanks to the ﬁelds com-\\npetitiveness, often high-stakes. The prospect of preparing for one can be\\ndaunting, and the fear of failure can be paralyzing and many interviewees\\nﬁnd their ideas slipping away alongside their conﬁdence.\\nThis book was written for you: an aspiring data scientist with a quantitative back-\\nground, facing down the gauntlet of the interview process in an increasingly competit-\\nive ﬁeld. For most of you, the interview process is the most signiﬁcant hurdle between\\nyou and a dream job. Even though you have the ability , the background, and the mo-\\ntivation to excel in your target position, you might need some guidance on how to get\\nyour foot in the door.\\nThough this book is highly technical it is not too dense to work through quickly . It\\naims to be comprehensive, including many of the terms and topics involved in modern\\ndata science and deep learning. That thoroughness makes it unique; no other single\\nwork offers such breadth of learning targeted so speciﬁcally at the demands of the\\ninterview.\\nMost comparable information is available in a variety of formats, locations, struc-\\ntures, and resourcesblog posts, tech articles, and short books scattered across the inter-\\nnet. Those resources are simply not adequate to the demands of deep learning inter-\\nview or exam preparation and were not assembled with this explicit purpose in mind.\\nIt is hoped that this book does not suffer the same shortcomings.\\nT\\nHIS books creation was guided by a few key principles: clarity and depth,\\nthoroughness and precision, interest and accuracy . The volume was de-\\nsigned for use by job seekers in the ﬁelds of machine learning and deep\\nlearning whose abilities and background locate them ﬁrmly within STEM\\n(science, technology , engineering, and mathematics). The book will still be of use to\\nother readers, such as those still undergoing their initial education in a STEM ﬁeld.\\nHowever, it is tailored most directly to the needs of active job seekers and stu-\\ndents attending M.Sc/Ph.D programmes in AI . It is, in any case, a book for engineers,\\nmathematicians, and computer scientists: nowhere does it include the kind of very\\nbasic background material that would allow it to be read by someone with no priorknowledge of quantitative and mathematical processes.\\nThe books contents are a large inventory of numerous topics relevant to deep learn-\\ning job interviews and graduate level exams. Ideas that are interesting or pertinent\\nhave been excluded if they are not valuable in that context. That places this work at\\nthe forefront of the growing trend in education and in business to emphasize a core\\nset of practical mathematical and computational skills. It is now widely understood\\nthat the training of every computer scientist must include a course dealing with the\\nfundamental theorems of machine learning in a rigorous manner; Deep Learning ap-\\npears in the curriculum of nearly every university; and this volume is designed as a\\nconvenient ongoing reference for graduates of such courses and programs.\\nThe book is grounded in both academic expertise and on-the-job experience and\\nthus has two goals. First, it compresses all of the necessary information into a coher-\\nent package. And second, it renders that information accessible and makes it easy to\\nnavigate. As a result, the book helps the reader develop a thorough understanding of\\nthe principles and concepts underlying practical data science. None of the textbooks I\\nread met all of those needs, which are:\\n1. Appropriate presentation level. I wanted a friendly introductory text accessible\\nto graduate students who have not had extensive applied experience as data\\nscientists.\\n2. A text that is rigorous and builds a solid understanding of the subject without\\ngetting bogged down in too many technicalities.\\n3. Logical and notational consistency among topics . There are intimate connec-\\ntions between calculus, logistic regression, entropy , and deep learning theory ,\\nwhich I feel need to be emphasized and elucidated if the reader is to fully under-\\nstand the ﬁeld. Differences in notation and presentation style in existing sources\\nmake it very difﬁcult for students to appreciate these kinds of connections.\\n4. Manageable size. It is very useful to have a text compact enough that all of the\\nmaterial in it can be covered in few weeks or months of intensive review. Most\\ncandidates will have only that much time to prepare for an interview, so a longer\\ntext is of no use to them.\\nThe text that follows is an attempt to meet all of the above challenges. It will\\ninevitably prove more successful at handling some of them than others, but it\\nhas at least made a sincere and devoted effort.A note about Bibliography\\nThe book provides a carefully curated bibliography to guide further study , whether\\nfor interview preparation or simply as a matter of interest or job-relevant research. A\\ncomprehensive bibliography would be far too long to include here, and would be of\\nlittle immediate use, so the selections have been made with deliberate attention to the\\nvalue of each included text.\\nOnly the most important books and articles on each topic have been included, and\\nonly those written in English that I personally consulted. Each is given a brief annota-\\ntion to indicate its scope and applicability . Many of the works cited will be found to\\ninclude very full bibliographies of the particular subject treated, and I recommend\\nturning there if you wish to dive deeper into a speciﬁc topic, method, or process.\\nWe have a web page for this book, where we list errata, examples, and any ad-\\nditional information. You can access this page at: http://www.interviews.ai.\\nTo comment or ask technical questions about this book, send email to: entropy@\\ninterviews.ai.\\nI would also like to solicit corrections, criticisms, and suggestions from students\\nand other readers. Although I have tried to eliminate errors over the multi year\\nprocess of writing and revising this text, a few undoubtedly remain. In particular,\\nsome typographical infelicities will no doubt ﬁnd their way into the ﬁnal version. I\\nhope you will forgive them .\\nTHE AUTHOR .\\nTEL AVIV ISRAEL, D ECEMBER , 2020. F IRST PRINTING , D ECEMBER 2020.ACKNOWLEDGEMENTS.\\nThe thanks and acknowledgements of the publisher are due to the following:\\nMy dear son, Amir Ivry , Matthew Isaac Harvey , Sandy Noymer, Steve foot and V elimir\\nGayevskiy .AUTHOR ’S BIOGRAPHY .\\nWhen Shlomo typed his book in LATEX, he wanted it to\\nreﬂect some of his passions: AI, design, typography , and\\nmost notably coding. On a typical day , his two halves - the\\nscientist and the artist - spend hours meticulously design-\\ning AI systems, from epilepsy prediction and pulmonary\\nnodule detection, to training a computer-vision model on\\na cluster.\\nShlomo spends whole days in a lab full of GPUs work-\\ning on his many interesting research projects. Though re-\\nsearch satisﬁes his itch for discovery , his most important\\nscientiﬁc contribution, he says, is helping other researchers.\\nAnd the results are evident in his publications. But, al-\\nthough theoretical studies are important, practical experi-\\nence has many great virtues. As the Head of AI at DeepOncology , he developed uses\\nof Deep Learning for precise tumour detection, expanding and reﬁning what human\\nexperts are capable of. The work, which relies on CNN’s, marks the culmination of a\\ncareer spent applying AI techniques to problems in medical AI. Shlomo holds an MSc\\nin Digital Signal Processing (Distinction) from the University of London.\\nA PERSONAL NOTE : In this ﬁrst volume, I purposely present a coherent, cumu-\\nlative, and content-speciﬁc core curriculum of the data science ﬁeld, including topics\\nsuch as information theory , Bayesian statistics, algorithmic differentiation, logistic re-\\ngression, perceptrons, and convolutional neural networks.\\nI hope you will ﬁnd this book stimulating. It is my belief that you the postgradu-\\nate students and job-seekers for whom the book is primarily meant will beneﬁt from\\nreading it; however, it is my hope that even the most experienced researchers will ﬁnd\\nit fascinating as well.\\nSHLOMO KASHANI ,T EL-AVIV,ISRAEL.ABOUT\\nTHE CHIEF\\nEDITOR .\\nAmir Ivry has been an applied research scientist in the ﬁelds\\nof deep learning and speech signal processing since 2015. A direct\\nPhD candidate in the Electrical and Computer Engineering Fac-\\nulty in the Technion - Israel Institute of Technology , Amir is the\\nauthor of over a dozen academic papers in leading IEEE journ-\\nals and top-tier conferences. For his contribution to the ﬁeld of\\nhands-free speech communication using deep neural networks,\\nAmir has received more than a dozen awards and honors, in-\\ncluding back-to-back Jacobs citations for research excellence, and\\nmost recently the international speech communication associ-\\nation grant. Being only 28 years old, he has been cemented as a popular lecturer in the\\nmachine learning community , and delivered technological sessions for MIT, Google\\nfor startups, Alibaba, and more. Amir is currently holding a position as an applied\\nresearch intern in Microsoft Advanced Technology Labs.Contents\\nI Rusty Nail 1\\nHOW-TO USE THIS BOOK 3\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\nII Kindergarten 9\\nLOGISTIC REGRESSION 11\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38PROBABILISTIC PROGRAMMING & BA YESIAN DL 41\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nIII High School 83\\nINFORMATION THEORY 85\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 87\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 101\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103Kullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION 121\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 155The Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\nIV Bachelors 183\\nDEEP LEARNING: NN ENSEMBLES 185\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 202\\nDEEP LEARNING: CNN FEATURE EXTRACTION 205\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213Neural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\nDEEP LEARNING 227\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 253\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 306\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nV Practice Exam 339\\nJOB INTERVIEW MOCK EXAM 341\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343Classiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nVI V olume two 357\\nVOLUME TWO - PLAN 359\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nVariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . . . 361\\nText to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL\"),\n",
              " Document(metadata={}, page_content='ization . . . . . . . . . . . . . . . . . . . . . . 361\\nText to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nxviRUSTY NAIL\\nPART ICHAPTER\\n1\\nHOW-TO USE THIS BOOK\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nStarting Your Career . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nAdvancing Your Career . . . . . . . . . . . . . . . . . . . . . . . 5\\nDiving Into Deep Learning . . . . . . . . . . . . . . . . . . . . . 5\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.1 Introduction\\nFirst of all, welcome to world of Deep Learning Interviews.\\n1.1.1 What makes this book so valuable\\nT\\nARGETED advertising. Deciphering dead languages. Detecting malignant\\ntumours. Predicting natural disasters. Every year we see dozens of new\\nuses for deep learning emerge from corporate R&R, academia, and plucky\\nentrepreneurs. Increasingly , deep learning and artiﬁcial intelligence are in-\\ngrained in our cultural consciousness. Leading universities are dedicating programs\\nto teaching them, and they make the headlines every few days.\\nThat means jobs. It means intense demand and intense competition. It means a\\ngeneration of data scientists and machine learning engineers making their way into1.1. INTRODUCTION\\nthe workforce and using deep learning to change how things work. This book is for\\nthem, and for you. It is aimed at current or aspiring experts and students in the ﬁeld\\npossessed of a strong grounding in mathematics, an active imagination, engaged cre-\\nativity , and an appreciation for data. It is hand-tailored to give you the best possible\\npreparation for deep learning job interviews by guiding you through hundreds of\\nfully solved questions.\\nThat is what makes the volume so speciﬁcally valuable to students and job seekers:\\nit provides them with the ability to speak conﬁdently and quickly on any relevant\\ntopic, to answer technical questions clearly and correctly , and to fully understand the\\npurpose and meaning of interview questions and answers.\\nThose are powerful, indispensable advantages to have when walking into the in-\\nterview room.\\nThe questions and problems the book poses are tough enough to cut your teeth\\non-and to dramatically improve your skills but theyre framed within thought provok-\\ning questions, powerful and engaging stories, and cutting edge scientiﬁc information.\\nWhat are bosons and fermions? What is choriionic villus? Where did the Ebola virus\\nﬁrst appear, and how does it spread? Why is binary options trading so dangerous?\\nYour curiosity will pull you through the book’s problem sets, formulas, and in-\\nstructions, and as you progress, you’ll deepen your understanding of deep learning.\\nThere are intricate connections between calculus, logistic regression, entropy , and deep\\nlearning theory; work through the book, and those connections will feel intuitive.\\n1.1.2 What will I learn\\nStarting Your Career\\nAre you actively pursuing a career in deep learning and data science, or hoping to do\\nso? If so, you’re in luck everything from deep learning to artiﬁcial intelligence is in\\nextremely high demand in the contemporary workforce. Deep learning professionals\\nare highly sought after and also ﬁnd themselves among the highest-paid employee\\ngroups in companies around the world.\\nSo your career choice is spot on, and the ﬁnancial and intellectual beneﬁts of land-\\ning a solid job are tremendous. But those positions have a high barrier to entry: the\\ndeep learning interview. These interviews have become their own tiny industry , with\\nHR employees having to specialize in the relevant topics so as to distinguish well-\\nprepared job candidates from those who simply have a loose working knowledge of\\nthe material. Outside the interview itself, the difference doesn’t always feel import-\\n4Chapter 1 HOW-TO USE THIS BOOK\\nant. Deep learning libraries are so good that a machine learning pipeline can often be\\nassembled with little high-skill input from the researcher themselves. But that level\\nof ability won’t cut it in the interview. You’ll be asked practical questions, technical\\nquestions, and theoretical questions, and expected to answer them all conﬁdently and\\nﬂuently .\\nFor unprepared candidates, that’s the end of the road. Many give up after repeated\\npost-interview rejections.\\nAdvancing Your Career\\nSome of you will be more conﬁdent. Those of you with years on the job will be highly\\nmotivated, exceptionally numerate, and prepared to take an active, hands-on role in\\ndeep learning projects. You probably already have extensive knowledge in applied\\nmathematics, computer science, statistics, and economics. Those are all formidable\\nadvantages.\\nBut at the same time, it’s unlikely that you will have prepared for the interview\\nitself. Deep learning interviews especially those for the most interesting, autonom-\\nous, and challenging positions demand that you not only know how to do your job\\nbut that you display that knowledge clearly , eloquently , and without hesitation. Some\\nquestions will be straightforward and familiar, but others might be farther aﬁeld or\\ndraw on areas you haven’t encountered since college.\\nThere is simply no reason to leave that kind of thing to chance. Make sure you’re\\nprepared. Conﬁrm that you are up-to-date on terms, concepts, and algorithms. Refresh\\nyour memory of fundamentals, and how they inform contemporary research practices.\\nAnd when the interview comes, walk into the room knowing that you’re ready for\\nwhat’s coming your way .\\nDiving Into Deep Learning\\n\"Deep Learning Job Interviews\" is organized into chapters that each consist of an Intro-\\nduction to a topic, Problems illustrating core aspects of the topic, and complete Solu-\\ntions. You can expect each question and problem in this volume to be clear, practical,\\nand relevant to the subject. Problems fall into two groups, conceptual and application-\\nbased. Conceptual problems are aimed at testing and improving your knowledge of\\nbasic underlying concepts, while applications are targeted at practicing or applying\\nwhat you’ve learned (most of these are relevant to Python and PyTorch). The chapters\\nare followed by a reference list of relevant formulas and a selective bibliography for\\nguide further reading.\\n51.1. INTRODUCTION\\n1.1.3 How to Work Problems\\nIn real life, like in exams, you will encounter problems of varying difﬁculty . A good\\nskill to practice is recognizing the level of difﬁculty a problem poses. Job interviews\\nwill have some easy problems, some standard problems, and some much harder prob-\\nlems.\\nEach chapter of this book is usually organized into three sections: Introduction,\\nProblems, and Solutions. As you are attempting to tackle problems, resist the tempta-\\ntion to prematurely peek at the solution; It is vital to allow yourself to struggle for\\na time with the material. Even professional data scientists do not always know right\\naway how to resolve a problem. The art is in gathering your thoughts and ﬁguring\\nout a strategy to use what you know to ﬁnd out what you don’t.\\nPRB-1 \\uf059 CH.PRB- 1.1.\\nProblems outlined in grey make up the representative question set . This set of prob-\\nlems is intended to cover the most essential ideas in each section. These problems are usually\\nhighly typical of what you’d see on an interview, although some of them are atypical but\\ncarry an important moral. If you ﬁnd yourself unconﬁdent with the idea behind one of these,\\nit’s probably a good idea to practice similar problems. This representative question set is our\\nsuggestion for a minimal selection of problems to work on. Y ou are highly encouraged to\\nwork on more.\\nSOL-1 \\uf14b CH.SOL- 1.1. I am a solution. \\x04\\nIf you ﬁnd yourself at a real stand-off, go ahead and look for a clue in one of the\\nrecommended theory books. Think about it for a while, and don’t be afraid to read\\nback in the notes to look for a key idea that will help you proceed. If you still can’t\\nsolve the problem, well, we included the Solutions section for a reason! As you’re\\nreading the solutions, try hard to understand why we took the steps we did, instead\\nof memorizing step-by-step how to solve that one particular problem.\\nIf you struggled with a question quite a lot, it’s probably a good idea to return to it\\nin a few days. That might have been enough time for you to internalize the necessary\\nideas, and you might ﬁnd it easily conquerable. If you’re still having troubles, read\\nover the solution again, with an emphasis on understanding why each step makes\\nsense. One of the reasons so many job candidates are required to demonstrate their\\nability to resolves data science problems on the board, is that it hiring managers as-\\nsume it reﬂects their true problem-solving skills.\\n6Chapter 1 HOW-TO USE THIS BOOK\\nIn this volume, you will learn lots of concepts, and be asked to apply them in\\na variety of situations. Often, this will involve answering one really big problem by\\nbreaking it up into manageable chunks, solving those chunks, then putting the pieces\\nback together. When you see a particularly long question, remain calm and look for a\\nway to break it into pieces you can handle.\\n1.1.4 Types of Problems\\nTwo main types of problems are presented in this book.\\nCONCEPTUAL : The ﬁrst category is meant to test and improve your understanding\\nof basic underlying concepts. These often involve many mathematical calculations.\\nThey range in difﬁculty from very basic reviews of deﬁnitions to problems that require\\nyou to be thoughtful about the concepts covered in the section.\\nAn example in Information Theory follows.\\nPRB-2 \\uf059 CH.PRB- 1.2.\\nWhat is the distribution of maximum entropy, that is, the distribution which has the\\nmaximum entropy among all distributions on the bounded interval [a, b],(−∞, +∞)\\nSOL-2 \\uf14b CH.SOL- 1.2.\\nThe uniform distribution has the maximum entropy among all distributions on the\\nbounded interval: [a, b],(−∞, +∞).\\nThe variance of U (a, b) is σ2 = 1/12(b − a)2.\\nTherefore the entropy is:\\n1/2 log 12 + log σ. (1.1)\\n\\x04\\nAPPLICATION : Problems in this category are for practicing skills. It’s not enough to\\nunderstand the philosophical grounding of an idea: you have to be able to apply it in\\nappropriate situations. This takes practice! mostly in Python or in one of the available\\nDeep Learning Libraries such as PyTorch.\\nAn example in PyTorch follows.\\n71.1. INTRODUCTION\\nPRB-3 \\uf059 CH.PRB- 1.3.\\nDescribe in your own words, what is the purpose of the following code in the context of\\ntraining a Convolutional Neural Network.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\nSOL-3 \\uf14b CH.SOL- 1.3.\\nDuring the training of a Convolutional Neural Network, data augmentation, and to some\\nextent dropout are used as core methods to decrease overﬁtting. Data augmentation is a regu-\\nlarization scheme that synthetically expands the data-set by utilizing label-preserving trans-\\nformations to add more invariant examples of the same data samples. It is most commonly\\nperformed in real time on the CPU during the training phase whilst the actual training mode\\ntakes place on the GPU. This may consist for instance, random rotations, random ﬂips, zoom-\\ning, spatial translations etc. \\x04\\n8KINDERGARTEN\\nPART IICHAPTER\\n2\\nLOGISTIC REGRESSION\\nY ou should call it entropy for two reasons. In the ﬁrst place, your uncertainty\\nfunction has been used in statistical mechanics under that name. In the second\\nplace, and more importantly, no one knows what entropy really is, so in a debate\\nyou will always have the advantage.\\n— John von Neumann to Claude Shannon\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382.1. INTRODUCTION\\n2.1 Introduction\\nM\\nUltivariable methods are routinely utilized in statistical analyses across a\\nwide range of domains. Logistic regression is the most frequently used\\nmethod for modelling binary response data and binary classiﬁcation.\\nWhen the response variable is binary , it characteristically takes the form of 1/0,\\nwith 1 normally indicating a success and 0 a failure. Multivariable methods usually\\nassume a relationship between two or more independent, predictor variables, and\\none dependent, response variable. The predicted value of a response variable may be\\nexpressed as a sum of products, wherein each product is formed by multiplying the\\nvalue of the variable and its coefﬁcient. How the coefﬁcients are computed? from a\\nrespective data set. Logistic regression is heavily used in supervised machine learning\\nand has become the workhorse for both binary and multiclass classiﬁcation problems.\\nMany of the questions introduced in this chapter are crucial for truly understanding\\nthe inner-workings of artiﬁcial neural networks.\\n2.2 Problems\\n2.2.1 General Concepts\\nPRB-4 \\uf059 CH.PRB- 2.1.\\nTrue or False: For a ﬁxed number of observations in a data set, introducing more vari-\\nables normally generates a model that has a better ﬁt to the data. What may be the drawback\\nof such a model ﬁtting strategy?\\nPRB-5 \\uf059 CH.PRB- 2.2.\\nDeﬁne the term “odds of success” both qualitatively and formally. Give a numerical\\nexample that stresses the relation between probability and odds of an event occurring.\\nPRB-6 \\uf059 CH.PRB- 2.3.\\n1. Deﬁne what is meant by the term \"interaction\", in the context of a logistic regression\\npredictor variable.\\n12Chapter 2 LOGISTIC REGRESSION\\n2. What is the simplest form of an interaction? Write its formulae.\\n3. What statistical tests can be used to attest the signiﬁcance of an interaction term?\\nPRB-7 \\uf059 CH.PRB- 2.4.\\nTrue or False: In machine learning terminology, unsupervised learning refers to the\\nmapping of input covariates to a target response variable that is attempted at being predicted\\nwhen the labels are known.\\nPRB-8 \\uf059 CH.PRB- 2.5.\\nComplete the following sentence: In the case of logistic regression, the response vari-\\nable is the log of the odds of being classiﬁed in [...].\\nPRB-9 \\uf059 CH.PRB- 2.6.\\nDescribe how in a logistic regression model, a transformation to the response variable is\\napplied to yield a probability distribution. Why is it considered a more informative repres-\\nentation of the response?\\nPRB-10 \\uf059 CH.PRB- 2.7.\\nComplete the following sentence: Minimizing the negative log likelihood also means\\nmaximizing the [...] of selecting the [...] class.\\n2.2.2 Odds, Log-odds\\nPRB-11 \\uf059 CH.PRB- 2.8.\\nAssume the probability of an event occurring is p = 0.1.\\n1. What are the odds of the event occurring?.\\n2. What are the log-odds of the event occurring?.\\n132.2. PROBLEMS\\n3. Construct the probability of the event as a ratio that equals 0.1.\\nPRB-12 \\uf059 CH.PRB- 2.9.\\nTrue or False: If the odds of success in a binary response is 4, the corresponding probab-\\nility of success is 0.8.\\nPRB-13 \\uf059 CH.PRB- 2.10.\\nDraw a graph of odds to probabilities , mapping the entire range of probabilities to\\ntheir respective odds.\\nPRB-14 \\uf059 CH.PRB- 2.11.\\nThe logistic regression model is a subset of a broader range of machine learning models\\nknown as generalized linear models (GLMs), which also include analysis of variance (AN-\\nOV A), vanilla linear regression, etc. There are three components to a GLM; identify these\\nthree components for binary logistic regression.\\nPRB-15 \\uf059 CH.PRB- 2.12.\\nLet us consider the logit transformation, i.e., log-odds. Assume a scenario in which the\\nlogit forms the linear decision boundary:\\nlog\\n(\\nPr(Y = 1|X)\\nPr(Y = 0|X)\\n)\\n= θ0 + θT X, (2.1)\\nfor a given vector of systematic components X and predictor variables θ. Write the mathem-\\natical expression for the hyperplane that describes the decision boundary.\\nPRB-16 \\uf059 CH.PRB- 2.13.\\nTrue or False: The logit function and the natural logistic (sigmoid) function are inverses\\nof each other.\\n14Chapter 2 LOGISTIC REGRESSION\\n2.2.3 The Sigmoid\\nThe sigmoid (Fig. 2.1) also known as the logistic function, is widely used in binary\\nclassiﬁcation and as a neuron activation function in artiﬁcial neural networks.\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−4x\\nσ(x) = 1\\n1+e−15x\\nFIGURE 2.1: Examples of two sigmoid functions.\\nPRB-17 \\uf059 CH.PRB- 2.14.\\nCompute the derivative of the natural sigmoid function:\\nσ(x) = 1\\n1 + e−x ∈ (0, 1). (2.2)\\nPRB-18 \\uf059 CH.PRB- 2.15.\\nRemember that in logistic regression, the hypothesis function for some parameter vector\\nβ and measurement vector x is deﬁned as:\\nhβ(x) = g(βT x) = 1\\n1 + e−βT x\\n= P (y = 1|x; β), (2.3)\\n152.2. PROBLEMS\\nwhere y holds the hypothesis value.\\nSuppose the coefﬁcients of a logistic regression model with independent variables are as\\nfollows: β0 = −1.5, β1 = 3, β2 = −0.5.\\nAssume additionally, that we have an observation with the following values for the dependent\\nvariables: x1 = 1, x2 = 5. As a result, the logit equation becomes:\\nlogit = β0 + β1x1 + β2x2. (2.4)\\n1. What is the value of the logit for this observation?\\n2. What is the value of the odds for this observation?\\n3. What is the value of P (y = 1) for this observation?\\n2.2.4 Truly Understanding Logistic Regression\\nPRB-19 \\uf059 CH.PRB- 2.16.\\nProton therapy (PT) [ 2] is a widely adopted form of treatment for many types of cancer\\nincluding breast and lung cancer (Fig. 2.2).\\nFIGURE 2.2: Pulmonary nodules (left) and breast cancer (right).\\nA PT device which was not properly calibrated is used to simulate the treatment of\\ncancer. As a result, the PT beam does not behave normally. A data scientist collects inform-\\nation relating to this simulation. The covariates presented in T able 2.1 are collected during\\n16Chapter 2 LOGISTIC REGRESSION\\nthe experiment. The columns Yes and No indicate if the tumour was eradicated or not, re-\\nspectively.\\nTumour eradication\\nCancer Type Yes No\\nBreast 560 260\\nLung 69 36\\nTABLE 2.1: Tumour eradication statistics.\\nReferring to T able2.1:\\n1. What is the explanatory variable and what is the response variable?\\n2. Explain the use of relative risk and odds ratio for measuring association.\\n3. Are the two variables positively or negatively associated?\\nFind the direction and strength of the association using both relative risk and odds\\nratio.\\n4. Compute a 95% conﬁdence interval (CI) for the measure of association.\\n5. Interpret the results and explain their signiﬁcance.\\nPRB-20 \\uf059 CH.PRB- 2.17.\\nConsider a system for radiation therapy planning (Fig. 2.3). Given a patient with a ma-\\nlignant tumour, the problem is to select the optimal radiation exposure time for that patient.\\nA key element in this problem is estimating the probability that a given tumour will be erad-\\nicated given certain covariates. A data scientist collects information relating to this radiation\\ntherapy system.\\n172.2. PROBLEMS\\nFIGURE 2.3: A multi-detector positron scanner used to locate tumours.\\nThe following covariates are collected; X1 denotes time in milliseconds that a patient is\\nirradiated with, X2 = holds the size of the tumour in centimeters, and Y notates a binary re-\\nsponse variable indicating if the tumour was eradicated. Assume that each response’ variable\\nYi is a Bernoulli random variable with success parameter pi, which holds:\\npi = eβ0+β1x1+β2x2\\n1 + eβ0+β1x1+β2x2\\n. (2.5)\\nThe data scientist ﬁts a logistic regression model to the dependent measurements and pro-\\nduces these estimated coefﬁcients:\\nˆβ0 = −6,\\nˆβ1 = 0.05,\\nˆβ2 = 1.\\n(2.6)\\n1. Estimate the probability that, given a patient who undergoes the treatment for 40\\nmilliseconds and who is presented with a tumour sized 3.5 centimetres, the system\\neradicates the tumour.\\n2. How many milliseconds the patient in part (a) would need to be radiated with to have\\nexactly a 50% chance of eradicating the tumour?\\n18Chapter 2 LOGISTIC REGRESSION\\nPRB-21 \\uf059 CH.PRB- 2.18.\\nRecent research [ 3] suggests that heating mercury containing dental amalgams may\\ncause the release of toxic mercury fumes into the human airways. It is also presumed that\\ndrinking hot coffee, stimulates the release of mercury vapour from amalgam ﬁllings (Fig.\\n2.4).\\nFIGURE 2.4: A dental amalgam.\\nT o study factors that affect migraines, and in particular, patients who have at least four\\ndental amalgams in their mouth, a data scientist collects data from 200K users with and\\nwithout dental amalgams. The data scientist then ﬁts a logistic regression model with an\\nindicator of a second migraine within a time frame of one hour after the onset of the ﬁrst mi-\\ngraine, as the binary response variable (e.g., migraine=1, no migraine=0). The data scientist\\nbelieves that the frequency of migraines may be related to the release of toxic mercury fumes.\\nThere are two independent variables:\\n1. X1 = 1 if the patient has at least four amalgams; 0 otherwise.\\n2. X2 = coffee consumption (0 to 100 hot cups per month).\\nThe output from training a logistic regression classiﬁer is as follows:\\nAnalysis of LR Parameter Estimates\\nParameter Estimate Std.Err Z-val Pr>|Z|\\nIntercept -6.36347 3.21362 -1.980 0.0477\\n$X_1$ -1.02411 1.17101 -0.875 0.3818\\n$X_2$ 0.11904 0.05497 2.165 0.0304\\n192.2. PROBLEMS\\n1. Using X1 and X2, express the odds of a patient having a migraine for a second time.\\n2. Calculate the probability of a second migraine for a patient that has at least four\\namalgams and drank 100 cups per month?\\n3. For users that have at least four amalgams, is high coffee intake associated with an\\nincreased probability of a second migraine?\\n4. Is there statistical evidence that having more than four amalgams is directly associ-\\nated with a reduction in the probability of a second migraine?\\nPRB-22 \\uf059 CH.PRB- 2.19.\\nT o study factors that affect Alzheimer’s disease using logistic regression, a researcher\\nconsiders the link between gum (periodontal) disease and Alzheimer as a plausible risk factor\\n[1]. The predictor variable is a count of gum bacteria (Fig. 2.5) in the mouth.\\nFIGURE 2.5: A chain of spherical bacteria.\\nThe response variable, Y , measures whether the patient shows any remission (e.g. yes=1).\\nThe output from training a logistic regression classiﬁer is as follows:\\nParameter DF Estimate Std\\nIntercept 1 -4.8792 1.2197\\ngum bacteria 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of gum bacteria of a patient\\nis 33.\\n20Chapter 2 LOGISTIC REGRESSION\\n2. Find out the gum bacteria count at which the estimated probability of improvement is\\n0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1 in the total gum\\nbacteria count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total gum bacteria count. Remember that the most common conﬁdence levels\\nare 90%, 95%, 99%, and 99.9%. T able9.1 lists the z values for these levels.\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 2.2: Common conﬁdence levels.\\nPRB-23 \\uf059 CH.PRB- 2.20.\\nRecent research [ 4] suggests that cannabis (Fig. 2.6) and cannabinoids administration\\nin particular, may reduce the size of malignant tumours in rats.\\nFIGURE 2.6: Cannabis.\\n212.2. PROBLEMS\\nT o study factors affecting tumour shrinkage, a deep learning researcher collects data from\\ntwo groups; one group is administered with placebo (a substance that is not medicine) and\\nthe other with cannabinoids. His main research revolves around studying the relationship\\n(T able2.3) between the anticancer properties of cannabinoids and tumour shrinkage:\\nTumour Shrinkage In Rats\\nGroup Yes No Sum\\nCannabinoids 60 6833 6893\\nPlacebo 130 6778 6909\\nSum 190 13611 13801\\nTABLE 2.3: Tumour shrinkage in rats.\\nFor the true odds ratio:\\n1. Find the sample odds ratio.\\n2. Find the sample log-odds ratio.\\n3. Compute a 95% conﬁdence interval ( z0.95 = 1.645; z0.975 = 1.96) for the true log odds\\nratio and true odds ratio.\\n2.2.5 The Logit Function and Entropy\\nPRB-24 \\uf059 CH.PRB- 2.21.\\nThe entropy (see Chapter 4) of a single binary outcome with probability p to receive 1 is\\ndeﬁned as:\\nH(p) ≡ −p log p − (1 − p) log(1 − p). (2.7)\\n1. At what p does H(p) attain its maximum value?\\n2. What is the relationship between the entropy H(p) and the logit function, given p?\\n22Chapter 2 LOGISTIC REGRESSION\\n2.2.6 Python/PyTorch/CPP\\nPRB-25 \\uf059 CH.PRB- 2.22.\\nThe following C++ code (Fig. 2.7) is part of a (very basic) logistic regression implement-\\nation module. For a theoretical discussion underlying this question, refer to problem 2.17.\\n1 #include ...\\n2 std::vector<double> theta { -6,0.05,1.0};\\n3 double sigmoid(double x) {\\n4 double tmp =1.0 / (1.0 + exp(-x));\\n5 std::cout << \"prob=\" << tmp<<std::endl;\\n6 return tmp;\\n7 }\\n8 double hypothesis(std::vector<double> x){\\n9 double z;\\n10 z=std::inner_product(std::begin(x), std ::end(x),\\nstd::begin(theta), 0.0);↪→\\n11 std::cout << \"inner_product=\" << z<<std::endl;\\n12 return sigmoid(z);\\n13 }\\n14 int classify(std::vector<double> x){\\n15 int hypo=hypothesis(x) > 0.5f;\\n16 std::cout << \"hypo=\" << hypo<<std::endl;\\n17 return hypo;\\n18 }\\n19 int main() {\\n20 std::vector<double> x1 { 1,40,3.5};\\n21 classify(x1);\\n22 }\\nFIGURE 2.7: Logistic regression in CPP\\n1. Explain the purpose of line 10, i.e., inner_product.\\n2. Explain the purpose of line 15, i.e., hypo(x) > 0.5f.\\n232.2. PROBLEMS\\n3. What does θ (theta) stand for in line 2?\\n4. Compile and run the code, you can use:\\nhttps://repl.it/languages/cpp11 to evaluate the code.\\nWhat is the output?\\nPRB-26 \\uf059 CH.PRB- 2.23.\\nThe following Python code (Fig. 2.8) runs a very simple linear model on a two-dimensional\\nmatrix.\\n1 import torch\\n2 import torch.nn as nn\\n3\\n4 lin = nn.Linear(5, 7)\\n5 data = (torch.randn(3, 5))\\n6\\n7 print(lin(data).shape)\\n8 >?\\nFIGURE 2.8: A linear model in PyTorch\\nWithout actually running the code, determine what is the size of the matrix printed as a\\nresult of applying the linear model on the matrix.\\nPRB-27 \\uf059 CH.PRB- 2.24.\\nThe following Python code snippet (Fig. 2.9) is part of a logistic regression implementa-\\ntion module in Python.\\n24Chapter 2 LOGISTIC REGRESSION\\n1 from scipy.special import expit\\n2 import numpy as np\\n3 import math\\n4\\n5 def Func001(x):\\n6 e_x = np.exp(x - np.max(x))\\n7 return e_x / e_x.sum()\\n8\\n9 def Func002(x):\\n10 return 1 / (1 + math.exp(-x))\\n11\\n12 def Func003(x):\\n13 return x * (1-x)\\nFIGURE 2.9: Logistic regression methods in Python.\\nAnalyse the methods Func001 , Func002 and Func003 presented in Fig. 2.9, ﬁnd their\\npurposes and name them.\\nPRB-28 \\uf059 CH.PRB- 2.25.\\nThe following Python code snippet (Fig. 2.10) is part of a machine learning module in\\nPython.\\n252.2. PROBLEMS\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5 ^^I^^I\\n6 def Func006(y_hat, y):\\n7 if y == 1:\\n8 return -np.log(y_hat)\\n9 else:\\n10 return -np.log(1 - y_hat)^^I\\nFIGURE 2.10: Logistic regression methods in Python.\\nAnalyse the method Func006 presented in Fig. 2.10. What important concept in machine-\\nlearning does it implement?\\nPRB-29 \\uf059 CH.PRB- 2.26.\\nThe following Python code snippet (Fig. 2.11) presents several different variations of the\\nsame function.\\n26Chapter 2 LOGISTIC REGRESSION\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5\\n6 def Ver001(x):\\n7 return 1 / (1 + math.exp(-x))\\n8\\n9 def Ver002(x):\\n10 return 1 / (1 + (np.exp(-x)))\\n11\\n12 WHO_AM_I = 709\\n13\\n14 def Ver003(x):\\n15 return 1 / (1 + np.exp(-(np.clip(x, -WHO_AM_I, None))))\\nFIGURE 2.11: Logistic regression methods in Python.\\n1. Which mathematical function do these methods implement?\\n2. What is signiﬁcant about the number 709 in line 11?\\n3. Given a choice, which method would you use?\\n2.3 Solutions\\n2.3.1 General Concepts\\nSOL-4 \\uf14b CH.SOL- 2.1.\\nTrue. However, when an excessive and unnecessary number of variables is used in a lo-\\ngistic regression model, peculiarities (e.g., speciﬁc attributes) of the underlying data set dis-\\nproportionately affect the coefﬁcients in the model, a phenomena commonly referred to as\\n“overﬁtting”. Therefore, it is important that a logistic regression model does not start training\\nwith more variables than is justiﬁed for the given number of observations. \\x04\\n272.3. SOLUTIONS\\nSOL-5 \\uf14b CH.SOL- 2.2.\\nThe odds of success are deﬁned as the ratio between the probability of success p ∈ [0, 1]\\nand the probability of failure 1 − p. Formally:\\nOdds(p) ≡\\n(\\np\\n1 − p\\n)\\n. (2.8)\\nFor instance, assuming the probability of success of an event is p = 0 .7. Then, in our\\nexample, the odds of success are 7/3, or 2.333 to 1. Naturally, in the case of equal probabilities\\nwhere p = 0.5, the odds of success is 1 to 1.\\n\\x04\\nSOL-6 \\uf14b CH.SOL- 2.3.\\n1. An interaction is the product of two single predictor variables implying a non-additive\\neffect.\\n2. The simplest interaction model includes a predictor variable formed by multiplying two\\nordinary predictors. Let us assume two variables X and Z. Then, the logistic regression\\nmodel that employs the simplest form of interaction follows:\\nβ0 + β1X + β2Z + β3XZ, (2.9)\\nwhere the coefﬁcient for the interaction term XZ is represented by predictor β3.\\n3. For testing the contribution of an interaction, two principal methods are commonly\\nemployed; the Wald chi-squared test or a likelihood ratio test between the model with\\nand without the interaction term. Note: How does interaction relates to information\\ntheory? What added value does it employ to enhance model performance?\\n\\x04\\nSOL-7 \\uf14b CH.SOL- 2.4.\\nFalse. This is exactly the deﬁnition of supervised learning; when labels are known then\\nsupervision guides the learning process. \\x04\\n28Chapter 2 LOGISTIC REGRESSION\\nSOL-8 \\uf14b CH.SOL- 2.5.\\nIn the case of logistic regression, the response variable is the log of the odds of being clas-\\nsiﬁed in a group of binary or multi-class responses. This deﬁnition essentially demonstrates\\nthat odds can take the form of a vector. \\x04\\nSOL-9 \\uf14b CH.SOL- 2.6.\\nWhen a transformation to the response variable is applied, it yields a probability distribu-\\ntion over the output classes, which is bounded between 0 and 1; this transformation can be\\nemployed in several ways, e.g., a softmax layer, the sigmoid function or classic normalization.\\nThis representation facilitates a soft-decision by the logistic regression model, which permits\\nconstruction of probability-based processes over the predictions of the model. Note: What are\\nthe pros and cons of each of the three aforementioned transformations? \\x04\\nSOL-10 \\uf14b CH.SOL- 2.7.\\nMinimizing the negative log likelihood also means maximizing the likelihood of selecting\\nthe correct class. \\x04\\n2.3.2 Odds, Log-odds\\nSOL-11 \\uf14b CH.SOL- 2.8.\\n1. The odds of the event occurring are, by deﬁnition:\\nodds = ( 0.1\\n0.9 ) = 0 .11. (2.10)\\n2. The log-odds of the event occurring are simply taken as the log of the odds:\\nlog-odds = ln(0.1/0.9) = −2.19685. (2.11)\\n3. The probability may be constructed by the following representation:\\nprobability = odds\\nodds + 1 = 0.11\\n1.11 = 0.1, (2.12)\\n292.3. SOLUTIONS\\nor, alternatively:\\np = exp (ln odds)\\nexp (ln odds) + 1 = 0.11\\n1.11 = 0.1. (2.13)\\nNote: What is the intuition behind this representation?\\n\\x04\\nSOL-12 \\uf14b CH.SOL- 2.9.\\nTrue. By deﬁnition of odds, it is easy to notice that p = 0.8 satisﬁes the following relation:\\nodds = ( 0.8\\n0.2) = 4 (2.14)\\n\\x04\\nSOL-13 \\uf14b CH.SOL- 2.10.\\nThe graph of odds to probabilities is depicted in Figure 2.12.\\n0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 0,9\\n2,0\\n4,0\\n6,0\\n8,0\\n10,0\\nProbability\\nOdds odds(p) = p\\n1−p\\nFIGURE 2.12: Odds vs. probability values.\\n\\x04\\n30Chapter 2 LOGISTIC REGRESSION\\nSOL-14 \\uf14b CH.SOL- 2.11.\\nA binary logistic regression GLM consists of there components:\\n1. Random component: refers to the probability distribution of the response variable (Y ),\\ne.g., binomial distribution for Y in the binary logistic regression, which takes on the\\nvalues Y = 0 or Y = 1.\\n2. Systematic component: describes the explanatory variables:\\n(X1, X2, ...) as a combination of linear predictors. The binary case does not constrain\\nthese variables to any degree.\\n3. Link function: speciﬁes the link between random and systematic components. It says\\nhow the expected value of the response relates to the linear predictor of explanatory\\nvariables.\\nNote: Assume that Y denotes whether a human voice activity was detected ( Y = 1 )\\nor not ( Y = 0 ) in a give time frame. Propose two systematic components and a link\\nfunction adjusted for this task.\\n\\x04\\nSOL-15 \\uf14b CH.SOL- 2.12.\\nThe hyperplane is simply deﬁned by:\\nθ0 + θT X = 0. (2.15)\\nNote: Recall the use of the logit function and derive this decision boundary rigorously. \\x04\\nSOL-16 \\uf14b CH.SOL- 2.13.\\nTrue. The logit function is deﬁned as:\\nz(p) = logit(p) = log\\n(\\np\\n1 − p\\n)\\n, (2.16)\\n312.3. SOLUTIONS\\nfor any p ∈ [0, 1]. A simple set of algebraic equations yields the inverse relation:\\np(z) = exp z\\n1 + exp z , (2.17)\\nwhich exactly describes the relation between the output and input of the logistic function, also\\nknown as the sigmoid. \\x04\\n2.3.3 The Sigmoid\\nSOL-17 \\uf14b CH.SOL- 2.14.\\nThere are various approaches to solve this problem, here we provide two; direct derivation\\nor derivation via the softmax function.\\n1. Direct derivation:\\nd\\ndx σ(x) = d\\ndx ((1 + e−x)−1) = −((1 + e−x)(−2)) d\\ndx (1 + e−x) = e−x\\n(1+e−x)2 .\\n2. Softmax derivation:\\nIn a classiﬁcation problem with mutually exclusive classes, where all of the values are\\npositive and sum to one, a softmax activation function may be used. By deﬁnition, the\\nsoftmax activation function consists of n terms, such that ∀i ∈ [1, n]:\\nf (θi) = eθi\\n∑\\nk evk\\n= 1\\n1 + e−θi\\n∑\\nk̸=i eθk\\n. (2.18)\\nT o compute the partial derivative of 2.18, we treat all θk where k ̸= i as constants and\\nthen differentiate θi using regular differentiation rules. For a given θi, let us deﬁne:\\nβ =\\n∑\\nk̸=i\\n'),\n",
              " Document(metadata={}, page_content='\\ndx (1 + e−x) = e−x\\n(1+e−x)2 .\\n2. Softmax derivation:\\nIn a classiﬁcation problem with mutually exclusive classes, where all of the values are\\npositive and sum to one, a softmax activation function may be used. By deﬁnition, the\\nsoftmax activation function consists of n terms, such that ∀i ∈ [1, n]:\\nf (θi) = eθi\\n∑\\nk evk\\n= 1\\n1 + e−θi\\n∑\\nk̸=i eθk\\n. (2.18)\\nT o compute the partial derivative of 2.18, we treat all θk where k ̸= i as constants and\\nthen differentiate θi using regular differentiation rules. For a given θi, let us deﬁne:\\nβ =\\n∑\\nk̸=i\\neθk, (2.19)\\nand\\nf (θi) = 1\\n1 + βe−θi\\n= (1 + βe−θi)−1. (2.20)\\nIt can now be shown that the derivative with respect to θi holds:\\nf ′(θi) =\\n(\\n1 + βe−θi\\n) −2\\nβe−θi, (2.21)\\n32Chapter 2 LOGISTIC REGRESSION\\nwhich can take on the informative form of:\\nf ′(θi) = f (θi)(1 − f (θi)). (2.22)\\nIt should be noted that 2.21 holds for any constant β, and for β = 1 it clearly reduces\\nto the sigmoid activation function.\\nNote: Characterize the sigmoid function when its argument approaches 0, ∞ and −∞.\\nWhat undesired properties of the sigmoid function do this values entail when considered as an\\nactivation function?\\n\\x04\\nSOL-18 \\uf14b CH.SOL- 2.15.\\n1. The logit value is simply obtained by substituting the values of the dependent variables\\nand model coefﬁcients into the linear logistic regression model, as follows:\\nlogit = β0 + β1x1 + β2x2 = −1.5 + 3 · 1 + −0.5 · 5 = −1. (2.23)\\n2. According to the natural relation between the logit and the odds, the following holds:\\nodds = elogit = eβ0+β1x1+β2x2 = e−1 = 0.3678794. (2.24)\\n3. The odds ratio is, by deﬁnition:\\nodds = P (y = 1)\\nP (y = 0) , (2.25)\\nso the logistic response function is:\\nP (y = 1) = 1\\n1 + e−logit = 1\\n1 + e1 = 0.2689414. (2.26)\\n\\x04\\n2.3.4 Truly Understanding Logistic Regression\\n332.3. SOLUTIONS\\nSOL-19 \\uf14b CH.SOL- 2.16.\\n1. T umour eradication (Y ) is the response variable and cancer type ( X) is the explanatory\\nvariable.\\n2. Relative risk (RR) is the ratio of risk of an event in one group (e.g., exposed group)\\nversus the risk of the event in the other group (e.g., non-exposed group). The odds ratio\\n(OR) is the ratio of odds of an event in one group versus the odds of the event in the\\nother group.\\n3. If we calculate odds ratio as a measure of association:\\nˆθ = 560 × 36\\n69 × 260 = 1.23745. (2.27)\\nAnd the log-odds ratio is (log(1.23745)) = 0 .213052:\\nThe odds ratio is larger than one, indicating that the odds for a breast cancer is more\\nthan the odds for a lung cancer to be eradicated. Notice however, that this result is too\\nclose to one, which prevents conclusive decision regarding the odds relation.\\nAdditionally, if we calculate relative risk as a measure of association:\\nRR =\\n560\\n560+260\\n69\\n69+36\\n= 1.0392. (2.28)\\n4. The 95% conﬁdence interval for the odds-ratio, θ is computed from the sample conﬁd-\\nence interval for log odds ratio:\\nˆσ\\n(\\nlog(ˆθ)\\n)\\n=\\n√\\n1\\n560 + 1\\n260 + 1\\n69 + 1\\n36 = 0.21886. (2.29)\\nTherefore, the 95% CI for log (θ) is:\\n0.213052 ± 1.95 × 0.21886 = (0 .6398298, −0.2137241). (2.30)\\n34Chapter 2 LOGISTIC REGRESSION\\nTherefore, the 95% CI for θ is:\\n(e−0.210, e0.647) = (0 .810, 1.909). (2.31)\\n5. The CI (0.810, 1.909) contains 1, which indicates that the true odds ratio is not signi-\\nﬁcantly different from 1 and there is not enough evidence that tumour eradication is\\ndependent on cancer type.\\n\\x04\\nSOL-20 \\uf14b CH.SOL- 2.17.\\n1. By using the deﬁned values for X1 and X2, and the known logistic regression model,\\nsubstitution yields:\\nˆp(X) = e−6+0.05X1+X2\\n(1 + e−6+0.05X1+X2) = 0.3775. (2.32)\\n2. The equation for the predicted probability tells us that:\\ne−6+0.05X1+3.5\\n(1 + e−6+0.05X1+3.5) = 0.5, (2.33)\\nwhich is equivalent to constraining:\\ne−6+0.05X1+3.5 = 1. (2.34)\\nBy taking the logarithm of both sides, we get that the number of milliseconds needed is:\\nX1 = 2.5\\n0.05 = 50. (2.35)\\n\\x04\\nSOL-21 \\uf14b CH.SOL- 2.18.\\n352.3. SOLUTIONS\\nFor the purpose of this exercise, it is instructive to pre-deﬁne z as:\\nz (X1, X2) = −6.36 − 1.02 × X1 + 0.12 × X2. (2.36)\\n1. By employing the classic logistic regression model:\\nodds = exp(z (X1, X2)). (2.37)\\n2. By substituting the given values of X1, X2 into z (X1, X2), the probability holds:\\np = exp(z (1, 100))/(1 + exp(z (1, 100))) = 0 .99. (2.38)\\n3. Y es. The coefﬁcient for coffee consumption is positive ( 0.119) and the p-value is less\\nthan 0.05 (0.0304).\\nNote: Can you describe the relation between these numerical relations and the positive\\nconclusion?\\n4. No. The p-value for this predictor is 0.3818 > 0.05.\\nNote: Can you explain why this inequality implicates a lack of statistical evidence?\\n\\x04\\nSOL-22 \\uf14b CH.SOL- 2.19.\\n1. The estimated probability of improvement is:\\nˆπ(gum bacteria) =\\nexp(−4.8792 + 0.0258 × gum bacteria)\\n1 + exp(−4.8792 + 0.0258 × gum bacteria).\\nHence, ˆπ(33) = 0 .01748.\\n36Chapter 2 LOGISTIC REGRESSION\\n2. For ˆπ(gum bacteria) = 0 .5 we know that:\\nˆπ(gum) = exp( ˆα + ˆβx)\\n1 + exp( ˆα + ˆβx)\\n= 0.5 (2.39)\\ngum bacteria = −ˆα/ ˆβ = 4.8792/0.0258 = 189 .116. (2.40)\\n3. The estimated odds ratio are given by:\\nexp( ˆβ) = exp(0 .0258) = 1 .0504. (2.41)\\n4. A 99% conﬁdence interval for β is calculated as follows:\\nˆβ ± z0.005 × ASE( ˆβ) = (2.42)\\n0.0258 ± 2.576 × 0.0194 (2.43)\\n= (−0.00077, 0.9917). (2.44)\\nTherefore, a 99% conﬁdence interval for the true odds ratio exp(β) is given by:\\n(exp(−0.00077), exp(0.9917)) = (0 .99923, 2.6958). (2.45)\\n\\x04\\nSOL-23 \\uf14b CH.SOL- 2.20.\\n1. The sample odds ratio is:\\nˆθ = 130 × 6833\\n60 × 6778 = 2.1842. (2.46)\\n372.3. SOLUTIONS\\n2. The estimated standard error for log\\n(\\nˆθ\\n)\\nis:\\nˆσ\\n(\\nlog ˆθ\\n)\\n=\\n√\\n1\\n60 + 1\\n6833 + 1\\n130 + 1\\n6778 = 0.1570. (2.47)\\n3. According to previous sections, the 95% CI for the true log odds ratio is:\\n0.7812 ± 1.96 × 0.1570 = (0 .4734, 1.0889). (2.48)\\nCorrespondingly, the 95% CI for the true odds ratio is:\\n(e0.4734, e1.0889) = (1 .6060, 2.9710). (2.49)\\n\\x04\\n2.3.5 The Logit Function and Entropy\\nSOL-24 \\uf14b CH.SOL- 2.21.\\n1. The entropy (Fig. 2.13) has a maximum value of log2(2) for probability p = 1/2, which\\nis the most chaotic distribution. A lower entropy is a more predictable outcome, with\\nzero providing full certainty.\\n2. The derivative of the entropy with respect to p yields the negative of the logit func-\\ntion:\\ndH(p)\\ndp = −logit(p). (2.50)\\nNote: The curious reader is encouraged to rigorously prove this claim.\\n\\x04\\n2.3.6 Python, PyTorch, CPP\\nSOL-25 \\uf14b CH.SOL- 2.22.\\n38Chapter 2 LOGISTIC REGRESSION\\nFIGURE 2.13: Binary entropy .\\n1. During inference, the purpose of inner_product is to multiply the vector of logistic re-\\ngression coefﬁcients with the vector of the input which we like to evaluate, e.g., calculate\\nthe probability and binary class.\\n2. The line hypo(x) > 0.5f is commonly used for the evaluation of binary classiﬁcation\\nwherein probability values above 0.5 (i.e., a threshold) are regarded as TRUE whereas\\nvalues below 0.5 are regarded as F ALSE.\\n3. The term θ (theta) stands for the logistic regression coefﬁcients which were evaluated\\nduring training.\\n4. The output is as follows:\\n1 > inner_product=-0.5\\n2 > prob=0.377541\\n3 > hypo=0\\nFIGURE 2.14: Logistic regression in C++\\n\\x04\\nSOL-26 \\uf14b CH.SOL- 2.23.\\n392.3. SOLUTIONS\\nBecause the second dimension of lin is 7, and the ﬁrst dimension of data is 3, the result-\\ning matrix has a shape of torch.Size([3, 7]) .\\n\\x04\\nSOL-27 \\uf14b CH.SOL- 2.24.\\nIdeally, you should be able to recognize these functions immediately upon a request from\\nthe interviewer.\\n1. A softmax function.\\n2. A sigmoid function.\\n3. A derivative of a sigmoid function.\\n\\x04\\nSOL-28 \\uf14b CH.SOL- 2.25.\\nThe function implemented in Fig. 2.10 is the binary cross-entropy function. \\x04\\nSOL-29 \\uf14b CH.SOL- 2.26.\\n1. All the methods are variations of the sigmoid function.\\n2. In Python, approximately 1.797e + 308 holds the largest possible valve for a ﬂoating\\npoint variable. The logarithm of which is evaluated at 709.78. If you try to execute the\\nfollowing expression in Python, it will result in inf : np.log(1.8e + 308).\\n3. I would use Ver003 because of its stability. Note: Can you entail why is this method\\nmore stable than the others?\\n\\x04\\n40CHAPTER\\n3\\nPROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAnyone who considers arithmetical methods of producing random digits is, of\\ncourse, in a state of sin.\\n— John von Neumann (1903-1957)\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nThe Beta-Binomial distribution . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 773.1. INTRODUCTION\\n3.1 Introduction\\nT\\nHE Bayesian school of thought has permeated ﬁelds such as mechanical\\nstatistics, classical probability , and ﬁnancial mathematics [ 13]. In tandem,\\nthe subject matter itself has gained attraction, particularly in the ﬁeld of\\nBML. It is not surprising then, that several new Python based probabilistic\\nprogramming libraries such as PyMc3 and Stan [ 11] have emerged and have become\\nwidely adopted by the machine learning community .\\nThis chapter aims to introduce the Bayesian paradigm and apply Bayesian infer-\\nences in a variety of problems. In particular, the reader will be introduced with real-\\nlife examples of conditional probability and also discover one of the most important\\nresults in Bayesian statistics: that the family of beta distributions is conjugate to a bi-\\nnomial likelihood . It should be stressed that Bayesian inference is a subject matter\\nthat students evidently ﬁnd hard to grasp, since it heavily relies on rigorous probab-\\nilistic interpretations of data. Speciﬁcally , several obstacles hamper with the prospect\\nof learning Bayesian statistics:\\n1. Students typically undergo merely basic introduction to classical probability and\\nstatistics. Nonetheless, what follows requires a very solid grounding in these\\nﬁelds.\\n2. Many courses and resources that address Bayesian learning do not cover essen-\\ntial concepts.\\n3. A strong comprehension of Bayesian methods involves numerical training and\\nsophistication levels that go beyond ﬁrst year calculus.\\nConclusively , this chapter may be much harder to understand than other chapters.\\nThus, we strongly urge the readers to thoroughly solve the following questions and\\nverify their grasp of the mathematical concepts in the basis of the solutions [ 8].\\n3.2 Problems\\n3.2.1 Expectation and Variance\\nPRB-30 \\uf059 CH.PRB- 3.1.\\nDeﬁne what is meant by a Bernoulli trial.\\n42Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPRB-31 \\uf059 CH.PRB- 3.2.\\nThe binomial distribution is often used to model the probability that k out of a group of n\\nobjects bare a speciﬁc characteristic. Deﬁne what is meant by a binomial random variable\\nX.\\nPRB-32 \\uf059 CH.PRB- 3.3.\\nWhat does the following shorthand stand for?\\nX ∼ Binomial(n, p ) (3.1)\\nPRB-33 \\uf059 CH.PRB- 3.4.\\nFind the probability mass function (PMF) of the following random variable:\\nX ∼ Binomial(n, p ) (3.2)\\nPRB-34 \\uf059 CH.PRB- 3.5.\\nAnswer the following questions:\\n1. Deﬁne what is meant by (mathematical) expectation.\\n2. Deﬁne what is meant by variance.\\n3. Derive the expectation and variance of a the binomial random variable X ∼ Binomial(n, p )\\nin terms of p and n.\\nPRB-35 \\uf059 CH.PRB- 3.6.\\nProton therapy (PT) is a widely adopted form of treatment for many types of cancer [ 6].\\nA PT device which was not properly calibrated is used to treat a patient with pancreatic\\ncancer (Fig. 3.1). As a result, a PT beam randomly shoots 200 particles independently and\\ncorrectly hits cancerous cells with a probability of 0.1.\\n433.2. PROBLEMS\\nFIGURE 3.1: Histopathology for pancreatic cancer cells.\\n1. Find the statistical distribution of the number of correct hits on cancerous cells in\\nthe described experiment. What are the expectation and variance of the corresponding\\nrandom variable?\\n2. A radiologist using the device claims he was able to hit exactly 60 cancerous cells.\\nHow likely is it that he is wrong?\\n3.2.2 Conditional Probability\\nPRB-36 \\uf059 CH.PRB- 3.7.\\nGiven two events A and B in probability space H, which occur with probabilities P (A)\\nand P (B), respectively:\\n1. Deﬁne the conditional probability of A given B. Mind singular cases.\\n2. Annotate each part of the conditional probability formulae.\\n3. Draw an instance of Venn diagram, depicting the intersection of the events A and B.\\nAssume that A ⋃ B = H.\\nPRB-37 \\uf059 CH.PRB- 3.8.\\nBayesian inference amalgamates data information in the likelihood function with known\\nprior information. This is done by conditioning the prior on the likelihood using the Bayes\\nformulae. Assume two events A and B in probability space H, which occur with probabilities\\n44Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nP (A) and P (B), respectively. Given that A ⋃ B = H, state the Bayes formulae for this case,\\ninterpret its components and annotate them.\\nPRB-38 \\uf059 CH.PRB- 3.9.\\nDeﬁne the terms likelihood and log-likelihood of a discrete random variable X given\\na ﬁxed parameter of interest γ. Give a practical example of such scenario and derive its\\nlikelihood and log-likelihood.\\nPRB-39 \\uf059 CH.PRB- 3.10.\\nDeﬁne the term prior distribution of a likelihood parameter γ in the continuous case.\\nPRB-40 \\uf059 CH.PRB- 3.11.\\nShow the relationship between the prior, posterior and likelihood probabilities.\\nPRB-41 \\uf059 CH.PRB- 3.12.\\nIn a Bayesian context, if a ﬁrst experiment is conducted, and then another experiment is\\nfollowed, what does the posterior become for the next experiment?\\nPRB-42 \\uf059 CH.PRB- 3.13.\\nWhat is the condition under which two events A and B are said to be statistically\\nindependent?\\n3.2.3 Bayes Rule\\nPRB-43 \\uf059 CH.PRB- 3.14.\\nIn an experiment conducted in the ﬁeld of particle physics (Fig. 3.2), a certain particle\\nmay be in two distinct equally probable quantum states: integer spin or half-integer spin.\\nIt is well-known that particles with integer spin are bosons, while particles with half-integer\\nspin are fermions [ 4].\\n453.2. PROBLEMS\\nFIGURE 3.2: Bosons and fermions: particles with half-integer spin are fermions.\\nA physicist is observing two such particles, while at least one of which is in a half-integer\\nstate. What is the probability that both particles are fermions?\\nPRB-44 \\uf059 CH.PRB- 3.15.\\nDuring pregnancy, the Placenta Chorion T est [1] is commonly used for the diagnosis of\\nhereditary diseases (Fig. 3.3). The test has a probability of 0.95 of being correct whether or\\nnot a hereditary disease is present.\\n46Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.3: Foetal surface of the placenta\\nIt is known that 1% of pregnancies result in hereditary diseases. Calculate the probability\\nof a test indicating that a hereditary disease is present.\\nPRB-45 \\uf059 CH.PRB- 3.16.\\nThe Dercum disease [ 3] is an extremely rare disorder of multiple painful tissue growths.\\nIn a population in which the ratio of females to males is equal, 5% of females and 0.25% of\\nmales have the Dercum disease (Fig. 3.4).\\nFIGURE 3.4: The Dercum disease\\nA person is chosen at random and that person has the Dercum disease. Calculate the\\nprobability that the person is female.\\nPRB-46 \\uf059 CH.PRB- 3.17.\\nThere are numerous fraudulent binary options websites scattered around the Internet,\\nand for every site that shuts down, new ones are sprouted like mushrooms. A fraudulent AI\\n473.2. PROBLEMS\\nbased stock-market prediction algorithm utilized at the New Y ork Stock Exchange, (Fig. 3.6)\\ncan correctly predict if a certain binary option [ 7] shifts states from 0 to 1 or the other way\\naround, with 85% certainty.\\nFIGURE 3.5: The New York Stock Exchange.\\nA ﬁnancial engineer has created a portfolio consisting twice as many state-1 options then\\nstate-0 options. A stock option is selected at random and is determined by said algorithm to\\nbe in the state of 1. What is the probability that the prediction made by the AI is correct?\\nPRB-47 \\uf059 CH.PRB- 3.18.\\nIn an experiment conducted by a hedge fund to determine if monkeys (Fig. 3.6) can\\noutperform humans in selecting better stock market portfolios, 0.05 of humans and 1 out of\\n15 monkeys could correctly predict stock market trends correctly.\\n48Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.6: Hedge funds and monkeys.\\nFrom an equally probable pool of humans and monkeys an “expert” is chosen at ran-\\ndom. When tested, that expert was correct in predicting the stock market shift. What is the\\nprobability that the expert is a human?\\nPRB-48 \\uf059 CH.PRB- 3.19.\\nDuring the cold war, the U.S.A developed a speech to text (STT) algorithm that could\\ntheoretically detect the hidden dialects of Russian sleeper agents. These agents (Fig. 3.7),\\nwere trained to speak English in Russia and subsequently sent to the US to gather intelli-\\ngence. The FBI was able to apprehend ten such hidden Russian spies [ 9] and accused them\\nof being \"sleeper\" agents.\\nFIGURE 3.7: Dialect detection.\\n493.2. PROBLEMS\\nThe Algorithm relied on the acoustic properties of Russian pronunciation of the word\\n(v-o-k-s-a-l) which was borrowed from English V-a-u-x-h-a-l-l. It was alleged that it is im-\\npossible for Russians to completely hide their accent and hence when a Russian would\\nsay V-a-u-x-h-a-l-l, the algorithm would yield the text \"v-o-k-s-a-l\". T o test the algorithm\\nat a diplomatic gathering where 20% of participants are Sleeper agents and the rest Americ-\\nans, a data scientist randomly chooses a person and asks him to say V-a-u-x-h-a-l-l. A single\\nletter is then chosen randomly from the word that was generated by the algorithm, which\\nis observed to be an \"l\". What is the probability that the person is indeed a Russian sleeper\\nagent?\\nPRB-49 \\uf059 CH.PRB- 3.20.\\nDuring World War II, forces on both sides of the war relied on encrypted communica-\\ntions. The main encryption scheme used by the German military was an Enigma machine\\n[5], which was employed extensively by Nazi Germany. Statistically, the Enigma machine\\nsent the symbols X and Z Fig. ( 3.8) according to the following probabilities:\\nP (X) = 2\\n9 (3.3)\\nP (Z) = 7\\n9 (3.4)\\nFIGURE 3.8: The Morse telegraph code.\\nIn one incident, the German military sent encoded messages while the British army used\\ncountermeasures to deliberately tamper with the transmission. Assume that as a result of the\\nBritish countermeasures, an X is erroneously received as a Z (and mutatis mutandis) with a\\n50Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nprobability 1\\n7. If a recipient in the German military received a Z, what is the probability that\\na Z was actually transmitted by the sender?\\n3.2.4 Maximum Likelihood Estimation\\nPRB-50 \\uf059 CH.PRB- 3.21.\\nWhat is likelihood function of the independent identically distributed (i.i.d) random\\nvariables:\\nX1, · · · , Xn where Xi ∼ binomial(n, p ), ∀i ∈ [1, n],\\nand where p is the parameter of interest?\\nPRB-51 \\uf059 CH.PRB- 3.22.\\nHow can we derive the maximum likelihood estimator (MLE) of the i.i.d samples\\nX1, · · · , Xn introduced in Q. 3.21?\\nPRB-52 \\uf059 CH.PRB- 3.23.\\nWhat is the relationship between the likelihood function and the log-likelihood function?\\nPRB-53 \\uf059 CH.PRB- 3.24.\\nDescribe how to analytically ﬁnd the MLE of a likelihood function?\\nPRB-54 \\uf059 CH.PRB- 3.25.\\nWhat is the term used to describe the ﬁrst derivative of the log-likelihood function?\\nPRB-55 \\uf059 CH.PRB- 3.26.\\nDeﬁne the term Fisher information.\\n3.2.5 Fisher Information\\n513.2. PROBLEMS\\nPRB-56 \\uf059 CH.PRB- 3.27.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history [ 2] with a death tool far exceeding all\\npast outbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976\\nin Sudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 3.9: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the center for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ | y) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y, γ ∈ [0, 1], y = 1, 2, . . . , n (3.5)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ,\\nthe proportion of infected humans in the entire population. The expectation and variance of\\nthe binomial distribution are:\\nE(y|γ, n) = nγ, V (y|γ, n) = nγ(1 − γ) (3.6)\\nAnswer the following; for the likelihood function of the form Lx(γ):\\n1. Find the log-likelihood function lx(γ) = ln Lx(γ).\\n52Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. Find the gradient of lx(γ).\\n3. Find the Hessian matrix H(γ).\\n4. Find the Fisher information I(γ).\\n5. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\nPRB-57 \\uf059 CH.PRB- 3.28.\\nIn this question, you are going to derive the Fisher information function for several\\ndistributions. Given a probability density function (PDF) f (X|γ), you are provided with\\nthe following deﬁnitions:\\n1. The natural logarithm of the PDF ln f (X|γ) = Φ(X|γ).\\n2. The ﬁrst partial derivative Φ′(X|γ).\\n3. The second partial derivative Φ′′(X|γ).\\n4. The Fisher Information for a continuous random variable:\\nI(γ) = −Eγ\\n[\\nΦ′(X|γ)2\\n]\\n. (3.7)\\nFind the Fisher Information I(γ) for the following distributions:\\n1. The Bernoulli Distribution X ∼ B(1, γ).\\n2. The Poisson Distribution X ∼ P oiss(θ).\\nPRB-58 \\uf059 CH.PRB- 3.29.\\n1. True or False: The Fisher Information is used to compute the Cramer-Rao bound on\\nthe variance of any unbiased maximum likelihood estimator.\\n2. True or False: The Fisher Information matrix is also the Hessian of the symmetrized\\nKL divergence.\\n533.2. PROBLEMS\\n3.2.6 Posterior & prior predictive distributions\\nPRB-59 \\uf059 CH.PRB- 3.30.\\nIn chapter 3 we discussed the notion of a prior and a posterior distribution.\\n1. Deﬁne the term posterior distribution.\\n2. Deﬁne the term prior predictive distribution.\\nPRB-60 \\uf059 CH.PRB- 3.31.\\nLet y be the number of successes in 5 independent trials, where the probability of success\\nis θ in each trial. Suppose your prior distribution for θ is as follows: P (θ = 1 /2) = 0 .25,\\nP (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y) after observing y.\\n2. Derive the prior predictive distribution for y.\\n3.2.7 Conjugate priors\\nPRB-61 \\uf059 CH.PRB- 3.32.\\nIn chapter 3 we discussed the notion of a prior and a posterior.\\n1. Deﬁne the term conjugate prior.\\n2. Deﬁne the term non-informative prior.\\nThe Beta-Binomial distribution\\nPRB-62 \\uf059 CH.PRB- 3.33.\\nThe Binomial distribution was discussed extensively in chapter 3. Here, we are going to\\nshow one of the most important results in Bayesian machine learning. Prove that the family\\nof beta distributions is conjugate to a binomial likelihood , so that if a prior is in that\\n54Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nfamily then so is the posterior. That is, show that:\\nx ∼ Ber(γ), γ ∼ B (α, β) ⇒ γ|x ∼ B (α′, β′) (3.8)\\nFor instance, for h heads and t tails, the posterior is:\\nB(h + α, t + β) (3.9)\\n3.2.8 Bayesian Deep Learning\\nPRB-63 \\uf059 CH.PRB- 3.34.\\nA recently published paper presents a new layer for a new Bayesian neural network\\n(BNN). The layer behaves as follows. During the feed-forward operation, each of the hidden\\nneurons Hn , n ∈ 1, 2 in the neural network (Fig. 3.10) may, or may not ﬁre independently\\nof each other according to a known prior distribution.\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 3.10: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ binomial(n, γ ) random variable\\nand ﬁres with a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U nif orm(0, γ) random variable\\nand ﬁres with a probability of γ.\\nPRB-64 \\uf059 CH.PRB- 3.35.\\nY our colleague, a veteran of the Deep Learning industry, comes up with an idea for for\\n553.2. PROBLEMS\\na BNN layer entitled OnOffLayer. He suggests that each neuron will stay on (the other\\nstate is off) following the distribution f (x) = e−x for x > 0 and f (x) = 0 otherwise\\n(Fig. 3.11). X indicates the time in seconds the neuron stays on . In a BNN, 200 such\\nneurons are activated independently in said OnOffLayer. The OnOffLayer is set to off (e.g.\\nnot active) only if at least 150 of the neurons are shut down . Find the probability that\\nthe OnOffLayer will be active for at least 20 seconds without being shut down.\\non offtime = f (x) = e−x\\nFIGURE 3.11: OnOffLayer in a BNN model.\\nPRB-65 \\uf059 CH.PRB- 3.36.\\nA Dropout layer [12] (Fig. 3.12) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 3.12: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [10], a Dropout layer is declared as follows ( 3.1):\\n56Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 3.1: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 3.1) indicates that the probability of zeroing an\\nelement is 0.2.\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 3.13: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 3.12). Here, for illustration purposes, all two\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\nY ou are interested in the proportionθ of dropped-out neurons. Assume that the chance of\\ndrop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the posterior\\nof θ.\\nPRB-66 \\uf059 CH.PRB- 3.37.\\nA new data scientist in your team, who was formerly a Quantum Physicist, suggests\\nthe following procedure for a Dropout layer entitled QuantumDrop which is based on\\nQuantum principles and the Maxwell Boltzmann distribution. In the Maxwell-Boltzmann\\n573.2. PROBLEMS\\ndistribution, the likelihood of ﬁnding a particle with a particular velocity v is provided by:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.10)\\n0 1 000 2 000 3 000 4 000 5 000\\n0\\n2\\n4\\n·10−4\\nv in m·s−1\\nP (v)\\nHelium\\nFIGURE 3.14: The Maxwell-Boltzmann distribution.\\nIn the suggested QuantumDrop layer ( 3.15), each of the neurons behaves like a molecule\\nand is distributed according to the Maxwell-Boltzmann distribution and ﬁres only when\\nthe most probable speed is reached . This speed is the velocity associated with the highest\\npoint in the Maxwell distribution ( 3.14). Using calculus, brain power and some mathem-\\natical manipulation, ﬁnd the most likely value (speed) at which the neuron will ﬁre .\\noff firedneuron − f ires\\nFIGURE 3.15: A QuantumDrop layer.\\n58Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3.3 Solutions\\n3.3.1 Expectation and Variance\\nSOL-30 \\uf14b CH.SOL- 3.1.\\nThe notion of a Bernoulli trial refers to an experiment with two dichotomous binary out-\\ncomes; success (x = 1), and failure (x = 0). \\x04\\nSOL-31 \\uf14b CH.SOL- 3.2.\\nA binomial random variable X = k represents k successes in n mutually independent\\nBernoulli trials. \\x04\\nSOL-32 \\uf14b CH.SOL- 3.3.\\nThe shorthand X ∼ Binomial(n, p ) indicates that the random variable X has the bi-\\nnomial distribution (Fig. 3.16). The positive integer parameter n indicates the number of\\nBernoulli trials and the real parameter p, 0 < p < 1 holds the probability of success in each of\\nthese trials.\\n0 10 20 30 40 50\\n0,0\\n0,2\\n0,4\\np(x = k) =\\n( n\\nk\\n)\\n· pk · (1 − p)n−k\\nx\\np(x)\\nn = 50, p = 0.3\\nn = 50, p = 0.7\\nn = 50, p = 0.9\\nFIGURE 3.16: The binomial distribution.\\n\\x04\\nSOL-33 \\uf14b CH.SOL- 3.4.\\n593.3. SOLUTIONS\\nThe random variable X ∼ Binomial(n, p ) has the following PMF:\\nP (X = k) =\\n(\\nn\\nk\\n)\\npk (1 − p)n−k ; k = 0, 1, 2, . . . , n. (3.11)\\n\\x04\\nSOL-34 \\uf14b CH.SOL- 3.5.\\nThe answers below regard a discrete random variable. The curious reader is encouraged to\\nexpend them to the continuous case.\\n1. For a random variable X with probability mass function P (X = k) and a set of out-\\ncomes K, the expected value of X is deﬁned as:\\nE[X] :=\\n∑\\nk∈K\\nkP (X = k). (3.12)\\nNote: The expectation of X may also be denoted by µX.\\n2. The variance of X is deﬁned as:\\nVar[X] := E\\n[\\n(X − E[X])2\\n]\\n. (3.13)\\nNote: The variance of X may also be denoted by σ2\\nX, while σX itself denotes the stand-\\nard deviation of X.\\n3. The population mean and variance of a binomial random variable with parameters n\\nand p are:\\nE[X] = np V [X] = np(1 − p) (3.14)\\nNote: Why is this solution intuitive? What information theory-related phenomenon\\noccurs when p = 1/2?\\n\\x04\\nSOL-35 \\uf14b CH.SOL- 3.6.\\n60Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1. This scenario describes an experiment that is repeated 200 times independently with a\\nsuccess probability of 0.1. Thus, if the random variable X denotes the number of times\\nsuccess was obtained, then it is best characterized by the binomial distribution with\\nparameters n = 200 and p = 0.1. Formally:\\nX ∼ Binomial(200, 0.1). (3.15)\\nThe expectation of X is given by:\\nx = E(x) = 200 × 0.1 = 20 , (3.16)\\nand its respective variance is:\\nV ar = 200 × 0.10(1 − 0.10) = 18 .0. (3.17)\\n2. Here we propose two distinguished methods to answer the question.\\nPrimarily, the straightforward solution is to employ the deﬁnition of the binomial dis-\\ntribution and substitute the value of X in it. Namely:\\nP (X = 60; n = 200, p = 0.1)\\n=\\n(\\n200\\n60\\n)\\n0.160 (1 − 0.1)200−60\\n=≈ 2.7 × e−15.\\n(3.18)\\nThis leads to an extremely high probability that the radiologist is mistaken.\\nThe following approach is longer and more advanced, but grants the reader with insights\\nand intuition regarding the results. T o derive how wrong the radiologist is, we can\\nemploy an approximation by considering the standard normal distribution. In statistics,\\nthe Z-score allows us to understand how far from the mean is a data point in units of\\nstandard deviation, thus revealing how likely it is to occur (Fig. 3.17).\\n613.3. SOLUTIONS\\nZ-score\\nz =\\nData point\\nx − µ\\nExpectation\\nσ\\nStandard dev .\\n. (3.19)\\nFIGURE 3.17: Z-score\\nTherefore, the probability of correctly hitting 60 cells is:\\nP (X ≥ 60) = P (Z ≥ 60 − 20√\\n18.0 ) = P (Z ≥ 9.428) ≈ 0. (3.20)\\nAgain, the outcome'),\n",
              " Document(metadata={}, page_content=' extremely high probability that the radiologist is mistaken.\\nThe following approach is longer and more advanced, but grants the reader with insights\\nand intuition regarding the results. T o derive how wrong the radiologist is, we can\\nemploy an approximation by considering the standard normal distribution. In statistics,\\nthe Z-score allows us to understand how far from the mean is a data point in units of\\nstandard deviation, thus revealing how likely it is to occur (Fig. 3.17).\\n613.3. SOLUTIONS\\nZ-score\\nz =\\nData point\\nx − µ\\nExpectation\\nσ\\nStandard dev .\\n. (3.19)\\nFIGURE 3.17: Z-score\\nTherefore, the probability of correctly hitting 60 cells is:\\nP (X ≥ 60) = P (Z ≥ 60 − 20√\\n18.0 ) = P (Z ≥ 9.428) ≈ 0. (3.20)\\nAgain, the outcome shows the likelihood that the radiologist was wrong approaches 1.\\nNote: Why is the relation depicted in Fig. 3.17 deduces that Z is a standard Gaussian?\\nUnder what terms is this conclusion valid? Why does eq. (3.20) employs the cumulative\\ndistribution function and not the probability mass function?\\n\\x04\\n3.3.2 Conditional Probability\\nSOL-36 \\uf14b CH.SOL- 3.7.\\n1. For two events A and B with P (B) > 0, the conditional probability of A given that\\nB has occurred is deﬁned as:\\nP (A|B) = P (A ∩ B)\\nP (B) . (3.21)\\nIt is easy to note that if P (B) = 0 , this relation is not deﬁned mathematically. In this\\ncase, P (A|B) = P (A ∩ B) = P (A).\\n2. The annotated probabilities are displayed in Fig. 3.18:\\n62Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nA given B\\nP (A|B) =\\nA and B\\nP (A ∩ B)\\nP (B)\\nB only\\n. (3.22)\\nFIGURE 3.18: Conditional probability\\n3. An example of a diagram depicting the intersected events A and B is displayed in Fig.\\n3.19:\\nA B\\nH\\nFIGURE 3.19: V enn diagram of the intersected events A and B in probability space H\\n\\x04\\nSOL-37 \\uf14b CH.SOL- 3.8.\\nThe Bayes formulae reads:\\nP (A|B) = P (B|A)P (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac), (3.23)\\nwhere P (Ac) is the complementary probability of P (A). The interpretation of the elements in\\n633.3. SOLUTIONS\\nBayes formulae is as follows:\\nposterior probability = likelihood of the data × prior probability\\nnormalization constant . (3.24)\\nNote: What is the important role of the normalization constant? Analyze the cases where\\nP (B) → 0 and P (B) → 1. The annotated probabilities are displayed in (Fig. 3.20):\\nPosterior\\nP (A|B) =\\nLikelihood\\nP (B|A)\\nPrior\\nP (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac)\\nB only\\n. (3.25)\\nFIGURE 3.20: Annotated components of the Bayes formula (eq. 3.23)\\n\\x04\\nSOL-38 \\uf14b CH.SOL- 3.9.\\nGiven X as a discrete randomly distributed variable and given γ as the parameter of\\ninterest, the likelihood and the log-likelihood of X given γ follows respectively:\\nLγ(X = x) = p(X = x|γ) (3.26)\\nℓγ(X = x) = ln ( p(X = x|γ)) (3.27)\\nThe term likelihood can be intuitively understood from this deﬁnition; it deduces how likely is\\nto obtain a value x when a prior information is given regarding its distribution, namely the\\nparameter γ. For example, let us consider a biased coin toss with ph = γ. Then:\\nLγ(X = “h′′) = p(X = “h′′|γ) = γ. (3.28)\\nℓγ(X = “h′′) = ln ( p(X = “h′′|γ)) = ln ( γ) . (3.29)\\n64Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nNote: The likelihood function may also follow continuous distributions such as the normal\\ndistribution. In the latter, it is recommended and often obligatory to employ the log-likelihood.\\nWhy? We encourage the reader to modify the above to the continuous case of normal distribu-\\ntion and derive the answer. \\x04\\nSOL-39 \\uf14b CH.SOL- 3.10.\\nThe continuous prior distribution, f (Γ = γ) represents what is known about the probab-\\nility of the value γ before the experiment has commenced. It is termed as being subjective,\\nand therefore may vary considerably between researchers. By proceeding the previous example,\\nf (Γ = 0.8) holds the probability of randomly ﬂipping a coin that yields “heads” with chance\\nof 80% of times. \\x04\\nSOL-40 \\uf14b CH.SOL- 3.11.\\nThe essence of Bayesian analysis is to draw inference of unknown quantities or quantiles\\nfrom the posterior distribution p(Γ = γ|X = x), which is traditionally derived from prior\\nbeliefs and data information. Bayesian statistical conclusions about chances to obtain the para-\\nmeter Γ = γ or unobserved values of random variable X = x, are made in terms of prob-\\nability statements. These probability statements are conditional on the observed values of X,\\nwhich is denoted as p(Γ = γ|X = x), called posterior distributions of parameter γ. Bayesian\\nanalysis is a practical method for making inferences from data and prior beliefs using probab-\\nility models for quantities we observe and for quantities which we wish to learn. Bayes rule\\nprovides a relationship of this form:\\nposterior ∝ p(x|γ)p(γ) ∝ data given prior × chance of prior . (3.30)\\n\\x04\\nSOL-41 \\uf14b CH.SOL- 3.12.\\nThe posterior density summarizes what is known about the parameter of interest γ after\\nthe data is observed. In Bayesian statistics, the posterior density p(Γ = γ|X = x) becomes\\nthe prior for this next experiment. This is part of the well-known Bayesian updating mech-\\nanism wherein we update our knowledge to reﬂect the actual distribution of data that we\\nobserved. T o summarize, from the perspective of Bayes Theorem, we update the prior distri-\\nbution to a posterior distribution after seeing the data. \\x04\\n653.3. SOLUTIONS\\nSOL-42 \\uf14b CH.SOL- 3.13.\\nTwo events A and B are statistically independent if (and only if):\\nP (A ∩ B) = P (A)P (B). (3.31)\\nNote: Use conditional probability and rationalize this outcome. How does this property be-\\ncome extremely useful in practical researches that consider likelihood of normally distributed\\nfeatures? \\x04\\n3.3.3 Bayes Rule\\nSOL-43 \\uf14b CH.SOL- 3.14.\\nLet γ stand for the number of half-integer spin states, and given the prior knowledge that\\nboth states are equally probable:\\nP (γ = 2|γ ≥ 1) (3.32)\\n= P (γ = 2, γ ≥ 1)\\nP (γ ≥ 1) (3.33)\\n= P (γ = 2)\\n1 − P (γ = 0) = 1/4\\n1 − 1/4 = 1\\n3 (3.34)\\nNote: Under what statistical property do the above relations hold? \\x04\\nSOL-44 \\uf14b CH.SOL- 3.15.\\nLet event A indicate present hereditary-disease and let event B to hold a positive test result.\\nThe calculated probabilities are presented in T able 3.1. We were asked to ﬁnd the probability\\nof a test indicating that hereditary-disease is present, namely P (B). According to the law of\\ntotal probability:\\nP (B) = P (B|A) ∗ P (A) + P (B|A) ∗ P (A)\\n= [0.95 ∗ 0.01] + [0.05 ∗ 0.99] = 0 .059 (3.35)\\nNote: In terms of performance evaluation, P (B|A) is often referred to as the probability of\\n66Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPROBABILITY EXPLANATION\\nP(A)= 0.01 The probability of hereditary-disease.\\nP(A)=1-0.01=.99 The probability of no hereditary-disease.\\nP(B|A)=0.95 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is NOT present [Ã].\\nP(B|B)=1-0.95=.05 The probability that the test will yield a positive result [B]\\nif hereditary-disease is NOT present [Ã] (probability of false\\nalarm).\\nP(B|A)=0.95 The probability that the test will yield a positive result [B] if\\nhereditary-disease is present [A] (probability of detection).\\nP(B|A)=1-0.95=.05 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is present [A].\\nTABLE 3.1: Probability values of hereditary-disease detection.\\ndetection and P (B|A) is considered the probability of false alarm. Notice that these measures\\ndo not, neither logically nor mathematically, combine to probability of 1. \\x04\\nSOL-45 \\uf14b CH.SOL- 3.16.\\nWe ﬁrst enumerate the probabilities one by one:\\nP (Dercum|f emale) = 0 .05, (3.36)\\nP (Dercum|male) = 0 .0025, (3.37)\\nP (male) = P (f emale) = 0 .5. (3.38)\\nWe are asked to ﬁnd P (f emale|Dercum). Using Bayes Rule:\\nP (f emale|Dercum) = P (Dercum|f emale)P (f emale)\\nP (Dercum) . (3.39)\\n673.3. SOLUTIONS\\nHowever we are missing the term P (Dercum). T o ﬁnd it, we apply the Law of T otal Probab-\\nility:\\nP (Dercum) = P (Dercum|f emale)P (f emale)\\n+P (Dercum|male)P (male)\\n=\\n0.05 · 0.5 + 0.0025 · 0.5 = 0 .02625.\\nAnd ﬁnally, returning to eq. ( 3.39):\\nP (f emale|Dercum) = 0.05 · 0.5\\n0.02625 ≈ 0.9524 (3.40)\\nNote: How could this result be reached with one mathematical equation? \\x04\\nSOL-46 \\uf14b CH.SOL- 3.17.\\nIn order to solve this problem, we introduce the following events:\\n1. AI: the AI predicts that the state of the stock option is 1.\\n2. State1: the state of the stock option is 1.\\n3. State0: the state of the stock option is 0.\\nA direct application of Bayes formulae yields:\\nP (State1|AI) = (3.41)\\nP (AI|State1)P (State1)\\nP (AI|State1)P (State1)+P (AI|State0)P (State0) (3.42)\\n= 0.85·2/3\\n0.85·2/3+0.15·1/3 ≈ 0.9189.\\n\\x04\\nSOL-47 \\uf14b CH.SOL- 3.18. In order to solve this problem, we introduce the following events:\\n1. H: a human.\\n68Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. M : a monkey.\\n3. C: a correct prediction.\\nBy employing Bayes theorem and the Law of T otal probability:\\nP (H|C) = P (H ∩ C)\\nP (C)\\n= P (C|H)P (H)\\nP (C|H)P (H) + P (C|M )P (M )\\n=\\n1\\n20 · 1\\n2\\n1\\n20 · 1\\n2 + 1\\n15 · 1\\n2\\n≈ 0.42.\\n(3.43)\\nNote: If something seems off in this outcome, do not worry - it is a positive sign for\\nunderstanding of conditional probability. \\x04\\nSOL-48 \\uf14b CH.SOL- 3.19.\\nIn order to solve this problem, we introduce the following events:\\n1. RU S: a Russian sleeper agent is speaking.\\n2. AM : an American is speaking.\\n3. L: the TTS system generates an “l”.\\nWe are asked to ﬁnd the value of P (RU S|L). Using Bayes Theorem we can write:\\nP (RU S|L) = P (L|RU S)P (RU S)\\nP (L) . (3.44)\\nWe were told that the Russians consist 1/5 of the attendees at the gathering, therefore:\\nP (RU S) = 1\\n5. (3.45)\\n693.3. SOLUTIONS\\nAdditionally, because \"v-o-k-s-a-l\" has a single l out of a total of six letters:\\nP (L|RU S) = 1\\n6. (3.46)\\nAdditionally, because \"V-a-u-x-h-a-l-l\" has two l’s out of a total of eight letters:\\nP (L|AM ) = 2\\n8. (3.47)\\nAn application of the Law of T otal Probability yields:\\nP (L) = P (AM )P (L|AM ) + P (RU S)P (L|RU S) (3.48)\\n=\\n( 4\\n5\\n) ( 2\\n8\\n)\\n+\\n( 1\\n5\\n) ( 1\\n6\\n)\\n= 7\\n30.\\nUsing Bayes Theorem we can write:\\nP (RU S|L) =\\n1\\n5\\n(\\n1\\n6\\n)\\n7\\n30\\n= 1\\n7. (3.49)\\nNote: What is the letter by which the algorithm is most likely to discover a Russian sleeper\\nagent? \\x04\\nSOL-49 \\uf14b CH.SOL- 3.20.\\nWe are given that:\\nP (X is erroneously received as a Z ) = 1 /7. Using Bayes Theorem we can write:\\nP (Z trans |Z received ) =\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received ) . (3.50)\\n70Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAn application of the Law of T otal Probability yields:\\nP (Z received ) =\\nP (Z received |Z trans )P (Z trans )\\n+P (Z received |X trans )P (X trans )\\n= 6\\n7 · 7\\n9 + 1\\n7 · 2\\n9\\n= 44\\n63.\\nSo, using Bayes Rule, we have that\\nP (Z trans |Z received )\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received )\\n=\\n6\\n7\\n7\\n9\\n44\\n63\\n= 44\\n63 = 0.95.\\n(3.51)\\n\\x04\\n3.3.4 Maximum Likelihood Estimation\\nSOL-50 \\uf14b CH.SOL- 3.21.\\nFor the set of i.i.d samples X1, · · · , Xn, the likelihood function is the product of the\\nprobability functions:\\nL(p) = p(X1 = x1; p)p(X2 = x2; p) · · ·p(Xn = xn; p)\\n=\\nn∏\\ni=1\\n(\\nn\\nxi\\n)\\npxi(1 − p)n−xi. (3.52)\\nNote: What is the distribution of X n when X is a Bernoulli distributed random variable?\\n\\x04\\n713.3. SOLUTIONS\\nSOL-51 \\uf14b CH.SOL- 3.22.\\nThe maximum likelihood estimator (MLE) of p is the value of all possible p values that\\nmaximizes L(p). Namely, the p value that renders the set of measurements X1, · · · , Xn as the\\nmost likely. Formally:\\nˆp = arg max0≤p≤1L(p) (3.53)\\nNote: The curious student is highly encouraged to derive ˆp from L(p). Notice that L(p) can\\nbe extremely simpliﬁed. \\x04\\nSOL-52 \\uf14b CH.SOL- 3.23.\\nThe log-likelihood is the logarithm of the likelihood function. Intuitively, maximizing\\nthe likelihood function L(γ) is equivalent to maximizing ln L(γ) in terms of ﬁnding the MLE\\nˆγ, since ln is a monotonically increasing function. Often, we maximize ln(f (γ)) instead of\\nthe f (γ). A common example is when L(γ) is comprised of normally distribution random\\nvariables.\\nFormally, if X1, · · · , Xn are i.i.d, each with probability mass function (PMF) of fXi(xi | γ),\\nthen\\nf (γ) =\\nn∏\\ni=1\\nfXi(xi | γ), (3.54)\\nln(f (γ)) =\\nn∑\\ni=1\\nln fXi(xi | γ). (3.55)\\n\\x04\\nSOL-53 \\uf14b CH.SOL- 3.24.\\nThe general procedure for ﬁnding the MLE, given that the likelihood function is differen-\\ntiable, is as follows:\\n1. Start by differentiating the log-likelihood function ln (L(γ)) with respect to a parameter\\nof interest γ.\\n2. Equate the result to zero.\\n72Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3. Solve the equation to ﬁnd ˆγ that holds:\\n∂ ln L(ˆγ | x1, · · ·xn)\\n∂γ = 0 (3.56)\\n4. Compute the second derivative to verify that you indeed have a maximum rather than\\na minimum.\\n\\x04\\nSOL-54 \\uf14b CH.SOL- 3.25.\\nThe ﬁrst derivative of the log-likelihood function is commonly known as the Fisher score\\nfunction, and is deﬁned as:\\nu(γ) = ∂ ln L(γ | x1, · · ·xn)\\n∂γ (3.57)\\n\\x04\\nSOL-55 \\uf14b CH.SOL- 3.26.\\nFisher information, is the term used to describe the expected value of the second derivat-\\nives (the curvature) of the log-likelihood function, and is deﬁned by:\\nI(γ) = −E\\n[\\n∂2 ln L(γ | x1, · · ·xn)\\n∂γ2\\n]\\n(3.58)\\n\\x04\\n3.3.5 Fisher Information\\nSOL-56 \\uf14b CH.SOL- 3.27.\\n1. Given L(γ):\\nln L(γ) = ln\\n(\\nny\\n)\\n+ y ∗ ln(γ) + (n − y) ln(1 − γ). (3.59)\\n733.3. SOLUTIONS\\n2. T o ﬁnd the gradient, we differentiate once:\\ng(γ) = yγ −1 − (n − y)(1 − γ)−1 =\\n(γ(1 − γ))−1y − n(1 − γ)−1. (3.60)\\n3. The Hessian is generated by differentiating g(γ):\\nH(γ) = −yγ −2 − (n − y)(1 − γ)−2 (3.61)\\n4. The Fisher information is calculated as follows:\\nI(γ) = −E(H(γ)) = n\\nγ(1 − γ), (3.62)\\nsince:\\nE(y|γ, n) = n ∗ γ (3.63)\\n5. Equating the gradient to zero and solving for our parameter γ, we get:\\nˆγ = y\\nn (3.64)\\nIn our case this equates to: 300/10000 = 0 .03. Regarding the error, there is a close\\nrelationship between the variance of γ and the Fisher information, as the former is the\\ninverse of the latter:\\nvar(γ) = [ I(γ)]−1\\nV (γ) = γ(1 − γ)\\nn\\n(3.65)\\nPlugging the numbers from our question:\\nˆV (ˆγ) = 0.03(1 − 0.03)\\n10000 = 2.9 × 10−7. (3.66)\\n74Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nStatistically, the standard error that we are asked to ﬁnd is the square root of eq. 3.66\\nwhich equals 5.3 × 10−4. Note: What desired property is revealed in this experiment?\\nAt was cost could we ensure a low standard error?\\n\\x04\\nSOL-57 \\uf14b CH.SOL- 3.28.\\nThe Fisher Information for the distributions is as follows:\\n1. Bernoulli:\\nΦ(x|γ) = x log γ + (1 − x) log(1 − γ), (3.67)\\nΦ′(x|γ) = x\\nγ − 1 − x\\n1 − γ , (3.68)\\nΦ′′(x|γ) = − x\\nγ2 − 1 − x\\n(1 − γ)2 , (3.69)\\nI(γ) = −Eγ\\n[\\nX(1 − γ)2 + (1 − X)γ2\\nγ2(1 − γ)2\\n]\\n= 1\\nγ(1 − γ). (3.70)\\n2. Poisson:\\nλ(x|θ) = x log θ − log x! − θ,\\nλ′(x|θ) = x − θ\\nθ ,\\nλ′′(x|θ) = − x\\nθ2 ,\\nI(θ) = −Eθ\\n[\\n(X − θ)2\\nθ2\\n]\\n= 1\\nθ .\\n(3.71)\\n\\x04\\nSOL-58 \\uf14b CH.SOL- 3.29.\\n753.3. SOLUTIONS\\n1. T rue.\\n2. T rue.\\n\\x04\\n3.3.6 Posterior & prior predictive distributions\\nSOL-59 \\uf14b CH.SOL- 3.30.\\n1. Given a sample of the form x = ( x1, · · · , xn) drawn from a density p(θ; x) and θ is\\nrandomly generated according to a prior density of p(θ). Then the posterior density is\\ndeﬁned by:\\np(θ|x) = p(θ; x)p(θ)\\np(x) . (3.72)\\n2. The prior predictive density is:\\np(x) =\\n∫\\nθ∈Θ p(θ; x)p(θ)dθ (3.73)\\n\\x04\\nSOL-60 \\uf14b CH.SOL- 3.31.\\n1. The posterior p(θ|y) ∝ p(y|θ)p(θ) is:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3\\n( 5\\ny\\n)\\n(1/2)y(1/2)5−y0.25, θ = 1/2( 5\\ny\\n)\\n(1/6)y(5/6)5−y0.5, θ = 1/6( 5\\ny\\n)\\n(1/4)y(3/4)5−y0.25, θ = 1/4\\n0, otherwise\\n2. The prior predictive distribution p(y):\\n(\\n5\\ny\\n)\\n((1/2)y(1/2)5−y0.25 (3.74)\\n76Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n+\\n(1/6)y(5/6)5−y0.5 + (1/4)y(3/4)5−y0.25). (3.75)\\n\\x04\\n3.3.7 Conjugate priors\\nSOL-61 \\uf14b CH.SOL- 3.32.\\n1. A class F of prior distributions is said to form a conjugate family if the posterior density\\nis in F for all each sample, whenever the prior density is in F.\\n2. Often we would like a prior that favours no particular values of the parameter over\\nothers. Bayesian analysis requires prior information, however sometimes there is no\\nparticularly useful information before data is collected. In these situations, priors with\\n“no information” are expected. Such priors are called non-informative priors.\\n\\x04\\nSOL-62 \\uf14b CH.SOL- 3.33.\\nIf x ∼ B(n, γ) so\\np(x|γ) ∝ γx(1 − γ)n−x\\nand the prior for γ is B(α, β) so\\np(γ) ∝ γα−1(1 − γ)β−1\\nthen the posterior is\\nγ|x ∼ B (α + x, β + n − x)\\nIt is immediately clear the family of beta distributions is conjugate to a\\nbinomial likelihood.\\n\\x04\\n3.3.8 Bayesian Deep Learning\\n773.3. SOLUTIONS\\nSOL-63 \\uf14b CH.SOL- 3.34.\\n1. The hidden neuron is distributed according to:\\nX ∼ binomial(n, γ ) random variable and ﬁres with a probability of γ. There are 100\\nneurons and only 20 are ﬁred.\\nP (x = 20|θ) =\\n\\uf8eb\\n\\uf8ed 100\\n20\\n\\uf8f6\\n\\uf8f8 θ20(1 − θ)80 (3.76)\\n2. The hidden neuron is distributed according to:\\nX unif orm(0, γ) random variable and ﬁres with a probability of γ.\\nThe uniform distribution is, of course, a very simple case:\\nf (x; a, b) = 1\\nb − a for a ≤ x ≤ b (3.77)\\nTherefore:\\nf (x|γ) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0 if γ < x or x < 0\\n1/γ if 0 ≤ x ≤ θ\\n(3.78)\\n\\x04\\nSOL-64 \\uf14b CH.SOL- 3.35.\\nThe provided distribution is from the exponential family. Therefore, a single neuron be-\\ncomes inactive with a probability of:\\np = P (X < 20) =\\n∫ 20\\n0\\ne−x dx = 1 − e−20. (3.79)\\nThe OnOffLayer is off only if at least 150 out of 200 neurons are off. Therefore, this may be\\nrepresented as a Binomial distribution and the probability for the layer to be off is:\\nV =\\n∑\\nn≥150\\n\\uf8eb\\n\\uf8ed 200\\nn\\n\\uf8f6\\n\\uf8f8 ˜pn(1 − ˜p)200−n (3.80)\\n78Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nHence, the probability of the layer being active for at least 20 seconds is 1 minus this value:\\n[1 − V ]. (3.81)\\n\\x04\\nSOL-65 \\uf14b CH.SOL- 3.36.\\nThe observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (3.82)\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (3.83)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (3.84)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (3.85)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(3.86)\\n\\x04\\nSOL-66 \\uf14b CH.SOL- 3.37.\\nNeurons are dropped whenever their value (or the equivalent quantum term- speed) reach\\n79REFERENCES\\nthe most likely value:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.87)\\nFrom calculus, we know that in order to maximize a function, we have to equate its ﬁrst\\nderivative to zero:\\nd\\ndv n(v) = 0 (3.88)\\nThe constants can be taken out as follows:\\nd\\ndv v2e− mv2\\n2kT = 0 (3.89)\\nApplying the chain rule from calculus:\\n2ve− mv2\\n2kT + v2\\n(\\n− m\\n2kT 2v\\n)\\ne− mv2\\n2kT = 0 (3.90)\\nWe notice that several terms cancel out:\\nv2 m\\n2kT = 1 (3.91)\\nNow the quadratic equation can be solved yielding:\\nvmost_probable =\\n√\\n2kT\\nm\\n(3.92)\\nTherefore, this is the most probable value at which the dropout layer will ﬁre.\\n\\x04\\nReferences\\n[1] M. Barati and P . ‘Comparison of complications of chorionic villus sampling and\\namniocentesis’. In: 5.4 (2012), pp. 241–244 (cit. on p. 46).\\n[2] J. D. e. a. Bell BP Damon IK. ‘Overview, Control Strategies, and Lessons Learned\\nin the CDC Response to the 20142016 Ebola Epidemic.’ In: Morbidity and Mortal-\\nity Weekly Report 65.3 (2016), pp. 4–11 (cit. on p. 52).\\n80Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n[3] J. C. Cook and G. P . Gross. Adiposis Dolorosa (Dercum, Anders Disease) . StatPearls\\n[Internet], 2019 (cit. on p. 47).\\n[4] G. Ecker. Particles, Field, From Quantum Mechanics to the Standard Model of Particle\\nPhysics. Springer., 2019 (cit. on p. 45).\\n[5] K. Gaj and A. Orlowski. ‘Facts and Myths of Enigma: Breaking Stereotypes’. In:\\nInternational Conference on the Theory and Applications of Cryptographic T echniques .\\n2003 (cit. on p. 50).\\n[6] B. Gottschalk. ‘Techniques of Proton Radiotherapy: Transport Theory’. In: arXiv\\n(2012) (cit. on p. 43).\\n[7] T. S. O. of Investor Education and Advocacy. Binary options and Fraud (cit. on\\np. 48).\\n[8] E. T. Jaynes. Probability Theory as Logic . Ed. by P . F. Fougère. Maximum-Entropy\\nand Bayesian Methods. Kluwer, Dordrecht, 1990 (cit. on p. 42).\\n[9] D. o. J. National Security Division. Conspiracy to Act as Unregistered Agents of a\\nForeign Government. 2010 (cit. on p. 49).\\n[10] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on p. 56).\\n[11] J. Salvatier, T. V . Wiecki and C. Fonnesbeck. ‘Probabilistic programming in Py-\\nthon using PyMC3’. In: PeerJ Computer Science 2 (Jan. 2016), e55 (cit. on p. 42).\\n[12] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 56).\\n[13] E. B. Starikov. ‘Bayesian Statistical Mechanics: Entropy Enthalpy Compensation\\nand Universal Equation of State at the Tip of Pen’. In: Frontiers in Physics 6 (2018),\\np. 2 (cit. on p. 42).\\n81REFERENCES\\n82HIGH SCHOOL\\nPART IIICHAPTER\\n4\\nINFORMATION THEORY\\nA basic idea in information theory is that information can be treated very much\\nlike a physical quantity, such as mass or energy.\\n— Claude Shannon, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 87\\nShannon\\'s Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen\\'s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 101\\nShannon\\'s Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\nKullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen\\'s inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1184.1. INTRODUCTION\\n4.1 Introduction\\nI\\nNDUCTIVE inference, is the problem of reasoning under conditions of in-\\ncomplete information, or uncertainty. According to Shannon’s theory [ 2],\\ninformation and uncertainty are two sides of the same coin: the more uncer-\\ntainty there is, the more information we gain by removing the uncertainty .\\nEntropy plays central roles in many scientiﬁc realms ranging from physics and statist-\\nics to data science and economics. A basic problem in information theory is encoding\\nlarge quantities of information [ 2].\\nShannon’s discovery of the fundamental laws of data compression and transmis-\\nsion marked the birth of information theory . In his fundamental paper of 1948, “ A\\nMathematical Theory of Communication ” [4], Shannon proposed a measure of the uncer-\\ntainty associated with a random memory-less source, called Entropy.\\nH(X) H(Y )\\nH(Z)\\nH(Y |X)\\nH(Z|XY )\\nI(X; Z|Y )\\nFIGURE 4.1: Mutual information\\nEntropy ﬁrst emerged in thermodynamics in the 18 th century by\\nCarnot, [1] in his pioneering work on steam entitled “ Reﬂection on the Motive Power of\\nFire” (Fig. 4.2). Subsequently it appeared in statistical mechanics where it was viewed\\nas a measure of disorder. However, it was Boltzmann ( 4.30) who found the connection\\nbetween entropy and probability , and the notion of information as used by Shannon is\\na generalization of the notion of entropy . Shannon’s entropy shares some instinct with\\nBoltzmann’s entropy , and likewise the mathematics developed in information theory\\nis highly relevant in statistical mechanics.\\n86Chapter 4 INFORMATION THEORY\\nFIGURE 4.2: Reﬂection on the motive power of ﬁre.\\nThe majority of candidates I interview fail to come up with an answer to the fol-\\nlowing question: what is the entropy of tossing a non-biased coin? Surprisingly , even after\\nI explicitly provide them with Shannon’s formulae for calculating entropy ( 4.4), many\\nare still unable to calculate simple logarithms. The purpose of this chapter is to present\\nthe aspiring data scientist with some of the most signiﬁcant notions of entropy and\\nto elucidate its relationship to probability . Therefore, it is primarily focused on basic\\nquantities in information theory such as entropy , cross-entropy , conditional entropy ,\\nmutual information and Kullback-Leibler divergence, also known as relative entropy .\\nIt does not however, discuss more advanced topics such as the concept of ’active in-\\nformation’ introduced by Bohm and Hiley [ 3].\\n4.2 Problems\\n4.2.1 Logarithms in Information Theory\\nIt is important to note that all numerical calculations in this chapter use the binary\\nlogarithm log2. This speciﬁc logarithm produces units of bits, the commonly used units\\nof information in the ﬁeld on information theory .\\n874.2. PROBLEMS\\nPRB-67 \\uf059 CH.PRB- 4.1.\\nRun the following Python code ( 4.3) in a Python interpreter. What are the results?\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n5\\n6 print (math.log10(1.0/0.98)) # Common log (base 10)\\n7 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n8\\n9 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n10 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\nFIGURE 4.3: Natural ( ln), binary (log2) and common ( log10) logarithms.\\nPRB-68 \\uf059 CH.PRB- 4.2.\\nThe three basic laws of logarithms:\\n1. First law\\nlog A + log B = log AB. (4.1)\\nCompute the following expression:\\nlog10 3 + log10 4.\\n2. Second law\\nlog An = n log A. (4.2)\\n88Chapter 4 INFORMATION THEORY\\nCompute the following expression:\\nlog2 46.\\n3. Third law\\nlog A − log B = log A\\nB . (4.3)\\nTherefore, subtracting log B from log A results in log A\\nB .\\nCompute the following expression:\\nloge 15 − loge 3.\\n4.2.2 Shannon\\'s Entropy\\nPRB-69 \\uf059 CH.PRB- 4.3.\\nWrite Shannon\\'s famous general formulae for uncertainty.\\nPRB-70 \\uf059 CH.PRB- 4.4.\\nChoose exactly one, and only one answer.\\n1. For an event which is certain to happen, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N ), N being the number of possible events\\n894.2. PROBLEMS\\n2. For N equiprobable events, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N )\\nPRB-71 \\uf059 CH.PRB- 4.5.\\nShannon found that entropy was the only function satisfying three natural properties.\\nEnumerate these properties.\\nPRB-72 \\uf059 CH.PRB- 4.6.\\nIn information theory, minus the logarithm of the probability of a symbol (essentially\\nthe number of bits required to represent it efﬁciently in a binary code) is deﬁned to be the\\ninformation conveyed by transmitting that symbol. In this context, the entropy can be\\ninterpreted as the expected information conveyed by transmitting a single symbol from an\\nalphabet in which the symbols occur with the probabilities πk.\\nMark the correct answer : Information is a/an [decrease/increase] in uncertainty.\\nPRB-73 \\uf059 CH.PRB- 4.7.\\nClaud Shannon\\'s paper “A mathematical theory of communication” [ 4], marked the\\nbirth of information theory. Published in 1948, it has become since the Magna Carta of the\\ninformation age. Describe in your own words what is meant by the term Shannon bit.\\nPRB-74 \\uf059 CH.PRB- 4.8.\\nWith respect to the notion of surprise in the context of information theory:\\n1. Deﬁne what it actually meant by being surprised.\\n90Chapter 4 INFORMATION THEORY\\n2. Describe how it is related to the likelihood of an event happening.\\n3. True or False: The less likely the occurrence of an event, the smaller information it\\nconveys.\\nPRB-75 \\uf059 CH.PRB- 4.9.\\nAssume a source of signals that transmits a given message a with probability Pa. Assume\\nfurther that the message is encoded into an ordered series of ones and zeros (a bit string) and\\nthat a receiver has a decoder that converts the bit string back into its respective message.\\nShannon devised a formulae that describes the size that the mean length of the bit string can\\nbe compressed to. Write the formulae.\\nPRB-76 \\uf059 CH.PRB- 4.10.\\nAnswer the following questions:\\n1. Assume a source that provides a constant stream of N equally likely symbols\\n{x1, x2, . . . , xN }. What does Shannon\\'s formulae ( 4.4) reduce to in this particular\\ncase?\\n2. Assume that each equiprobable pixel in a monochrome image that is fed to a DL classi-\\nﬁcation pipeline, can have values ranging from 0 to 255. Find the entropy in bits.\\nPRB-77 \\uf059 CH.PRB- 4.11.\\nGiven Shannon\\'s famous general formulae for uncertainty ( 4.4):\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.4)\\n1. Plot a graph of the curve of probability vs. uncertainty.\\n2. Complete the sentence: The curve is [symmetrical/asymmetrical].\\n914.2. PROBLEMS\\n3. Complete the sentence: The curve rises to a [minimum/maximum] when the two\\nsymbols are equally likely ( Pa = 0.5).\\nPRB-78 \\uf059 CH.PRB- 4'),\n",
              " Document(metadata={}, page_content='e ( 4.4) reduce to in this particular\\ncase?\\n2. Assume that each equiprobable pixel in a monochrome image that is fed to a DL classi-\\nﬁcation pipeline, can have values ranging from 0 to 255. Find the entropy in bits.\\nPRB-77 \\uf059 CH.PRB- 4.11.\\nGiven Shannon\\'s famous general formulae for uncertainty ( 4.4):\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.4)\\n1. Plot a graph of the curve of probability vs. uncertainty.\\n2. Complete the sentence: The curve is [symmetrical/asymmetrical].\\n914.2. PROBLEMS\\n3. Complete the sentence: The curve rises to a [minimum/maximum] when the two\\nsymbols are equally likely ( Pa = 0.5).\\nPRB-78 \\uf059 CH.PRB- 4.12.\\nAssume we are provided with biased coin for which the event ‘heads’ is assigned probab-\\nility p, and ‘tails’ - a probability of 1 − p. Using (4.4), the respective entropy is:\\nH(p) = −p log p − (1 − p) log (1 − p) . (4.5)\\nTherefore, H ≥ 0 and the maximum possible uncertainty is attained when p = 1 /2, is\\nHmax = log 2 2.\\nGiven the above formulation, describe a helpful property of the entropy that follows from\\nthe concavity of the logarithmic function.\\nPRB-79 \\uf059 CH.PRB- 4.13.\\nTrue or False: Given random variables X, Y and Z where Y = X + Z then:\\nH(X, Y ) = H(X, Z). (4.6)\\nPRB-80 \\uf059 CH.PRB- 4.14.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n92Chapter 4 INFORMATION THEORY\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh)+ p(xt) = 1 , what is formulae\\nfor the average surprise?\\n6. What is the value of the average surprise in bits?\\n4.2.3 Kullback-Leibler Divergence (KLD)\\nPRB-81 \\uf059 CH.PRB- 4.15.\\nWrite the formulae for the Kullback-Leibler divergence between two discrete probability\\ndensity functions P and Q.\\nPRB-82 \\uf059 CH.PRB- 4.16.\\nDescribe one intuitive interpretation of the KL-divergence with respect to bits.\\nPRB-83 \\uf059 CH.PRB- 4.17.\\n1. True or False: The KL-divergence is not a symmetric measure of similarity, i.e.:\\nDKL(P ∥Q) ̸= D KL(Q∥P ).\\n2. True or False: The KL-divergence satisﬁes the triangle inequality.\\n3. True or False: The KL-divergence is not a distance metric.\\n4. True or False: In information theory, KLD is regarded as a measure of the informa-\\ntion gained when probability distribution Q is used to approximate a true probability\\ndistribution P .\\n5. True or False: The units of KL-divergence are units of information.\\n6. True or False: The KLD is always non-negative, namely:\\nDKL(P ∥Q) ≥ 0.\\n934.2. PROBLEMS\\n.\\n7. True or False: In a decision tree, high information gain indicates that adding a split\\nto the decision tree results in a less accurate model.\\nPRB-84 \\uf059 CH.PRB- 4.18.\\nGiven two distributions f1 and f2 and their respective joint distribution f , write the\\nformulae for the mutual information of f1 and f2.\\nPRB-85 \\uf059 CH.PRB- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem.\\n4.2.4 Classification and Information Gain\\nPRB-86 \\uf059 CH.PRB- 4.20.\\nThere are several measures by which one can determine how to optimally split attributes\\nin a decision tree. List the three most commonly used measures and write their formulae.\\nPRB-87 \\uf059 CH.PRB- 4.21.\\nComplete the sentence: In a decision tree, the attribute by which we choose to split is\\nthe one with [minimum/maximum] information gain.\\nPRB-88 \\uf059 CH.PRB- 4.22.\\nT o study factors affecting the decision of a frog to jump (or not), a deep learning re-\\nsearcher from a Brazilian rain-forest, collects data pertaining to several independent binary\\nco-variates.\\n94Chapter 4 INFORMATION THEORY\\nFIGURE 4.4: A Frog in its natural habitat. Photo taken by my son.\\nThe binary response variable Jump indicates whether a jump was observed. Referring to\\nT able (4.1), each row indicates the observed values, columns denote features and rows denote\\nlabelled instances while class label ( Jump) denotes whether the frog had jumped.\\nObservation Green Rain Jump\\nx1 1 0 +\\nx2 1 1 +\\nx3 1 0 +\\nx4 1 1 +\\nx5 1 0 +\\nx6 0 1 +\\nx7 0 0 −\\nx8 0 1 −\\nTABLE 4.1: Decision trees and frogs.\\nWithout explicitly determining the information gain values for each of the three attrib-\\nutes, which attribute should be chosen as the attribute by which the decision tree should be\\nﬁrst partitioned? e.g which attribute has the highest predictive power regarding the decision\\nof the frog (Fig. 4.4) to jump.\\n954.2. PROBLEMS\\nPRB-89 \\uf059 CH.PRB- 4.23.\\nThis question discusses the link between binary classiﬁcation, information gain and de-\\ncision trees. Recent research [ 5] suggests that Cannabis (Fig. 4.5), and Cannabinoids ad-\\nministration in particular may reduce the size of malignant tumours in rodents. The data\\n(T able9.2) comprises a training set of feature vectors with corresponding class labels which\\na researcher intents classifying using a decision tree.\\nFIGURE 4.5: Cannabis\\nT o study factors affecting tumour shrinkage, the deep learning researcher collects data\\nregrading two independent binary variables; θ1 (T/F) indicating whether the rodent is a fe-\\nmale, and θ2 (T/F) indicating whether the rodent was administrated with Cannabinoids. The\\nbinary response variable, γ, indicates whether tumour shrinkage was observed (e.g. shrink-\\nage=+, no shrinkage=-). Referring to T able ( 9.2), each row indicates the observed values,\\ncolumns (θi) denote features and class label ( γ) denotes whether shrinkage was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 4.2: Decision trees and Cannabinoids administration\\n96Chapter 4 INFORMATION THEORY\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\nPRB-90 \\uf059 CH.PRB- 4.24.\\nT o study factors affecting the expansion of stars, a physicist is provided with data re-\\ngrading two independent variables; θ1 (T/F) indicating whether a star is dense, and θ2 (T/F)\\nindicating whether a star is adjacent to a black-hole. He is told that the binary response vari-\\nable, γ, indicates whether expansion was observed.\\ne.g.:\\nexpansion=+, no expansion=-. Referring to table ( 4.3), each row indicates the observed val-\\nues, columns (θi) denote features and class label (γ) denotes whether expansion was observed.\\nγ (expansion) θ1 (dense) θ2 (black-hole)\\n+ F T\\n+ T T\\n+ T T\\n- F T\\n+ T F\\n- F F\\n- F F\\nTABLE 4.3: Decision trees and star expansion.\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (expansion)\\nbefore splitting.\\n2. Using log2 and the provided dataset, calculate the information gain of H(γ|θ1).\\n974.2. PROBLEMS\\n3. Using log2 and the provided dataset, calculate the information gain of H(γ|θ2).\\nPRB-91 \\uf059 CH.PRB- 4.25.\\nT o study factors affecting tumour shrinkage in humans, a deep learning researcher is\\nprovided with data regrading two independent variables; θ1 (S/M/L) indicating whether the\\ntumour is small(S), medium(M) or large(L), and θ2 (T/F) indicating whether the tumour\\nhas undergone radiation therapy. He is told that the binary response variable, γ, indicates\\nwhether tumour shrinkage was observed (e.g. shrinkage=+, no shrinkage=-).\\nReferring to table ( 4.4), each row indicates the observed values, columns ( θi) denote\\nfeatures and class label ( γ) denotes whether shrinkage was observed.\\nγ (shrinkage) θ1 θ2\\n- S F\\n+ S T\\n- M F\\n+ M T\\n+ H F\\n+ H T\\nTABLE 4.4: Decision trees and radiation therapy .\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (shrinkage).\\n2. Using log2 and the provided dataset, calculate the entropy of H(γ|θ1).\\n3. Using log2 and the provided dataset, calculate the entropy of H(γ|θ2).\\n4. True or false: We should split on a speciﬁc variable that minimizes the information\\ngain, therefore we should split on θ2 (radiation therapy).\\n4.2.5 Mutual Information\\nPRB-92 \\uf059 CH.PRB- 4.26.\\n98Chapter 4 INFORMATION THEORY\\nShannon described a communications system consisting ﬁve elements (4.6), two of which\\nare the source S and the destination D.\\nSourse S Trans\\nT\\nChannel\\nCH\\nReceiver\\nR\\nDest\\nD\\nMESSAGE\\nSIGNAL\\nSIGNAL\\nMESSAGE\\nFIGURE 4.6: Shannon\\'s ﬁve element communications system.\\n1. Draw a Venn diagram depicting the relationship between the entropies of the source\\nH(S) and of the destination H(D).\\n2. Annotate the part termed equivocation.\\n3. Annotate the part termed noise.\\n4. Annotate the part termed mutual information.\\n5. Write the formulae for mutual information.\\nPRB-93 \\uf059 CH.PRB- 4.27.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\n994.2. PROBLEMS\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\nPRB-94 \\uf059 CH.PRB- 4.28.\\nComplete the sentence: Mutual information is a Shannon entropy-based measure of\\ndependence between random variables. The mutual information between X and Z can be\\nunderstood as the (a) [___] of the (b) [___] in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.7)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X.\\n4.2.6 Mechanical Statistics\\nSome books have a tendency of sweeping \"unseen\" problems under the rug. We will\\nnot do that here. This subsection may look intimidating and for a good reason; it\\ninvolves equations that, unless you are a physicists, you have probably never en-\\ncountered before. Nevertheless, the ability to cope with new concepts lies at the heart\\nof every job interview.\\nFor some of the questions, you may need these constants:\\nPHYSICAL CONSTANTS\\nk Boltzmanns constant 1.381 × 10−23 J K−1\\nc Speed of light in vacum 2.998 × 108m s−1\\nh Planck’s constant 6.626 × 10−34 J s\\nPRB-95 \\uf059 CH.PRB- 4.29.\\nWhat is the expression for the Boltzmann probability distribution?\\nPRB-96 \\uf059 CH.PRB- 4.30.\\nInformation theory, quantum physics and thermodynamics are closely interconnected.\\nThere are several equivalent formulations for the second law of thermodynamics. One ap-\\nproach to describing uncertainty stems from Boltzmanns fundamental work on entropy in\\n100Chapter 4 INFORMATION THEORY\\nstatistical mechanics. Describe what is meant by Boltzmanns entropy.\\nPRB-97 \\uf059 CH.PRB- 4.31.\\nFrom Boltzmanns perspective, what is the entropy of an octahedral dice ( 4.7)?\\nFIGURE 4.7: An octahedral dice.\\n4.2.7 Jensen\\'s inequality\\nPRB-98 \\uf059 CH.PRB- 4.32.\\n1. Deﬁne the term concave function.\\n2. Deﬁne the term convex function.\\n3. State Jensen\\'s inequality and its implications.\\nPRB-99 \\uf059 CH.PRB- 4.33.\\nTrue or False: Using Jensen\\'s inequality, it is possible to show that the KL divergence\\nis always greater or equal to zero.\\n4.3 Solutions\\n4.3.1 Logarithms in Information Theory\\n1014.3. SOLUTIONS\\nSOL-67 \\uf14b CH.SOL- 4.1.\\nNumerical results (4.8) are provided using Python interpreter version 3.6.\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 > 0.02020270731751947\\n5 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n6 > 3.912023005428146\\n7 print (math.log10(1.0/0.98)) # Common log (base 10)\\n8 > 0.008773924307505152\\n9 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n10 > 1.6989700043360187\\n11 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n12 > 0.02914634565951651\\n13 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n14 > 5.643856189774724\\nFIGURE 4.8: Logarithms in information theory .\\n\\x04\\nSOL-68 \\uf14b CH.SOL- 4.2.\\nThe logarithm base is explicitly written in each solution.\\n1.\\nlog10 3 + log10 4 = log 10(3 × 4) = log 10 12.\\n2.\\nlog2 46 = 6 log2 4.\\n3.\\nloge 15 − loge 3 = log e\\n15\\n3 = log e 5.\\n102Chapter 4 INFORMATION THEORY\\n\\x04\\n4.3.2 Shannon\\'s Entropy\\nSOL-69 \\uf14b CH.SOL- 4.3.\\nShannons famous general formulae for uncertainty is:\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.8)\\n\\x04\\nSOL-70 \\uf14b CH.SOL- 4.4.\\n1. No information is conveyed by an event which is a-priori known to occur for certain\\n(Pa = 1), therefore the entropy is 0.\\n2. Equiprobable events mean that Pi = 1 /N ∀i ∈ [1, N]. Therefore for N equally-likely\\nevents, the entropy is log2(N ).\\n\\x04\\nSOL-71 \\uf14b CH.SOL- 4.5.\\nThe three properties are as follows:\\n1. H(X) is always non-negative, since information cannot be lost.\\n2. The uniform distribution maximizes H(X), since it also maximizes uncertainty.\\n3. The additivity property which relates the sum of entropies of two independent events.\\nFor instance, in thermodynamics, the total entropy of two isolated systems which co-\\nexist in equilibrium is the sum of the entropies of each system in isolation.\\n\\x04\\n1034.3. SOLUTIONS\\nSOL-72 \\uf14b CH.SOL- 4.6.\\nInformation is an [increase] in uncertainty. \\x04\\nSOL-73 \\uf14b CH.SOL- 4.7.\\nThe Shannon bit has two distinctive states; it is either 0 or 1, but never both at the same\\ntime. Shannon devised an experiment in which there is a question whose only two possible\\nanswers were equally likely to happen .\\nHe then deﬁned one bit as the amount of information gained (or alternatively, the amount\\nof entropy removed) once an answer to the question has been learned. He then continued to\\nstate that when the a-priori probability of any one possible answer is higher than the other, the\\nanswer would have conveyed less than one bit of information. \\x04\\nSOL-74 \\uf14b CH.SOL- 4.8.\\nThe notion of surprise is directly related to the likelihood of an event happening. Mathem-\\natically is it inversely proportional to the probability of that event.\\nAccordingly, learning that a high-probability event has taken place, for instance the sun rising,\\nis much less of a surprise and gives less information than learning that a low-probability\\nevent, for instance, rain in a hot summer day, has taken place. Therefore, the less likely the\\noccurrence of an event, the greater information it conveys.\\nIn the case where an event is a-priori known to occur for certain ( Pa = 1 ), then no inform-\\nation is conveyed by it. On the other hand, an extremely intermittent event conveys a lot of\\ninformation as it surprises us and informs us that a very improbable state exists. Therefore,\\nthe statement in part 3 is false.\\n\\x04\\nSOL-75 \\uf14b CH.SOL- 4.9.\\nThis quantity ISh, represented in the formulae is called the Shannon information of the\\nsource:\\nISh = −\\n∑\\na\\npa log2 pa. (4.9)\\nIt refers to the mean length in bits, per message, into which the messages can be compressed\\n104Chapter 4 INFORMATION THEORY\\nto. It is then possible for a communications channel to transmit ISh bits per message with a\\ncapacity of ISh. \\x04\\nSOL-76 \\uf14b CH.SOL- 4.10.\\n1. For N equiprobable events it holds that Pi = 1 /N, ∀i ∈ [1, N]. Therefore if we substi-\\ntute this into Shannon\\'s equation we get:\\nHequiprobable = −\\nN∑\\ni=1\\n1\\nN log2\\n1\\nN . (4.10)\\nSince N does not depend on i, we can pull it out of the sum:\\nHequiprobable = −( 1\\nN log2\\n1\\nN )\\nN∑\\ni=1\\n1 (4.11)\\n= −\\n( 1\\nN log2\\n1\\nN\\n)\\nN\\n= − log2\\n1\\nN (4.12)\\n= log 2 N.\\nIt can be shown that for a given number of symbols (i.e., N is ﬁxed) the uncertainty H\\nhas its largest value only when the symbols are equally probable.\\n2. The probability for each pixel to be assigned a value in the given range is:\\npi = 1/256. (4.13)\\nTherefore the entropy is:\\nH = −(256)(1/256)(−8) = 8 [bits/symbol]. (4.14)\\n\\x04\\nSOL-77 \\uf14b CH.SOL- 4.11.\\n1054.3. SOLUTIONS\\nRefer to Fig. 4.9 for the corresponding illustration of the graph, where information is\\nshown as a function of p. It is equal to 0 for p = 0 and for p = 1. This is reasonable because for\\nsuch values of p the outcome is certain, so no information is gained by learning the outcome.\\nThe entropy in maximal uncertainty equals to 1 bit for p = 0 .5. Thus, the information gain\\nis maximal when the probabilities of two possible events are equal. Furthermore, for the entire\\nrange of probabilities between p = 0.4 and p = 0.6 the information is close to 1 bit. \\x04\\nFIGURE 4.9: H vs. Probability\\nSOL-78 \\uf14b CH.SOL- 4.12.\\nAn important set of properties of the entropy follows from the concavity of the entropy,\\nwhich follows from the concavity of the logarithm. Suppose that in an experiment, we cannot\\ndecide whether the actual probability of ‘heads’ is p1 or p2. We may decide to assign probability\\nq to the ﬁrst alternative and probability 1 − q to the second. The actual probability of ‘heads’\\nthen is the mixture qp1 + (1 − q)p2. The corresponding entropies satisfy the inequality:\\nS (qp1 + (1 − q)p2) ≥ qS (p1) + (1 − q) S (p2) , (4.15)\\n106Chapter 4 INFORMATION THEORY\\nThese probabilities, are equal in the extreme cases where p1 = p2, or q = 0, or q = 1. \\x04\\nSOL-79 \\uf14b CH.SOL- 4.13.\\nGiven (X, Y ), we can determine X and Z = Y − X. Conversely, given (X, Z), we can\\ndetermine X and Y = X + Z. Hence, H(X, Y ) = H(X, Z) due to the existence of this\\nbijection. \\x04\\nSOL-80 \\uf14b CH.SOL- 4.14.\\nThe solution and numerical calculations are provided using log2.\\n1. We can predict ‘heads’ for each ﬂip with an accuracy of p(xh) = 98 %.\\n2. According to Fig. ( 4.10), if the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is log2(1/0.98) [bits] .\\n1 import math\\n2 import numpy\\n3 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n4 > 0.02914634565951651\\n5 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n6 > 5.643856189774724\\nFIGURE 4.10: Shannon information gain for a biased coin toss.\\n3. Likewise, if the result of the coin toss is ‘tails’, the amount of Shannon information\\ngained is log2(1/0.02) [bits] .\\n4. It is always true that the more information is associated with an outcome, the more\\nsurprising it is.\\n5. The formulae for the average surprise is:\\nH(x) = p(xh) log 1\\np(xh) + p(xt) log 1\\np(xt). (4.16)\\n1074.3. SOLUTIONS\\n6. The value of the average surprise in bits is ( 4.11):\\nH(x) = [0 .98 × 0.0291] + [0.02 × 5.643] (4.17)\\n= 0.1414 [bits].\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4 print (\"binaryEntropy(p) is:{}\\nbits\".format(binaryEntropy(0.98)))↪→\\n5 > binaryEntropy(p) is:0.1414 bits\\nFIGURE 4.11: Average surprise\\n\\x04\\n4.3.3 Kullback-Leibler Divergence\\nSOL-81 \\uf14b CH.SOL- 4.15.\\nFor discrete probability distributions P and Q, the Kullback-Leibler divergence from P\\nto Q, the KLD is deﬁned as:\\nD(P ∥ Q) =\\n∑\\nx\\nP (x) log P (x)\\nQ(x) (4.18)\\n= EP\\n[\\nlog 1\\nQ(x) − log 1\\nP (x)\\n]\\n= HP (Q)\\ued19 \\ued18\\ued17 \\ued1a\\nCross Entropy\\n− H(P )\\ued19 \\ued18\\ued17 \\ued1a\\nEntropy\\n.\\n\\x04\\n108Chapter 4 INFORMATION THEORY\\nSOL-82 \\uf14b CH.SOL- 4.16.\\nOne interpretation is the following: the KL-divergence indicates the average number of\\nadditional bits required for transmission of values x ∈ X which are distributed according\\nto P (x), but we erroneously encoded them according to distribution Q(x). This makes sense\\nsince you have to “pay” for additional bits to compensate for not knowing the true distribution,\\nthus using a code that was optimized according to other distribution. This is one of the reason\\nthat the KL-divergence is also known as relative entropy. Formally, the cross entropy has an\\ninformation interpretation quantifying how many bits are wasted by using the wrong code:\\nHP (Q) =\\n∑\\nx\\nP (x)\\ued19 \\ued18\\ued17 \\ued1a\\nSending P\\ncode for Q\\n\\ued17 \\ued1a\\ued19 \\ued18\\nlog 1\\nQ(x) . (4.19)\\n\\x04\\nSOL-83 \\uf14b CH.SOL- 4.17.\\n1. True KLD is a non-symmetric measure, i.e. D(P ∥ Q) ̸= D(Q ∥ P ).\\n2. False KLD does not satisfy the triangle inequality.\\n3. True KLD is not a distance metric.\\n4. True KLD is regarded as a measure of the information gain. Notice that, however, KLD\\nis the amount of information lost.\\n5. True The units of KL divergence are units of information (bits, nats, etc.).\\n6. True KLD is a non-negative measure.\\n7. True Performing splitting based on highly informative event usually leads to low model\\ngeneralization and a less accurate one as well.\\n\\x04\\nSOL-84 \\uf14b CH.SOL- 4.18.\\n1094.3. SOLUTIONS\\nFormally, mutual information attempts to measure how correlated two variables are with\\neach other:\\nI(X; Y ) =\\n∑\\nx,y\\nP (x, y) log P (x, y)\\nP (x)P (y) (4.20)\\n= E\\n[\\nlog 1\\nP (x) + log 1\\nP (y) − log 1\\nP (x, y)\\n]\\n= H(X) + H(Y ) − H(X, Y ).\\nRegarding the question at hand, given two distributions f1 and f2 and their joint distri-\\nbution f , the mutual information of f1 and f2 is deﬁned as I(f1, f2) = H(f, f1f2). If the\\ntwo distributions are independent, i.e. f = f1 · f2, the mutual information will vanish. This\\nconcept has been widely used as a similarity measure in image analysis. \\x04\\nSOL-85 \\uf14b CH.SOL- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem. \\x04\\n4.3.4 Classification and Information Gain\\nSOL-86 \\uf14b CH.SOL- 4.20.\\nThe three most widely used methods are:\\n1.\\nEntropy (t) = −\\nc−1∑\\ni=0\\np(i) log2 p(i). (4.21)\\n2.\\n1 −\\nc−1∑\\ni=0\\n[p(i)]2 (4.22)\\n110Chapter 4 INFORMATION THEORY\\n3.\\nClassiﬁcation error (t) = 1 − max\\ni\\n[p(i)]. (4.23)\\n\\x04\\nSOL-87 \\uf14b CH.SOL- 4.21.\\nIn a decision tree, the attribute by which we choose to split is the one with [maximum]\\ninformation gain. \\x04\\nSOL-88 \\uf14b CH.SOL- 4.22.\\nIt is clear that the entropy will be decreased more by ﬁrst splitting on Green rather than\\non Rain.\\nFIGURE 4.12: First split.\\n\\x04\\nSOL-89 \\uf14b CH.SOL- 4.23.\\n1. Information gain is the expected reduction in entropy caused by partitioning values in\\na dataset according to a given attribute.\\n2. A decision tree learning algorithm chooses the next attribute to partition the currently\\nselected node, by ﬁrst computing the information gain from the entropy, for instance,\\nas a splitting criterion.\\n3. There are 3 positive examples corresponding to Shrinkage=+, and 2 negative examples\\n1114.3. SOLUTIONS\\ncorresponding to Shrinkage=-. Using the formulae:\\nH(Y ) = −\\nk∑\\ni=1\\nP (Y = yi) log2 P (Y = yi) (4.24)\\nand the probabilities:\\nP (γ = +) = 3\\n5 , (4.25)\\nP (γ = −) = 2\\n5 , (4.26)\\nthe overall entropy before splitting is ( 4.13):\\nEorig = −(3/5) log(3/5) − (2/5) log(2/5)\\n= H(γ) ≈ 0.97095[bits/symbol]. (4.27)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is: 0.97095 bits\\nFIGURE 4.13: Entropy before splitting.\\n4. If we split on θ1, (4.5) the relative shrinkage frequency is:\\n112Chapter 4 INFORMATION THEORY\\nTotal θ1 = T θ1 = F\\n+ 3 0\\n- 1 1\\nTABLE 4.5: Splitting on θ1.\\nT o compute the information gain (IG) based on feature θ1, we must ﬁrst compute the\\nentropy of γ after a split based on θ1, H(γ|θ1):\\nH(γ|θ1)\\n= −\\nv∑\\nj=1\\n[ k∑\\ni=1\\nP (γ = γi|θ1 = θj) log2 P (γ = γi|θ1 = θj)\\n]\\nP (θ1 = θj).\\nTherefore, using the data for the the relative shrinkage frequency ( 4.5), the information\\ngain after splitting on θ1 is:\\nEθ1=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.8112,\\nEθ1=F = −0\\n1 log 0\\n1 − 1\\n1 log 1\\n1 = 0.0.\\n(4.28)\\nNow we know that P (θ1 = T ) = 4/5 and P (θ1 = F ) = 1/5 , therefore:\\n∆ = Eorig − (4/5) Eθ1=T − (1/5) Eθ1=F\\n= 0.97095 − (4/5) ∗ 0.8112 − (1/5) ∗ (0.0)\\n=≈ 0.32198 [bits/symbol].\\n(4.29)\\n\\x04\\nSOL-90 \\uf14b CH.SOL- 4.24.\\nThere are 4 positive examples corresponding to Expansion=+, and 3 negative examples\\n1134.3. SOLUTIONS\\ncorresponding to Expansion=-.\\n1. The overall entropy before splitting is ( 4.14):\\nEorig = −(4/7) log(4/7) − (3/7) log(3/7)\\n= 0.9852281 [bits/symbol]. (4.30)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is:0.9852281 bits\\nFIGURE 4.14: Entropy before splitting.\\n2. If we split on θ1, (4.6) the relative star expansion frequency is:\\nTotal θ1 = T θ1 = F\\n+ 3 1\\n- 0 3\\nTABLE 4.6: Splitting on θ1.\\nTherefore, the information gain after splitting on A is:\\nEθ1=T = −3\\n3 log 3\\n3 − 0\\n3 log 0\\n3 = 0.0,\\nEθ1=F = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.81127.\\n(4.31)\\n114Chapter 4 INFORMATION THEORY\\nNow we know that P (θ1 = T ) = 3/7 and P (θ1 = F ) = 4/7 , therefore:\\n∆ = Eorig − (3/7) Eθ1=T − (4/7) Eθ1=F\\n= 0.98522 − (3/7) ∗ 0.0 − (4/7) ∗ (0.81127)\\n= 0.52163 [bits/symbol].\\n(4.32)\\n3. If we split on θ2, (4.7) the relative star expansion frequency is:\\nTotal θ2 = T θ2 = F\\n+ 3 1\\n- 1 2\\nTABLE 4.7: Splitting on θ2.\\nThe information gain after splitting on B is:\\nEθ2=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.0.8112,\\nEθ2=F = −1\\n3 log 1\\n3 − 2\\n3 log 2\\n3 = 0.9182.\\n(4.33)\\nNow we know that P (θ2 = T ) = 4/7 and P (θ2 = F ) = 3/7 , therefore:\\n∆ = Eorig − (4/7) Eθ2=T − (3/7) Eθ2=F\\n= 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol].\\n∆ = 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol]. (4.34)\\n\\x04\\n1154.3. SOLUTIONS\\nSOL-91 \\uf14b CH.SOL- 4.25.\\n1.\\nH(γ) = −\\n( 2\\n6 log2\\n2\\n6 + 4\\n6 log2\\n4\\n6\\n)\\nH(γ) = −\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n≈ 0.92 [bits/symbol].\\n(4.35)\\n2.\\nH(γ|θ1) = −1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n−\\n1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n− 1\\n3 (1 log2 1) .\\nH(γ|θ1) = 1\\n3(1) + 1\\n3(1) + 1\\n3 (0).\\nH(γ|θ1) = 2\\n3 ≈ 0.66[bits/symbol].\\n(4.36)\\n3.\\nH(γ|θ2) = −1\\n2\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n− 1\\n2 (1 log2 1) .\\nH(γ|θ2) = 1\\n2\\n(\\nlog2 3 − 2\\n3\\n)\\n.\\nH(γ|θ2) = 1\\n2 log2 3 − 1\\n3 ≈ 0.46 [bits/symbol].\\n(4.37)\\n4. False.\\n\\x04\\n4.3.5 Mutual Information\\nSOL-92 \\uf14b CH.SOL- 4.26.\\n1. The diagram is depicted in Fig. 4.15.\\n116Chapter 4 INFORMATION THEORY\\nE N\\nH(S) H(D)\\nFIGURE 4.15: Mutual Information between H(S) & H(D).\\n2. Equivocation is annotated by E.\\n3. Noise is annotated by N .\\n4. The intersection (shaded area) in (4.15) corresponds to mutual information of the source\\nH(S) and of the destination H(D).\\n5. The formulae for mutual information is:\\nH(S; D) = H(S) − E = H(D) − N. (4.38)\\n\\x04\\nSOL-93 \\uf14b CH.SOL- 4.27.\\nThe relative entropy D(p||q) is the measure of difference between two distributions. It\\ncan also be expressed like a measure of the inefﬁciency of assuming that the distribution is q\\nwhen the true distribution is p. \\x04\\nSOL-94 \\uf14b CH.SOL- 4.28.\\nMutual information is a Shannon entropy-based measure of dependence between random\\nvariables. The mutual information between X and Z can be understood as the reduction of\\n1174.3. SOLUTIONS\\nthe uncertainty in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.39)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X. \\x04\\n4.3.6 Mechanical Statistics\\nSOL-95 \\uf14b CH.SOL- 4.29.\\nIs this question valuable? \\x04\\nSOL-96 \\uf14b CH.SOL- 4.30.\\nBoltzmann related the degree of disorder of the state of a physical system to the logarithm\\nof its probability. If, for example, the system has n non-interacting and identical particles,\\neach capable of existing in each of K equally likely states, the leading term in the logarithm of\\nthe probability of ﬁnding the system in a conﬁguration with n1 particles in state 1, n2 in state\\n2, etc, is given by the Boltzmann entropy Hπ = − ∑K\\n1 πi log(πi), where πi = ni/n. \\x04\\nSOL-97 \\uf14b CH.SOL- 4.31.\\nThere are 8 equiprobable events in each roll of the dice, therefore:\\nH = −\\n8∑\\ni=1\\n1\\n8 log2\\n1\\n8 = 3 [bits] . (4.40)\\n\\x04\\n4.3.7 Jensen\\'s inequality\\nSOL-98 \\uf14b CH.SOL- 4.32.\\n1. A function f is concave in the range [a, b] if f φ2 is negative in the range [a, b].\\n2. A function f is convex in the range [a, b] if f φ2 is positive in the range [a, b].\\n118Chapter 4 INFORMATION THEORY\\n3. The following inequality was published by J.L. Jensen in 1906:\\n(Jensen’s Inequality)Let f be a function convex up on (a, b). Then for any n ≥ 2\\nnumbers xi ∈ (a, b):\\nf\\n( ∑n\\ni=1 xi\\nn\\n)\\n≤\\n∑n\\ni=1 f (xi)\\nn ,\\nand that the equality is attained if and only if f is linear or all xi are equal.\\nFor a convex down function, the sign of the inequality changes to ≥.\\nJensen’s inequality states that if f is convex in the range [a, b], then:\\nf (a) + f (b)\\n2 ≥ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b. Jensen’s inequality states that if f is concave in the\\nrange [a, b], then:\\nf (a) + f (b)\\n2 ≤ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b.\\n\\x04\\nSOL-99 \\uf14b CH.SOL- 4.33.\\nTrue The non-negativity of KLD can be proved using Jensen\\'s inequality. \\x04\\nReferences\\n[1] S. Carnot. Reﬂections on the Motive Power of Fire: And Other Papers on the Second\\nLaw of Thermodynamics . Dover books on physics. Dover Publications, 2012 (cit.\\non p. 86).\\n[2] T. M. Cover and J. A. Thomas. Elements of Information Theory . John Wiley and\\nSons, Inc., 2006 (cit. on p. 86).\\n[3] B. J. Hiley. ‘From the Heisenberg Picture to Bohm: a New Perspective on Active\\nInformation and its relation to Shannon Information’. In: Proc. Conf. Quantum\\nTheory: reconsideration of foundations (2002), pp. 141–162 (cit. on p. 87).\\n119REFERENCES\\n[4] C. Shannon. ‘A mathematical theory of communication’. In: Bell System T echnical\\nJournal 27 (1948), pp. 379–423 (cit. on pp. 86, 90).\\n[5] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 96).\\n120CHAPTER\\n5\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1465.1. INTRODUCTION\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 155\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n5.1 Introduction\\nC\\nALCULUS is the mathematics of change; the differentiation of a function is\\nkey to almost every domain in the scientiﬁc and engineering realms and\\ncalculus is also very much central to DL. A standard curriculum of ﬁrst year\\ncalculus includes topics such as limits, differentiation, the derivative, Taylor\\nseries, integration, and the integral. Many aspiring data scientists who lack a relevant\\nmathematical background and are shifting careers, hope to easily enter the ﬁeld but\\nfrequently encounter a mental barricade.\\n122Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nf (x) f ′(x)\\nsin(x) cos(x)\\ncos(x) − sin(x)\\nlog(x) 1\\nx\\nex ex\\nThanks to the rapid advances in processing power and the proliferation of GPUs,\\nit is possible to lend the burden of computation to a computer with high efﬁciency\\nand precision. For instance, extremely fast implementations of backpropagation, the\\ngradient descent algorithm, and automatic differentiation (AD) [5] brought artiﬁcial in-\\ntelligence from a mere concept to reality .\\nCalculus is frequently taught in a way that is very burdensome to the student,\\ntherefore I tried incorporating the writing of Python code snippets into the learning\\nprocess and the usage of:\\nDAGs (Directed Acyclic Graphs). Gradient descent is the essence of optimization in\\ndeep learning, which requires efﬁcient access to ﬁrst and second order derivatives that\\nAD frameworks provide. While older AD frameworks were written in C++ ([ 4]), the\\nnewer ones are Python-based such as Autograd ([ 10]) and JAX ([ 3], [1]).\\nDerivatives are also crucial in graphics applications. For example, in a render-\\ning technique entitled global illumination, photons bounce in a synthetically generated\\nscene while their direction and colour has to be determined using derivatives based\\non the speciﬁc material each photon hits. In ray tracing algorithms, the colour of the\\npixels is determined by tracing the trajectory the photons travel from the eye of the\\nobserver through a synthetic 3D scene.\\nA function is usually represented by a DAG. For instance, one commonly used\\nform is to represent intermediate values as nodes and operations as arcs ( 5.2). One\\nother commonly used form is to represent not only the values but also the operations\\nas nodes ( 5.11).\\nThe ﬁrst representation of a function by a DAG goes back to [ 7].\\n1235.2. PROBLEMS\\nx\\ny\\nk\\nf (a)\\nf (b)\\na bc\\nFIGURE 5.1: Intermediate value theorem\\nManual differentiation is tedious and error-prone and practically unusable for real-\\ntime graphics applications wherein numerous successive derivatives have to be re-\\npeatedly calculated. Symbolic differentiation on the other hand, is a computer based\\nmethod that uses a collection of differentiation rules to analytically calculate an exact\\nderivative of a function resulting in a purely symbolic derivatives. Many symbolic\\ndifferentiation libraries utilize what is known as operator-overloading ([9]) for both the\\nforward and reverse forms of differentiation, albeit they are not quite as fast as AD.\\n5.2 Problems\\n5.2.1 AD, Gradient descent & Backpropagation\\nAD [5] is the application of the chain rule to functions by computers in order to auto-\\nmatically compute derivatives. AD plays a signiﬁcant role in training deep learning\\nalgorithms and in order to understand AD you need a solid grounding in Calculus. As\\nopposed to numerical differentiation, AD is a procedure for establishing exact deriv-\\natives without any truncation errors. AD breaks a computer program into a series of\\nfundamental mathematical operations, and the gradient or Hessian of the computer\\nprogram is found by successive application of the chain rule ( 5.1) to it’s elementary\\nconstituents.\\n124Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nFor instance, in the C++ programming language, two techniques ([ 4]) are com-\\nmonly utilized in transforming a program that calculates numerical values of a func-\\ntion into a program which calculates numerical values for derivatives of that function;\\n(1) an operator overloading approach and (2) systematic source code transformation.\\n∂\\n∂t f (g(t))\\n⏐⏐⏐⏐⏐\\nt=t0\\n=\\n\\uf8eb\\n\\uf8ed ∂\\n∂s f (s)\\n⏐⏐⏐⏐⏐\\ns=g(t0)\\n\\uf8f6\\n\\uf8f8\\n(\\n∂\\n∂t g(t)\\n⏐⏐⏐⏐⏐\\nt=t0\\n)\\n(5.1)\\nOne notable feature of AD is that the values of the derivatives produced by apply-\\ning AD, as opposed to numerical differentiation (ﬁnite difference formulas), are exact\\nand accurate. Two variants of AD are widely adopted by the scientiﬁc community: the\\nforward mode or the reverse mode where the underlying distinction between them is\\nthe order in which the chain rule is being utilized. The forward mode, also entitled\\ntangent mode, propagates derivatives from the dependent towards the independent\\nvariables, whereas the reverse or adjoint mode does exactly the opposite. AD makes\\nheavy use of a concept known as dual numbers (DN) ﬁrst introduced by Clifford ([ 2]).\\nx1 v1 v2 f\\n(x)2\\nln(1 + v1)\\nexp(v1)\\nv2 + 1\\nFIGURE 5.2: A Computation graph with intermediate values as nodes and operations as\\narcs.\\n5.2.2 Numerical differentiation\\nPRB-100 \\uf059 CH.PRB- 5.1.\\n1. Write the formulae for the ﬁnite difference rule used in numerical differentiation.\\n2. What is the main problem with this formulae?\\n1255.2. PROBLEMS\\n3. Indicate one problem with software tools which utilize numerical differentiation and\\nsuccessive operations on ﬂoating point numbers.\\nPRB-101 \\uf059 CH.PRB- 5.2.\\n1. Given a function f (x) and a point a, deﬁne the instantaneous rate of change of\\nf (x) at a.\\n2. What other commonly used alternative name does the instantaneous rate of change\\nhave?\\n3. Given a function f (x) and a point a, deﬁne the tangent line of f (x) at a.\\n5.2.3 Directed Acyclic Graphs\\nThere are two possible ways to traverse a DAG (Directed Acyclic Graph). One\\nmethod is simple. Start at the bottom and go through all nodes to the top of the com-\\nputational tree. That is nothing else than passing the corresponding computation se-\\nquence top down. Based on this method, the so called forward mode or of AD was\\ndeveloped [ 8]. In contrast to this forward mode the reverse mode was ﬁrst used by\\nSpeelpenning [ 13] who passed the underlying graph top down and propagated the\\ngradient backwards.\\nPRB-102 \\uf059 CH.PRB- 5.3.\\n1. State the deﬁnition of the derivative f (c) of a function f (x) at x = c.\\n2. With respect to the DAG depicted in 5.3:\\n126Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx √x\\n1\\n/\\ng(x)\\nFIGURE 5.3: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.3 and ﬁnd the function g(x) it represents.\\n(b) Using the deﬁnition of the derivative, ﬁnd g′(9).\\nPRB-103 \\uf059 CH.PRB- 5.4.\\n1. With respect to the expression graph depicted in 5.4, traverse the graph and ﬁnd the\\nfunction g(x) it represents.\\nx\\n**2\\n2\\n*\\n-\\n+\\n1\\ng(x)\\nFIGURE 5.4: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n2. Using the deﬁnition of the derivative ﬁnd the derivative of g(x).\\n5.2.4 The chain rule\\nPRB-104 \\uf059 CH.PRB- 5.5.\\n1275.2. PROBLEMS\\n1. The chain rule is key concept in differentiation. Deﬁne it.\\n2. Elaborate how the chain rule is utilized in the context of neural networks.\\n5.2.5 Taylor series expansion\\nThe idea behind a Taylor series is that if you know a function and all its derivatives\\nat one point x = a, you can approximate the function at other points near a. As an\\nexample, take f (x) = √x. You can use Taylor series to approximate\\n√\\n10 by knowing\\nf (9) and all the derivatives f ′(9), f ′′(9).\\nThe MacLaurin series ( 5.2) is a special case of Taylor series when f (0), f ′(0) are\\nknown:\\nf (x) = f (0) + xf ′(0) + x2\\n2! f ′′(0) + x3\\n3! f ′′′(0) + · · · =\\n∞∑\\np=0\\nxp\\np! f (p)(0) (5.2)\\nFor instance, the Maclaurin expansion of cos(x) is:\\nf (x) = cos x, f ′(x) = − sin x,\\nf ′′(x) = − cos x, f ′′′(x) = sin x (5.3)\\nWhen evaluated at 0 results in:\\ncos x = 1 − x2\\n2! + x4\\n4! − x6\\n6! + · · · (5.4)\\nPRB-105 \\uf059 CH.PRB- 5.6.\\nFind the T aylor series expansion for:\\n1.\\n1\\n1 − x (5.5)\\n128Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2.\\nex (5.6)\\n3.\\nsin(x) (5.7)\\n4.\\ncos(x) (5.8)\\nPRB-106 \\uf059 CH.PRB- 5.7.\\nFind the T aylor series expansion for:\\nlog(x) (5.9)\\nPRB-107 \\uf059 CH.PRB- 5.8.\\nFind the T aylor series expansion centered at x = −3 for:\\nf (x) = 5 x2 − 11x + 1 (5.10)\\nPRB-108 \\uf059 CH.PRB- 5.9.\\nFind the 101th degree T aylor polynomial centered at x = 0 for:\\nf (x) = cos( x) (5.11)\\nPRB-109 \\uf059 CH.PRB- 5.10.\\nAt x = 1, compute the ﬁrst 7 terms of the T aylor series expansion of:\\nf (x) = ln 3 x. (5.12)\\n1295.2. PROBLEMS\\n5.2.6 Limits and continuity\\nTheorem 1 (L’Hopital’s rule) .\\n[limx→a\\nf (x)\\ng(x) = limx→a\\nf ′(x)\\ng′(x) ]. (5.13)\\nPRB-110 \\uf059 CH.PRB- 5.11.\\nFind the following limits:\\n1. lim\\nx→3\\nex3\\n− e27\\n3x − 9\\n2. lim\\nx→0\\nex2\\n− x − 1\\n3 cos x − x − 3\\n3. limx→∞\\nx − ln x\\n100√x + 4\\n5.2.7 Partial derivatives\\nPRB-111 \\uf059 CH.PRB- 5.12.\\n1. True or false: When applying a partial derivative, there are two variables considered\\nconstants - the dependent and independent variable.\\n2. Given g(x, y), ﬁnd its partial derivative with respect to x:\\ng(x, y) = x2y + yx + 8y. (5.14)\\nPRB-112 \\uf059 CH.PRB- 5.13.\\n130Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe gradient of a two-dimensional function is given by\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j (5.15)\\n1. Find the gradient of the function:\\nf (x, y) = xy2 − y2 + x3 (5.16)\\n2. Given the function:\\ng(x, y) = x2y = xy2 − y − 1, (5.17)\\nevaluate it at (−1, 0), directed at (1, 1).\\nPRB-113 \\uf059 CH.PRB- 5.14.\\nFind the partial derivatives of:\\nf (x, y) = 3 sin 2(x − y) (5.18)\\nPRB-114 \\uf059 CH.PRB- 5.15.\\nFind the partial derivatives of:\\nz = 2 sin(x) sin(y) (5.19)\\n5.2.8 Optimization\\nPRB-115 \\uf059 CH.PRB- 5.16.\\nConsider f (x) = x2 + 1\\n(x + 2)2 .\\n1. Where is f (x) well deﬁned?\\n1315.2. PROBLEMS\\n2. Where is f (x) increasing and decreasing?\\n3. Where is f (x) reaching minimum and maximum values.\\nPRB-116 \\uf059 CH.PRB- 5.17.\\nConsider f (x) = 2 x3 − x.\\n1. Derive f (x) and conclude on its behavior.\\n2. Derive once again and discuss the concavity of the function f (x).\\nPRB-117 \\uf059 CH.PRB- 5.18.\\nConsider the function\\nf (x, y) = 2 x2 − xy + y2,\\nand ﬁnd maximum, minimum, and saddle points.\\n5.2.9 The Gradient descent algorithm\\nPRB-118 \\uf059 CH.PRB- 5.19.\\nThe gradient descent algorithm can be utilized for the minimization of convex functions.\\nStationary points are required in order to minimize a convex function. A very simple ap-\\nproach for ﬁnding stationary points is to start at an arbitrary point, and move along the\\ngradient at that point towards the next point, and repeat until converging to a stationary\\npoint.\\n1. What is the term used to describe the vector of all partial derivatives for a function\\nf (x)?\\n2. Complete the sentence: when searching for a minima, if the derivative is positive, the\\nfunction is increasing/decreasing.\\n132Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n3. The function x2 as depicted in 5.5, has a derivative of f ′(x) = 2 x. Evaluated at x =\\n−1, the derivative equals f ′(x = −1) = −2. At x = −1, the function is decreasing\\nas x gets larger. We will happen if we wish to ﬁnd a minima using gradient descent,\\nand increase (decrease) x by the size of the gradient , and then again repeatedly keep\\njumping?\\n4. How this phenomena can be alleviated?\\n5. True or False: The gradient descent algorithm is guaranteed to ﬁnd a local minimum\\nif the learning rate is correctly decreased and a ﬁnite local minimum exists.\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−1,0\\n1,0\\n2,0\\n3,0\\n4,0\\nx = −1\\nx\\ny\\nx2\\nFIGURE 5.5: x2 Function\\nPRB-119 \\uf059 CH.PRB- 5.20.\\n1. Is the data linearly separable?\\nX1 X2 Y\\n1 1 +\\n12 12 −\\n4 5 −\\n12 12 +\\n(5.20)\\n1335.2. PROBLEMS\\n2. What is loss function for linear regression?\\n3. What is the gradient descent algorithm to minimize a function f (x)?\\n5.2.10 The Backpropagation algorithm\\nThe most important, expensive and hard to implement part of any hardware realiz-\\nation of ANNs is the non-linear activation function of a neuron. Commonly applied\\nactivation functions are the sigmoid and the hyperbolic tangent. In the most used\\nlearning algorithm in present day applications, back-propagation, the derivatives of\\nthe sigmoid function are needed when back propagating the errors.\\nThe backpropagation algorithm looks for the minimum of the error function in\\nweight space using the method of gradient descent.\\nPRB-120 \\uf059 CH.PRB- 5.21.\\n1. During the training of an ANN, a sigmoid layer applies the sigmoid function to every\\nelement in the forward pass, while in the backward pass the chain rule is being util-\\nized as part of the backpropagation algorithm. With respect to the backpropagation\\nalgorithm, given a sigmoid σ(x) = ex\\n1+ex activation function, and a J as the cost func-\\ntion, annotate each part of equation (5.21):\\ndZ = dJ\\ndσ(x)\\ndσ(x)\\ndx = dA · σ(x) ·\\n(\\n1 − σ(x)\\n)\\n(5.21)\\n2. Code snippet 5.6 provides a pure Python-based (e.g. not using Autograd) implement-\\nation of the forward pass for the sigmoid function. Complete the backward pass that\\ndirectly computes the analytical gradients.\\n134Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5 def backward(self, grad):\\n6 grad_input = [???]\\n7 return grad_input\\nFIGURE 5.6: Forward pass for the sigmoid function.\\nPRB-121 \\uf059 CH.PRB- 5.22.\\nThis question deals with the effect of customized transfer functions. Consider a neural\\nnetwork with hidden units that use x3 and output units that use sin(2x) as transfer func-\\ntions. Using the chain rule, starting from ∂E/∂yk, derive the formulas for the weight updates\\n∆wjk and ∆wij. Notice - do not include partial derivatives in your ﬁnal answer.\\n5.2.11 Feed forward neural networks\\nUnderstanding the inner-workings of Feed Forward Neural Networks (FFNN) is\\ncrucial to the understanding of other, more advanced Neural Networks such as CNN’s.\\nA Neural Network (NN) is an interconnected assembly of simple processing\\nelements, units or nodes, whose functionality is loosely based on the animal\\nneuron. The processing ability of the network is stored in the inter-unit\\nconnection strengths, or weights, obtained by a process of adaptation to, or\\nlearning from, a set of training patterns. [ 6]\\nThe Backpropagation Algorithm is the most widely used learning algorithm for\\nFFNN. Backpropagation is a training method that uses the Generalized Delta Rule . Its\\nbasic idea is to perform a gradient descent on the total squared error of the network\\noutput, considered as a function of the weights. It was ﬁrst described by Werbos and\\nmade popular by Rumelhart’s, Hinton’s and Williams’ paper [ 12].\\n1355.2. PROBLEMS\\n5.2.12 Activation functions, Autograd/JAX\\nActivation functions, and most commonly the sigmoid activation function, are\\nheavily used for the construction of NNs. We utilize Autograd ([ 10]) and the recently\\npublished JAX ([ 1]) library to learn about the relationship between activation func-\\ntions and the Backpropagation algorithm.\\nUsing a logistic, or sigmoid, activation function has some beneﬁts in being able\\nto easily take derivatives and then interpret them using a logistic regression model.\\nAutograd is a core module in PyTorch ([ 11]) and adds inherit support for automatic\\ndifferentiation for all operations on tensors and functions. Moreover, one can imple-\\nment his own custom Autograd function by sub classing the autograd F unction and\\nimplementing the forward and backward passes which operate on PyTorch tensors.\\nPyTorch provides a simple syntax ( 5.7) which is transparent to both CPU/GPU sup-\\nport.\\nimport torch\\nfrom torch.autograd import Function\\nclass DLFunction(Function):\\n@staticmethod\\ndef forward(ctx, input):\\n...\\n@staticmethod\\ndef backward(ctx, grad_output):\\n...\\nFIGURE 5.7: PyTorch syntax for autograd.\\nPRB-122 \\uf059 CH.PRB- 5.23.\\n1. True or false:In Autograd, if any input tensor of an operation has requires_grad=T rue,\\nthe computation will be tracked. After computing the backward pass, a gradient w.r.t.\\nthis tensor is accumulated into .grad attribute\\n136Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. True or false: In Autograd, multiple calls to backward will sum up previously com-\\nputed gradients if they are not zeroed.\\nPRB-123 \\uf059 CH.PRB- 5.24.\\nY our friend, a veteran of the DL community wants to use logistic regression and im-\\nplement custom activation functions using Autograd. Logistic regression is used when the\\nvariable y that we want to predict can only take on discrete values (i.e. classiﬁcation). Con-\\nsidering a binary classiﬁcation problem (y = 0 or y = 1) ( 5.8), the hypothesis function could\\nbe deﬁned so that it is bounded between [0, 1] in which we use some form of logistic function,\\nsuch as the sigmoid function. Other, more efﬁcient functions exist such as the ReLU (Rec-\\ntiﬁed Linear Unit) which we discussed later. Note: The weights in ( 5.8) are only meant for\\nillustration purposes and are not part of the solution.\\nxn\\nx2\\nx1\\n1\\n∑\\nwn\\nw2\\nw1\\nw0\\n0\\n1\\n0\\n1\\nSummation Activation\\nyk =f(netk)\\ninputs weights\\nFIGURE 5.8: A typical binary classiﬁcation problem.\\n1. Given the sigmoid function: g(x) = 1\\n1+e−z what is the expression for the corresponding\\nhypothesis in logistic regression?\\n2. What is the decision boundary?\\n3. What does hΘ(x) = 0 .8 mean?\\n4. Using an Autograd based Python program, implement both the forward and backward\\npass for the sigmoid activation function and evaluate it’s derivative at x = 1\\n1375.2. PROBLEMS\\n5. Using an Autograd based Python program, implement both the forward and backward\\npass for the ReLU activation function and evaluate it’s derivative at x = 1\\nPRB-124 \\uf059 CH.PRB- 5.25.\\nFor real values, −1 < x < 1 the hyperbolic tangent function is deﬁned as:\\ntanh−1 x = 1\\n2 [ln(1 + x) − ln(1 − x)] (5.22)\\nOn the other hand, the artanh function, which returns the inverse hyperbolic tangent of\\nits argument x, is implemented in numpy as arctanh().\\nIts derivative is given by:\\n(arctanh(x))′ = 1\\n1 − x2 (5.23)\\nY our friend, a veteran of the DL community wants to implement a custom activation\\nfunction for the arctanh function using Autograd. Help him in realize the method.\\n1. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n2. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the forward pass for the arctanh function in Python.\\n3. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the backward pass for the arctanh function in Python.\\n4. Name the class ArtanhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\n5.2.13 Dual numbers in AD\\nDual numbers (DN) are analogous to complex numbers and augment real numbers\\n138Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nwith a dual element by adjoining an inﬁnitesimal element d, for which d2 = 0.\\nPRB-125 \\uf059 CH.PRB- 5.26.\\n1. Explain how AD uses ﬂoating point numerical rather than symbolic expressions.\\n2. Explain the notion of DN as introduced by ([ 2]).\\n3. What arithmetic operations are possible on DN?.\\n4. Explain the relationship between a T aylor series and DN.\\nPRB-126 \\uf059 CH.PRB- 5.27.\\n1. Expand the following function using DN:\\nsin(x + ˙xd) (5.24)\\n2. With respect to the expression graph depicted in 5.9:\\nx\\n3\\n* +\\n2\\ng(x)\\nFIGURE 5.9: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.9 and ﬁnd the function g(x) it represents.\\n(b) Expand the function g(x) using DN.\\n3. Show that the general identity :\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.25)\\n1395.2. PROBLEMS\\nholds in this particular case too.\\n4. Using the derived DN, evaluate the function g(x) at x = 2.\\n5. Using an Autograd based Python program implement the function and evaluate it’s\\nderivative at x = 2.\\nPRB-127 \\uf059 CH.PRB- 5.28.\\nWith respect to the expression graph depicted in 5.10:\\nx\\n**2\\n5\\n*\\n*\\n+\\n14\\ng(x)\\nFIGURE 5.10: An expression graph for g(x). Constants are shown in gray , crossed-out\\nsince derivatives should not be propagated to constant operands.\\n1. T raverse the graph5.10 and ﬁnd the function g(x) it represents.\\n2. Expand the function g(x) using DN.\\n3. Using the derived DN, evaluate the function g(x) at x = 5.\\n4. Using an AutoGrad based Python program implement the function and evaluate it’s\\nderivative at x = 5.\\n5.2.14 Forward mode AD\\nPRB-128 \\uf059 CH.PRB- 5.29.\\n140Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nWhen differentiating a function using forward-mode AD, the computation of such an\\nexpression can be computed from its corresponding directed a-cyclical graph by propagating\\nthe numerical values.\\n1. Find the function, g(A, B, C) represented by the expression graph in 5.11.\\nA\\nB\\nC\\nln\\n+* g (A, B, C))\\nFIGURE 5.11: A computation graph for g(x)\\n2. Find the partial derivatives for the function g(x).\\nPRB-129 \\uf059 CH.PRB- 5.30.\\nAnswer the following given that a computational graph of a function has N inputs and\\nM outputs.\\n1. True or False?:\\n(a) Forward and reverse mode AD always yield the same result.\\n(b) In reverse mode AD there are fewer operations (time) and less space for interme-\\ndiates (memory).\\n(c) The cost for forward mode grows with N.\\n(d) The cost for reverse mode grows with M.\\nPRB-130 \\uf059 CH.PRB- 5.31.\\n1415.2. PROBLEMS\\n1. T ransform the source code in code snippet 5.1 into a function g(x1, x2).\\nCODE 5.1: A function, g(x1, x2) in the C programming language.\\n1 float g( float x1 , float x2) {\\n2 float v1, v2, v3 , v4 , v5;\\n3 v1=x1;\\n4 v2=x2;\\n5 v3 = v1 * v2;\\n6 v4 = ln (v1 );\\n7 v5 = v3 + v4;\\n8 return v5;\\n9 }\\n2. T ransform the functiong(x1, x2) into an expression graph.\\n3. Find the partial derivatives for the function g(x1, x2).\\n5.2.15 Forward mode AD table construction\\nPRB-131 \\uf059 CH.PRB- 5.32.\\n1. Given the function:\\nf (x1, x2) = x1x2 + ln (x1) (5.26)\\nand the graph 5.1, annotate each vertex (edge) of the graph with the partial derivatives\\nthat would be propagated in forward mode AD.\\n2. T ransform the graph into a table that computes the function:\\ng(x1, x2) evaluated at (x1; x2) = ( e2; π) using forward-mode AD.\\n3. Write and run a Python code snippet to prove your results are correct.\\n4. Describe the role of seed values in forward-mode AD.\\n142Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n5. T ransform the graph into a table that computes the derivative of g(x1, x2) evalu-\\nated at (x1; x2) = ( e2; π) using forward-mode AD for x1 as the chosen independent\\nvariable.\\n6. Write and run a Python code snippet to prove your results are correct.\\n5.2.16 Symbolic differentiation\\nIn this section, we introduce the basic functionality of the SymPy (SYMbolic Python)\\nlibrary commonly used for symbolic mathematics as a means to deepen your under-\\nstanding in both Python and calculus. If you are using Sympy in a Jupyter notebook\\nin Google Colab (e.g. https://colab.research.google.com/) then rendering\\nsympy equations requires MathJax to be available within each cell output. The follow-\\ning is a hook function that will make this possible:\\nCODE 5.2: Sympy in Google Colab\\n1 from IPython.display import Math, HTML\\n2 def enable_sympy_in_cell():\\n3 display(HTML(\"<script\\nsrc=\\'https://cdnjs.cloudflare.com/ajax/libs/\"↪→\\n4 \"mathjax/2.7.3/latest.js?config=default\\'>\\n5 </script>\"))\\n6 get_ipython().events.register(\\'pre_run_cell\\' ,\\nenable_sympy_in_cell)↪→\\nAfter successfully registering this hook, SymPy rendering ( 5.3) will work correctly:\\nCODE 5.3: Rendering Sympy in Google Colab\\n1 import sympy\\n2 from sympy import *\\n3 init_printing()\\n4 x, y, z = symbols(\\'x y z\\' )\\n5 Integral(sqrt(1/x), (x, 0, oo))\\n1435.2. PROBLEMS\\nIt is also recommended to use the latest version of Sympy:\\nCODE 5.4: Updating Sympy\\n> pip install --upgrade sympy\\n5.2.17 Simple differentiation\\nPRB-132 \\uf059 CH.PRB- 5.33.\\nAnswer the following questions:\\n1. Which differentiation method is inherently prone to rounding errors?\\n2. Deﬁne the term symbolic differentiation.\\nPRB-133 \\uf059 CH.PRB- 5.34.\\nAnswer the following questions:\\n1. Implement the sigmoid function σ(x) = 1\\n1+e−x symbolically using a Python based\\nSymPy program.\\n2. Differentiate the sigmoid function using SymPy and compare it with the analytical\\nderivation σ′(x) = σ(x)(1 − σ(x)).\\n3. Using SymPy, evaluate the gradient of the sigmoid function at x = 0.\\n4. Using SymPy, plot the resulting gradient of the sigmoid function.\\n5.2.18 The Beta-Binomial model\\nPRB-134 \\uf059 CH.PRB- 5.35.\\n144Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nY ou will most likely not be given such a long programming task during a face-to-face\\ninterview. Nevertheless, an extensive home programming assignment is typically given at\\nmany of the start-ups I am familiar with. Y ou should allocate around approximately four to\\nsix hours to completely answer all questions in this problem.\\nWe discussed the Beta-Binomial model extensively in chapter 3. Recall that the Beta-\\nBinomial distribution is frequently used in Bayesian statistics to model the number of suc-\\ncesses in n trials. We now employ SymPy to do the same; demonstrate computationally how\\na prior distribution is updated to develop into a posterior distribution after observing the\\ndata via the relationship of the Beta-Binomial distribution.\\nProvided the probability of success, the number of successes after n trials follows a bino-\\nmial distribution. Note that the beta distribution is a conjugate prior for the parameter of\\nthe binomial distribution. In this case, the likelihood function is binomial, and a beta prior\\ndistribution yields a beta posterior distribution.\\nRecall that for the Beta-Binomial distribution the following relationships exist:\\nPrior of θ Beta(a,b)\\nLikelihood binomial (n, θ)\\nPosterior of θ Beta (a + x, b + n − x)\\nPosterior Mean (a + x)/(a + b + n − x)\\n(5.27)\\n1. Likelihood: The starting point for our inference problem is the Likelihood, the prob-\\nability of the observed data. Find the Likelihood function symbolically using sympy.\\nConvert the SymPy representation to a purely Numpy based callable function with a\\nLambda expression. Evaluate the Likelihood function at θ = 0 .5 with 50 successful\\ntrials out of 100.\\n2. Prior: The Beta Distribution. Deﬁne the Beta distribution which will act as our prior\\ndistribution symbolically using sympy. Convert the SymPy representation to a purely\\nNumpy based callable function. Evaluate the Beta Distribution at θ : 0.5, a : 2, b : 7\\n3. Plot the Beta distribution, using the Numpy based function.\\n4. Posterior: Find the posterior distribution by multiplying our Beta prior by the Bi-\\nnomial Likelihood symbolically using sympy. Convert the SymPy representation to\\n1455.3. SOLUTIONS\\na purely Numpy based callable function. Evaluate the Posterior Distribution at θ :\\n0.5, a : 2, b : 7\\n5. Plot the posterior distribution, using the Numpy based function.\\n6. Show that the posterior distribution has the same functional dependence on θ as the\\nprior, and it is just another Beta distribution.\\n7. Given:\\nPrior : Beta(θ|a = 2, b = 7) = 56 θ (−θ + 1)6 and:\\nLikelihood : Bin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47 ﬁnd the resulting posterior\\ndistribution and plot it.\\n5.3 Solutions\\n5.3.1 Algorithmic differentiation, Gradient descent\\n5.3.2 Numerical differentiation\\nSOL-100 \\uf14b CH.SOL- 5.1.\\n1. The formulae is:\\nf ′(x) ≈ f (x + h) − f (x)\\nh . (5.28)\\n2. The main problem with this formulae is that it suffers from numerical instability for\\nsmall values of h.\\n3. In some numerical software systems, the number\\n√\\n2 may be represented as the a ﬂoat-\\ning point number ≈ 1.414213562. Therefore, the result of:\\nf loat\\n( √\\n(2)\\n)\\n∗ f loat\\n( √\\n(2)\\n)\\nmay equal ≈ 2.000000446.\\n\\x04\\nSOL-101 \\uf14b CH.SOL- 5.2.\\n146Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The instantaneous rate of change equals:\\nlim\\nh→0\\nf (a + h) − f (a)\\na + h − a . (5.29)\\n2. The instantaneous rate of change of f (x) at a is also commonly known as the tangent\\nline of f (x) at a.\\n3. Given a function f (x) and a point a, the tangent (Fig. 5.12) line of f (x) at a is a line\\nthat touches f (a) but does not cross f (x) (sufﬁciently close to a).\\nFIGURE 5.12: A Tangent line\\n\\x04\\n5.3.3 Directed Acyclic Graphs\\nSOL-102 \\uf14b CH.SOL- 5.3.\\n1475.3. SOLUTIONS\\n1. The deﬁnition is:\\nf ′(c) = lim\\nh→0\\nf (c + h) − f (c)\\nh .\\n2. If we traverse the graph 5.3 from left to right we derive the following function:\\ng(x) = 1√x . (5.30)\\nf ′(9) = lim\\nh→0\\n1/\\n√\\n9 + h − 1/\\n√\\n9\\nh\\n= lim\\nh→0\\n√\\n9 −\\n√\\n9 + h√\\n9 ·\\n√\\n9 + h · h\\n= lim\\nh→0\\n(3 −\\n√\\n9 + h)(3 +\\n√\\n9 + h)\\n3\\n√\\n9 + h · (3 +\\n√\\n9 + h) · h\\n= lim\\nh→0\\n9 − (9 + h)\\n9\\n√\\n9 + h · h + 3 · (9 + h) · h\\n= − 1\\n9 · 3 + 3 · 9\\n= − 1\\n54\\n\\x04\\nSOL-103 \\uf14b CH.SOL- 5.4.\\n1. The function g(x) = 2 x2 − x + 1 represents the expression graph depicted in 5.4.\\n148Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. By the deﬁnition:\\nf ′(x) = lim\\nh→0\\nf (x + h) − f (x)\\nx + h − x\\n= lim\\nh→0\\n2(x + h)2 − (x + h) + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2(x2 + 2xh + h2) − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2x2 + 4xh + 2h2 − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n4xh + 2h2 − h\\nh\\n= lim\\nh→0\\n4x + 2h − 1\\n= 4x − 1.\\n(5.31)\\nf (x) = 2 x2 − x + 1\\nf ′(x) = 4 x − 1\\n\\x04\\n5.3.4 The chain rule\\nSOL-104 \\uf14b CH.SOL- 5.5.\\n1. The chain rule states that the partial derivative of E = E(x, y) with respect to x can be\\ncalculated via another variable y = y(x), as follows:\\n∂E\\n∂x = ∂E\\n∂y · ∂y\\n∂x (5.'),\n",
              " Document(metadata={}, page_content=' + 4xh + 2h2 − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n4xh + 2h2 − h\\nh\\n= lim\\nh→0\\n4x + 2h − 1\\n= 4x − 1.\\n(5.31)\\nf (x) = 2 x2 − x + 1\\nf ′(x) = 4 x − 1\\n\\x04\\n5.3.4 The chain rule\\nSOL-104 \\uf14b CH.SOL- 5.5.\\n1. The chain rule states that the partial derivative of E = E(x, y) with respect to x can be\\ncalculated via another variable y = y(x), as follows:\\n∂E\\n∂x = ∂E\\n∂y · ∂y\\n∂x (5.32)\\n2. For instance, the chain rule [ 8] is applied in neural networks to calculate the change in\\n1495.3. SOLUTIONS\\nits weights resulting from tuning the cost function. This derivative is calculated via a\\nchain of partial derivatives (e.g. of the activation functions).\\n\\x04\\n5.3.5 Taylor series expansion\\nSOL-105 \\uf14b CH.SOL- 5.6.\\n1.\\n1\\n1 − x =\\n∞∑\\nn=0\\nxn = 1 + x + x2 + x3\\n(when −1 < x < 1) (5.33)\\n2.\\nex =\\n∞∑\\nn=0\\nxn\\nn! = 1 + x + x2\\n2! + x3\\n3! + · · · (5.34)\\n3.\\nsin x =\\n∞∑\\nn=0\\n(−1)n\\n(2n + 1)! x2n+1 = x − x3\\n3! + x5\\n5! − · · · (5.35)\\n4.\\ncos x =\\n∞∑\\nn=0\\n(−1)n\\n(2n)! x2n = 1 − x2\\n2! + x4\\n4! − · · · (5.36)\\n\\x04\\nSOL-106 \\uf14b CH.SOL- 5.7.\\n150Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nlog x =\\n∞∑\\nn=1\\n(−1)n+1 (x − 1)n\\nn = (x − 1) − (x − 1)2\\n2 +\\n(x − 1)3\\n3 − (x − 1)4\\n4 + · · ·\\n(5.37)\\n\\x04\\nSOL-107 \\uf14b CH.SOL- 5.8.\\nIn this case, all derivatives can be computed:\\nf 0(x) = 5 x2 − 11x + 1,\\nf 0(−3) = 79 ,\\nf 1(x) = 10 x − 11,\\nf 1(−3) = −41,\\nf 2(x) = 10 ,\\nf 2(−3) = 10 ,\\nf n(x) = 0, ∀n ≥ 3.\\n(5.38)\\n\\x04\\nSOL-108 \\uf14b CH.SOL- 5.9.\\nThe immediate answer is 1. Refer to eq. 5.36 to verify this logical consequence. \\x04\\nSOL-109 \\uf14b CH.SOL- 5.10.\\nBy employing eq. 5.37, one can substitute x by 3 − x and generate the ﬁrst 7 terms of the\\nx-dependable outcome before assigning the point x = 1.\\n\\x04\\n5.3.6 Limits and continuity\\nSOL-110 \\uf14b CH.SOL- 5.11.\\n1515.3. SOLUTIONS\\n1. With an indeterminate form 0/0, L’Hopital’s rule holds. We look at\\nlim\\nx→3\\n3x2ex3\\n3 = 9e27,\\nwhich equals to the original limit.\\n2. Again, we yield 0/0 at interim, so we look at the ﬁrst order derivative\\nlim\\nx→0\\n2xex − 1\\n−3 sin x − 1 = 1.\\nThe original limit is also equal to 1.\\n3. This time, the intermediate form is of ∞/∞ and L’Hopital applies as well. The quotient\\nof the derivatives is\\n1 − 1\\nx\\n0.01x−99/100 = 100(x − 1)x1/99\\nAs x → ∞, this goes to ∞, so the original limit is equal to ∞ also.\\n\\x04\\n5.3.7 Partial derivatives\\nSOL-111 \\uf14b CH.SOL- 5.12.\\n1. T rue.\\n2. By treating y as constant, one can derive that\\n∂g\\n∂x = 2xy + y. (5.39)\\n\\x04\\nSOL-112 \\uf14b CH.SOL- 5.13.\\n152Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1.\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j\\n=\\n(\\ny2 + 3x2\\n)\\ni + (2xy − 2y) j\\n(5.40)\\n2. It can be shown that ∇g(x, y) = (2 xy + y2) i + (x2 + 2xy − 1) j at (−1, 0) equals\\n(0, 0). According to the deﬁnition of directional derivative:\\n(0, 0) · (1, 1)\\n|(1, 1)| = 0 (5.41)\\n\\x04\\nSOL-113 \\uf14b CH.SOL- 5.14.\\n∂f\\n∂x = 6 sin(x − y) cos(x − y)\\n∂f\\n∂y = −6 sin(x − y) cos(x − y)\\n(5.42)\\n\\x04\\nSOL-114 \\uf14b CH.SOL- 5.15.\\n∂z\\n∂x = 2 cos x sin y\\n∂z\\n∂y = 2 sin x cos y\\n(5.43)\\n\\x04\\n5.3.8 Optimization\\nSOL-115 \\uf14b CH.SOL- 5.16.\\n1535.3. SOLUTIONS\\n1. The function is only deﬁned where x ̸= −2, in the domain of:\\n(−∞, −2) ∪ (−2, +∞).\\n2. By a simple quotient-based derivation:\\nf ′(x) = 2(x + 2)(2x − 1)\\n(x + 2)4 . (5.44)\\nNamely, expect for the ill-deﬁned x = −2, the critical point of x = 0 .5 should be\\nconsidered. For x > 0.5, the derivative is positive and the function increases, in contrast\\nto x < 0.5.\\n3. The requested coordinate is (0.5, 0.2).\\n\\x04\\nSOL-116 \\uf14b CH.SOL- 5.17.\\n1. f ′(x) = 6 x2 − 1, which entails the behavior of the function changes around the points\\nx = ± 1√\\n6. The derivative is negative between x = − 1√\\n6 and x = 1√\\n6, i.e., it decreases\\nin the domain, and increases otherwise.\\n2. The second derivative is f ′′(x) = 12 x, which means the function is concave for negative\\nx values and convex otherwise.\\n\\x04\\nSOL-117 \\uf14b CH.SOL- 5.18.\\nThe function should be derived according to each variable separately and be equated to 0,\\nas follows:\\nfx(x, y) = 4 x − y = 0 , f y(x, y) = −y + 2y = 0 .\\nSo, the solution to these equations yield the coordinate (0, 0), and f (0, 0) = 0 .\\nLet us derive the second order derivative, as follows:\\n∂2f\\n∂x2 (x, y) = 4 , ∂2f\\n∂y2 (x, y) = 2 , ∂2f\\n∂x∂y (x, y) = −1 ,\\n154Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nAlso, the following relation exists:\\nD(x, y) = ∂2f\\n∂x2\\n∂2f\\n∂y2 −\\n(\\n∂2f\\n∂x∂y\\n) 2\\n= 7 ,\\nThus, the critical point (0, 0) is a minimum. \\x04\\n5.3.9 The Gradient descent algorithm\\nSOL-118 \\uf14b CH.SOL- 5.19.\\n1. It is the gradient of a function which is mathematically represented by:\\n∇f (x, y) =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\n∂f (x,y)\\n∂x\\n∂f (x,y)\\n∂y\\n\\uf8f6\\n\\uf8f7\\uf8f8 (5.45)\\n2. Increasing.\\n3. We will keep jumping between the same two points without ever reaching a minima.\\n4. This phenomena can be alleviated by using a learning rate or step size . For instance,\\nx+ = 2 ∗ η where η is a learning rate with small value such as η = 0.25.\\n5. T rue.\\n\\x04\\nSOL-119 \\uf14b CH.SOL- 5.20.\\n1. The point (12,12) has two classes, so the classes cannot be separated by any line.\\n2.\\nJ(θ) = 1\\n2m\\nm∑\\ni=1\\n(ˆyi − yi)2\\n(5.46)\\n1555.3. SOLUTIONS\\n3. Simple but fundamental algorithm for minimizing f . Just repeatedly move in the direc-\\ntion of the negative gradient\\n(a) Start with initial guess θ(0), step size η\\n(b) For k = 1, 2, 3, . . .:\\ni. Compute the gradient ∇f (θ(k−1))\\nii. Check if gradient is close to zero; is so stop, otherwise continue\\niii. Update θ(k) = θ(k−1) − η∇f (θ(k−1))\\n(c) Return ﬁnal θ(k) as approximate solution θ∗\\n\\x04\\n5.3.10 The Backpropagation algorithm\\nSOL-120 \\uf14b CH.SOL- 5.21.\\n1. The annotated parts of equation (5.21) appear in (5.47):\\nσ(x) = ex\\n1 + ex = The Sigmoid activation function\\nσ(x) ·\\n(\\n1 − σ(x)\\n)\\nThe deriviative of the Sigmoid activation function =\\n1Z = The input\\ndZ = The error introduced by input Z.\\nA = The output\\ndA = The error introduced by output A.\\n(5.47)\\n2. Code snippet 5.13 provides an implementation of both the forward and backward passes\\nfor the sigmoid function.\\n156Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5\\n6 def backward(self, grad):\\n7 grad_input = self.x*(1-self.x) * grad\\n8 return grad_input\\nFIGURE 5.13: Forward and backward passes for the sigmoid activation function in pure\\nPython.\\n\\x04\\nSOL-121 \\uf14b CH.SOL- 5.22.\\nThe key concept in this question is merely understanding that the transfer function and\\nits derivatives are changing compared to traditional activation functions, namely:\\n∂E\\n∂yk\\n= (yk − dk) (5.48)\\n∂E\\n∂netk\\n= ∂E\\n∂yk\\n· ∂yk\\n∂netk\\n= (yk − dk) · 2 cos(2netk) (5.49)\\n∆wjk = −η ∂E\\n∂wjk\\n= −η ∂E\\n∂netk\\n· ∂netk\\n∂wjk\\n= −η · (yk − dk) · 2 cos(2netk) · yj (5.50)\\n∂E\\n∂yj\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\n· ∂netk\\n∂yj\\n)\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\nwjk\\n)\\n(5.51)\\n∂E\\n∂netj\\n= ∂E\\n∂yj\\n· ∂yj\\n∂netj\\n= ∂E\\n∂yj\\n· 3net2\\nj (5.52)\\n1575.3. SOLUTIONS\\n∆wij = −η ∂E\\n∂wij\\n= −η ∂E\\n∂netj\\n· ∂netj\\n∂wij\\n= −η · (∑\\nk [(yk − dk) · 2 cos(2netk) · wjk]) · 3net2\\nj · yi\\n(5.53)\\n\\x04\\n5.3.11 Feed forward neural networks\\n5.3.12 Activation functions, Autograd/JAX\\nSOL-122 \\uf14b CH.SOL- 5.23.\\n1. T rue.\\n2. T rue.\\n\\x04\\nSOL-123 \\uf14b CH.SOL- 5.24.\\nThe answers are as follows:\\n1. hΘ(x) = g(ΘT x) = 1\\n1+e−Θ\\nT\\nx\\n.\\n2. The decision boundary for the logistic sigmoid function is where hΘ(x) = 0 .5 (values\\nless than 0.5 mean false, values equal to or more than 0.5 mean true).\\n3. That there is a 80% chance that the instance is of the corresponding class, therefore:\\n• hΘ(x) = g(Θ0 + Θ1x1 + Θ2x2). We can predict y = 1 if x0 + x1 + x2 ≥ 0.\\n4. The code snippet in 5.14 implements the function using Autograd.\\n158Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 from torch.autograd import Function\\n2 class Sigmoid(Function):\\n3 @staticmethod\\n4 def forward(ctx, x):\\n5 output = 1 / (1 + torch.exp(-x))\\n6 ctx.save_for_backward(output)\\n7 return output\\n8\\n9 @staticmethod\\n10 def backward(ctx, grad_output):\\n11 output, = ctx.saved_tensors\\n12 grad_x = output * (1 - output) * grad_output\\n13 return grad_x\\nFIGURE 5.14: Forward and backward for the sigmoid function in Autograd.\\n5. The code snippet in 5.15 implements the function using Autograd.\\n1595.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ReLU(torch.autograd.Function):\\n3 @staticmethod\\n4 def forward(ctx, input):\\n5 ctx.save_for_backward(input)\\n6 return input.clamp(min=0)\\n7\\n8 @staticmethod\\n9 def backward(ctx, grad_output):\\n10 input, = ctx.saved_tensors\\n11 grad_input = grad_output.clone()\\n12 grad_input[input < 0] = 0\\n13 return grad_input\\nFIGURE 5.15: Forward and backward for the ReLU function in Autograd.\\n\\x04\\nSOL-124 \\uf14b CH.SOL- 5.25. The answers are as follows:\\n1. Code snippet 5.16 implements the forward pass using pure Python.\\n160Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n3 requires_grad=True)).type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 arctanh_values = np.arctanh(xT_np)\\n7 print (\"Numpy:\", arctanh_values)\\n8 > Numpy: [[ 0.38842311 0.1944129 0.64900533]]\\nFIGURE 5.16: Forward pass for equation ( 5.23) using pure Python.\\n2. Code snippet 5.17 implements the forward pass using Autograd.\\n1 import torch\\n2 from torch.autograd import Function\\n3 class ArtanhFunction(Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward(x)\\n7 r = (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5)\\n8 return r\\nFIGURE 5.17: Forward pass for equation ( 5.23).\\n3. Code snippet 5.18 implements the backward pass using Autograd.\\n1615.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ArtanhFunction(Function):\\n3 @staticmethod\\n4 input, = ctx.saved_tensors\\n5 out= grad_output / (1 - input ** 2)\\n6 print (\"backward:{}\".format(out))\\n7 return out\\nFIGURE 5.18: Backward pass for equation ( 5.23).\\n4. Code snippet 5.19 veriﬁes the correctness of the implementation using gradcheck.\\n1 import numpy as np\\n2\\n3 xT =\\ntorch.abs(torch.tensor([[0.11,0.19,0.57]],requires_grad=True))↪→\\n4 .type(torch.DoubleTensor)\\n5 arctanh_values_torch = arctanhPyTorch(xT)\\n6 print (\"Torch:\", arctanh_values_torch)\\n7 from torch.autograd import gradcheck, Variable\\n8 f = ArtanhFunction.apply\\n9 test=gradcheck(lambda t: f(t), xT)\\n10 print(test)\\n11\\n12 > PyTorch version: 1.7.0\\n13 > Torch: tensor([[ 0.3884, 0.1944, 0.6490]], dtype =torch.float64,\\n14 > grad_fn=<ArtanhFunctionBackward>)\\n15 > backward:tensor([[1.1586, 1.0383,1.4838]], dtype =torch.float64,\\n16 grad_fn=<CopyBackwards>)\\nFIGURE 5.19: Invoking arctanh using gradcheck\\n162Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n\\x04\\n5.3.13 Dual numbers in AD\\nSOL-125 \\uf14b CH.SOL- 5.26.\\nThe answers are as follows:\\n1. The procedure of AD is to use verbatim text of a computer program which calculates\\na numerical value and to transform it into the text of a computer program called the\\ntransformed program which calculates the desired derivative values. The transformed\\ncomputer program carries out these derivative calculations by repeated use of the chain\\nrule however applied to actual ﬂoating point values rather than to a symbolic rep-\\nresentation.\\n2. Dual numbers extend all numbers by adding a second component x ↦→ x + ˙xd where\\nx + ˙x is the dual part.\\n3. The following arithmetic operations are possible on DN:\\n(a) d2 = 0\\n(b) (x + ˙xd) + (y + ˙yd) = x + y + ( ˙x + ˙y)d\\n(c) −(x + ˙xd) = −x − ˙xd\\n(d) 1\\nx+ ˙xd = 1\\nx − ˙x\\nx2 d\\n4. For f (x + ˙xd) the T aylor series expansion is:\\nf (x + ˙xd) = f (x) + f ′(x)\\n1! ˙xd + . . .0 (5.54)\\nThe immediate and important result is that all higher-order terms (n >= 2) disappear\\nwhich provides closed-form mathematical expression that represents a function and its\\nderivative.\\n\\x04\\nSOL-126 \\uf14b CH.SOL- 5.27.\\n1635.3. SOLUTIONS\\nThe answers are as follows:\\n1.\\nsin(x + ˙xd) = sin( x) + cos(x) ˙xd (5.55)\\n2. If we traverse the graph 5.9 from left to right we drive the following simple function:\\ng(x) = 3 ∗ x + 2 (5.56)\\n3. We know that:\\ng(x) = 3 ∗ x + 2 (5.57)\\ng′(x) = 3 (5.58)\\nNow if we expand the function using DN:\\ng(x + ˙xd) = 3 ∗ (x + ˙xd) + 2 = (5.59)\\n3 ∗ x + 3 ∗ ( ˙xd) + 2 (5.60)\\nRearranging:\\n3 ∗ x + 2 + 3 ∗ ( ˙xd) (5.61)\\nBut since g(x) = 3 ∗ x + 2 then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.62)\\n4. Evaluating the function g(x) at x = 2 using DN we get:\\ng(x = 2) = (3 ∗ 2 + 2) + (3) ˙xd = (5.63)\\n8 + (3) ˙xd (5.64)\\n5. The code snippet in 5.20 implements the function using Autograd.\\n164Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([2.0], dtype =float)\\n4 def f1(x):\\n5 return 3*x + 2\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 8.0\\n8 print(grad_f1(x)) # > 3.0\\nFIGURE 5.20: Autograd\\n\\x04\\nSOL-127 \\uf14b CH.SOL- 5.28. The answers are as follows:\\n1. If we traverse the graph 5.9 from left to right we drive the following function:\\ng(x) = 5 ∗ x2 + 4 ∗ x + 1 (5.65)\\n2. We know that:\\ng(x1) = 5 ∗ x2 + 4 ∗ x + 1 (5.66)\\ng′(x1) = 10 ∗ x1 + 4 (5.67)\\nNow if we expand the function using DN we get:\\ng(x + ˙xd) = 5 ∗ (x + ˙xd)2 + 4 ∗ (x + ˙xd) + 1 = (5.68)\\n5 ∗ (x2 + 2 ∗ x + ˙xd + ( ˙xd)2) + 4 ∗ x + 4 ∗ ( ˙xd) + 1 (5.69)\\n1655.3. SOLUTIONS\\nHowever by deﬁnition (d2) = 0 and therefore that term vanishes. Rearranging the\\nterms:\\n(5 ∗ x2 + 4 ∗ x + 1) + (10 ∗ x + 4) ˙xd (5.70)\\nBut since g(x) = (5 ∗ x2 + 4 ∗ x + 1) then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.71)\\n3. Evaluating the function g(x) at x = 5 using DN we get:\\ng(x = 4) = (5 ∗ 52 + 4 ∗ 5 + 1) + (10 ∗ 5 + 4) ˙xd =\\n146 + (54) ˙xd (5.72)\\n4. The code snippet in 5.21 implements the function using Autograd.\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([5.0], dtype =float)\\n4 def f1(x):\\n5 return 5*x**2 + 4*x +1\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 146.0\\n8 print(grad_f1(x)) # > 54.0\\nFIGURE 5.21: Autograd\\n\\x04\\n5.3.14 Forward mode AD\\nSOL-128 \\uf14b CH.SOL- 5.29.\\nThe answers are as follows:\\n166Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The function g(x) represented by the expression graph in 5.11 is:\\ng(x) = A + B ∗ ln(C) (5.73)\\n2. For a logarithmic function:\\nd\\ndx ln(x) = 1\\nx (5.74)\\nTherefore, the partial derivatives for the function g(x) are:\\n∂f\\n∂A = 1\\n∂f\\n∂B = ln(C)\\n∂f\\n∂C = B ∗ 1\\nC\\n(5.75)\\n\\x04\\nSOL-129 \\uf14b CH.SOL- 5.30. The answers are as follows:\\n1. T rue. Both directions yield the exact same results.\\n2. T rue. Reverse mode is more efﬁcient than forward mode AD (why?).\\n3. T rue.\\n4. T rue.\\n\\x04\\nSOL-130 \\uf14b CH.SOL- 5.31.\\nThe answers are as follows:\\n1675.3. SOLUTIONS\\n1. The function is\\nf (x1, x2) = x1x2 + ln (x1) (5.76)\\n2. The graph associated with the forward mode AD is as follows:\\nx1\\nx2\\n*\\n+\\nln\\nf (x1, x2)\\nFIGURE 5.22: A Computation graph for g(x1, x2) in 5.1\\n3. The partial derivatives are:\\n∂f\\n∂x1\\n= x2 − 1\\n(x1)\\n∂f\\n∂x2\\n= x1\\n(5.77)\\n\\x04\\n5.3.15 Forward mode AD table construction\\nSOL-131 \\uf14b CH.SOL- 5.32.\\nThe answers are as follows:\\n1. The graph with the intermediate values is depicted in ( 5.23)\\n168Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx1\\nx2\\n*\\n+\\nln\\ng(x1, x2)\\nv1\\nv2\\nv1 v4\\nv3\\nv5\\nFIGURE 5.23: A derivative graph for g(x1, x2) in 5.1\\n2. Forward mode AD for g (x1, x2) = ln ( x1) + x1x2 evaluated at (x1, x2) = ( e2, π).\\nForward-mode function evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\nv1 = ln v−1 = ln (e2) = 2\\nv2 = v−1 × v0 = e2 × π = 23.2134\\nv3 = v1 + v2 2 + 23.2134 = 25 .2134\\nf = v3 =≈ 25.2134\\nTABLE 5.1: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n3. The following Python code ( 5.24) proves that the numerical results are correct:\\n1695.3. SOLUTIONS\\n1 import math\\n2 print (math.log(math.e*math.e) + math.e*math.e*math.pi)\\n3 > 25.2134^^I\\nFIGURE 5.24: Python code- AD of the function g(x1, x2)\\n4. Seed values indicate the values by which the dependent and independent variables are\\ninitialized to before being propagated in a computation graph. For instance:\\n˙v1 = ∂x1\\n∂x1\\n= 1\\n˙v2 = ∂x2\\n∂x1\\n= 0\\nTherefore we set ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n5. Here we construct a table for the forward-mode AD for the derivative of f (x1, x2) =\\nln (x1) + x1x2 evaluated at (x1, x2) = ( e2, π) while setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.. In\\nforward-mode AD a derivative is called a tangent.\\nIn the derivation that follows, note that mathematically using manual differentiation:\\nd\\ndx1\\n[ln(x) + x2x]\\n= d\\ndx1\\n[ln(x1)] + x2 · d\\ndx1\\n[x1]\\n= 1\\nx1\\n+ x2 · 1\\n= 1\\nx1\\n+ x2\\nand also since d\\ndx ln(x) = 1\\nx then ˙v1 = 1\\nv−1\\n∗ ˙v−1 = ˙v−1/v−1 = 1\\ne2 ∗ 1 = 1 /e2.\\n170Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nForward-mode AD derivative evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\n˙v−1 = ˙x1 = 1\\n˙v0 = ˙x2 = 0\\n˙v1 = ˙v−1/v−1 = 1/e2\\n˙v2 = ˙v−1 × v0 + ˙v0 ×\\nv−1 = 1 × π + 0 ×\\ne2 = π\\n˙v4 = ˙v1 + ˙v2 = 1/e2 +\\nπ\\n˙f = ˙v4 = 1 /e2 +\\nπ =≈ 3.2769\\nTABLE 5.3: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute ∂y\\n∂x1\\n.\\n6. The following Python code ( 5.25) proves that the numerical results are correct:\\n1715.3. SOLUTIONS\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 import math\\n4\\n5 x1 = math.e* math.e\\n6 x2 = math.pi\\n7\\n8 def f1(x1,x2):\\n9 return (np.log(x1) + x1*x2)\\n10\\n11 grad_f1 = grad(f1)\\n12\\n13 print(f1(x1,x2)) # > 25.2134\\n14 print(grad_f1(x1,x2)) # > 3.2769\\nFIGURE 5.25: Python code- AD of the function g(x1, x2)\\n\\x04\\n5.3.16 Symbolic differentiation\\n5.3.17 Simple differentiation\\nSOL-132 \\uf14b CH.SOL- 5.33.\\nThe answers are as follows:\\n1. Approximate methods such as numerical differentiation suffer from numerical instabil-\\nity and truncation errors.\\n2. In symbolic differentiation, a symbolic expression for the derivative of a function is\\ncalculated. This approach is quite slow and requires symbols parsing and manipulation.\\nFor example, the number\\n√\\n2 is represented in SymPy as the object Pow(2,1/2). Since\\nSymPy employees exact representations Pow(2,1/2)*Pow(2,1/2) will always equal 2.\\n\\x04\\n172Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nSOL-133 \\uf14b CH.SOL- 5.34.\\n1. First:\\n1 import sympy\\n2 sympy.init_printing()\\n3 from sympy import Symbol\\n4 from sympy import diff, exp, sin, sqrt\\n5 y = Symbol(\\'y\\' )\\n6 y = sympy.Symbol(\"y\")\\n7 sigmoid = 1/(1+sympy.exp(-y))^^I\\nFIGURE 5.26: Sigmoid in SymPy\\n2. Second:\\n1 sig_der=sym.diff(sigmoid, y)\\nFIGURE 5.27: Sigmoid gradient in SymPy\\n3. Third:\\n1 sig_der.evalf(subs={y:0})\\n2 > 0.25\\nFIGURE 5.28: Sigmoid gradient in SymPy\\n1735.3. SOLUTIONS\\n4. The plot is depicted in 5.29.\\n1 p = sym.plot(sig_der);\\n10.0\\n 7.5\\n 5.0\\n 2.5\\n 0.0 2.5 5.0 7.5 10.0\\ny\\n0.00\\n0.05\\n0.10\\n0.15\\n0.20\\n0.25f(y)\\nFIGURE 5.29: SymPy gradient of the Sigmoid() function\\n\\x04\\n5.3.18 The Beta-Binomial model\\nSOL-134 \\uf14b CH.SOL- 5.35.\\nT o correctly render the generated LaT eX in this problem, we import and conﬁgure several\\nlibraries as depicted in 5.30.\\n174Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 import scipy.stats as st\\n3 import matplotlib.pyplot as plt\\n4 import sympy as sp\\n5 sp.interactive.printing.\\n6 init_printing(use_latex=True)\\n7 from IPython.display import display, Math, Latex\\n8 maths = lambda s: display(Math(s))\\n9 latex = lambda s: display(Latex(s)) ^^I\\nFIGURE 5.30: SymPy imports\\n1. The Likelihood function can be created as follows. Note the speciﬁc details of generating\\nthe Factorial function in SymPy.\\n1755.3. SOLUTIONS\\n1 n = sp.Symbol(\\'n\\' , integer =True, positive =True)\\n2 r = sp.Symbol(\\'r\\' , integer =True, positive =True)\\n3 theta = sp.Symbol(\\'theta\\' )\\n4 # Create the function symbolically\\n5 from sympy import factorial\\n6 cNkSym= (factorial(n))/ (factorial(r) *factorial(n-r))\\n7 cNkSym.evalf()\\n8 binomSym= cNkSym*((theta **r)*(1-theta)**(n-r))\\n9 binomSym.evalf()\\n10 #Convert it to a Numpy-callable function\\n11 binomLambda = sp.Lambda((theta,r,n), binomSym)\\n12 maths(r\"\\\\operatorname{Bin}(r|n,\\\\theta) = \" )\\n13 display (binomLambda .expr)\\n14 #Evaluating the SymPy version results in:\\n15 > binomSym.subs({theta:0.5,r:50,n:100})\\n16 #Evaluating the pure Numpy version results in:\\n17 > binomLambda(0.5,50,100)= 0.07958923\\nFIGURE 5.31: Likelihood function using SymPy\\nThe Symbolic representation results in the following LaT eX:\\nBin(r|n, θ) = θr (−θ + 1)n−r n!\\nr! (n − r)! (5.78)\\n2. The Beta distribution can be created as follows.\\n176Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 #mu = sp.Symbol(\\'mu\\', integer=False, positive=True)\\n4 # Create the function symbolically\\n5 G = sp.gamma\\n6 # The normalisation factor\\n7 BetaNormSym = G(a + b)/(G(a)*G(b))\\n8 # The functional form\\n9 BetaFSym = theta**(a-1) * (1-theta)**(b-1)\\n10 BetaSym=BetaNormSym * BetaFSym\\n11 BetaSym.evalf() # this works\\n12 # Turn Beta into a function\\n13 BetaLambda = sp.Lambda((theta,a,b), BetaNormSym * BetaFSym)\\n14 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) = \" )\\n15 display(BetaSym)\\n16 #Evaluating the SymPy version results in:\\n17 > BetaLambda(0.5,2,7)=0.4375\\n18 #Evaluating the pure Numpy version results in:\\n19 > BetaSym.subs({theta:0.5,a:2,b:7})=0.4375\\nFIGURE 5.32: Beta distribution using SymPy\\nThe result is:\\nBeta(θ|a, b) = θa−1Γ(a + b)\\nΓ(a)Γ(b) (−θ + 1)b−1 (5.79)\\n3. The plot is depicted in 5.33.\\n1775.3. SOLUTIONS\\n1 %pylab inline\\n2 mus = arange(0,1,.01)\\n3 # Plot for various values of a and b\\n4 for ab in [(.1,.1),(.5,.5),(2,20),(2,3), ( 1,1)]:\\n5 plot(mus, vectorize(BetaLambda)(mus, *ab), label =\"a=%s b=%s\" % ab)\\n6 legend(loc=0)\\n7 xlabel(r\"$\\\\theta$\", size =22)\\nFIGURE 5.33: A plot of the Beta distribution\\n4. We can ﬁnd the posterior distribution by multiplying our Beta prior by the Binomial\\nLikelihood.\\n178Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 BetaBinSym=BetaSym * binomSym\\n4 # Turn Beta-bin into a function\\n5 BetaBinLambda = sp.Lambda((theta,a,b,n,r), BetaBinSym)\\n6 BetaBinSym=BetaBinSym.powsimp()\\n7 display(BetaBinSym)\\n8 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) \\\\times\\n\\\\operatorname{Bin}(r|n,\\\\theta) \\\\propto %s\" %\\nsp.latex(BetaBinSym))\\n↪→\\n↪→\\n9 > BetaBinSym.subs({theta:0.5,a:2,b:7,n:10,r:3})= 0.051269\\n10 > BetaBinLambda ( 0.5,2,7, 10,3)= 0.051269\\nFIGURE 5.34: A plot of the Beta distribution\\nThe result is:\\nBeta(θ|a, b) × Bin(r|n, θ) ∝\\nθa+r−1 (−θ + 1)b+n−r−1 n!\\nr! (n − r)!Γ(a)Γ(b) Γ(a + b)\\nSo the posterior distribution has the same functional dependence on θ as the prior, it is\\njust another Beta distribution.\\n5. Mathematically, the relationship is as follows:\\n1795.3. SOLUTIONS\\nPrior :\\nBeta(θ|a = 2, b = 7)\\n= 56θ (−θ + 1)6\\nLikelihood :\\nBin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47\\nPosterior(normalised) :\\nBeta(θ|2, 7) × Bin(3|50, θ) = 1097600 θ4 (−θ + 1)53\\n(5.80)\\n180Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 prior = BetaLambda(theta,2,7)\\n2 maths(\"\\\\mathbf{Prior}:\\\\operatorname{Beta}(\\\\theta|a=2,b=7) = %s\" %\\nsp.latex(prior))↪→\\n3 likelihood = binomLambda(theta,3,50) # = binomLambda(0.5,3,10)\\n4 maths(\"\\\\mathbf{Likelihood}: \\\\operatorname{Bin}(r=3|n=6, \\\\theta) =\\n%s\" % sp.latex(likelihood))↪→\\n5 posterior = prior * likelihood\\n6 posterior=posterior.powsimp()\\n7 maths(r\"\\\\mathbf{Posterior\\n(normalised)}:\\\\operatorname{Beta}(\\\\theta|2,7) \\\\times\\n\\\\operatorname{Bin}(3|50,\\\\theta)=%s\"\\n↪→\\n↪→\\n8 posterior.subs({theta:0.5})\\n9 plt.plot(mus, (sp .lambdify(theta,posterior))(mus), \\'r\\' )\\n10 xlabel(\"$\\\\\\\\theta$\", size =22)\\nFIGURE 5.35: A plot of the Posterior with the provided data samples.\\n\\x04\\nReferences\\n[1] J. Bradbury et al. JAX: composable transformations of NumPy programs. 2018 (cit. on\\npp. 123, 136).\\n181REFERENCES\\n[2] W. K. Clifford. ‘Preliminary Sketch of Bi-quaternions’. In: Proceedings of the Lon-\\ndon Mathematical Society 4 (1873), pp. 381–95 (cit. on pp. 125, 139).\\n[3] R. Frostig et al. JAX: Autograd and XLA . 2018 (cit. on p. 123).\\n[4] A. Griewank, D. Juedes and J. Utke. ‘Algorithm 755; ADOL-C: a package for the\\nautomatic differentiation of algorithms written in C/C++’. In: ACM T ransactions\\non Mathematical Software 22.2 (June 1996), pp. 131–167 (cit. on pp. 123, 125).\\n[5] A. Griewank and A. Walther. Evaluating Derivatives: Principles and T echniques\\nof Algorithmic Differentiation . Second. USA: Society for Industrial and Applied\\nMathematics, 2008 (cit. on pp. 123, 124).\\n[6] K. Gurney. An Introduction to Neural Networks . 1 Gunpowder Square, London\\nEC4A 3DE, UK: UCL Press, 1998 (cit. on p. 135).\\n[7] L. V . Kantorovich. ‘On a mathematical symbolism convenient for performing\\nmachine calculations’. In: Dokl. Akad. Nauk SSSR . V ol. 113. 4. 1957, pp. 738–741\\n(cit. on p. 123).\\n[8] G. Kedem. ‘Automatic differentiation of computer programs’. In: ACM T ransac-\\ntions on Mathematical Software (TOMS) 6.2 (1980), pp. 150–165 (cit. on pp. 126,\\n149).\\n[9] S. Laue. On the Equivalence of Forward Mode Automatic Differentiation and Symbolic\\nDifferentiation. 2019. arXiv: 1904.02990 [cs.SC] (cit. on p. 124).\\n[10] D. Maclaurin, D. Duvenaud and R. P . Adams. ‘Autograd: Effortless gradients in\\nnumpy’. In: ICML 2015 AutoML Workshop . V ol. 238. 2015 (cit. on pp. 123, 136).\\n[11] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: (2017) (cit. on p. 136).\\n[12] D. Rumelhart, G. Hinton and R. Williams. ‘Learning representations by back\\npropagating errors’. In: Nature 323 (1986), pp. 533–536 (cit. on p. 135).\\n[13] B. Speelpenning. Compiling fast partial derivatives of functions given by algorithms .\\nTech. rep. Illinois Univ Urbana Dept of Computer Science, 1980 (cit. on p. 126).\\n182BACHELORS\\nPART IVCHAPTER\\n6\\nDEEP LEARNING: NN ENSEMBLES\\nThe saddest aspect of life right now is that gathers knowledge faster than society\\n'),\n",
              " Document(metadata={}, page_content='ML 2015 AutoML Workshop . V ol. 238. 2015 (cit. on pp. 123, 136).\\n[11] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: (2017) (cit. on p. 136).\\n[12] D. Rumelhart, G. Hinton and R. Williams. ‘Learning representations by back\\npropagating errors’. In: Nature 323 (1986), pp. 533–536 (cit. on p. 135).\\n[13] B. Speelpenning. Compiling fast partial derivatives of functions given by algorithms .\\nTech. rep. Illinois Univ Urbana Dept of Computer Science, 1980 (cit. on p. 126).\\n182BACHELORS\\nPART IVCHAPTER\\n6\\nDEEP LEARNING: NN ENSEMBLES\\nThe saddest aspect of life right now is that gathers knowledge faster than society\\ngathers wisdom.\\n— Isaac Asimov\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 2026.1. INTRODUCTION\\n6.1 Introduction\\nI\\nNtuition and practice demonstrate that a poor or an inferior choice may\\nbe altogether prevented merely by motivating a group (or an ensemble)\\nof people with diverse perspectives to make a mutually acceptable choice.\\nLikewise, in many cases, neural network ensembles signiﬁcantly improve\\nthe generalization ability of single-model based AI systems [ 5, 11]. Shortly follow-\\ning the foundation of Kaggle, research in the ﬁeld had started blooming; not only\\nbecause researchers are advocating and using advanced ensembling approaches in\\nalmost every competition, but also by the empirical success of the top winning mod-\\nels. Though the whole process of training ensembles typically involves the utilization\\nof dozens of GPUs and prolonged training periods, ensembling approaches enhance\\nthe predictive power of a single model. Though ensembling obviously has a signiﬁc-\\nant impact on the performance of AI systems in general, research shows its effect is\\nparticularly dramatic in the ﬁeld of neural networks [ Russakovsky_2015, 1, 4, 7, 13].\\nTherefore, while we could examine combinations of any type of learning algorithms,\\nthe focus of this chapter is the combination of neural networks.\\n6.2 Problems\\n6.2.1 Bagging, Boosting and Stacking\\nPRB-135 \\uf059 CH.PRB- 6.1.\\nMark all the approaches which can be utilized to boost a single model performance:\\n(i) Majority Voting\\n(ii) Using K-identical base-learning algorithms\\n(iii) Using K-different base-learning algorithms\\n(iv) Using K-different data-folds\\n(v) Using K-different random number seeds\\n(vi) A combination of all the above approaches\\n186Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nPRB-136 \\uf059 CH.PRB- 6.2.\\nAn argument erupts between two senior data-scientists regarding the choice of an ap-\\nproach for training of a very small medical corpus. One suggest that bagging is superior\\nwhile the other suggests stacking. Which technique, bagging or stacking, in your opinion is\\nsuperior? Explain in detail.\\n(i) Stacking since each classier is trained on all of the available data.\\n(ii) Bagging since we can combine as many classiﬁers as we want by training each on a\\ndifferent sub-set of the training corpus.\\nPRB-137 \\uf059 CH.PRB- 6.3.\\nComplete the sentence: A random forest is a type of a decision tree which utilizes [bag-\\nging/boosting]\\nPRB-138 \\uf059 CH.PRB- 6.4.\\nThe algorithm depicted in Fig. 6.1 was found in an old book about ensembling. Name the\\nalgorithm.\\n1876.2. PROBLEMS\\nAlgorithm 1: Algo 1\\nData: A set of training data, Q with N elements has been established\\nwhile K times do\\nCreate a random subset of N ′ data by sampling from Q containing the N\\nsamples;\\nN ′ < N ;\\nExecute algorithm Algo 2;\\nReturn all N ′ back to Q\\nAlgorithm 2: Algo 2\\nChoose a learner hm;\\nwhile K times do\\nPick a training set and train with hm;\\nFIGURE 6.1: A speciﬁc ensembling approach\\nPRB-139 \\uf059 CH.PRB- 6.5.\\nFig. 6.2 depicts a part of a speciﬁc ensembling approach applied to the models x1, x2...xk.\\nIn your opinion, which approach is being utilized?\\nGenerelizerx3\\nx2\\nx1\\n...\\nxk\\nBase Learners\\nf\\n?\\nFIGURE 6.2: A speciﬁc ensembling approach\\n(i) Bootstrap aggregation\\n(ii) Snapshot ensembling\\n(iii) Stacking\\n188Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n(iv) Classical committee machines\\nPRB-140 \\uf059 CH.PRB- 6.6.\\nConsider training corpus consisting of balls which are glued together as triangles, each\\nof which has either 1, 3, 6, 10, 15, 21, 28, 36, or 45 balls.\\n1. We draw several samples from this corpus as presented in Fig. 6.3 wherein each sample\\nis equiprobable. What type of sampling approach is being utilized here?\\nFIGURE 6.3: Sampling approaches\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n2. Two samples are drawn one after the other. In which of the following cases is the\\ncovariance between the two samples equals zero?\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n3. During training, the corpus sampled with replacement and is divided into several\\nfolds as presented in Fig. 6.4.\\nT1:\\nT2:\\nT3:\\nT4:\\nFIGURE 6.4: Sampling approaches\\n1896.2. PROBLEMS\\nIf 10 balls glued together is a sample event that we know is hard to correctly classify,\\nthen it is impossible that we are using:\\n(i) Bagging\\n(ii) Boosting\\n6.2.2 Approaches for Combining Predictors\\nPRB-141 \\uf059 CH.PRB- 6.7.\\nThere are several methods by which the outputs of base classiﬁers can be combined to\\nyield a single prediction. Fig. 6.5 depicts part of a speciﬁc ensembling approach applied to\\nseveral CNN model predictions for a labelled data-set. Which approach is being utilized?\\n(i) Majority voting for binary classiﬁcation\\n(ii) Weighted majority voting for binary classiﬁcation\\n(iii) Majority voting for class probabilities\\n(iv) Weighted majority class probabilities\\n(v) An algebraic weighted average for class probabilities\\n(vi) An adaptive weighted majority voting for combining multiple classiﬁers\\n190Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 l = []\\n2 for i,f in enumerate(filelist):\\n3 temp = pd.read_csv(f)\\n4 l.append(temp)\\n5 arr = np.stack(l,axis=-1)\\n6 avg_results = pd.DataFrame(arr[:,:-1,:].mean(axis=2))\\n7 avg_results[\\'image\\' ] = l[0][\\'image\\' ]\\n8 avg_results.columns = l[0].columns\\nFIGURE 6.5: PyTorch code snippet for an ensemble\\nPRB-142 \\uf059 CH.PRB- 6.8.\\nRead the paper Neural Network Ensembles [3] and then complete the sentence: If the\\naverage error rate for a speciﬁc instance in the corpus is less than [...]% and the respective\\nclassiﬁers in the ensemble produce independent [...], then when the number of classiﬁers\\ncombined approaches inﬁnity, the expected error can be diminished to zero.\\nPRB-143 \\uf059 CH.PRB- 6.9.\\nTrue or false: A perfect ensemble comprises of highly correct classiﬁers that differ as\\nmuch as possible.\\nPRB-144 \\uf059 CH.PRB- 6.10.\\nTrue or false: In bagging, we re-sample the training corpus with replacement and there-\\nfore this may lead to some instances being represented numerous times while other instances\\nnot to be represented at all.\\n6.2.3 Monolithic and Heterogeneous Ensembling\\nPRB-145 \\uf059 CH.PRB- 6.11.\\n1916.2. PROBLEMS\\n1. True or false: T raining an ensemble of a single monolithic architecture results in\\nlower model diversity and possibly decreased model prediction accuracy.\\n2. True or false: The generalization accuracy of an ensemble increases with the number\\nof well-trained models it consists of.\\n3. True or false: Bootstrap aggregation (or bagging), refers to a process wherein a CNN\\nensemble is being trained using a random subset of the training corpus.\\n4. True or false: Bagging assumes that if the single predictors have independent errors,\\nthen a majority vote of their outputs should be better than the individual predictions.\\nPRB-146 \\uf059 CH.PRB- 6.12.\\nRefer to the papers: Dropout as a Bayesian Approximation [2] and Can Y ou Trust\\nY our Model’s Uncertainty? [12] and answer the following question: Do deep ensembles\\nachieve a better performance on out-of-distribution uncertainty benchmarks compared with\\nMonte-Carlo (MC)-dropout?\\nPRB-147 \\uf059 CH.PRB- 6.13.\\n1. In a transfer-learning experiment conducted by a researcher, a number of ImageNet-\\npretrained CNN classiﬁers, selected from T able 6.1 are trained on ﬁve different folds\\ndrawn from the same corpus. Their outputs are fused together producing a composite\\nmachine. Ensembles of these convolutional neural networks architectures have been\\nextensively studies an evaluated in various ensembling approaches [ 4, 9]. Is it likely\\nthat the composite machine will produce a prediction with higher accuracy than that\\nof any individual classiﬁer? Explain why.\\n192Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nCNN Model Classes Image Size Top-1 accuracy\\nResNet152 1000 224 78.428\\nDPN98 1000 224 79.224\\nSeNet154 1000 224 81.304\\nSeResneXT101 1000 224 80.236\\nDenseNet161 1000 224 77.560\\nInceptionV4 1000 299 80.062\\nTABLE 6.1: ImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches.\\n2. True or False: In a classiﬁcation task, the result of ensembling is always superior.\\n3. True or False: In an ensemble, we want differently trained models converge to differ-\\nent local minima.\\nPRB-148 \\uf059 CH.PRB- 6.14.\\nIn committee machines, mark all the combiners that do not make direct use of the input:\\n(i) A mixture of experts\\n(ii) Bagging\\n(iii) Ensemble averaging\\n(iv) Boosting\\nPRB-149 \\uf059 CH.PRB- 6.15.\\nTrue or False: Considering a binary classiﬁcation problem ( y = 0 or y = 1 ), ensemble\\naveraging, wherein the outputs of individual models are linearly combined to produce a fused\\noutput is a form of a static committee machine.\\n1936.2. PROBLEMS\\nMn\\nM2\\nM1\\n∑\\nwn\\nw2\\nw1\\n0\\n1\\n0\\n1\\nFIGURE 6.6: A typical binary classiﬁcation problem.\\nPRB-150 \\uf059 CH.PRB- 6.16.\\nTrue or false: When using a single model, the risk of overﬁtting the data increases when\\nthe number of adjustable parameters is large compared to cardinality (i.e., size of the set) of\\nthe training corpus.\\nPRB-151 \\uf059 CH.PRB- 6.17.\\nTrue or false:If we have a committee of K trained models and the errors are uncorrelated,\\nthen by averaging them the average error of a model is reduced by a factor of K.\\n6.2.4 Ensemble Learning\\nPRB-152 \\uf059 CH.PRB- 6.18.\\n1. Deﬁne ensemble learning in the context of machine learning.\\n2. Provide examples of ensemble methods in classical machine-learning.\\n3. True or false: Ensemble methods usually have stronger generalization ability.\\n4. Complete the sentence: Bagging is variance/bias reduction scheme while boosting\\nreduced variance/bias.\\n194Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n6.2.5 Snapshot Ensembling\\nPRB-153 \\uf059 CH.PRB- 6.19.\\nY our colleague, a well-known expert in ensembling methods, writes the following pseudo\\ncode in Python shown in Fig. 6.7 for the training of a neural network. This runs inside a\\nstandard loop in each training and validation step.\\n1 import torchvision.models as models\\n2 ...\\n3 models = [\\'resnext\\' ]\\n4 for m in models:\\n5 train ...\\n6 compute VAL loss ...\\n7 amend LR ...\\n8 if (val_acc > 90.0):\\n9 saveModel()\\nFIGURE 6.7: PyTorch code snippet for an ensemble\\n1. What type of ensembling can be used with this approach? Explain in detail.\\n2. What is the main advantage of snapshot ensembling? What are the disadvantages, if\\nany?\\nPRB-154 \\uf059 CH.PRB- 6.20.\\nAssume further that your colleague amends the code as follows in Fig. 6.8.\\n1956.2. PROBLEMS\\n1 import torchvision.models as models\\n2 import random\\n3 import np\\n4 ...\\n5 models = [\\'resnext\\' ]\\n6 for m in models:\\n7 train ...\\n8 compute loss ...\\n9 amend LR ...\\n10 manualSeed= draw a new random number\\n11 random.seed(manualSeed)\\n12 np.random.seed(manualSeed)\\n13 torch.manual_seed(manualSeed)\\n14 if (val_acc > 90.0):\\n15 saveModel()\\nFIGURE 6.8: PyTorch code snippet for an ensemble\\nExplain in detail what would be the possible effects of adding lines 10-13.\\n6.2.6 Multi-model Ensembling\\nPRB-155 \\uf059 CH.PRB- 6.21.\\n1. Assume your colleague, a veteran in DL and an expert in ensembling methods writes\\nthe following Pseudo code shown in Fig. 6.9 for the training of several neural networks.\\nThis code snippet is executed inside a standard loop in each and every training/valida-\\ntion epoch.\\n196Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 import torchvision.models as models\\n2 ...\\n3 models = [\\'resnext\\' ,\\'vgg\\' ,\\'dense\\' ]\\n4 for m in models:\\n5 train ...\\n6 compute loss /acc ...\\n7 if (val_acc > 90.0):\\n8 saveModel()\\nFIGURE 6.9: PyTorch code snippet for an ensemble\\nWhat type of ensembling is being utilized in this approach? Explain in detail.\\n2. Name one method by which NN models may be combined to yield a single prediction.\\n6.2.7 Learning-rate Schedules in Ensembling\\nPRB-156 \\uf059 CH.PRB- 6.22.\\n1. Referring to Fig. ( 6.10) which depicts a speciﬁc learning rate schedule, describe the\\nbasic notion behind its mechanism.\\n1976.3. SOLUTIONS\\n1\\n0,5\\n1\\nx\\ny\\nFIGURE 6.10: A learning rate schedule.\\n2. Explain how cyclic learning rates [10] can be effective for the training of convolutional\\nneural networks such as the ones in the code snippet of Fig. 6.10.\\n3. Explain how a cyclic cosine annealing schedule as proposed by Loshchilov [ 10] and\\n[13] is used to converge to multiple local minima.\\n6.3 Solutions\\n6.3.1 Bagging, Boosting and Stacking\\nSOL-135 \\uf14b CH.SOL- 6.1.\\nAll the presented options are correct. \\x04\\nSOL-136 \\uf14b CH.SOL- 6.2.\\nThe correct choice would be stacking. In cases where the given corpus is small, we would\\nmost likely prefer training our models on the full data-set. \\x04\\nSOL-137 \\uf14b CH.SOL- 6.3.\\nA random forest is a type of a decision tree which utilizes bagging. \\x04\\n198Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-138 \\uf14b CH.SOL- 6.4.\\nThe presented algorithm is a classic bagging. \\x04\\nSOL-139 \\uf14b CH.SOL- 6.5.\\nThe approach which is depicted is the ﬁrst phase of stacking. In stacking, we ﬁrst (phase\\n0) predict using several base learners and then use a generalizer (phase 1) that learns on top\\nof the base learners predictions. \\x04\\nSOL-140 \\uf14b CH.SOL- 6.6.\\n1. Sampling with replacement\\n2. Sampling without replacement\\n3. This may be mostly a result of bagging, since in boosting we would have expected miss-\\ncorrectly classiﬁed observations to repeatedly appear in subsequent samples.\\n\\x04\\n6.3.2 Approaches for Combining Predictors\\nSOL-141 \\uf14b CH.SOL- 6.7.\\nAn Algebraic weighted average for class probabilities. \\x04\\nSOL-142 \\uf14b CH.SOL- 6.8.\\nThis is true, [ 3] provides a mathematical proof. \\x04\\nSOL-143 \\uf14b CH.SOL- 6.9.\\nThis is true. For extension, see instance [ 8]. \\x04\\nSOL-144 \\uf14b CH.SOL- 6.10.\\nThis is true. In a bagging approach, we ﬁrst randomly draw (with replacement), K ex-\\n1996.3. SOLUTIONS\\namples where K is the size of the original training corpus therefore leading to an imbalanced\\nrepresentation of the instances. \\x04\\n6.3.3 Monolithic and Heterogeneous Ensembling\\nSOL-145 \\uf14b CH.SOL- 6.11.\\n1. True Due to their lack of diversity, an ensemble of monolithic architectures tends to\\nperform worse than an heterogeneous ensemble.\\n2. True This has be consistently demonstrated in [ 11, 5].\\n3. True In [6] there is a discussion about both using the whole corpus and a subset much\\nlike in bagging.\\n4. True The total error decreases with the addition of predictors to the ensemble.\\n\\x04\\nSOL-146 \\uf14b CH.SOL- 6.12.\\nY es, they do. \\x04\\nSOL-147 \\uf14b CH.SOL- 6.13.\\n1. Y es, it is very likely, especially if their errors are independent.\\n2. True It may be proven that ensembles of models perform at least as good as each of the\\nensemble members it consists of.\\n3. True Different local minima add to the diversiﬁcation of the models.\\n\\x04\\nSOL-148 \\uf14b CH.SOL- 6.14.\\nBoosting is the only one that does not. \\x04\\n200Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-149 \\uf14b CH.SOL- 6.15.\\nFalse By deﬁnition, static committee machines use only the output of the single predict-\\nors. \\x04\\nSOL-150 \\uf14b CH.SOL- 6.16.\\nTrue \\x04\\nSOL-151 \\uf14b CH.SOL- 6.17.\\nFalse Though this may be theoretically true, in practice the errors are rarely uncorrelated\\nand therefore the actual error can not be reduced by a factor of K. \\x04\\n6.3.4 Ensemble Learning\\nSOL-152 \\uf14b CH.SOL- 6.18.\\n1. Ensemble learning is an excellent machine learning idea which displays noticeable bene-\\nﬁts in many applications, one such notable example is the widespread use of ensembles\\nin Kaggle competitions. In an ensemble several individual models (for instance Res-\\nNet18 and VGG16) which were trained on the same corpus, work in tandem and during\\ninference, their predictions are fused by a pre-deﬁned strategy to yield a single predic-\\ntion.\\n2. In classical machine learning Ensemble methods usually refer to bagging, boosting and\\nthe linear combination of regression or classiﬁcation models.\\n3. True The stronger generalization ability stems from the voting power of diverse models\\nwhich are joined together.\\n4. Bagging is variance reduction scheme while boosting reduced bias.\\n\\x04\\n6.3.5 Snapshot Ensembling\\n2016.3. SOLUTIONS\\nSOL-153 \\uf14b CH.SOL- 6.19.\\n1. Since only a single model ie being utilized, this type of ensembling is known as snap-\\nshot ensembling. Using this approach, during the training of a neural network and\\nin each epoch, a snapshot, e.g. the weights of a trained instance of a model (a PTH\\nﬁle in PyT orch nomenclature) are persisted into permanent storage whenever a certain\\nperformance metrics, such as accuracy or loss is being surpassed. Therefore the name\\n“snapshot”; weights of the neural network are being snapshot at speciﬁc instances in\\ntime. After several such epochs the top-5 performing Snapshots which converged to\\nlocal minima [4] are combined as part of an ensemble to yield a single prediction.\\n2. Advantages: during a single training cycle, many model instances may be collected.\\nDisadvantages: inherent lack of diversity by virtue of the fact that the same models is\\nbeing repeatedly used.\\n\\x04\\nSOL-154 \\uf14b CH.SOL- 6.20.\\nChanging the random seed at each iteration/epoch, helps in introducing variation which\\nmay contribute to diversifying the trained neural network models. \\x04\\n6.3.6 Multi-model Ensembling\\nSOL-155 \\uf14b CH.SOL- 6.21.\\n1. Multi-model ensembling.\\n2. Both averaging and majority voting.\\n\\x04\\n6.3.7 Learning-rate Schedules in Ensembling\\nSOL-156 \\uf14b CH.SOL- 6.22.\\n202Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1. Capturing the best model of each training cycle allows to obtain multiple models settled\\non various local optima from cycle to cycle at the cost of training a single mode\\n2. The approach is based on the non-convex nature of neural networks and the ability to\\nconverge and escape from local minima using a speciﬁc schedule to adjust the learning\\nrate during training.\\n3. Instead of monotonically decreasing the learning rate, this method lets the learning rate\\ncyclically vary between reasonable boundary values.\\n\\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 186).\\n[2] Y . Gal and Z. Ghahramani. ‘Dropout as a Bayesian approximation’. In: arXiv\\npreprint arXiv:1506.02157 (2015) (cit. on p. 192).\\n[3] L. K. Hansen and P . Salamon. ‘Neural Network Ensembles’. In: IEEE T rans. Pat-\\ntern Anal. Mach. Intell. 12 (1990), pp. 993–1001 (cit. on pp. 191, 199).\\n[4] G. Huang et al. ‘Snapshot ensembles: Train 1, get M for free. arXiv 2017’. In:\\narXiv preprint arXiv:1704.00109 () (cit. on pp. 186, 192, 202).\\n[5] J. Huggins, T. Campbell and T. Broderick. ‘Coresets for scalable Bayesian logistic\\nregression’. In: Advances in Neural Information Processing Systems . 2016, pp. 4080–\\n4088 (cit. on pp. 186, 200).\\n[6] C. Ju, A. Bibaut and M. van der Laan. ‘The relative performance of ensemble\\nmethods with deep convolutional neural networks for image classiﬁcation’. In:\\nJournal of Applied Statistics 45.15 (2018), pp. 2800–2818 (cit. on p. 200).\\n[7] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on p. 186).\\n[8] A. Krogh and J. V edelsby. ‘Neural Network Ensembles, Cross Validation, and\\nActive Learning’. In: NIPS. 1994 (cit. on p. 199).\\n[9] S. Lee et al. ‘Stochastic multiple choice learning for training diverse deep en-\\nsembles’. In: Advances in Neural Information Processing Systems . 2016, pp. 2119–\\n2127 (cit. on p. 192).\\n203REFERENCES\\n[10] I. Loshchilov and F. Hutter. ‘Sgdr: Stochastic gradient descent with warm re-\\nstarts’. In: arXiv preprint arXiv:1608.03983 (2016) (cit. on p. 198).\\n[11] P . Oshiro et al.(2012)Oshiro and Baranauskas. ‘How many trees in a random\\nforest?’ In: International Workshop on Machine Learning and Data Mining in Pattern\\nRecognition. 2012 (cit. on pp. 186, 200).\\n[12] Y . Ovadia et al. ‘Can you trust your model’s uncertainty? Evaluating predict-\\nive uncertainty under dataset shift’. In: Advances in Neural Information Processing\\nSystems. 2019, p. 13991 (cit. on p. 192).\\n[13] L. N. Smith. ‘Cyclical learning rates for training neural networks’. In: 2017 IEEE\\nWinter Conference on Applications of Computer Vision (WACV). IEEE. 2017, pp. 464–\\n472 (cit. on pp. 186, 198).\\n204CHAPTER\\n7\\nDEEP LEARNING: CNN FEATURE EXTRACTION\\nWhat goes up must come down.\\n— Isaac Newton\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\\nNeural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\n7.1 Introduction\\nT\\nHE extraction of an n-dimensional feature vector (FV) or an embedding from\\none (or more) layers of a pre-trained CNN, is termed feature extraction (FE).\\nUsually , FE works by ﬁrst removing the last fully connected (FC) layer from\\na CNN and then treating the remaining layers of the CNN as a ﬁxed FE. As\\nexempliﬁed in Fig. ( 7.1) and Fig. ( 7.2), applying this method to the ResNet34 archi-\\ntecture, the resulting FV consists of 512 ﬂoating point values. Likewise, applying the\\nsame logic on the ResNet152 architecture, the resulting FV has 2048 ﬂoating point ele-\\nments.7.2. PROBLEMS\\n1 2 3 4 · · · k = 512\\nA ﬁxed k-element FV .\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nActual values of a normalized k-element FV .\\nFIGURE 7.1: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depicted is\\nthe ResNet CNN architecture with 34 layers.\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.2: PyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed).\\nThe premise behind FE is that CNNs which were originally trained on the Im-\\nageNet Large Scale Visual Recognition Competition [ 7], can be adapted and used (for\\ninstance in a classiﬁcation task) on a completely different (target) domain without any\\nadditional training of the CNN layers. The power of a CNN to do so lies in its ability\\nto generalize well beyond the original data-set it was trained on, therefore FE on a\\nnew target data-set involves no training and requires only inference.\\n7.2 Problems\\n7.2.1 CNN as Fixed Feature Extractor\\nBefore attempting the problems in this chapter you are highly encouraged to read the\\nfollowing papers [ 1, 3, 7]. In many DL job interviews, you will be presented with a\\npaper you have never seen before and subsequently be asked questions about it; so\\nreading these references would be an excellent simulation of this real-life task.\\n206Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-157 \\uf059 CH.PRB- 7.1.\\nTrue or False: While AlexNet [ 4] used 11 × 11 sized ﬁlters, the main novelty presented\\nin the VGG [ 8] architecture was utilizing ﬁlters with much smaller spatial extent, sized\\n3 × 3.\\nPRB-158 \\uf059 CH.PRB- 7.2.\\nTrue or False : Unlike CNN architectures such as AlexNet or VGG, ResNet does not\\nhave any hidden FC layers.\\nPRB-159 \\uf059 CH.PRB- 7.3.\\nAssuming the VGG-Net has 138, 357, 544 ﬂoating point parameters, what is the phys-\\nical size in Mega-Bytes (MB) required for persisting a trained instance of VGG-Net on\\npermanent storage?\\nPRB-160 \\uf059 CH.PRB- 7.4.\\nTrue or False : Most attempts at researching image representation using FE, focused\\nsolely on reusing the activations obtained from layers close to the output of the CNN, and\\nmore speciﬁcally the fully-connected layers.\\nPRB-161 \\uf059 CH.PRB- 7.5.\\nTrue or False: FE in the context of deep learning is particularly useful when the target\\nproblem does not include enough labeled data to successfully train CNN that generalizes\\nwell.\\nPRB-162 \\uf059 CH.PRB- 7.6.\\nWhy is a CNN trained on the ImageNet dataset [ 7] a good candidate for a source prob-\\nlem?\\nPRB-163 \\uf059 CH.PRB- 7.7.\\n2077.2. PROBLEMS\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of [...] layers.\\n2. It consists of [...] convolutional and 3 [...] layers.\\n3. The input image size is [...].\\n4. The number of input channels is [...].\\n5. Every image has it’s mean RGB value [subtracted / added].\\n6. Each convolutional layer has a [small/large] kernel sized [...].\\n7. The number of pixels for padding and stride is [...].\\n8. There are 5 [...] layers having a kernel size of [...] and a stride of [...] pixels.\\n9. For non-linearity a [rectiﬁed linear unit (ReLU [ 5])/sigmoid] is used.\\n10. The [...] FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of [...] features.\\n12. The last FC layer has only [...] features.\\n13. The last FC layer is terminated by a [...] activation layer.\\n14. Dropout [is / is not] being used between the FC layers.\\nPRB-164 \\uf059 CH.PRB- 7.8.\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture [ 8] for the classiﬁcation of pancreatic cancer. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with\\nit by utilizing the same logic. In Fig. ( 9.7) three different classes of pancreatic cancer are\\ndisplayed: A, B and C, curated from a dataset of 4K Whole Slide Images (WSI) labeled by\\na board certiﬁed pathologist. Y our task is to use FE to correctly classify the images in the\\ndataset.\\n208Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nFIGURE 7.3: A dataset of 4K histopathology WSI from three severity classes: A, B and C.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture [ 8]. As de-\\npicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters),\\nlearnable parameters (weights,biases), and FV size are presented.\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 7.1: Incomplete listing of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4K images from the dataset, how can\\nyou now classify the images into their respective categories?\\n2097.2. PROBLEMS\\nPRB-165 \\uf059 CH.PRB- 7.9.\\nStill referring to T able ( 9.3), a data scientist suggests using the output layer of the\\nVGG19 CNN as a ﬁxed FE. What is the main advantage of using this layer over using\\nfor instance, the f c7 layer? (Hint: think about an ensemble of feature extractors)\\nPRB-166 \\uf059 CH.PRB- 7.10.\\nStill referring to T able (9.3) and also to the code snippet in Fig. ( 7.4), which represents a\\nnew CNN derived from the VGG19 CNN:\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=[???])\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = [???]\\n11 self.classifier = torch.nn.Sequential([???])\\n12 self.num_feats = [???]\\n13\\n14 def forward(self, x):\\n15 f = self.features(x)\\n16 f = f.view(f.size(0), -1)\\n17 f = [???]\\n18 print (f.data.size())\\n19 return f\\nFIGURE 7.4: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n210Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. Complete line 6; what should be the value of pretrained ?\\n2. Complete line 10; what should be the value of self.features ?\\n3. Complete line 12; what should be the value of self.num_feats ?\\n4. Complete line 17; what should be the value of f ?\\nPRB-167 \\uf059 CH.PRB- 7.11.\\nWe are still referring to T able ( 9.3) and using the skeleton code provided in Fig. ( 7.5)\\nto derive a new CNN entitled ResNetBottom from the ResNet34 CNN, to extract a 512-\\ndimensional FV for a given input image. Complete the code as follows:\\n1. The value of self.features in line 7.\\n2. The forward method in line 11.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7\\n8 def forward(self, x):\\n9 x = [???]\\n10 x = x.view(x.size(0), -1)\\n11 return x\\nFIGURE 7.5: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\n2117.2. PROBLEMS\\nPRB-168 \\uf059 CH.PRB- 7.12.\\nStill referring to T able (9.3), the PyT orch based pseudo code snippet in Fig. (7.6) returns\\nthe 512-dimensional FV from the modiﬁed ResNet34 CNN, given a 3-channel RGB image\\nas an input.\\n1 import torchvision.models as models\\n2 from torchvision import transforms\\n3 ...\\n4\\n5 test_trans = transforms.Compose([\\n6 transforms.Resize(imgnet_size),\\n7 transforms.ToTensor(),\\n8 transforms.Normalize([0.485, 0.456, 0.406],\\n9 [0.229, 0.224, 0.225])])\\n10\\n11 def ResNet34FE(image, model):\\n12 f=None\\n13 image = test_trans(image)\\n14 image = Variable(image, requires_grad =False).cuda()\\n15 image= image.cuda()\\n16 f = model(image)\\n17 f = f.view(f.size(1), -1)\\n18 print (\"Size : {}\" .format(f.shape))\\n19 f = f.view(f.size(1),-1)\\n20 print (\"Size : {}\" .format(f.shape))\\n21 f =f.cpu().detach().numpy()[0]\\n22 print (\"Size : {}\" .format(f.shape))\\n23 return f\\nFIGURE 7.6: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\nAnswer the following questions regarding the code in Fig. ( 7.6):\\n212Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. What is the purpose of test_trans in line 5?\\n2. Why is the parameter requires_grad set to False in line 14?\\n3. What is the purpose of f.cpu() in line 23?\\n4. What is the purpose of detach() in line 23?\\n5. What is the purpose of numpy()[0] in line 23?\\n7.2.2 Fine-tuning CNNs\\nPRB-169 \\uf059 CH.PRB- 7.13.\\nDeﬁne the term ﬁne-tuning (FT) of an ImageNet pre-trained CNN .\\nPRB-170 \\uf059 CH.PRB- 7.14.\\nDescribe three different methods by which one can ﬁne-tune an ImageNet pre-trained\\nCNN.\\nPRB-171 \\uf059 CH.PRB- 7.15.\\nMelanoma is a lethal form of malignant skin cancer, frequently misdiagnosed as a benign\\nskin lesion or even left completely undiagnosed.\\nIn the United States alone, melanoma accounts for an estimated 6, 750 deaths per annum\\n[6]. With a 5-year survival rate of 98%, early diagnosis and treatment is now more likely\\nand possibly the most suitable means for melanoma related death reduction. Dermoscopy\\nimages, shown in Fig. ( 7.7) are widely used in the detection and diagnosis of skin lesions.\\nDermatologists, relying on personal experience, are involved in a laborious task of manually\\nsearching dermoscopy images for lesions.\\nTherefore, there is a very real need for automated analysis tools, providing assistance to\\nclinicians screening for skin metastases. In this question, you are tasked with addressing\\nsome of the fundamental issues DL researchers face when building deep learning pipelines.\\nAs suggested in [ 3], you are going to use ImageNet pre-trained CNN to resolve a classiﬁca-\\ntion task.\\n2137.2. PROBLEMS\\nFIGURE 7.7: Skin lesion categories. An exemplary visualization of melanoma.\\n1. Given that the skin lesions fall into seven distinct categories, and you are training us-\\ning cross-entropy loss, how should the classes be represented so that a typical PyT orch\\ntraining loop will successfully converge?\\n2. Suggest several data augmentation techniques to augment the data.\\n3. Write a code snippet in PyT orch to adapt the CNN so that it can predict 7 classes\\ninstead of the original source size of 1000.\\n4. In order to ﬁne tune our CNN, the (original) output layer with 1000 classes was\\nremoved and the CNN was adjusted so that the (new) classiﬁcation layer comprised\\nseven softmax neurons emitting posterior probabilities of class membership for each\\nlesion type.\\n7.2.3 Neural style transfer, NST\\nBefore attempting the problems in the section, you are strongly recommended to read\\nthe paper: “A Neural Algorithm of Artistic Style ” [2].\\nPRB-172 �'),\n",
              " Document(metadata={}, page_content='.\\n1. Given that the skin lesions fall into seven distinct categories, and you are training us-\\ning cross-entropy loss, how should the classes be represented so that a typical PyT orch\\ntraining loop will successfully converge?\\n2. Suggest several data augmentation techniques to augment the data.\\n3. Write a code snippet in PyT orch to adapt the CNN so that it can predict 7 classes\\ninstead of the original source size of 1000.\\n4. In order to ﬁne tune our CNN, the (original) output layer with 1000 classes was\\nremoved and the CNN was adjusted so that the (new) classiﬁcation layer comprised\\nseven softmax neurons emitting posterior probabilities of class membership for each\\nlesion type.\\n7.2.3 Neural style transfer, NST\\nBefore attempting the problems in the section, you are strongly recommended to read\\nthe paper: “A Neural Algorithm of Artistic Style ” [2].\\nPRB-172 \\uf059 CH.PRB- 7.16.\\nBrieﬂy describe how neural style transfer (NST) [ 2] works.\\nPRB-173 \\uf059 CH.PRB- 7.17.\\nComplete the sentence : When using the VGG-19 CNN [ 8] for neural-style transfer,\\nthere different images are involved. Namely they are: [...], [...] and [...].\\n214Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-174 \\uf059 CH.PRB- 7.18.\\nRefer to Fig. 7.8 and answer the following questions:\\nFIGURE 7.8: Artistic style transfer using the style of Francis Picabia’s Udnie painting.\\n1. Which loss is being utilized during the training process?\\n2. Brieﬂy describe the use of activations in the training process.\\nPRB-175 \\uf059 CH.PRB- 7.19.\\nStill referring to Fig. 7.8:\\n1. How are the activations utilized in comparing the content of the content image to the\\ncontent of the combined image?.\\n2. How are the activations utilized in comparing the style of the content image to the\\n2157.3. SOLUTIONS\\nstyle of the combined image?.\\nPRB-176 \\uf059 CH.PRB- 7.20.\\nStill referring to Fig. 7.8. For a new style transfer algorithm, a data scientist extracts a\\nfeature vector from an image using a pre-trained ResNet34 CNN ( 7.9).\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.9: PyTorch declaration for a pre-trained ResNet34 CNN.\\nHe then deﬁnes the cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and :\\nv = {v1, v2, . . . , vN }\\nas:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures thecosine of the angle between\\nthe vectors irrespective of their magnitude. It is calculated as the dot product of two numeric\\nvectors, and is normalized by the product of the length of the vectors.\\nAnswer the following questions:\\n1. Deﬁne the term Gram matrix.\\n2. Explain in detail how vector similarity is utilised in the calculation of the Gram mat-\\nrix during the training of NST.\\n7.3 Solutions\\n7.3.1 CNN as Fixed Feature Extractor\\n216Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nSOL-157 \\uf14b CH.SOL- 7.1.\\nT rue. The increased depth in VGG-Net was made possible using smaller ﬁlters without\\nsubstantially increasing the number of learnable parameters. Albeit an unwanted side effect\\nof the usage of smaller ﬁlters is the increase in the number of ﬁlters per-layer. \\x04\\nSOL-158 \\uf14b CH.SOL- 7.2.\\nT rue. The ResNet architecture terminates with a global average pooling layer followed\\nby a K-way FC layer with a softmax activation function, where K is the number of classes\\n(ImageNet has 1000 classes). Therefore, the ResNet has no hidden FC layers. \\x04\\nSOL-159 \\uf14b CH.SOL- 7.3. Note that 1bit = 0.000000125 MB, therefore:\\n138, 357544 × 32 = 4427441408 bits = 553.430176 MB. (7.1)\\n\\x04\\nSOL-160 \\uf14b CH.SOL- 7.4.\\nT rue. There are dozens of published papers supporting this claim. Y ou are encouraged to\\nsearch them on Arxiv or Google Scholar. \\x04\\nSOL-161 \\uf14b CH.SOL- 7.5.\\nT rue. One of the major hurdles of training a medical AI system is the lack of annotated\\ndata. Therefore, extensive research is conducted to exploit ways for FE and transfer learning,\\ne.g., in the application of ImageNet trained CNNs, to target datasets in which labeled data is\\nscarce. \\x04\\nSOL-162 \\uf14b CH.SOL- 7.6.\\nThere are two main reasons why this is possible:\\n1. The huge number of images inside the ImageNet dataset ensures a CNN model that gen-\\neralizes to additional domains, like the histopathology domain, which is substantially\\ndifferent from the original domain the model was trained one (e.g., cats and dogs).\\n2177.3. SOLUTIONS\\n2. A massive array of disparate visual patterns is produced by an ImageNet trained CNN,\\nsince it consists of 1, 000 different groups.\\n\\x04\\nSOL-163 \\uf14b CH.SOL- 7.7.\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of 19 layers.\\n2. It consists of 5 convolutional and 3 FC layers.\\n3. The input image size is 244 , the default size most ImageNet trained CNNs work on.\\n4. The number of input channels is 3 .\\n5. Every image has its mean RGB value subtracted . (why?)\\n6. Each convolutional layer has a small kernel sized 3 × 3 . (why?)\\n7. The number of pixels for padding and stride is the same and equals 1 .\\n8. There are 5 convolutional layers having a kernel size of 2 × 2 and a stride of 2 pixels.\\n9. For non-linearity a rectiﬁed linear unit (ReLU [ 5]) is used.\\n10. The 3 FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of 4096 features.\\n12. The last FC layer has only 1000 features.\\n13. The last FC layer is terminated by a softmax activation layer.\\n14. Dropout is being used between the FC layers.\\n\\x04\\nSOL-164 \\uf14b CH.SOL- 7.8.\\n218Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. One or more layers of the VGG19 CNN are selected for extraction and a new CNN\\nis designed on top of it. Thus, during inference our target layers are extracted and\\nnot the original softmax layer. Subsequently, we iterate and run inference over all\\nthe images in our pancreatic cancer data-set, extract the features, and persist them to\\npermanent storage such as a solid-state drive (SSD) device. Ultimately, each image has\\na corresponding FV .\\n2. Regarding the VGG19 CNN, there are numerous ways of extracting and combining\\nfeatures from different layers. Of course, these different layers, e.g., the FC, conv4_3,\\nand fc7 layer may be combined together to form a larger feature vector. T o determine\\nwhich method works best, you shall have to experiment on your data-set; there is no way\\nof a-priory determining the optimal combination of layers. Here are several examples:\\n(a) Accessing the last FC layer resulting in a 1000-D FV . The output is the score for\\neach of the 1000 classes of the ImageNet data-set.\\n(b) Removing the last FC layer leaves the fc7 layer, resulting in a 4096-D FV .\\n(c) Directly accessing the conv4_3 layer results in a 512-D FV .\\n3. Once the FVs are extracted, we can train any linear classiﬁer such as an SVM or\\nsoftmax classiﬁer on the FV data-set, and not on the original images.\\n\\x04\\nSOL-165 \\uf14b CH.SOL- 7.9.\\nOne beneﬁt of using the FC layer is that other ImageNet CNNs can be used in tandem\\nwith the VGG19 to create an ensemble since they all produce the same 1000-D sized FV . \\x04\\nSOL-166 \\uf14b CH.SOL- 7.10. The full code is presented in Fig. ( 7.10).\\n2197.3. SOLUTIONS\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=True)\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = original_model.features\\n11 self.classifier = torch.nn.Sequential(\\n12 (*list(original_model.classifier.\\n13 children())[:-1]))\\n14 self.num_feats = 4096\\n15\\n16 def forward(self, x):\\n17 f = self.features(x)\\n18 f = f.view(f.size(0), -1) # (1, 4096) -> (4096,)\\n19 f = self.classifier(f)\\n20 print (f.data.size())\\n21 return f\\nFIGURE 7.10: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n1. The value of the parameter pretrained should be T rue in order to instruct PyT orch to\\nload an ImageNet trained weights.\\n2. The value of self.features should be original_model.features . This is because we like to\\nretain the layers of the original classiﬁer (original_model).\\n3. The value of self.num_feats should be 4096 . (Why?)\\n4. The value of f should be self.classiﬁer(f) since our newly created CNN has to be in-\\nvoked to generate the FV .\\n220Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n\\x04\\nSOL-167 \\uf14b CH.SOL- 7.11.\\n1. Line number 7 in Fig. ( 7.11) takes care of extracting the the correct 512-D FV .\\n2. Line number 11 in Fig. ( 7.11) extracts the correct 512-D FV by creating a sequential\\nmodule on top of the existing features.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7 def forward(self, x):\\n8 x = [???]\\n9 x = x.view(x.size(0), -1)\\n10 return x\\nFIGURE 7.11: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n\\x04\\nSOL-168 \\uf14b CH.SOL- 7.12.\\n1. T ransforms are incorporated into deep learning pipelines in order to apply one or more\\noperations on images which are represented as tensors. Different transforms are usu-\\nally utilized during training and inference. For instance, during training we can use a\\ntransform to augment our data-set, while during inference our transform may be lim-\\nited only to normalizing an image. PyT orch allows the use of transforms either during\\ntraining or inference. The purpose of test_trans in line 5 is to normalize the data.\\n2217.3. SOLUTIONS\\n2. The parameter requires_grad is set to False in line 14 since during inference the com-\\nputation of gradients is obsolete.\\n3. The purpose of f.cpu() in line 11 is to move a tensor that was allocated on the GPU\\nto the CPU. This may be required if we want to apply a CPU-based method from the\\nPython numpy package on a T ensor that does not live in the CPU.\\n4. detach() in line 23 returns a newly created tensor without affecting the current tensor.\\nIt also detaches the output from the current computational graph, hence no gradient is\\nbackpropagated for this speciﬁc variable.\\n5. The purpose of numpy()[0] in line 23 is to convert the variable (an array) to a numpy\\ncompatible variable and also to retrieve the ﬁrst element of the array.\\n\\x04\\n7.3.2 Fine-tuning CNNs\\nSOL-169 \\uf14b CH.SOL- 7.13.\\nThe term ﬁne-tuning (FT) of an ImageNet pre-trained CNN refers to the method by which\\none or more of the weights of the CNN are re-trained on a new target data-set, which may or\\nmay-not have similarities with the ImageNet data-set. \\x04\\nSOL-170 \\uf14b CH.SOL- 7.14. The three methods are as follows:\\n1. Replacing and re-training only the classiﬁer (usually the FC layer) of the ImageNet\\npre-trained CNN, on a target data-set.\\n2. FT all of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n3. FT part of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n\\x04\\nSOL-171 \\uf14b CH.SOL- 7.15.\\n222Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The categories have to be represented numerically. One such option is presented in Code\\n(7.1).\\n1 \\'MEL\\' : 0, \\'NV\\' : 1, \\'BCC\\' : 2, \\'AKIEC\\' : 3, \\'BKL\\' : 4, \\'DF\\' : 5,\\n\\'VASC\\' : 6↪→\\nCODE 7.1: The seven categories of skin lesions.\\n2. Several possible augmentations are presented in Code ( 7.2). It is usually, that by trial\\nand error one ﬁnds the best possible augmentation for a target data-set. However, meth-\\nods such as AutoAugment may render the manual selection of augmentations obsolete.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\n6 if brightness != 0:\\n7 self.transforms.append(PILBrightness())\\n8 if contrast != 0:\\n9 self.transforms.append(PILContrast())\\n10 if colorbalance != 0:\\n11 self.transforms.append(PILColorBalance())\\n12 if sharpness != 0:\\n13 self.transforms.append(PILSharpness())\\nCODE 7.2: Pseudeo code for augmentations.\\n3. In contrast to the ResNet CNN which ends by an FC layer, the ImageNet pre-trained\\nDPN CNN family, in this case the pretrainedmodels.dpn107, terminated by a Conv2d\\n2237.3. SOLUTIONS\\nlayer and hence must be adapted accordingly if one wishes to change the number fo\\nclasses from the 1000 (ImageNet) classes to our skin lession classiﬁcation problem (7\\nclasses). Line 7 in Code ( 7.3) demonstrated this idiom.\\n1 import torch\\n2 class Dpn107Finetune(nn.Module):\\n3 def __init__(self, num_classes: int, net_kwards):\\n4 super().__init__()\\n5 self.net = pretrainedmodels.dpn107(**net_kwards)\\n6 self.net.__name__= str (self.net)\\n7 self.net.classifier = torch.nn.Conv2d(2688,\\nnum_classes,kernel_size=1)↪→\\n8 print(self.net)\\nCODE 7.3: Change between 1000 classes to 7 classes for the ImageNet pre-trained DPN\\nCNN family .\\n\\x04\\n7.3.3 Neural style transfer\\nSOL-172 \\uf14b CH.SOL- 7.16.\\nThe images are: a content image, a style image and lastly a combined image. \\x04\\nSOL-173 \\uf14b CH.SOL- 7.17.\\nThe algorithm presented in the paper suggests how to combine the content a ﬁrst image\\nwith the style of a second image to generate a third, stylized image using CNNs.\\n\\x04\\nSOL-174 \\uf14b CH.SOL- 7.18.\\nThe answers are as follows:\\n224Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The training pipeline uses a combined loss which consists of a weighted average of the\\nstyle loss and the content loss.\\n2. Different CNN layers at different levels are utilized to capture both ﬁne-grained styl-\\nistic details as well as larger stylistic features.\\n\\x04\\nSOL-175 \\uf14b CH.SOL- 7.19.\\n1. The content loss is the mean square error (MSE) calculated as the difference between\\nthe CNN activations of the last convolutional layer of both the content image and the\\nstyle images.\\n2. The style loss amalgamates the losses of several layers together. For each layer, the gram\\nmatrix (see 7.2) for the activations at that layer is obtained for both the style and the\\ncombined images. Then, just like in the content loss, the MSE of the Gram matrices is\\ncalculated.\\n\\x04\\nSOL-176 \\uf14b CH.SOL- 7.20.\\nFor each feature map, a feature vector is extracted. The gram matrix captures the correl-\\nation between these feature vectors which is then being used in the loss function. Provided a\\nlist of feature vectors extracted from the images, u1, . . . , uk ∈ Rn, the Gram matrix is deﬁned\\nas: \\uf8eb\\n\\uf8ec\\uf8ec\\uf8ec\\uf8ed\\nu1 · u1 . . . u 1 · uk\\n... . . . ...\\nuk · u1 . . . u k · uk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f7\\uf8f8 (7.2)\\nThe Gram matrix \\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 206).\\n225REFERENCES\\n[2] L. A. Gatys, A. S. Ecker and M. Bethge. A Neural Algorithm of Artistic Style . 2015.\\narXiv: 1508.06576 [cs.CV] (cit. on p. 214).\\n[3] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on pp. 206, 213).\\n[4] A. Krizhevsky. One weird trick for parallelizing convolutional neural networks . 2014.\\narXiv: 1404.5997 [cs.NE] (cit. on p. 207).\\n[5] V . Nair and G. E. Hinton. ‘Rectiﬁed Linear Units Improve Restricted Boltzmann\\nMachines’. In: ICML 10 . Madison, WI, USA: Omnipress, 2010, pp. 807–814 (cit.\\non pp. 208, 218).\\n[6] A. J. R. L. Siegel K. D. Miller. ‘Cancer statistics 2016’. In: CA: a cancer journal for\\nclinicians 66,1 (2016), pp. 7–30 (cit. on p. 213).\\n[7] Russakovsky. ‘ImageNet Large Scale Visual Recognition Challenge’. In: Journal\\nof Computer Vision 115.3 (Apr. 2015), pp. 211–252 (cit. on pp. 206, 207).\\n[8] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 207–209, 214).\\n226CHAPTER\\n8\\nDEEP LEARNING\\nIt is the weight, not numbers of experiments that is to be regarded.\\n— Isaac Newton.\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 234\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 235\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 236\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 239\\nConvolution and correlation in python . . . . . . . . . . . . . . 240\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 241\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 244\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 246The Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 247\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 248\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 249\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 251\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 251\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 253\\nSigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 260\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 268\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 273\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 274\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 276\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 280\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 283\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 284\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\n228Chapter 8 DEEP LEARNING\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 286\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 291\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 291\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 292\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 293\\nConvolution and correlation in python . . . . . . . . . . . . . . 294\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 295\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 297\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 299\\nThe Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 300\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 301\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 301\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 304\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 305\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 306\\n229Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 318\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 324\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 324\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 326\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 326\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 327\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 328\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 329\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 331\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333\\n230Chapter 8 DEEP LEARNING\\n8.1 Introduction\\nI\\nT was Alex Krizhevsky who ﬁrst demonstrated that a convolutional neural\\nnetwork (CNN) can be effectively trained on the ImageNet large scale visual\\nrecognition challenge. A CNN automatically provides some degree of trans-\\nlation and assumes that we wish to learn ﬁlters, in a data-driven fashion, as\\na means to extract features describing the inputs. CNNs are applied to numerous com-\\nputer vision, imaging, and computer graphics tasks as in [ 24], [ 23], [ 15], [ 5]. Further-\\nmore, they have become extremely popular, and novel architectures and algorithms\\nare continually popping up overnight.\\n8.2 Problems\\n8.2.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nPRB-177 \\uf059 CH.PRB- 8.1.\\nFig (8.1) depicts two different cross-validation approaches. Name them.\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\nTRAIN VAL\\nFIGURE 8.1: Two CV approaches\\n2318.2. PROBLEMS\\nPRB-178 \\uf059 CH.PRB- 8.2.\\n1. What is the purpose of the following Python code snippet 8.2 ?\\n1 skf = StratifiedKFold(y, n_folds =5, random_state =989,\\nshuffle=True)↪→\\nFIGURE 8.2: Stratiﬁed K-fold\\n2. Explain the beneﬁts of using the K-fold cross validation approach.\\n3. Explain the beneﬁts of using the Stratiﬁed K-fold cross validation approach.\\n4. State the difference between K-fold cross validation and stratiﬁed cross validation.\\n5. Explain in your own words what is meant by “We adopted a 5-fold cross-validation\\napproach to estimate the testing error of the model”.\\nK-Fold CV\\nPRB-179 \\uf059 CH.PRB- 8.3.\\nT rue or False: In a K-fold CV approach, the testing set is completely excluded from the\\nprocess and only the training and validation sets are involved in this approach.\\nPRB-180 \\uf059 CH.PRB- 8.4.\\nT rue or False: In a K-fold CV approach, the ﬁnal test error is:\\nCV (k) = 1\\nk\\nk∑\\ni=1\\nMSEi (8.1)\\n232Chapter 8 DEEP LEARNING\\nPRB-181 \\uf059 CH.PRB- 8.5.\\nMark all the correct choices regarding a cross-validation approach:\\n(i) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted.\\n(ii) A 5-fold cross-validation approach results in 1 model instance being ﬁtted over and\\nover again 5 times.\\n(iii) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted\\nover and over again 5 times.\\n(iv) Uses K-different data-folds.\\nPRB-182 \\uf059 CH.PRB- 8.6.\\nMark all the correct choices regarding the approach that should be taken to compute the\\nperformance of K-fold cross-validation:\\n(i) We compute the cross-validation performance as the arithmetic mean over the K per-\\nformance estimates from the validation sets.\\n(ii) We compute the cross-validation performance as the best one over the K performance\\nestimates from the validation sets.\\nStratification\\nPRB-183 \\uf059 CH.PRB- 8.7.\\nA data-scientist who is interested in classifying cross sections of histopathology image\\nslices (8.3) decides to adopt a cross-validation approach he once read about in a book. Name\\nthe approach from the following options:\\n2338.2. PROBLEMS\\n1st\\n2nd\\n3rd\\nK-fold CV\\nVAL FOLD TRAIN FOLD\\nFIGURE 8.3: A speciﬁc CV approach\\n(i) 3-fold CV\\n(ii) 3-fold CV with stratiﬁcation\\n(iii) A (repeated) 3-fold CV\\nLOOCV\\nPRB-184 \\uf059 CH.PRB- 8.8.\\n1. T rue or false: The leave-one-out cross-validation (LOOCV) approach is a sub-case of\\nk-fold cross-validation wherein K equals N , the sample size.\\n2. T rue or false: It is always possible to ﬁnd an optimal value n, K = n in K-fold\\ncross-validation.\\n8.2.2 Convolution and correlation\\nThe convolution operator\\nPRB-185 \\uf059 CH.PRB- 8.9.\\nEquation 8.2 is commonly used in image processing:\\n(f ∗ g)(t) =\\n∫ ∞\\n−∞\\nf (τ )g(t − τ )dτ (8.2)\\n234Chapter 8 DEEP LEARNING\\n1. What does equation 8.2 represent?\\n2. What does g(t) represent?\\nPRB-186 \\uf059 CH.PRB- 8.10.\\nA data-scientist assumes that:\\ni A convolution operation is both linear and shift invariant.\\nii A convolution operation is just like correlation, except that we ﬂip over the ﬁlter before\\napplying the correlation operator.\\niii The convolution operation reaches a maximum, only in cases where the ﬁlter is mostly\\nsimilar to a speciﬁc section of the input signal.\\nIs he right in assuming so? Explain in detail the meaning of these statements.\\nThe correlation operator\\nPRB-187 \\uf059 CH.PRB- 8.11.\\nMark the correct choice(s):\\n1. The cross-correlation operator is used to ﬁnd the location where two different signals\\nare most similar.\\n2. The autocorrelation operator is used to ﬁnd when a signal is similar to a delayed ver-\\nsion of itself.\\nPRB-188 \\uf059 CH.PRB- 8.12.\\nA data-scientist provides you with a formulae for a discrete 2D convolution operation\\n(8.3):\\nf (x, y) ∗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf (m, n)h(x − m, y − n) (8.3)\\n2358.2. PROBLEMS\\nUsing only (8.3), write the equivalent 2D correlation operation.\\nPadding and stride\\nRecommended reading : “A guide to convolution arithmetic for deep learning ” by Vincent\\nDumoulin and Francesco Visin (2016) [ 22].\\nPRB-189 \\uf059 CH.PRB- 8.13.\\nWhen designing a convolutional neural network layer, one must also deﬁne how the ﬁlter\\nor kernel slides through the input signal. This is controlled by what is known as the stride\\nand padding parameters or modes. The two most commonly used padding approached in\\nconvolutions are the V ALIDand the SAME modes. Given an input stride of 1:\\n1. Deﬁne SAME\\n2. Deﬁne V ALID\\nPRB-190 \\uf059 CH.PRB- 8.14.\\nTrue or False: A valid convolution is a type of convolution operation that does not use\\nany padding on the input.\\nPRB-191 \\uf059 CH.PRB- 8.15.\\nY ou are provided with aK × K input signal and a θ × θ ﬁlter. The signal is subjected to\\nthe valid padding mode convolution. What are the resulting dimensions?\\narr = [\\n0 ... 0\\n0 ... 0\\n0 ... 0\\n] (8.4)\\nPRB-192 \\uf059 CH.PRB- 8.16.\\nAs depicted in ( 8.4), a ﬁlter is applied to a ×3 input signal. Identify the correct choice\\ngiven a stride of 1 and Same padding mode.\\n236Chapter 8 DEEP LEARNING\\nFIGURE 8.4: A padding approach\\n'),\n",
              " Document(metadata={}, page_content=' V ALID\\nPRB-190 \\uf059 CH.PRB- 8.14.\\nTrue or False: A valid convolution is a type of convolution operation that does not use\\nany padding on the input.\\nPRB-191 \\uf059 CH.PRB- 8.15.\\nY ou are provided with aK × K input signal and a θ × θ ﬁlter. The signal is subjected to\\nthe valid padding mode convolution. What are the resulting dimensions?\\narr = [\\n0 ... 0\\n0 ... 0\\n0 ... 0\\n] (8.4)\\nPRB-192 \\uf059 CH.PRB- 8.16.\\nAs depicted in ( 8.4), a ﬁlter is applied to a ×3 input signal. Identify the correct choice\\ngiven a stride of 1 and Same padding mode.\\n236Chapter 8 DEEP LEARNING\\nFIGURE 8.4: A padding approach\\nPRB-193 \\uf059 CH.PRB- 8.17.\\nAs depicted in in ( 8.5), a ﬁlter is applied to a 3 × 3 input signal, mark the correct choices\\ngiven a stride of 1.\\n(i) A represents a V ALID convolution and B represents a SAME convolution\\n(ii) A represents a SAME convolution and B represents a V ALID convolution\\n(iii) Both A and B represent a V ALID convolution\\n(iv) Both A and B represent a SAME convolution\\n2378.2. PROBLEMS\\nFIGURE 8.5: A padding approach\\nPRB-194 \\uf059 CH.PRB- 8.18.\\nIn this question we discuss the two most commonly used padding approaches in convo-\\nlutions; V ALIDand SAME . Fig.8.6 presents python code for generating an input signal\\narr001 and a convolution kernel f ilter001. The input signal, arr001 is ﬁrst initialized to\\nall zeros as follows:\\narr001 = [\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n] (8.5)\\n1. Without actually executing the code, determine what would be the resulting shape of\\nthe convolve2d() operation.\\n2. Manually compute the result of convolving the input signal with the provided ﬁlter.\\n3. Elaborate why the size of the resulting convolutions is smaller than the size of the\\ninput signal.\\n238Chapter 8 DEEP LEARNING\\n1 import numpy\\n2 import scipy.signal\\n3\\n4 arr01 = numpy.zeros((6, 6),dtype=float)\\n5 print (arr01)\\n6 arr01[:,:3] = 3.0\\n7 arr01[:,3:] = 1.0\\n8\\n9 filter001 = numpy.zeros((3, 3), dtype =float)\\n10 filter001[:,0] = 2.0\\n11 filter001[:,2] = -2.0\\n12\\n13 output = scipy.signal.convolve2d(arr01, filter, mode =\\'valid\\' )\\nFIGURE 8.6: Convolution and correlation in python\\nKernels and filters\\nPRB-195 \\uf059 CH.PRB- 8.19.\\nEquation 8.6 is the discrete equivalent of equation 8.2 which is frequently used in image\\nprocessing:\\n(y ∗ k)[i, j] =\\n∑\\nn\\n∑\\nm\\ny[i − n, j − m]k[n, m] (8.6)\\n1. Given the following discrete kernel in the X direction, what would be the equivalent Y\\ndirection?\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 1\\n−1 1\\n\\uf8f9\\n\\uf8fb (8.7)\\n2. Identify the discrete convolution kernel presented in ( 8.7).\\n2398.2. PROBLEMS\\nFIGURE 8.7: A 3 by 3 convolution kernel\\nPRB-196 \\uf059 CH.PRB- 8.20.\\nGiven an image of size w × h, and a kernel with width K, how many multiplications and\\nadditions are required to convolve the image?\\nConvolution and correlation in python\\nPRB-197 \\uf059 CH.PRB- 8.21.\\nFig.8.8 presents two built-in Python functions for the convolution and correlation oper-\\nators.\\n1 import nympy as np\\n2 np.convolve(A,B,\"full\") # for convolution\\n3 np.correlate(A,B,\"full\") # for cross correlation\\nFIGURE 8.8: Convolution and correlation in python\\n1. Implement the convolution operation from scratch in Python. Compare it with the\\n240Chapter 8 DEEP LEARNING\\nbuilt-in numpy equivalent.\\n2. Implement the correlation operation using the implementation of the convolution op-\\neration. Compare it with the built-in numpy equivalent.\\nSeparable convolutions\\nPRB-198 \\uf059 CH.PRB- 8.22.\\nThe Gaussian distribution in the 1D and 2D is shown in Equations 8.8 and 8.9.\\nG(x) = 1√\\n2πσ e− x2\\n2σ2 (8.8)\\nG(x, y) = 1\\n2πσ 2 e− x2+y2\\n2σ2 (8.9)\\nThe Gaussian ﬁlter, is an operator that is used to blur images and remove detail and\\nnoise while acting like a low-pass ﬁlter. This is similar to the way a mean ﬁlter works, but\\nthe Gaussian ﬁlter uses a different kernel. This kernel is represented with a Gaussian bell\\nshaped bump.\\nAnswer the following questions:\\n1. Can 8.8 be used directly on a 2D image?\\n2. Can 8.9 be used directly on a 2D image?\\n3. Is the Gaussian ﬁlter separable? if so, what are the advantages of separable ﬁlters.\\n8.2.3 Similarity measures\\nImage, text similarity\\nPRB-199 \\uf059 CH.PRB- 8.23.\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n2418.2. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 8.9: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\n1 void xxx(std::vector<float>& arr) {\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nAn unknown algorithm in C++11\\nFIGURE 8.10: listing\\nWhich results in this vector ( 8.11):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 8.11: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n242Chapter 8 DEEP LEARNING\\nPRB-200 \\uf059 CH.PRB- 8.24.\\nFurther to the above, the scientist then applies the following algorithm:\\nAlgorithm 3: Algo 1\\nData: Two vectors v1 and v2 are provided\\nApply algorithm xxx on the two vectors\\nRun algorithm 2\\nAlgorithm 4: Algo 2\\n1 float algo2(const std::vector<float>& v1, const\\nstd::vector<float>& v2){↪→\\n2 double mul = 0;\\n3 for (size_t i = 0; i < v1.size(); ++i){\\n4 mul += v1[i] * v2[i];\\n5 }\\n6 if (mul < 0) {\\n7 return 0;\\n8 }\\n9 return mul;\\n10 }\\nFIGURE 8.12: An unknown algorithm\\n1. Name the algorithm algo2 that he used and explain in detail what he used it for.\\n2. Write the mathematical formulae behind it.\\n3. What are the minimum and maximum values it can return?\\n4. An alternative similarity measures between two vectors is:\\nsimeuc(v1, v2) = −||v1 − v2||. (8.10)\\nName the measure.\\n2438.2. PROBLEMS\\nJacard similarity\\nPRB-201 \\uf059 CH.PRB- 8.25.\\n1. What is the formulae for the Jaccard similarity [ 12] of two sets?:\\n2. Explain the formulae in plain words.\\n3. Find the Jacard similarity given the sets depicted in ( 8.13)\\nFIGURE 8.13: Jaccard similarity .\\n4. Compute the Jaccard similarity of each pair of the following sets:\\ni 12, 14, 16, 18.\\nii 11, 12, 13, 14, 15.\\niii 11, 16, 17.\\nThe Kullback-Leibler Distance\\nPRB-202 \\uf059 CH.PRB- 8.26.\\nIn this problem, you have to actually read 4 different papers, so you will probably not\\nencounter such a question during an interview, however reading academic papers is an ex-\\ncellent skill to master for becoming a DL researcher.\\nRead the following papers which discuss aspects of the Kullback-Leibler divergence:\\ni Bennet [2]\\n244Chapter 8 DEEP LEARNING\\nii Ziv [29]\\niii Bigi [3]\\niv Jensen [1]\\nThe Kullback-Leibler divergence, which was discussed thoroughly in chap 4 is a meas-\\nure of how different two probability distribution are. As noted, the KL divergence of the\\nprobability distributions P , Q on a set X is deﬁned as shown in Equation 8.11.\\nDKL(P ||Q) =\\n∑\\nx∈X\\nP (x)log P (x)\\nQ(x) (8.11)\\nNote however that since KL divergence is a non-symmetric information theoretical meas-\\nure of distance of P from Q, then it is not strictly a distance metric. During the past years,\\nvarious KL based distance measures (rather than divergence based) have been introduced in\\nthe literature generalizing this measure.\\nName each of the following KL based distances:\\nDKLD 1(P ||Q) = DKL(P ||Q) + DKL(Q||P ) (8.12)\\nDKLD 2(P ||Q) =\\n∑\\nx∈X\\n(P (x) − Q(x))log P (x)\\nQ(x) (8.13)\\nDKLD 3(P ||Q) = 1\\n2\\n[\\nDKL\\n(\\nP ||P + Q\\n2\\n)\\n+ DKL\\n(\\nQ||P + Q\\n2\\n)]\\n(8.14)\\nDKLD 4(P ||Q) = max (DKL(P ||Q) + DKL(Q||P )) (8.15)\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nPRB-203 \\uf059 CH.PRB- 8.27.\\nWhat is the goal of hashing? Draw a simple HashMap of keys and values. Explain what\\nis a collision and the notion of buckets. Explain what is the goal of MinHash.\\n2458.2. PROBLEMS\\nPRB-204 \\uf059 CH.PRB- 8.28.\\nWhat is Locality Sensitive Hashing or LSH?\\nPRB-205 \\uf059 CH.PRB- 8.29.\\nComplete the sentence : LSH main goal is to [...] the probability of a colliding, for\\nsimilar items in a corpus.\\n8.2.4 Perceptrons\\nThe Single Layer Perceptron\\nPRB-206 \\uf059 CH.PRB- 8.30.\\n1. complete the sentence : In a single-layer feed-forward NN, there are [...] input(s)\\nand [...]. output layer(s) and no [...] connections at all.\\nPRB-207 \\uf059 CH.PRB- 8.31.\\nIn its simplest form, a perceptron (8.16) accepts only a binary input and emits a binary\\noutput. The output, can be evaluated as follows:\\noutput =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0, if ∑\\nj wjxj + b ≤ 0,\\n1, if\\n∑\\nj wjxj + b > 0\\n. (8.16)\\nWhere weights are denoted by wj and biases are denoted by b. Answer the following ques-\\ntions:\\n1. T rue or False: If such a perceptron is trained using a labelled corpus, for each parti-\\ncipating neuron the values wj and b are learned automatically.\\n2. T rue or False: If we instead use a new perceptron (sigmoidial) deﬁned as follows:\\nσ(wx + b) (8.17)\\n246Chapter 8 DEEP LEARNING\\nwhere σ is the sigmoid function:\\nσ(z) = 1\\n1 + e−z . (8.18)\\nThen the new perceptron can process inputs ranging between 0 and 1 and emit output\\nranging between 0 and 1.\\n3. Write the cost function associated with the sigmoidial neuron.\\n4. If we want to train the perceptron in order to obtain the best possible weights and\\nbiases, which mathematical equation do we have to solve?\\n5. Complete the sentence: T o solve this mathematical equation, we have to apply [...]\\n6. What does the following equation stands for?\\n∇C = 1\\nn\\n∑\\nx\\n∇Cx (8.19)\\nWhere:\\nCx = 1\\n2∥y(x) − a(x, w, b)∥2 (8.20)\\n7. Complete the sentence: Due to the time-consuming nature of computing gradients for\\neach entry in the training corpus, modern DL libraries utilize a technique that gauges\\nthe gradient by ﬁrst randomly sampling a subset from the training corpus, and then\\naveraging only this subset in every epoch. This approach is known as [...]. The actual\\nnumber of randomly chosen samples in each epoch is termed [...]. The gradient itself\\nis obtained by an algorithm known as [...].\\nThe Multi Layer Perceptron\\nPRB-208 \\uf059 CH.PRB- 8.32.\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\n2478.2. PROBLEMS\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 8.14: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the value resulting from the application the sum operator?\\n3. Verify the correctness of your results using PyT orch.\\nActivation functions in perceptrons\\nPRB-209 \\uf059 CH.PRB- 8.33.\\nThe following questions refer to the MLP depicted in ( 8.15).\\n1. Further to the above, the ReLU non-linear activation function g(z) = max {0, z} is\\napplied ( 8.15) to the output of the linear transformation. What is the value of the\\noutput (out2) now?\\nx1\\nH1\\nx2\\ng(x1, x2)\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1 out2\\n0.001\\nInputs Hidden ActivationSum\\nFIGURE 8.15: Several nodes in a MLP .\\n248Chapter 8 DEEP LEARNING\\n2. Conﬁrm your manual calculation using PyT orch tensors.\\nBack-propagation in perceptrons\\nPRB-210 \\uf059 CH.PRB- 8.34.\\nY our co-worker, an postgraduate student at M.I.T, suggests using the following activa-\\ntion functions in a MLP . Which ones can never be back-propagated and why?\\ni\\nf (x) = |x| (8.21)\\nii\\nf (x) = x (8.22)\\niii\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx sin(1/x) if x ̸= 0\\n0 if x = 0\\n(8.23)\\niv\\nf (x) =\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f3\\nx2 x > 0\\n−x x < 0\\n0 x = 0\\n(8.24)\\nPRB-211 \\uf059 CH.PRB- 8.35.\\nY ou are provided with the following MLP as depicted in 8.16.\\n2498.2. PROBLEMS\\nθ0\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nγ2\\nFIGURE 8.16: A basic MLP\\nThe ReLU non-linear activation function g(z) = max {0, z} is applied to the hidden\\nlayers H1...H3 and the bias term equals 0.001.\\nAt a certain point in time it has the following values 8.17 all of which are belong to the\\ntype torch.F loatT ensor:\\n1 import torch\\n2 x= torch.tensor([0.9,0.7]) # Input\\n3 w= torch.tensor([\\n4 [-0.3,0.15],\\n5 [0.32,-0.91],\\n6 [0.37,0.47],\\n7 ]) # Weights\\n8 B= torch.tensor([0.002]) # Bias\\nFIGURE 8.17: MLP operations.\\n1. Using Python, calculate the output of the MLP at the hidden layers H1...H3.\\n2. Further to the above, you discover that at a certain point in time that the weights\\nbetween the hidden layers and the output layers γ1 have the following values:\\n1 w1= torch.tensor([\\n2 [0.15,-0.46,0.59],\\n3 [0.10,0.32,-0.79],\\n4 )\\n250Chapter 8 DEEP LEARNING\\nWhat is the value observed at the output nodes γ1..γ2?\\n3. Assume now that a Softmax activation is applied to the output. What are the resulting\\nvalues?\\n4. Assume now that a cross-entropy loss is applied to the output of the Softmax.\\nL = −\\n∑\\ni\\nˆyi log (yi) (8.25)\\nWhat are the resulting values?\\nThe theory of perceptrons\\nPRB-212 \\uf059 CH.PRB- 8.36. If someone is quoted saying:\\nMLP networks are universal function approximators.\\nWhat does he mean?\\nPRB-213 \\uf059 CH.PRB- 8.37.\\nT rue or False: the output of a perceptron is 0 or 1.\\nPRB-214 \\uf059 CH.PRB- 8.38.\\nT rue or False: A multi-layer perceptron falls under the category of supervised machine\\nlearning.\\nPRB-215 \\uf059 CH.PRB- 8.39.\\nT rue or False: The accuracy of a perceptron is calculated as the number of correctly\\nclassiﬁed samples divided by the total number of incorrectly classiﬁed samples.\\nLearning logical gates\\n2518.2. PROBLEMS\\nPRB-216 \\uf059 CH.PRB- 8.40.\\nThe following questions refer to the SLP depicted in ( 8.18). The weights in the SLP are\\nw1 = 1 and w2 = 1 respectively. There is a single hidden node, H1. The bias term, B1 equals\\n−2.5.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1 =\\n1\\nw2 =\\n1\\nout1\\n−2.5\\nInputs\\nHidden\\nSum\\nFIGURE 8.18: A single layer perceptron.\\n1. Assuming the inputs to the SLP in ( 8.18) are\\ni x1 = 0.0 and x2 = 0.0\\nii x1 = 0.0 and x2 = 1.0\\niii x1 = 1.0 and x2 = 0.0\\niv x1 = 1.0 and x2 = 1.0\\nWhat is the value resulting from the application the sum operator?\\n2. Repeat the above, assuming now that the bias term B1 was amended and equals −0.25.\\n3. Deﬁne what is the perceptron learning rule.\\n4. What was the most crucial difference between Rosenblatt’s original algorithm and\\nHinton’s fundamental papers of 1986:\\n“Learning representations by back-propagating errors ” [22]\\nand 2012:\\n“ImageNet Classiﬁcation with Deep Convolutional Neural Networks ” [18]?\\n5. The AND logic gate [ 7] is deﬁned by the following table ( 8.19):\\n252Chapter 8 DEEP LEARNING\\nx1 x2 y\\n1 1 1\\n1 0 0\\n0 1 0\\n0 0 0\\nFIGURE 8.19: Logical AND gate\\nCan a perceptron with only two inputs and a single output function as an AND logic\\ngate? If so, ﬁnd the weights and the threshold and demonstrate the correctness of your\\nanswer using a truth table.\\n8.2.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\nPRB-217 \\uf059 CH.PRB- 8.41.\\nThe Sigmoid sc(x) = 1\\n1+e−cx , also commonly known as the logistic function (Fig. 8.20),\\nis widely used in binary classiﬁcation and as a neuron activation function in artiﬁcial neural\\nnetworks. Typically, during the training of an ANN, a Sigmoid layer applies the Sigmoid\\nfunction to elements in the forward pass, while in the backward pass the chain rule is be-\\ning utilized as part of the backpropagation algorithm. In 8.20 the constant c was selected\\narbitrarily as 2 and 5 respectively.\\n2538.2. PROBLEMS\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−2x\\nσ(x) = 1\\n1+e−5x\\nσ(x) = 1\\n1+2−1.5x\\nFIGURE 8.20: Examples of two sigmoid functions and an approximation.\\nDigital hardware implementations of the sigmoid function do exist but they are expens-\\nive to compute and therefore several approximation methods were introduced by the research\\ncommunity. The method by [ 10] uses the following formulas to approximate the exponential\\nfunction:\\nex ≈ Ex(x) ≈ 21.44x (8.26)\\nBased on this formulation, one can calculate the sigmoid function as:\\nSigmoid (x) ≈ 1\\n1 + 2−1.44x ≈ 1\\n1 + 2−1.5x (8.27)\\n1. Code snippet 8.21 provides a pure C++ based (e.g. not using Autograd) implementa-\\ntion of the forward pass for the Sigmoid function. Implement the backward pass that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19] style tensors.\\n254Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001( const torch::Tensor & x ){\\n5 torch::Tensor sig = 1.0 / (1.0 + torch::exp(( -x)));\\n6 return sig;\\n7 }\\nFIGURE 8.21: Forward pass for the Sigmoid function using Libtorch\\n2. Code snippet 8.22 provides a skeleton for printing the values of the sigmoid and its\\nderivative for a range of values contained in the vector v. Complete the code (lines 7-8)\\nso that the values are printed.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 ...\\n8 ...\\n9 }\\n10 }\\n.\\nFIGURE 8.22: Evaluation of the sigmoid and its derivative using Libtorch\\n3. Manually derive the derivative of eq. 8.27, e.g:\\nd\\ndx\\n[ 1\\n1 + 2−1.5x\\n]\\n(8.28)\\n2558.2. PROBLEMS\\n4. Implement both the forward pass for the Sigmoid function approximation eq. 8.27 that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19].\\n5. Print the values of the Sigmoid function and the Sigmoid function approximation eq.\\n8.27 for the following vector:\\nv = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] (8.29)\\nTanh\\nPRB-218 \\uf059 CH.PRB- 8.42.\\nThe Hyperbolic tangent nonlinearity, or the tanh function (Fig. 8.23), is a widely used\\nneuron activation function in artiﬁcial neural networks:\\nftanh (x) = sinh(x)\\ncosh(x) = ex − e−x\\nex + e−x (8.30)\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−4,0\\n−2,0\\n2,0\\n4,0\\nx\\nyσ(x) = 4 ∗ tanh x\\n4\\nσ(x) = tanh x\\n4\\nFIGURE 8.23: Examples of two tanh functions.\\n1. Manually derive the derivative of the tanh function.\\n256Chapter 8 DEEP LEARNING\\n2. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n3. Use the PyT orch based torch.autograd.F unction class to write a custom Function\\nthat implements the forward and backward passes for the tanh function in Python.\\n4. Name the class T anhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\nPRB-219 \\uf059 CH.PRB- 8.43.\\nThe code snippet in 8.24 makes use of the tanh function.\\n1 import torch\\n2\\n3 nn001 = nn.Sequential(\\n4 nn.Linear(200, 512),\\n5 nn.Tanh(),\\n6 nn.Linear(512, 512),\\n7 nn.Tanh(),\\n8 nn.Linear(512, 10),\\n9 nn.LogSoftmax(dim=1)\\n10 )\\nFIGURE 8.24: A simple NN based on tanh in PyTorch.\\n1. What type of a neural network does nn001 in 8.24 represent?\\n2. How many hidden layers does the layer entitles nn001 have?\\nPRB-220 \\uf059 CH.PRB- 8.44.\\n2578.2. PROBLEMS\\nY our friend, a veteran of the DL community claims that MLPs based on tanh activation\\nfunction, have a symmetry around 0 and consequently cannot be saturated. Saturation, so\\nhe claims is a phenomenon typical of the top hidden layers in sigmoid based MLPs. Is he\\nright or wrong?\\nPRB-221 \\uf059 CH.PRB- 8.45.\\nIf we initialize the weights of a tanh based NN, which of the following approaches will\\nlead to the vanishing gradients problem?.\\ni Using the normal distribution, with parameter initialization method as suggested by\\nKaiming [14].\\nii Using the uniform distribution, with parameter initialization method as suggested by\\nXavier Glorot [9].\\niii Initialize all parameters to a constant zero value.\\nPRB-222 \\uf059 CH.PRB- 8.46.\\nY ou friend, who is experimenting with the tanh activation function designed a small\\nCNN with only one hidden layer and a linear output ( 8.25):\\nFIGURE 8.25: A small CNN composed of tanh blocks.\\nHe initialized all the weights and biases (biases not shown for brevity) to zero. What is\\nthe most signiﬁcant design ﬂaw in his architecture?\\nHint: think about back-propagation.\\nReLU\\nPRB-223 \\uf059 CH.PRB- 8.47.\\n258Chapter 8 DEEP LEARNING\\nThe rectiﬁed linear unit, or ReLU g(z) = max {0, z} is the default for many CNN archi-\\ntectures. It is deﬁned by the following function:\\nfReLU(x) = max(0 , x) (8.31)\\nOr:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.32)\\n1. In what sense is the ReLU better than traditional sigmoidal activation functions?\\nPRB-224 \\uf059 CH.PRB- 8.48.\\nY ou are experimenting with the ReLU activation function, and you design a small CNN\\n(8.26) which accepts an RGB image as an input. Each CNN kernel is denoted by w.\\nFIGURE 8.26: A small CNN composed of ReLU blocks.\\nWhat is the shape of the resulting tensor W ?\\nPRB-225 \\uf059 CH.PRB- 8.49.\\nName the following activation function where a ∈ (0, 1):\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx if x > 0\\nax otherwise\\n(8.33)\\nSwish\\n2598.2. PROBLEMS\\nPRB-226 \\uf059 CH.PRB- 8.50.\\nIn many interviews, you will be given a paper that you have never encountered before,\\nand be required to read and subsequently discuss it. Please read Searching for Activation\\nFunctions [21] before attempting the questions in this question.\\n1. In [21], researchers employed an automatic pipeline for searching what exactly?\\n2. What types of functions did the researchers include in their search space?\\n3. What were the main ﬁndings of their research and why were the results surprising?\\n4. Write the formulae for the Swish activation function.\\n5. Plot the Swish activation function.\\n8.2.6 Performance Metrics\\nComparing different machine learning models, tuning hyper parameters and learn-\\ning rates, ﬁnding optimal augmentations, are all important steps in ML research. Typ-\\nically our goal is to ﬁnd the best model with the lowest errors on both the training\\nand validation sets. To do so we need to be able to measure the performance of each\\napproach/model/parameter setting etc. and compare those measures. For valuable\\nreference, read: “Evaluating Learning Algorithms: A Classiﬁcation Perspective ” [22]\\nConfusion matrix, precision, recall\\nPRB-227 \\uf059 CH.PRB- 8.51.\\nY ou design a binary classiﬁer for detecting the presence of malfunctioning temperature\\nsensors. Non-malfunctioning (N) devices are the majority class in the training corpus. While\\nrunning inference on an unseen test-set, you discover that the Confusion Metrics (CM) has\\nthe following values 8.27:\\n260Chapter 8 DEEP LEARNING\\nPredicted\\nP N\\nActual P 12 7\\nN 24 1009\\nFIGURE 8.27: A confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices.\\n1. Find: TP , TN, FP , FN and correctly label the numbers in table 8.27.\\n2. What is the accuracy of the model?\\n3. What is the precision of the model?\\n4. What is the recall of the model?\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\nFIGURE 8.28: Receiver Operating Characteristic curve.\\n2618.2. PROBLEMS\\nPRB-228 \\uf059 CH.PRB- 8.52.\\nComplete the following sentences:\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween [...] and [...].\\n2. It is a plot of [...] vs. the [...]. In place of [...], one could also use [...] which are essen-\\ntially {1 - ‘true negatives’ }.\\n3. A typical ROC curve has a concave shape with [...] as the beginning and [...] as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely con-\\nfused and cannot at all distinguish between the two classes, has an AUC of [...] which\\nis the [...] line in an ROC curve plot.\\nPRB-229 \\uf059 CH.PRB- 8.53.\\nThe code 8.30 and Figure 8.29 are the output from running XGBOOST for a binary\\nclassiﬁcation task.\\nFIGURE 8.29: RUC AUC\\n262Chapter 8 DEEP LEARNING\\n1 XGBClassifier(base_score=0.5, colsample_bylevel =1,\\ncolsample_bytree=0.5,↪→\\n2 gamma=0.017, learning_rate =0.15, max_delta_step =0, max_depth =9,\\n3 min_child_weight=3, missing =None, n_estimators =1000, nthread =-1,\\n4 objective=\\'binary:logistic\\' , reg_alpha =0, reg_lambda =1,\\n5 scale_pos_weight=1, seed =0, silent =1,\\nsubsample=0.9)shape:(316200, 6)↪→\\n6\\n7 >ROC AUC: 0.984439608912\\n8 >LOG LOSS: 0.0421598347226\\nFIGURE 8.30: XGBOOST for binary classiﬁcation.\\nHow would you describe the results of the classiﬁcation?.\\n8.2.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nPRB-230 \\uf059 CH.PRB- 8.54.\\nGiven an input of size of n × n, ﬁlters of size f × f and a stride of s with padding of p,\\nwhat is the output dimension?\\nPRB-231 \\uf059 CH.PRB- 8.55.\\nReferring the code snippet in Fig. ( 8.31), answer the following questions regarding the\\nVGG11 architecture [25]:\\n2638.2. PROBLEMS\\n1 import torchvision\\n2 import torch\\n3 def main():\\n4 vgg11 = torchvision.models.vgg11(pretrained=True)\\n5 vgg_layers = vgg11.features\\n6 for param in vgg_layers.parameters():\\n7 param.requires_grad = False\\n8\\n9 example = [torch.rand(1, 3, 224, 224),\\n10 torch.rand(1, 3, 512, 512),\\n11 torch.rand(1, 3, 704, 1024)]\\n12 vgg11.eval()\\n13 for e in example:\\n14 out=vgg_layers(e)\\n15 print(out.shape)\\n16 if __name__ == \"__main__\":\\n17 main()^^I^^I\\nFIGURE 8.31: CNN arithmetics on the VGG11 CNN model.\\n1. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the VGG11 CNN to the respective input.\\n2. Choose the correct option. The last layer of the VGG11 architecture is:\\ni Conv2d\\nii MaxPool2d\\niii ReLU\\nPRB-232 \\uf059 CH.PRB- 8.56.\\nStill referring the code snippet in Fig. ( 8.31), and speciﬁcally to line 7, the code is\\namended so that the line is replaced by the line:\\nvgg_layers=vgg11.features[:3] .\\n264Chapter 8 DEEP LEARNING\\n1. What type of block is now represented by the new line? Print it using PyT orch.\\n2. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the block:\\nvgg_layers=vgg11.features[:3] to the respective input.\\nPRB-233 \\uf059 CH.PRB- 8.57.\\nT able (8.1) presents an incomplete listing of the of the VGG11 architecture [ 25]. As\\ndepicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters) are\\npresented.\\nLayer #Filters\\nconv4_3 512\\nfc6 4,096\\nfc7 4,096\\noutput 1,000\\nTABLE 8.1: Incomplete listing of the VGG11 architecture.\\nComplete the missing parts regarding the dimensions and arithmetics of the VGG11\\nCNN architecture:\\n1. The VGG11 architecture consists of [...] convolutional layers.\\n2. Each convolutional layer is followed by a [...] activation function, and ﬁve [...] opera-\\ntions thus reducing the preceding feature map size by a factor of [...].\\n3. All convolutional layers have a [...] kernel.\\n4. The ﬁrst convolutional layer produces [...] channels.\\n5. Subsequently as the network deepens, the number of channels [...] after each [...] oper-\\nation until it reaches [...].\\n2658.2. PROBLEMS\\nDropout\\nPRB-234 \\uf059 CH.PRB- 8.58.\\nA Dropout layer [26] (Fig. 8.32) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 8.32: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [20], a Dropout layer is declared as follows ( 8.2):\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 8.2: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 8.2) indicates that the probability of zeroing an\\nelement is 0.2.\\n266Chapter 8 DEEP LEARNING\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 8.33: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 8.32). Here, for illustration purposes, all four\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\n1. Y ou are interested in the proportionθ of dropped-out neurons. Assume that the chance\\nof drop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the\\nposterior of θ.\\n2. Describe the similarities of dropout to bagging.\\nPRB-235 \\uf059 CH.PRB- 8.59.\\nA co-worker claims he discovered an equivalence theorem where, two consecutive Dro-\\npout layers [26] can be replaced and represented by a single Dropout layer 8.34.\\nFIGURE 8.34: Two consecutive Dropout layers\\nHi realized two consecutive layers in PyT orch [20], declared as follows ( 8.3):\\n2678.2. PROBLEMS\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Sequential(\\n4 nn.Conv2d(1024, 32),\\n5 nn.ReLU(),\\n6 nn.Dropout(p=P, inplace =True),\\n7 nn.Dropout(p=Q, inplace =True)\\n8 )\\nCODE 8.3: Consequtive dropout in PyTorch\\nWhere nn.Dropout(0.1) (Line #6 in 8.3) indicates that the probability of zeroing an\\nelement is 0.1.\\n1. What do you think about his idea, is he right or wrong?\\n2. Either prove that he is right or provide a single example that refutes his theorem.\\nConvolutional Layer\\nThe convolution layer is probably one of the most important layers in the theory and\\npractice of modern deep learning and computer vision in particular.\\nTo study the optimal number of convolutional layers for the classiﬁcation of two\\ndifferent types of the Ebola virus, a researcher designs a binary classiﬁcation pipeline\\nusing a small CNN with only a few layers ( 8.35):\\n268Chapter 8 DEEP LEARNING\\nFIGURE 8.35: A CNN based classiﬁcation system.\\nAnswer the following questions while referring to ( 8.35):\\nPRB-236 \\uf059 CH.PRB- 8.60.\\nIf he uses the following ﬁlter for the convolutional operation, what would be the resulting\\ntensor after the application of the convolutional layer?\\nFIGURE 8.36: A small ﬁlter for a CNN\\nPRB-237 \\uf059 CH.PRB- 8.61.\\nWhat would be the resulting tensor after the application of the ReLU layer ( 8.37)?\\n2698.2. PROBLEMS\\nFIGURE 8.37: The result of applying the ﬁlter.\\nPRB-238 \\uf059 CH.PRB- 8.62.\\nWhat would be the resulting tensor after the application of the MaxPool layer ( 8.78)?\\nPooling Layers\\nA pooling layer transforms the output of a convolutional layer, and neurons in a pool-\\ning layer accept the outputs of a number of adjacent feature maps and merge their\\noutputs into a single number.\\nMaxPooling\\nPRB-239 \\uf059 CH.PRB- 8.63.\\nThe following input 8.38 is subjected to a MaxPool2D(2,2) operation having 2 × 2 max-\\npooling ﬁlter with a stride of 2 and no padding at all.\\n270Chapter 8 DEEP LEARNING\\nFIGURE 8.38: Input to MaxPool2d operation.\\nAnswer the following questions:\\n1. What is the most common use of max-pooling layers?\\n2. What is the result of applying the MaxPool2d operation on the input?\\nPRB-240 \\uf059 CH.PRB- 8.64.\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and evaluate its behaviour during inference:\\n2718.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 8.4: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n272Chapter 8 DEEP LEARNING\\nFIGURE 8.39: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist'),\n",
              " Document(metadata={}, page_content='.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 8.4: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n272Chapter 8 DEEP LEARNING\\nFIGURE 8.39: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet a second MaxPool2D(2,2).\\nWhat is the resulting tensor shape after running line 9? and line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\nBatch normalization, Gaussian PDF\\nRecommended readings for this topic are “ Batch Normalization: Accelerating Deep Net-\\nwork T raining by Reducing Internal Covariate Shift ” [16] and “ Delving deep into rectiﬁers:\\nSurpassing human-level performance on imagenet classiﬁcation ” [14].\\nA discussion of batch normalization (BN) would not be complete without a discus-\\nsion of the Gaussian normal distribution. Though it would be instructive to develop\\nthe forward and backwards functions for a BN operation from scratch, it would also\\nbe quite complex. As an alternative we discuss several aspects of the BN operation\\nwhile expanding on the Gaussian distribution.\\n2738.2. PROBLEMS\\nThe Gaussian distribution\\nPRB-241 \\uf059 CH.PRB- 8.65.\\n1. What is batch normalization?\\n2. The normal distribution is deﬁned as follows:\\nP (x) = 1\\nσ\\n√\\n2π e−(x−µ)2/2σ2\\n(8.34)\\nGenerally i.i.d. X ∼ N (µ, σ2) however BN uses the standard normal distribution.\\nWhat mean and variance does the standard normal distribution have?\\n3. What is the mathematical process of normalization?\\n4. Describe, how normalization works in BN.\\nPRB-242 \\uf059 CH.PRB- 8.66.\\nIn python, the probability density function for a normal distribution is given by 8.40:\\n1 import scipy\\n2 scipy.stats.norm.pdf(x, mu, sigma)\\nFIGURE 8.40: Normal distribution in Python.\\n1. Without using Scipy, implement the normal distribution from scratch in Python.\\n2. Assume, you want to back propagate on the normal distribution, and therefore you\\nneed the derivative. Using Scipy write a function for the derivative.\\nBN\\nPRB-243 \\uf059 CH.PRB- 8.67.\\n274Chapter 8 DEEP LEARNING\\nY our friend, a novice data scientist, uses an RGB image ( 8.41) which he then subjects to\\nBN as part of training a CNN.\\nFIGURE 8.41: A convolution and BN applied to an RGB image.\\n1. Help him understand, during BN, is the normalization applied pixel-wise or per colour\\nchannel?\\n2. In the PyT orch implementation, he made a silly mistake 8.42, help him identify it:\\n2758.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class BNl001(nn.Module):\\n4 def __init__(self):\\n5 super(BNl001, self).__init__()\\n6 self.cnn = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 64, kernel_size =3, padding =2),\\n8 )\\n9 self.math= torch.nn.Sequential(\\n10 torch.nn.BatchNorm2d(32),\\n11 torch.nn.PReLU(),\\n12 torch.nn.Dropout2d(0.05)\\n13 )\\n14 def forward(self, x):\\n15 ...\\nFIGURE 8.42: A mistake in a CNN\\nTheory of CNN design\\nPRB-244 \\uf059 CH.PRB- 8.68.\\nTrue or false: An activation function applied after a Dropout, is equivalent to an activ-\\nation function applied before a dropout.\\nPRB-245 \\uf059 CH.PRB- 8.69.\\nWhich of the following core building blocks may be used to construct CNNs? Choose all\\nthe options that apply:\\ni Pooling layers\\nii Convolutional layers\\niii Normalization layers\\niv Non-linear activation function\\n276Chapter 8 DEEP LEARNING\\nv Linear activation function\\nPRB-246 \\uf059 CH.PRB- 8.70.\\nY ou are designing a CNN which has a single BN layer. Which of the following core CNN\\ndesigns are valid? Choose all the options that apply:\\ni CONV → act → BN → Dropout → . . .\\nii CONV → act → Dropout → BN → . . .\\niii CONV → BN → act → Dropout → . . .\\niv BN → CONV → act → Dropout → . . .\\nv CONV → Dropout → BN → act → . . .\\nvi Dropout → CONV → BN → act → . . .\\nPRB-247 \\uf059 CH.PRB- 8.71.\\nThe following operator is known as the Hadamard product:\\nOUT = A ⊙ B (8.35)\\nWhere:\\n(A ⊙ B)i,j := (A)i,j(B)i,j (8.36)\\nA scientist, constructs a Dropout layer using the following algorithm:\\ni Assign a probability of p for zeroing the output of any neuron.\\nii Accept an input tensor T , having a shape S\\niii Generate a new tensor T ‘∈ {0, 1}S\\niv Assign each element in T ‘a randomly and independently sampled value from a Bernoulli\\ndistribution:\\nT ‘i ∼ B(1, p) (8.37)\\n2778.2. PROBLEMS\\nv Calculate the OU T tensor as follows:\\nOUT = T ‘⊙ T (8.38)\\nY ou are surprised to ﬁnd out that his last step is to multiply the output of a dropout layer\\nwith:\\n1\\n1 − p (8.39)\\nExplain what is the purpose of multiplying by the term 1\\n1−p .\\nPRB-248 \\uf059 CH.PRB- 8.72.\\nVisualized in (8.43) from a high-level view, is an MLP which implements a well-known\\nidiom in DL.\\nFIGURE 8.43: A CNN block\\n1. Name the idiom.\\n2. What can this type of layer learn?\\n3. A fellow data scientist suggests amending the architecture as follows ( 8.44)\\n278Chapter 8 DEEP LEARNING\\nFIGURE 8.44: A CNN block\\nName one disadvantage of this new architecture.\\n4. Name one CNN architecture where the input equals the output.\\nCNN residual blocks\\nPRB-249 \\uf059 CH.PRB- 8.73.\\nAnswer the following questions regarding residual networks ([ 13]).\\n1. Mathematically, the residual block may be represented by:\\ny = x + F(x) (8.40)\\nWhat is the function F?\\n2. In one sentence, what was the main idea behind deep residual networks (ResNets) as\\nintroduced in the original paper ([ 13])?\\nPRB-250 \\uf059 CH.PRB- 8.74.\\nY our friend was thinking about ResNet blocks, and tried to visualize them in ( 8.45).\\n2798.2. PROBLEMS\\nFIGURE 8.45: A resnet CNN block\\n1. Assuming a residual of the form y = x + F(x), complete the missing parts in Fig.\\n(8.45).\\n2. What does the symbol ⊕ denotes?\\n3. A fellow data scientist, who had coffee with you said that residual blocks may compute\\nthe identity function. Explain what he meant by that.\\n8.2.8 Training, hyperparameters\\nHyperparameter optimization\\nPRB-251 \\uf059 CH.PRB- 8.75.\\nA certain training pipeline for the classiﬁcation of large images (1024 x 1024) uses the\\nfollowing Hyperparameters (8.46):\\n280Chapter 8 DEEP LEARNING\\nHyperparameter Value\\nInitial learning rate 0.1\\nWeight decay 0.0001\\nMomentum 0.9\\nBatch size 1024\\n1 optimizer = optim.SGD(model.parameters(), lr =0.1,\\n2 momentum=0.9,\\n3 weight_decay=0.0001)\\n4 ...\\n5 trainLoader = torch.utils.data.DataLoader(\\n6 datasets.LARGE(\\'../data\\' , train =True, download =True,\\n7 transform=transforms.Compose([\\n8 transforms.ToTensor(),\\n9 ])),\\n10 batch\\\\_size=1024, shuffle =True)\\nFIGURE 8.46: Hyperparameters.\\nIn your opinion, what could possibly go wrong with this training pipeline?\\nPRB-252 \\uf059 CH.PRB- 8.76.\\nA junior data scientist in your team who is interested in Hyperparameter tuning, wrote\\nthe following code ( 8.5) for spiting his corpus into two distinct sets and ﬁtting an LR model:\\n2818.2. PROBLEMS\\n1 from sklearn.model_selection import train_test_split\\n2 dataset = datasets.load_iris()\\n3 X_train, X_test, y_train, y_test =\\n4 train_test_split(dataset.data, dataset .target, test_size =0.2)\\n5 clf = LogisticRegression(data_norm=12)\\n6 clf.fit(X_train, y_train)\\nCODE 8.5: Train and Validation split.\\nHe then evaluated the performance of the trained model on the Xtest set.\\n1. Explain why his methodology is far from perfect.\\n2. Help him resolve the problem by utilizing a difference splitting methodology.\\n3. Y our friend now amends the code an uses:\\n1 clf = GridSearchCV(method, params, scoring =\\'roc_auc\\' , cv =5)\\n2 clf.fit(train_X, train_y)\\nExplain why his new approach may work better.\\nPRB-253 \\uf059 CH.PRB- 8.77.\\nIn the context of Hyperparameter optimization, explain the difference between grid search\\nand random search.\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nPRB-254 \\uf059 CH.PRB- 8.78.\\n282Chapter 8 DEEP LEARNING\\nNon-invasive methods that forecast the existence of lung nodules ( 8.47), is a precursor\\nto lung cancer. Y et, in spite of acquisition standardization attempts, the manual detection of\\nlung nodules still remains predisposed to inter mechanical and observer variability. What is\\nmore, it is a highly laborious task.\\nFIGURE 8.47: Pulmonary nodules.\\nIn the majority of cases, the training data is manually labelled by radiologists who make\\nmistakes. Imagine you are working on a classiﬁcation problem and hire two radiologists for\\nlung cancer screening based on low-dose CT (LDCT). Y ou ask them to label the data, the\\nﬁrst radiologist labels only the training set and the second the validation set. Then you hire\\na third radiologist to label the test set.\\n1. Do you think there is a design ﬂow in the curation of the data sets?\\n2. A friend suggests that all there radiologists read all the scans and label them independ-\\nently thus creating a majority vote. What do you think about this idea?\\nValidation curve ACC\\nPRB-255 \\uf059 CH.PRB- 8.79.\\nAnswer the following questions regarding the validation curve visualized in ( 8.48):\\n2838.2. PROBLEMS\\n20 40 60 80 100\\n0,2\\n0,4\\n0,6\\n0,8\\nEPOCH\\nERR V ALID\\nTRAIN\\nFIGURE 8.48: A validation curve.\\n1. Describe in one sentence, what is a validation curve.\\n2. Which hyperparameter is being used in the curve?\\n3. Which well-known metric is being used in the curve? Which other metric is commonly\\nused?\\n4. Which positive phenomena happens when we train a NN longer?\\n5. Which negative phenomena happens when we train a NN longer than we should?\\n6. How this negative phenomena is reﬂected in 8.48?\\nValidation curve Loss\\nPRB-256 \\uf059 CH.PRB- 8.80.\\nRefer to the validation log-loss curve visualized in ( 8.49) and answer the following ques-\\ntions:\\n284Chapter 8 DEEP LEARNING\\nFIGURE 8.49: Log-loss function curve.\\n1. Name the phenomena that starts happening right after the marking by the letter E and\\ndescribe why it is happening.\\n2. Name three different weight initialization methods.\\n3. What is the main idea behind these methods?\\n4. Describe several ways how this phenomena can be alleviated.\\n5. Y our friend, a fellow data-scientist, inspects the code and sees the following Hyper-\\nparameters are being used:\\nHyperparameter Value\\nInitial LR 0.00001\\nMomentum 0.9\\nBatch size 1024\\nHe then tells you that the learning rate (LR) is constant and suggests amending the\\ntraining pipeline by adding the following code ( 8.50):\\n2858.2. PROBLEMS\\n1 scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt)\\nFIGURE 8.50: A problem with the log-loss curve.\\nWhat do you think about his idea?\\n6. Provide one reason against the use of the log-loss curve.\\nInference\\nPRB-257 \\uf059 CH.PRB- 8.81.\\nY ou ﬁnished training a face recognition algorithm, which uses a feature vector of 128\\nelements. During inference, you notice that the performance is not that good. A friend tells\\nyou that in computer vision faces are gathered in various poses and perspectives. He there-\\nfore suggests that during inference you would augment the incoming face ﬁve times, run\\ninference on each augmented image and then fuse the output probability distributions by\\naveraging.\\n1. Name the method he is suggesting.\\n2. Provide several examples of augmentation that you might use during inference.\\nPRB-258 \\uf059 CH.PRB- 8.82.\\nComplete the sentence: If the training loss is insigniﬁcant while the test loss is signiﬁc-\\nantly higher, the network has almost certainly learned features which are not present in an\\n[...] set. This phenomena is referred to as [...]\\n8.2.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nPRB-259 \\uf059 CH.PRB- 8.83.\\nWhat does the term stochastic in SGD actually mean? Does it use any random number\\n286Chapter 8 DEEP LEARNING\\ngenerator?\\nPRB-260 \\uf059 CH.PRB- 8.84.\\nExplain why in SGD, the number of epochs required to surpass a certain loss threshold\\nincreases as the batch size decreases?\\nMomentum\\nPRB-261 \\uf059 CH.PRB- 8.85.\\nHow does momentum work? Explain the role of exponential decay in the gradient descent\\nupdate rule.\\nPRB-262 \\uf059 CH.PRB- 8.86.\\nIn your training loop, you are using SGD and a logistic activation function which is\\nknown to suffer from the phenomenon of saturated units.\\n1. Explain the phenomenon.\\n2. Y ou switch to using the tanh activation instead of the logistic activation, in your\\nopinion does the phenomenon still exists?\\n3. In your opinion, is using the tanh function makes the SGD operation to converge\\nbetter?\\nPRB-263 \\uf059 CH.PRB- 8.87.\\nWhich of the following statements holds true?\\ni In stochastic gradient descent we ﬁrst calculate the gradient and only then adjust weights\\nfor each data point in the training set.\\nii In stochastic gradient descent, the gradient for a single sample is not so different from\\nthe actual gradient, so this gives a more stable value, and converges faster.\\niii SGD usually avoids the trap of poor local minima.\\n2878.2. PROBLEMS\\niv SGD usually requires more memory.\\nNorms, L1, L2\\nPRB-264 \\uf059 CH.PRB- 8.88.\\nAnswer the following questions regarding norms.\\n1. Which norm does the following equation represent?\\n|x1 − x2| + |y1 − y2| (8.41)\\n2. Which formulae does the following equation represent?\\n\\ued6a\\ued6b\\ued6b√\\nn∑\\ni=1\\n(xi − yi)2 (8.42)\\n3. When your read that someone penalized the L2 norm, was the euclidean or the Man-\\nhattan distance involved?\\n4. Compute both the Euclidean and Manhattan distance of the vectors:\\nx1 = [6 , 1, 4, 5] and x2 = [2 , 8, 3, −1].\\nPRB-265 \\uf059 CH.PRB- 8.89.\\nY ou are provided with a pure Python code implementation of the Manhattan distance\\nfunction (8.51):\\n1 from scipy import spatial\\n2 x1=[6,1,4,5]\\n3 x2=[2,8,3,-1]\\n4 cityblock = spatial.distance.cityblock(x1, x2)\\n5 print(\"Manhattan:\", cityblock)\\nFIGURE 8.51: Manhattan distance function.\\n288Chapter 8 DEEP LEARNING\\nIn many cases, and for large vectors in particular, it is better to use a GPU for imple-\\nmenting numerical computations. PyT orch has full support for GPU’s (and its my favourite\\nDL library ... ), use it to implement the Manhattan distance function on a GPU.\\nPRB-266 \\uf059 CH.PRB- 8.90.\\nY our friend is training a logistic regression model for a binary classiﬁcation problem\\nusing the L2 loss for optimization. Explain to him why this is a bad choice and which loss he\\nshould be using instead.\\n8.3 Solutions\\n8.3.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nSOL-177 \\uf14b CH.SOL- 8.1.\\nThe ﬁrst approach is a leave-one-out CV (LOOCV) and the second is a K-fold cross-\\nvalidation approach. \\x04\\nSOL-178 \\uf14b CH.SOL- 8.2.\\nCross Validation is a cornerstone in machine learning, allowing data scientists to take\\nfull gain of restricted training data. In classiﬁcation, effective cross validation is essential to\\nmaking the learning task efﬁcient and more accurate. A frequently used form of the technique\\nis identiﬁed as K-fold cross validation. Using this approach, the full data set is divided into K\\nrandomly selected folds, occasionally stratiﬁed, meaning that each fold has roughly the\\nsame class distribution as the overall data set . Subsequently, for each fold, all the other\\n(K − 1) folds are used for training, while the present fold is used for testing. This process\\nguarantees that sets used for testing, are not used by a classiﬁer that also saw it during\\ntraining.\\n\\x04\\nK-Fold CV\\n2898.3. SOLUTIONS\\nSOL-179 \\uf14b CH.SOL- 8.3.\\nT rue. We never utilize the test set during a K-fold CV process. \\x04\\nSOL-180 \\uf14b CH.SOL- 8.4.\\nT rue. This is the average of the individual errors of K estimates of the test error:\\nMSE1, . . . ,MSEk (8.43)\\n\\x04\\nSOL-181 \\uf14b CH.SOL- 8.5.\\nThe correct answer is: A 5-fold cross-validation approach results in 5-different model in-\\nstances being ﬁtted. It is a common misconception to think that in a K-fold approach the same\\nmodel instance is repeatedly used. We must create a new model instance in each fold. \\x04\\nSOL-182 \\uf14b CH.SOL- 8.6.\\nThe correct answer is: we compute the cross-validation performance as the arithmetic\\nmean over the K performance estimates from the validation sets. \\x04\\nStratification\\nSOL-183 \\uf14b CH.SOL- 8.7.\\nThe correct answer is: 3-fold CV . A k-fold cross-validation is a special case of cross-\\nvalidation where we iterate over a dataset set k times. In each round, we split the dataset\\ninto k parts: one part is used for validation, and the remaining k − 1 parts are merged into\\na training subset for model evaluation. Stratiﬁcation is used to balance the classes in the\\ntraining and validation splits in cases where the corpus is imbalanced. \\x04\\nLOOCV\\nSOL-184 \\uf14b CH.SOL- 8.8.\\n1. T rue: In (LOOCV) K = N the full sample size.\\n2. False: There is no way of a-priori ﬁnding an optimal value for K, and the relationship\\n290Chapter 8 DEEP LEARNING\\nbetween the actual sample size and the resulting accuracy is unknown.\\n\\x04\\n8.3.2 Convolution and correlation\\nThe convolution operator\\nSOL-185 \\uf14b CH.SOL- 8.9.\\n1. This is the deﬁnition of a convolution operation on the two signals f and g.\\n2. In image processing, the term g(t) represents a ﬁltering kernel.\\n\\x04\\nSOL-186 \\uf14b CH.SOL- 8.10.\\n1. T rue. These operations have two key features: they are shift invariant, and they are\\nlinear. Shift invariance means that we perform the same operation at every point in the\\nimage. Linearity means that this operation is linear, that is, we replace every pixel with\\na linear combination of its neighbours\\n2. T rue. See for instance Eq. (8.3).\\n3. T rue.\\n\\x04\\nThe correlation operator\\nSOL-187 \\uf14b CH.SOL- 8.11.\\n1. T rue.\\n2. T rue.\\n\\x04\\n2918.3. SOLUTIONS\\nSOL-188 \\uf14b CH.SOL- 8.12.\\nA convolution operation is just like correlation, except that we ﬂip over the ﬁlter both\\nhorizontally and vertically before correlating.\\nf (x, y) ⊗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf ∗(m, n)h(x + m, y + n) (8.44)\\n\\x04\\nPadding and stride\\nRecommended reading : “ A guide to convolution arithmetic for deep learning by Vincent\\nDumoulin and Francesco Visin (2016) ” [22].\\nSOL-189 \\uf14b CH.SOL- 8.13.\\n1. The Valid padding only uses values from the original input; however, when the data\\nresolution is not a multiple of the stride, some boundary values are ignored entirely in\\nthe feature calculation.\\n2. The Same padding ensures that every input value is included, but also adds zeros near\\nthe boundary which are not in the original input.\\n\\x04\\nSOL-190 \\uf14b CH.SOL- 8.14.\\nT rue. Contrast this with the two other types of convolution operations. \\x04\\nSOL-191 \\uf14b CH.SOL- 8.15.\\n⌊\\nK − θ\\nθ\\n⌋\\n+ 1 ×\\n⌊\\nn − θ\\nθ\\n⌋\\n+ 1 (8.45)\\n\\x04\\nSOL-192 \\uf14b CH.SOL- 8.16.\\n292Chapter 8 DEEP LEARNING\\nA is the correct choice. \\x04\\nSOL-193 \\uf14b CH.SOL- 8.17.\\nA represents the V ALID mode while B represents the SAME mode. \\x04\\nSOL-194 \\uf14b CH.SOL- 8.18.\\n1. The resulting output has a shape of 4 × 4.\\n2. Convolution operation\\n[[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]]\\n[[ 2. 0. -2.]\\n[ 2. 0. -2.]\\n[ 2. 0. -2.]]\\n3. By deﬁnition, convolutions in the valid mode, reduce the size of the resulting input\\ntensor.\\n[[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]]\\n\\x04\\nKernels and filters\\nSOL-195 \\uf14b CH.SOL- 8.19.\\n2938.3. SOLUTIONS\\n1. Flipping by 180 degrees we get:\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 −1\\n1 1\\n\\uf8f9\\n\\uf8fb (8.46)\\n2. The Sobel ﬁlter which is being frequently used for edge detection in classical computer\\nvision.\\n\\x04\\nSOL-196 \\uf14b CH.SOL- 8.20.\\nThe resulting complexity is given by:\\nK 2wh (8.47)\\n\\x04\\nConvolution and correlation in python\\nSOL-197 \\uf14b CH.SOL- 8.21.\\n1. Convolution operation:\\n294Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 def convolution(A,B):\\n3 l_A = np.size(A)\\n4 l_B = np.size(B)\\n5 C = np.zeros(l_A + l_B -1)\\n6\\n7 for m in np.arange(l_A):\\n8 for n in np.arange(l_B):\\n9 C[m+n] = C[m+n] + A[m]*B[n]\\n10\\n11 return C\\nFIGURE 8.52: Convolution and correlation in python\\n2. Correlation operation:\\n1 def crosscorrelation(A,B):\\n2 return convolution(np.conj(A),B[::-1])\\nFIGURE 8.53: Convolution and correlation in python\\n\\x04\\nSeparable convolutions\\nSOL-198 \\uf14b CH.SOL- 8.22.\\n1. No.Since images are usually stored as discrete pixel values one would have to use a\\ndiscrete approximation of the Gaussian function on the ﬁltering mask before performing\\nthe convolution.\\n2. No.\\n2958.3. SOLUTIONS\\n3. Y es it is separable, a factor that has great implications. For instance, separability means\\nthat a 2D convolution can be reduced to two consequent 1D convolutions reducing the\\ncomputational runtime from O (n2 m2) to O (n2 m).\\n\\x04\\n8.3.3 Similarity measures\\nImage, text similarity\\nSOL-199 \\uf14b CH.SOL- 8.23.\\nThe algorithm presented in ( 8.12) normalizes the input vector. This is usually done prior\\nto applying any other method to the vector or before persisting a vector to a database of FVs.\\n\\x04\\nSOL-200 \\uf14b CH.SOL- 8.24.\\n1. The algorithm presented in ( 8.1) is one of the most commonly used image similarity\\nmeasures and is entitled cosine similarity. It can be applied to any pair of images.\\n2. The mathematical formulae behind it is:\\nThe cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and v = {v1, v2, . . . , vN } is deﬁned as:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures the cosine of the angle\\nbetween the vectors irrespective of their magnitude. It is calculated as the dot product\\nof two numeric vectors, and is normalized by the product of the length of the vectors.\\n3. The minimum and maximum values it can return are 0 and 1 respectively. Thus, a\\ncosine similarity value which is close to 1 indicated a very high similarity while that\\nclose to 0 indicates a very low similarity.\\n4. It represents the negative distance in Euclidean space between the vectors.\\n296Chapter 8 DEEP LEARNING\\n\\x04\\nJacard similarity\\nSOL-201 \\uf14b CH.SOL- 8.25.\\n1. The general formulae for the Jaccard similarity of two sets is given as follows:\\nJ(A, B) = |A ∩ B|\\n|A ∪ B|\\n2. That is, the ratio of the size of the intersection of A and B to the size of their union.\\n3. The Jaccard similarity equals:\\n2\\n7\\n4. Given (8.13)\\nFor the three combinations of pairs above, we have\\nJ({11, 16, 17}, {12, 14, 16, 18}) = 1\\n6\\nJ({11, 12, 13, 14, 15}, {11, 16, 17}) = 1\\n7\\nJ({11, 12, 13, 14, 15}, {12, 14, 16, 18}) = 2\\n7\\n\\x04\\nThe Kullback-Leibler Distance\\nSOL-202 \\uf14b CH.SOL- 8.26.\\nEach KLD corresponds to the deﬁnition of:\\ni Jensen [1]\\n2978.3. SOLUTIONS\\nii Bennet [2]\\niii Bigi [3]\\niv Ziv [29]\\n\\x04\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nSOL-203 \\uf14b CH.SOL- 8.27.\\nA Hashing function ( 8.54) maps a value into a constant length string that can be com-\\npared with other hashed values.\\nFIGURE 8.54: The idea of hashing\\nThe idea behind hashing is that items are hashed into buckets, such that similar items\\nwill have a higher probability of hashing into the same buckets.\\nThe goal of MinHash is to compute the Jaccard similarity without actually computing the\\nintersection and union of the sets, which would be slower. The main idea behind MinHash\\nis to devise a signature scheme such that the probability that there is a match between the\\nsignatures of two sets, S1 and S2, is equal to the Jaccard measure [ 12].\\n\\x04\\n298Chapter 8 DEEP LEARNING\\nSOL-204 \\uf14b CH.SOL- 8.28.\\nLocality-Sensitive Hashing (LSH) is a method which is used for determining which items\\nin a given set are similar. Rather than using the naive approach of comparing all pairs of items\\nwithin a set, items are hashed into buckets, such that similar items will be more likely to hash\\ninto the same buckets.\\n\\x04\\nSOL-205 \\uf14b CH.SOL- 8.29.\\nMaximise.\\n\\x04\\n8.3.4 Perceptrons\\nThe Single Layer Perceptron\\nSOL-206 \\uf14b CH.SOL- 8.30.\\nAnswer: one, one, feedback.\\n\\x04\\nSOL-207 \\uf14b CH.SOL- 8.31.\\n1. T rue.\\n2. T rue.\\n3.\\nC(w, b) = 1\\n2n\\n∑\\nx\\n∥y(x) − a(x, w, b)∥2 (8.48)\\nwhere w denotes the collection of all weights in the network, b all the biases, n is the\\ntotal number of training inputs and a(x, w, b) is the vector of outputs from the network\\nwhich has weights w, biases b and the input x.\\n4.\\narg min\\nw,b\\nC(w, b). (8.49)\\n5. Gradient descent.\\n2998.3. SOLUTIONS\\n6. The gradient.\\n7. Stochastic gradient descent. Batch size. Back-propagation.\\n\\x04\\nThe Multi Layer Perceptron\\nSOL-208 \\uf14b CH.SOL- 8.32.\\n1. This operation is a dot product with the given weights. Therefore:\\nout = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 = −0.164 (8.50)\\n2. This operation (sum) is a dot product with the given weights and with the given bias\\nadded. Therefore:\\nout1 = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 + 0.001 = −0.165 (8.51)\\n3. Code snippet 8.55 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 # .type(torch.FloatTensor)\\n3 x= torch.tensor([0.9,0.7])\\n4 w= torch.tensor([-0.3,0.15])\\n5 B= torch.tensor([0.001])\\n6 print (torch.sum(x*w))\\n7 print (torch.sum(x*w) + B)\\nFIGURE 8.55: MLP operations.\\n\\x04\\n300Chapter 8 DEEP LEARNING\\nActivation functions in perceptrons\\nSOL-209 \\uf14b CH.SOL- 8.33.\\n1. Since by deﬁnition:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.52)\\nAnd the output of the linear sum operation was −0.164 then, the output out2 = 0 .\\n2. Code snippet 8.56 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 x= torch.tensor([0.9,0.7])\\n3 w= torch.tensor([-0.3,0.15])\\n4 B= torch.tensor([0.001])\\n5 print (torch.sum(x*w))\\n6 print (torch.sum(x*w) + B)\\n7 print (torch.relu(torch.sum(x*w + B)))\\nFIGURE 8.56: MLP operations.\\n\\x04\\nBack-propagation in perceptrons\\nSOL-210 \\uf14b CH.SOL- 8.34. The answers are as follows:\\n1. Non-differentiable at 0.\\n2. Non-differentiable at 0.\\n3018.3. SOLUTIONS\\n3. Even though for x ̸= 0:\\nf ′(x) = sin 1\\nx − 1\\nx cos 1\\nx, (8.53)\\nthe function is still non-differentiable at 0.\\n4. Non-differentiable at 0.\\n\\x04\\nSOL-211 \\uf14b CH.SOL- 8.35.\\n1. Fig 8.57 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 for i in range(0,w.size(0)):\\n2 print (torch.relu(torch.sum(x*w[i]) + B))\\n3 > tensor([0.])\\n4 > tensor([0.])\\n5 > tensor([0.6630])\\nFIGURE 8.57: MLP operations- values.\\n2. The values at each hidden layer are depicted in 8.58\\n302Chapter 8 DEEP LEARNING\\n0.0\\n0.0\\n0.6630\\nOutput\\nFIGURE 8.58: Hidden layer values, simple MLP .\\n3. Fig 8.59 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 x1= torch.tensor([0.0,0.0,0.6630])# Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 for i in range(0,w1.size(0)):\\n7 print (torch.sum(x1*w1[i]))\\n8 > tensor(0.3912)\\n9 > tensor(-0.5238)\\nFIGURE 8.59: MLP operations- values at the output.\\n4. We can apply the Softmax function like so 8.60:\\n3038.3. SOLUTIONS\\n1 x1= torch.tensor([0.0,0.0,0.6630]) # Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 out1 = torch.tensor([[torch.sum(x1*w1[0]).item()],\\n7 [torch.sum(x1*w1[1]).item()]])\\n8 print (out1)\\n9 yhat = torch.softmax(out1, dim =0)\\n10 print (yhat)\\n11 > tensor([[ 0.3912],\\n12 [-0.5238]])\\n13 > tensor([[0.7140],\\n14 [0.2860]])\\nFIGURE 8.60: MLP operations- Softmax.\\n5. For the cross-entropy loss, we use the Softmax values and calculate the result as follows:\\n−1.0 ∗ log(0.7140) − 0.0 ∗ log(0.2860) = 1 .31 (8.54)\\n\\x04\\nThe theory of perceptrons\\nSOL-212 \\uf14b CH.SOL- 8.36.\\nHe means that theoretically [ 6], a non-linear layer followed by a linear layer, can ap-\\nproximate any non-linear function with arbitrary accuracy, provided that there are enough\\nnon-linear neurons\\n\\x04\\nSOL-213 \\uf14b CH.SOL- 8.37. T rue \\x04\\nSOL-214 \\uf14b CH.SOL- 8.38. T rue \\x04\\n304Chapter 8 DEEP LEARNING\\nSOL-215 \\uf14b CH.SOL- 8.39.\\nFalse. Divided by the training samples, not the number of incorrectly classiﬁed samples. \\x04\\nLearning logical gates\\nSOL-216 \\uf14b CH.SOL- 8.40.\\n1. The values are presented in the following table ( 8.61):\\nBias = −2.5\\nInput Weighted sum Output\\n(0,0) -2.5 0\\n(0,1) -1.5 0\\n(1,0) -1.5 0\\n(1,1) -0.5 0\\nFIGURE 8.61: Logical AND: B=-2.5\\n2. The values are presented in the following table ( 8.62):\\nBias = −0.25\\nInput Weighted sum Output\\n(0,0) -0.25 0\\n(0,1) -0.75 0\\n(1,0) -0.75 0\\n(1,1) 1.75 1\\nFIGURE 8.62: Logical AND: B=-0.25\\n3. The perceptron learning rule is an algorithm that can automatically compute optimal\\nweights for the perceptron.\\n3058.3. SOLUTIONS\\n4. The main addition by [ 22] and [ 18] was the introduction of a differentiable activation\\nfunction.\\n5. if we select w1 = 1;w2 = 1 and threshold=1. We get:\\nx1 = 1, x2 = 1 :\\nn = 1 × 1 + 1 × 1 = 2 ,thus,y = 1\\nx1 = 1, x2 = −1 :\\nn = 1 × 1 + 1 × (−1) = 0 ,thus,y = −1\\nx1 = −1, x2 = 1 :\\nn = 1 × (−1) + 1 × 1 = 0 ,thus,y = −1\\nx1 = −1, x2 = −1 :\\nn = 1 × (−1) + 1 × (−1) = −2,thus,y = −1\\n(8.55)\\nOr summarized in a table ( 8.63):\\nAND gate\\nin1 in2 out\\n0 0 0\\n0 1 0\\n1 0 0\\n1 1 1\\nFIGURE 8.63: Logical AND gate\\n\\x04\\n8.3.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\n306Chapter 8 DEEP LEARNING\\nSOL-217 \\uf14b CH.SOL- 8.41.\\n1. Remember that the analytical derivative is of the sigmoid:\\nd\\ndxs(x) = d\\ndx((1 + e−x)−1) (8.56)\\nd\\ndxs(x) = −1((1 + e−x)(−1−1)) d\\ndx(1 + e−x) (8.57)\\nd\\ndxs(x) = −1((1 + e−x)(−2))( d\\ndx (1) + d\\ndx(e−x)) (8.58)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(0 + e−x( d\\ndx(−x))) (8.59)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(e−x)(−1) (8.60)\\nd\\ndx s(x) = ((1 + e−x)(−2))(e−x) (8.61)\\nd\\ndxs(x) = 1\\n(1 + e−x)2 (e−x) (8.62)\\nd\\ndxs(x) = (e−x)\\n(1 + e−x)2 (8.63)\\nCode snippet 8.64 provides a pure C++ based implementation of the backward pass that\\ndirectly computes the analytical gradients in C++.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001_d(torch ::Tensor & x) {\\n5 torch::Tensor s = sigmoid001(x);\\n6 return (1 - s) * s;\\n7 }\\nFIGURE 8.64: Backward pass for the Sigmoid function using Libtorch.\\n3078.3. SOLUTIONS\\n2. Code snippet 8.65 depicts one way of printing the values.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"\\n9 << sigmoid001_d (t0).data().detach().item().toFloat()\\n10 << \\'\\\\n\\' ;\\n11 }\\n12 }\\nFIGURE 8.65: Evaluation of the sigmoid and its derivative in C++ using Libtorch.\\n3. The manual derivative of eq. 8.27 is:\\n3 ln(2)×\\n[\\n2−1.5x\\n(2−1.5x + 1)2\\n]\\n(8.64)\\n4. The forward pass for the Sigmoid function approximation eq. 8.27 is presented in code\\nsnippet 8.66:\\n308Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 torch::Tensor sig_approx( const torch::Tensor & x ){\\n4 torch::Tensor sig = 1.0 / (1.0 + torch::pow(2,( -1.5*x)));\\n5 return sig;\\n6 }\\nFIGURE 8.66: Forward pass for the Sigmoid function approximation in C++ using Libtorch.\\n5. The values are 8.67: :\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"<< sig_approx (t0).data().detach().item().\\n9 toFloat()<<\\'\\\\'),\n",
              " Document(metadata={}, page_content='5*x)));\\n5 return sig;\\n6 }\\nFIGURE 8.66: Forward pass for the Sigmoid function approximation in C++ using Libtorch.\\n5. The values are 8.67: :\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"<< sig_approx (t0).data().detach().item().\\n9 toFloat()<<\\'\\\\n\\' ;\\n10 }\\nFIGURE 8.67: Printing the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch.\\nAn the values are presented in T able 8.2:\\n3098.3. SOLUTIONS\\nValue Sig Approx\\n0 0.5 0.5\\n0.1 0.524979 0.52597\\n0.2 0.549834 0.5518\\n0.3 0.574443 0.577353\\n0.4 0.598688 0.602499\\n0.5 0.622459 0.627115\\n0.6 0.645656 0.65109\\n0.7 0.668188 0.674323\\n0.8 0.689974 0.69673\\n0.9 0.710949 0.71824\\n0.99 0.729088 0.736785\\nTABLE 8.2: Computed values for the Sigmoid and the Sigmoid approximation.\\n\\x04\\nTanh\\nSOL-218 \\uf14b CH.SOL- 8.42.\\nThe answers are as follows:\\n1. The derivative is:\\nftanh(x) = 1 − ftanh(x)2 (8.65)\\n2. Code snippet 8.68 implements the forward pass using pure Python.\\n310Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 xT =\\ntorch.abs(torch.tensor([[0.37,0.192,0.571]],requires_grad=True))↪→\\n3 .type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 tanh_values = np.tanh(xT_np)\\n7 print (\"Numpy:\", tanh_values)\\n8 > Numpy: [[ 0.35399172 0.18967498 0.51609329]]\\nFIGURE 8.68: Forward pass for tanh using pure Python.\\n3. In order to implement a PyT orch based torch.autograd.F unction function such as\\ntanh, we must provide both the forward and backward passes implementation. The\\nmechanism behind this idiom in PyT orch is via the use of a context, abbreviated ctx\\nwhich is like a state manager for automatic differentiation. The implementation is de-\\npicted in 8.69:\\n3118.3. SOLUTIONS\\n1 import torch\\n2\\n3 class TanhFunction(torch.autograd.Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward( x )\\n7 y = x.tanh()\\n8 return y\\n9\\n10 @staticmethod\\n11 def backward(ctx, grad_output):\\n12 input, = ctx.saved_tensors\\n13 dy_dx = 1 / (input.cosh() ** 2)\\n14 out = grad_output * dy_dx\\n15 print (\"backward:{}\".format(out))\\n16 return out\\nFIGURE 8.69: Tanh in PyTorch.\\n4. Code snippet 8.70 veriﬁes the correctness of the implementation using gradcheck.\\n312Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 import numpy as np\\n3 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n4 requires_grad=True))\\n5 .type(torch.DoubleTensor)\\n6 xT_np=xT.detach().cpu().numpy()\\n7 tanh_values = np.tanh(xT_np)\\n8 tanh_values_torch = tanhPyTorch(xT)\\n9 print (\"Torch:\", tanh_values_torch)\\n10 from torch.autograd import gradcheck, Variable\\n11 f = TanhFunction.apply\\n12 test=gradcheck(lambda t: f(t), xT)\\n13 print(test)\\n14 > PyTorch version: 1.7.0\\n15 > Torch: tensor([[ 0.3540, 0.1897, 0.5161]], dtype =torch.float64)\\n16 > backward:tensor([[0.8747, 0.9640, 0.7336]],dtype=torch.float64)\\nFIGURE 8.70: Invoking gradcheck on tanh.\\n\\x04\\nSOL-219 \\uf14b CH.SOL- 8.43.\\n1. The type of NN is a MultiLayer Perceptron or MLP .\\n2. There are two hidden layers.\\n\\x04\\nSOL-220 \\uf14b CH.SOL- 8.44.\\nHe is partially correct , see for example Understanding the difﬁculty of training deep\\nfeedforward neural networks [9]. \\x04\\n3138.3. SOLUTIONS\\nSOL-221 \\uf14b CH.SOL- 8.45.\\nInitialize all parameters to a constant zero value. When we apply the tanh function to an\\ninput which is very large, the output which is almost zero, will be propagated to the remaining\\npartial derivatives leading to the well known phenomenon.\\n\\x04\\nSOL-222 \\uf14b CH.SOL- 8.46.\\nDuring the back-propagation process, derivatives are calculated with respect to (W (1))\\nand also (W (2)). The design ﬂaw:\\ni Y our friend initialized all weights and biases to zero.\\nii Therefore any gradient with respect to (W (2)) would also be zero.\\niii Subsequently, (W (2)) will never be updated.\\niv This would inadvertently cause the derivative with respect to (W (1)) to be always zero.\\nv Finally, would also never be updated (W (1)).\\n\\x04\\nReLU\\nSOL-223 \\uf14b CH.SOL- 8.47.\\nThe ReLU function has the beneﬁt of not saturating for positive inputs since its derivative\\nis one for any positive value.\\n\\x04\\nSOL-224 \\uf14b CH.SOL- 8.48.\\nThe shape is:\\n3 × 3 × 3 × 16\\n\\x04\\nSOL-225 \\uf14b CH.SOL- 8.49.\\nThe activation function is a leaky ReLU which in some occasions may outperform the\\n314Chapter 8 DEEP LEARNING\\nReLU activation function. \\x04\\nSwish\\nSOL-226 \\uf14b CH.SOL- 8.50.\\n1. They intended to ﬁnd new better-performing activation functions.\\n2. They had a list of basic mathematical functions to choose from, for instance the expo-\\nnential families exp(), sin(), min and max.\\n3. Previous research found several activation function properties which were considered\\nvery useful. For instance, gradient preservation and non-monotonicity. However the\\nsurprising discovery was that the swish function violates both of these previously deemed\\nuseful properties.\\n4. The equation is:\\nf (x) = x · σ(x) (8.66)\\n5. The plot is 8.71\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n−1,0\\n−0,5\\n0,5\\n1,0\\nx\\nyx ∗ σ(x) = x ∗ 1\\n1+e−4x\\nFIGURE 8.71: A plot of the Swish activation function.\\n\\x04\\n3158.3. SOLUTIONS\\n8.3.6 Performance Metrics\\nConfusion matrix, precision, recall\\nSOL-227 \\uf14b CH.SOL- 8.51.\\n1. The values are labelled inside 8.27:\\nPredicted\\nP N\\nTruth P TP=12 FN=7\\nN FP=24 TN=1009\\nFIGURE 8.72: TP , TN, FP , FN.\\n2.\\nacc = 12 + 1009\\n12 + 7 + 24 + 1009 = 0.97 (8.67)\\n3.\\nprec = 12\\n12 + 24 = 0.333 (8.68)\\n4.\\nrecall = 12\\n12 + 7 = 0.631 (8.69)\\n\\x04\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\n316Chapter 8 DEEP LEARNING\\nFIGURE 8.73: Receiver Operating Characteristic curve.\\nSOL-228 \\uf14b CH.SOL- 8.52.\\nROC allows to attest the relationship between sensitivity and speciﬁcity of a binary clas-\\nsiﬁer. Sensitivity or true positive rate measures the proportion of positives correctly classiﬁed;\\nspeciﬁcity or true negative rate measures the proportion of negatives correctly classiﬁed. Con-\\nventionally, the true positive rate tpr is plotted against the false positive rate fpr, which is one\\nminus true negative rate.\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween selectivity and sensitivity.\\n2. It is a plot of ‘true positives’ vs. the ‘true negatives’ . In place of ‘true negatives’ ,\\none could also use ‘false positives’ which are essentially 1 - ‘true negatives’ .\\n3. A typical ROC curve has a concave shape with (0,0) as the beginning and (1,1) as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely confused\\nand cannot at all distinguish between the two classes, has an AUC of 0.5, the ‘x = y’\\nline in an ROC curve plot.\\n3178.3. SOLUTIONS\\n\\x04\\nSOL-229 \\uf14b CH.SOL- 8.53.\\nThe ROC curve of an ideal classiﬁer (100% accuracy) has an AUC of 1, with 0.0 ‘false\\npositives’ and 1.0 ‘true positives’ . The ROC curve in our case, is almost ideal, which may\\nindicate over-ﬁtting of the XGBOOST classiﬁer to the training corpus. \\x04\\n8.3.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nSOL-230 \\uf14b CH.SOL- 8.54.\\nOutput dimension: L × L × M where L = n−f +2p\\ns + 1 \\x04\\nSOL-231 \\uf14b CH.SOL- 8.55.\\nThe answers are as follows:\\n1. Output dimensions:\\ni torch.Size([1, 512, 7, 7])\\nii torch.Size([1, 512, 16, 16])\\niii torch.Size([1, 512, 22, 40])\\n2. The layer is MaxPool2d.\\n\\x04\\nSOL-232 \\uf14b CH.SOL- 8.56.\\nThe answers are as follows:\\n1. A convolutional block 8.74.\\n318Chapter 8 DEEP LEARNING\\n1 Sequential(\\n2 (0): Conv2d( 3, 64, kernel_size =(3, 3), stride =(1, 1), padding =(1,\\n1))↪→\\n3 (1): ReLU(inplace =True)\\n4 (2): MaxPool2d(kernel_size =2, stride =2, padding =0, dilation =1,\\nceil_mode=False↪→\\n5 )\\nFIGURE 8.74: Convolutional block from the VGG11 architecture.\\n2. The shapes are as follows:\\ni torch.Size([1, 64, 112, 112])\\nii torch.Size([1, 64, 256, 256])\\niii torch.Size([1, 64, 352, 512])\\n\\x04\\nSOL-233 \\uf14b CH.SOL- 8.57.\\nThe VGG11 architecture contains seven convolutional layers, each followed by a ReLU\\nactivation function, and ﬁve max-polling operations, each reducing the respective feature\\nmap by a factor of 2. All convolutional layers have a 3 × 3 kernel. The ﬁrst convolutional\\nlayer produces 64 channels and subsequently, as the network deepens, the number of channels\\ndoubles after each max-pooling operation until it reaches 512. \\x04\\nDropout\\nSOL-234 \\uf14b CH.SOL- 8.58.\\n1. The observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (8.70)\\n3198.3. SOLUTIONS\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (8.71)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (8.72)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (8.73)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(8.74)\\n2. In dropout, in every training epoch, neurons are randomly pruned with probability\\nP = p sampled from a Bernoulli distribution. During inference, all the neurons are used\\nbut their output is multiplied by the a-priory probability P . This approach resembles to\\nsome degree the model averaging approach of bagging.\\n\\x04\\nSOL-235 \\uf14b CH.SOL- 8.59.\\nThe answers are as follows:\\n1. The idea is true and a solid one.\\n2. The idiom may be exempliﬁed as follows 8.75:\\n320Chapter 8 DEEP LEARNING\\nFIGURE 8.75: Equivalence of two consecutive dropout layers\\nThe probabilities add up by multiplication at each layer, resulting in a single dropout\\nlayer with probability:\\n1 − (1 − p)(1 − q) (8.75)\\n\\x04\\nConvolutional Layer\\nSOL-236 \\uf14b CH.SOL- 8.60.\\nThe result is ( 8.76):\\nFIGURE 8.76: The result of applying the ﬁlter.\\n\\x04\\n3218.3. SOLUTIONS\\nSOL-237 \\uf14b CH.SOL- 8.61.\\nThe result is ( 8.77):\\nFIGURE 8.77: The result of applying a ReLU activation.\\n\\x04\\nSOL-238 \\uf14b CH.SOL- 8.62.\\nThe result is ( 8.78):\\nFIGURE 8.78: The result of applying a MaxPool layer.\\n\\x04\\nPooling Layers\\nMaxPooling\\n322Chapter 8 DEEP LEARNING\\nSOL-239 \\uf14b CH.SOL- 8.63.\\nThe answers are as follows:\\n1. A max-pooling layer is most commonly used after a convolutional layer in order to\\nreduce the spatial size of CNN feature maps.\\n2. The result is 8.79:\\nFIGURE 8.79: Output of the MaxPool2d operation.\\n\\x04\\nSOL-240 \\uf14b CH.SOL- 8.64.\\n1. In MaxPool2D(2,2), the ﬁrst parameter is the size of the pooling operation and the\\nsecond is the stride of the pooling operation.\\n2. The BatchNorm2D operation does not change the shape of the tensor from the previous\\nlayer and therefore it is:\\ntorch.Size ([1, 32, 222, 222]).\\n3. During the training of a CNN we use model.train() so that Dropout layers are ﬁred.\\nHowever, in order to run inference, we would like to turn this ﬁring mechanism off,\\nand this is accomplished by model.eval() instructing the PyT orch computation graph\\nnot to activate dropout layers.\\n4. The resulting tensor shape is:\\ntorch.Size ([1, 32, 55, 55])\\nIf we reshape the tensor like in line 17 using:\\nx = x.view(x.size(0), −1)\\n3238.3. SOLUTIONS\\nThen the tensor shape becomes:\\ntorch.Size ([1, 96800])\\n5. Y es, you should agree with him, as depicted by the following plot 8.80:\\nFIGURE 8.80: A single MaxPool layer.\\n\\x04\\nBatch normalization, Gaussian PDF\\nThe Gaussian distribution\\nSOL-241 \\uf14b CH.SOL- 8.65.\\nThe answers are as follows:\\n1. BN is a method that normalizes the mean and variance of each of the elements during\\ntraining.\\n2. X ∼ N (0, 1) a mean of zero and a variance of one. The standard normal distribution\\noccurs when (σ)2 = 1 and µ = 0.\\n3. In order to normalize we:\\ni Step one is to subtract the mean to shift the distribution.\\nii Divide all the shifted values by their standard deviation (the square root of the\\nvariance).\\n4. In BN, the normalization is applied on an element by element basis. During training at\\neach epoch, every element in the batch has to be shifted and scaled so that it has a zero\\nmean and unit variance within the batch.\\n\\x04\\n324Chapter 8 DEEP LEARNING\\nSOL-242 \\uf14b CH.SOL- 8.66.\\n1. One possible realization is as follows 8.81:\\n1 from math import sqrt\\n2 import math\\n3 def normDist(x, mu, sigSqrt):\\n4 return (1 / sqrt(2 * math.pi * sigSqrt)) * math.e ** ((-0.5) *\\n(x - mu) ** 2 / sigSqrt)↪→\\nFIGURE 8.81: Normal distribution in Python: from scratch.\\n2. The derivative is given by 8.82:\\n1 scipy.stats.norm.pdf(x, mu, sigma) *(mu - x)/sigma**2\\nFIGURE 8.82: The derivative of a Normal distribution in Python.\\n\\x04\\nBN\\nSOL-243 \\uf14b CH.SOL- 8.67.\\n1. During training of a CNN, when a convolution is being followed by a BN layer, for\\neach of the three RGB channels a single separate mean and variance is being computed.\\n2. The mistake he made is using a BN with a batch size of 32, while the output from the\\nconvolutional layer is 64.\\n\\x04\\n3258.3. SOLUTIONS\\nTheory of CNN design\\nSOL-244 \\uf14b CH.SOL- 8.68.\\nT rue.\\n\\x04\\nSOL-245 \\uf14b CH.SOL- 8.69.\\nAll the options may be used to build a CNN. \\x04\\nSOL-246 \\uf14b CH.SOL- 8.70. While the original paper ([ 16]) suggests that BN layers be\\nused before an activation function, it is also possible to use BN after the activation function.\\nIn some cases, it actually leads to better results ([ 4]).\\n\\x04\\nSOL-247 \\uf14b CH.SOL- 8.71.\\nWhen dropout is enabled during the training process, in order to keep the expected output\\nat the same value, the output of a dropout layer must be multiplied with this term. Of course,\\nduring inference no dropout is taking place at all. \\x04\\nSOL-248 \\uf14b CH.SOL- 8.72.\\n1. The idiom is a bottleneck layer ([ 27]), which may act much like an autoencoder.\\n2. Reducing and then increasing the activations, may force the MLP to learn a more com-\\npressed representation.\\n3. The new architecture has far more connections and therefore it would be prone to over-\\nﬁtting.\\n4. Once such architecture is an autoencoder ([ 28]).\\n\\x04\\nCNN residual blocks\\nSOL-249 \\uf14b CH.SOL- 8.73.\\n326Chapter 8 DEEP LEARNING\\n1. The function F is the residual function.\\n2. The main idea was to add an identity connection which skips two layers all together.\\n\\x04\\nSOL-250 \\uf14b CH.SOL- 8.74.\\n1. The missing parts are visualized in ( 8.83).\\nFIGURE 8.83: A resnet CNN block\\n2. The symbol represents the addition operator.\\n3. Whenever F returns a zero, then the input X will reach the output without being\\nmodiﬁed. Therefore, the term identity function.\\n\\x04\\n8.3.8 Training, hyperparameters\\nHyperparameter optimization\\nSOL-251 \\uf14b CH.SOL- 8.75.\\nThe question states that image size is quite large, and the batch size is 1024, therefore it\\nmay fail to allocate memory on the GPU with an Out Of Memory (OOM) error message. This\\n3278.3. SOLUTIONS\\nis one of the most commonly faced errors when junior data-scientist start training models.\\n\\x04\\nSOL-252 \\uf14b CH.SOL- 8.76.\\n1. Since hs is tuning his Hyperparameters on the validation set, he would most probably\\noverﬁt to the validation set which he also used for evaluating the performance of the\\nmodel.\\n2. One way would be to amend the splitting, is by ﬁrst keeping a fraction of the training set\\naside, for instance 0.1, and then split the remaining .90 into a training and a validation\\nset, for instance 0.8 and 0.1.\\n3. His new approach uses GridSearchCV with 5-fold cross-validation to tune his Hyper-\\nparameters. Since he is using cross validation with ﬁve folds, his local CV metrics would\\nbetter reﬂect the performance on an unseen data set.\\n\\x04\\nSOL-253 \\uf14b CH.SOL- 8.77.\\nIn grid search, a set of pre-determined values is selected by a user for each dimension in\\nhis search space, and then thoroughly attempting each and every combination. Naturally, with\\nsuch a large search space the number of the required combinations that need to be evaluated\\nscale exponentially in the number of dimensions in the grid search.\\nIn random search the main difference is that the algorithm samples completely random\\npoints for each of the dimensions in the search space. Random search is usually faster and may\\neven produce better results.\\n\\x04\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nSOL-254 \\uf14b CH.SOL- 8.78.\\nThere is a potential for bias in certain settings such as this. If the whole training set\\nis labelled only by a single radiologist, it may be possible that his professional history would\\n328Chapter 8 DEEP LEARNING\\ninadvertently generate bias into the corpus. Even if we use the form of radiology report reading\\nknown as double reading it would not be necessarily true that the annotated scans would be\\ndevoid of bias or that the quality would be better [ 8].\\n\\x04\\nValidation curve ACC\\nSOL-255 \\uf14b CH.SOL- 8.79.\\nThe answers are as follows:\\n1. A validation curve displays on a single graph a chosen hyperparameter on the hori-\\nzontal axis and a chosen metric on the vertical axis.\\n2. The hyperparameter is the number of epochs\\n3. The quality metric is the error (1 -accuracy). Accuracy, error = (1`accuracy) or loss are\\ntypical quality metrics.\\n4. The longer the network is trained, the better it gets on the training set.\\n5. At some point the network is ﬁt too well to the training data and loses its capability to\\ngeneralize. While the classiﬁer is still improving on the training set, it gets worse on\\nthe validation and the test set.\\n6. At this point the quality curve of the training set and the validation set diverge.\\n\\x04\\nValidation curve Loss\\nSOL-256 \\uf14b CH.SOL- 8.80.\\nThe answers are as follows:\\n1. What we are witnessing is phenomena entitled a plateau. This may happen when the\\noptimization protocol can not improve the loss for several epochs.\\n2. There possible methods are:\\ni Constant\\nii Xavier/Glorot uniform\\n3298.3. SOLUTIONS\\niii Xavier/Glorot normal\\n3. Good initialization would optimally generate activations that produce initial gradients\\nthat are larger than zero. One idea is that the training process would converge faster if\\nunit variance is achieved ([ 16]). Moreover, weights should be selected carefully so that:\\ni They are large enough thus preventing gradients from decaying to zero.\\nii They are not too large causing activation functions to over saturate.\\n4. There are several ways to reduce the problem of plateaus:\\ni Add some type of regularization.\\nii In cases wherein the plateau happens right at the beginning, amend the way weights\\nare initialized.\\niii Amending the optimization algorithm altogether, for instance using SGD instead\\nof Adam and vice versa.\\n5. Since the initial LR is already very low, his suggestion may worsen the situation since\\nthe optimiser would not be able to jump off and escape the plateau.\\n6. In contrast to accuracy, Log loss has no upper bounds and therefore at times may be\\nmore difﬁcult to understand and to explain.\\n\\x04\\nInference\\nSOL-257 \\uf14b CH.SOL- 8.81.\\n1. Usually data augmentation, is a technique that is heavily used during training, espe-\\ncially for increasing the number of instances of minority classes. In this case, augment-\\nations are using during inference and this method is entitled T est Time Augmentation\\n(TTA).\\n2. Here are several image augmentation methods for TTA, with two augmentations shown\\nalso in PyT orch.\\n330Chapter 8 DEEP LEARNING\\nHorizontal ﬂip\\nV ertical ﬂip\\nRotation\\nScaling\\nCrops\\n1 transforms.HorizolntalFlip(p=1)(image)\\n2 transforms.VerticalFlip(p=1)(image)\\nFIGURE 8.84: Several image augmentation methods for TTA.\\n\\x04\\nSOL-258 \\uf14b CH.SOL- 8.82.\\ni Unseen\\nii Overﬁtting\\n\\x04\\n8.3.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nSOL-259 \\uf14b CH.SOL- 8.83.\\nThere is no relation to random number generation, the true meaning is the use of batches\\nduring the training process.\\n\\x04\\nSOL-260 \\uf14b CH.SOL- 8.84.\\nA larger batch size decreases the variance of the gradient estimation of SGD. Therefore, if\\nyour training loop uses larger batches, the model will converge faster. On the other hand, smal-\\n3318.3. SOLUTIONS\\nler batch sizes increase the variance, leading to the opposite phenomena; longer convergence\\ntimes.\\n\\x04\\nMomentum\\nSOL-261 \\uf14b CH.SOL- 8.85.\\nMomentum introduces an extra term which comprises a moving average which is used\\nin gradient descent update rule to exponentially decay the historical gradients Using such\\nterm has been demonstrated to accelerate the training process ([ 11]) requiring less epochs to\\nconverge.\\n\\x04\\nSOL-262 \\uf14b CH.SOL- 8.86.\\nThe answers are as follows:\\n1. The derivative of the logistic activation function is extremely small for either negtive or\\npositive large inputs.\\n2. The use of the tanh function does not alleviate the problem since we can scale and\\ntranslate the sigmoid function to represent the tanh function:\\ntanh(z) = 2 σ(2z) − 1 (8.76)\\nWhile the sigmoid function is centred around 0.5, the tanh activation is centred around\\nzero. Similar to the application of BN, centring the activations may aid the optimizer con-\\nverge faster. Note: there is no relation to SGD; the issue exists when using other optimization\\nfunctions as well. \\x04\\nSOL-263 \\uf14b CH.SOL- 8.87.\\nThe answers are as follows:\\ni T rue.\\nii False. In stochastic gradient descent, the gradient for a single sample is quite different\\n332Chapter 8 DEEP LEARNING\\nfrom the actual gradient, so this gives a more noisy value, and converges slower\\niii T rue.\\niv False. SGD requires less memory.\\n\\x04\\nNorms, L1, L2\\nSOL-264 \\uf14b CH.SOL- 8.88.\\n1. The L2 norm.\\n2. The Euclidean distance which is calculated as the square root of the sum of differences\\nbetween each point in a set of two points.\\n3. The Manhattan distance is an L1 norm (introduced by Hermann Minkowski) while the\\nEuclidean distance is an L2 norm.\\n4. The Manhattan distance is:\\n|6 − 2| + |1 − 8| + |4 − 3| + |5 − (−1)|\\n= 4 + 7 + 1 + 6 = 18 (8.77)\\n5. The Euclidean distance is:\\n√\\n(6 − 2)2 + (1 − 8)2 + (4 − 3)2 + (5 − (−1))2\\n=\\n√\\n102\\n(8.78)\\n\\x04\\nSOL-265 \\uf14b CH.SOL- 8.89.\\nThe PyT orch implementation is in ( 8.85). Note that we are allocating tensors on a GPU\\nbut ﬁrst they are created on a CPU using numpy. This is also always the interplay between\\nthe CPU and the GPU when training NN models. Note that this only work if you have GPU\\navailable; in case there is no GPU detected, the code has a fallback to the CPU.\\n333REFERENCES\\n1 %reset -f\\n2 import torch\\n3 import numpy\\n4\\n5 use_cuda = torch.cuda.is_available()\\n6 device = torch.device(\"cuda\" if use_cuda else \"cpu\")\\n7 print (device)\\n8 x1np=numpy.array([6,1,4,5])\\n9 x2np=numpy.array([2,8,3,-1])\\n10 x1t=torch.FloatTensor(x1np).to(device) # Move to GPU if available\\n11 x2t=torch.FloatTensor(x2np).to(device)\\n12 dist = torch.sqrt (torch .pow(x1t - x2t, 2).sum())\\n13 dist\\n14 >cuda\\n15 >tensor(10.0995, device =\\'cuda:0\\' )\\nFIGURE 8.85: Manhattan distance function in PyTorch.\\n\\x04\\nSOL-266 \\uf14b CH.SOL- 8.90.\\nThe L2 loss is suitable for a target, or a response variable that is continuous. On the other\\nhand, in a binary classiﬁcation problem using LR we would like the output to match either\\nzero or one and a natural candidate for a loss function is the binary cross-entropy loss. \\x04\\nReferences\\n[1] F. T. B. Fuglede. ‘Jensen-Shannon Divergence and Hilbert space embedding’. In:\\nIEEE Int Sym. Information Theory (2004) (cit. on pp. 245, 297).\\n[2] C. Bennett. ‘Information Distance’. In: IEEE T rans. Pattern Anal. Inform. Theory.\\n44:4 (1998), pp. 1407–1423 (cit. on pp. 244, 298).\\n[3] B. Bigi. ‘Using Kullback-Leibler Distance for Text Categorization’. In: In Pro-\\nceedings of the ECIR-2003, Lecture Notes in Computer Science, Springer-Verlag 2633\\n(2003), pp. 305–319 (cit. on pp. 245, 298).\\n334Chapter 8 DEEP LEARNING\\n[4] G. Chen. Rethinking the Usage of Batch Normalization and Dropout in the T raining of\\nDeep Neural Networks. 2019. arXiv: 1905.05928 [cs.LG] (cit. on p. 326).\\n[5] Y . S. Chen et al. ‘Deep photo enhancer: Unpaired learning for image enhance-\\nment from photographs with gans’. In: IEEE Conference on Computer Vision and\\nPattern Recognition. 2018, p. 6306 (cit. on p. 231).\\n[6] I. Ciuca and J. A. Ware. ‘Layered neural networks as universal approximators’.\\nIn: Computational Intelligence Theory and Applications . Ed. by B. Reusch. Berlin,\\nHeidelberg: Springer Berlin Heidelberg, 1997, pp. 411–415 (cit. on p. 304).\\n[7] T. Floyd. Digital Fundamentals. Prentice Hall, 2003 (cit. on p. 252).\\n[8] H. Geijer and M. Geijer. ‘Added value of double reading in diagnostic radi-\\nology ,a systematic review’. In: Insights into Imaging 9 (Mar. 2018). DOI : 10.1007/\\ns13244-018-0599-0 (cit. on pp. 282, 328, 329).\\n[9] X. Glorot and Y . Bengio. ‘Understanding the difﬁculty of training deep feedfor-\\nward neural networks’. In: Journal of Machine Learning Research - Proceedings T rack\\n9 (Jan. 2010), pp. 249–256 (cit. on pp. 258, 313).\\n[10] S. Gomar, M. Mirhassani and M. Ahmadi. ‘Precise digital implementations of\\nhyperbolic tanh and sigmoid function’. In: 2016 50th Asilomar Conference on Sig-\\nnals, Systems and Computers (2016) (cit. on p. 254).\\n[11] I. Goodfellow, Y . Bengio and A. Courville. Adaptive computation and machine\\nlearning. MIT Press, 2016 (cit. on p. 332).\\n[12] J. Gurmeet Singh Manku. ‘Detecting near-duplicates for web crawling’. In: Pro-\\nceedings of the 16th International Conference on World Wide Web (2007), p. 141 (cit.\\non pp. 244, 245, 298).\\n[13] K. He. Deep Residual Learning for Image Recognition . 2015. arXiv: 1512 . 03385\\n(cit. on p. 279).\\n[14] K. He et al. Delving Deep into Rectiﬁers: Surpassing Human-Level Performance on\\nImageNet Classiﬁcation. 2015. arXiv: 1502.01852 [cs.CV] (cit. on pp. 258, 273).\\n[15] A. Ignatov et al. ‘Dslr-quality photos on mobile devices with deep convolu-\\ntional networks’. In: IEEE International Conference on Computer Vision (ICCV) .\\n2017, pp. 3297–3305 (cit. on p. 231).\\n[16] S. Ioffe and C. Szegedy. ‘Batch Normalization’. In: CoRR abs/1502.03167 (2015).\\narXiv: 1502.03167 (cit. on pp. 273, 326, 330).\\n335REFERENCES\\n[17] R. Kohavi. ‘A Study of Cross-Validation and Bootstrap for Accuracy Estima-\\ntion and Model Selection’. In: Morgan Kaufmann, 1995, pp. 1137–1143 (cit. on\\npp. 231, 289).\\n[18] A. Krizhevsky , I. Sutskever and G. E. Hinton. ‘ImageNet Classiﬁcation with\\nDeep Convolutional Neural Networks’. In: Advances in Neural Information Pro-\\ncessing Systems . Ed. by F. Pereira et al. V ol. 25. Curran Associates, Inc., 2012,\\npp. 1097–1105 (cit. on pp. 252, 306).\\n[19] Libtorch: The PyT orch C++ frontend is a C++14 library for CPU and GPU tensor com-\\nputation. 2020 (cit. on pp. 254, 256).\\n[20] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on pp. 266, 267).\\n[21] P . Ramachandran.Searching for Activation Functions . 2017. arXiv: 1710.05941\\n[cs.NE] (cit. on p. 260).\\n[22] D. E. Rumelhart and G. E. Hinton. ‘Learning Representations by Back Propagat-\\ning Errors’. In: Neurocomputing: Foundations of Research . Cambridge, MA, USA:\\nMIT Press, 1988, pp. 696–699 (cit. on pp. 236, 252, 260, 292, 306).\\n[23] S. Sengupta et al. ‘Sfsnet: Learning shape, reﬂectance and illuminance of faces\\nin the wild’. In: Computer Vision and Pattern Regognition (CVPR) . 2018 (cit. on\\np. 231).\\n[24] Z. Shu, E. Yumer and S. Hadap. ‘Neural face editing with intrinsic image dis-\\nentangling’. In: Computer Vision and Pattern Recognition (CVPR) IEEE Conference .\\n2017, pp. 5444–5453 (cit. on p. 231).\\n[25] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 263, 265).\\n[26] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on pp. 266, 267).\\n[27] C. Szegedy et al. ‘Inception v4, Inception-ResNet and the Impact of Residual\\nConnections on Learning’. In: ICLR 2016 Workshop. 2016 (cit. on p. 326).\\n[28] P . Vincent et al. ‘Extracting and composing robust features with denoising au-\\ntoencoders’. In: Proceedings of the 25th international conference on Machine learning .\\n2008, pp. 1096–1103 (cit. on p. 326).\\n336Chapter 8 DEEP LEARNING\\n[29] J. Ziv and N. Merhav . ‘A measure of relative entropy between individual se-\\nquences with application to universal classiﬁcation’. In: IEEE T ransactions on In-\\nformation Theory 39(4) (1993), pp. 1270–1279 (cit. on pp. 245, 298).\\n337REFERENCES\\n338PRACTICE EXAM\\nPART VCHAPTER\\n9\\nJOB INTER VIEW MOCK EXAM\\nA man who dares to waste one hour of time has not discovered the value of life.\\n— Charles Darwin\\nContents\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nClassiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nStressful events, such as a job interview, prompt concern and anxiety (as they do for\\nvirtually every person), but it’s the lack of preparation that fuels unnecessary nervous-\\nness. Many perceive the interview as a potentially threatening event. Testing your\\nknowledge in AI using a mock exam, is an effective way to not only identifying your\\nweaknesses and to pinpointing the concepts and topics that need brushing up, but\\nalso to becoming more relaxed in similar situations. Remember that at the heart of job\\ninterview conﬁdence is feeling relaxed.\\nDoing this test early enough, gives you a head-start before the actual interview, so\\nthat you can target areas that require perfection. The exam includes questions from\\na wide variety of topics in AI, so that these areas are recognised and it would then\\nbe a case of solving all the problems in this book over a period of few months to be\\nproperly prepared. Do not worry even if you can not solve any of the problems in the\\nexam as some of them are quite difﬁcult.DEEP LEARNING JOB INTER VIEW MOCK EXAM\\nEXAM INSTRUCTIONS :\\nYOU SHOULD NOT SEARCH FOR SOLUTIONS ON THE WEB . M ORE GENERALLY , YOU\\nARE URGED TO TRY AND SOLVE THE PROBLEMS WITHOUT CONSULTING ANY REFER -\\nENCE MATERIAL , AS WOULD BE THE CASE IN A REAL JOB INTERVIEW .\\n9.0.1 Rules\\nREMARK: In order to receive credits, you must:\\ni Show all work neatly .\\nii A sheet of formulas and calculators are permitted but not notes or texts.\\niii Read the problems CAREFULLY\\niv Do not get STUCK at any problem (or in local minima ...) for too much time!\\nv After completing all problems, a double check is STRONGLY advised.\\nvi You have three hours to complete all questions.\\n342Chapter 9 JOB INTER VIEW MOCK EXAM\\n9.1 Problems\\n9.1.1 Perceptrons\\nPRB-267 \\uf059 CH.PRB- 9.1. [PERCEPTRONS]\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 9.1: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the resulting value from the application of the sum operator?\\n3. Using PyT orch tensors, verify the correctness of your answers.\\n9.1.2 CNN layers\\nPRB-268 \\uf059 CH.PRB- 9.2. [CNN LAYERS]\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and examine its behaviour during inference:\\n3439.1. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 9.'),\n",
              " Document(metadata={}, page_content=' PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 9.1: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n344Chapter 9 JOB INTER VIEW MOCK EXAM\\nFIGURE 9.2: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet\\na second MaxPool2D(2,2). What is the resulting tensor shape after running line 9?\\nand line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\n9.1.3 Classification, Logistic regression\\nPRB-269 \\uf059 CH.PRB- 9.3. [CLASSIFICATION, LR]\\nT o study factors that affect the survivability of humans infected with COVID19 using\\nlogistic regression, a researcher considers the link between lung cancer and COVID19 as a\\n3459.1. PROBLEMS\\nplausible risk factor. The predictor variable is a count of removed pulmonary nodules (Fig.\\n9.3) in the lungs.\\nFIGURE 9.3: Pulmonary nodules.\\nThe response variable Y measures whether the patient shows any remission (as in the\\nmanifestations of a disease, e. g. yes=1, no=0) when the pulmonary nodules count shifts up\\nor down. The output from training a logistic regression classiﬁer is as follows:\\nStandard\\nParameter DF Estimate Error\\nIntercept 1 -4.8792 1.0732\\nPulmonary nodules 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of removed pulmonary nod-\\nules of a patient is 33.\\n2. Find out the removed pulmonary nodules count at which the estimated probability of\\nimprovement is 0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1, in the total\\nremoved pulmonary nodule count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total removed pulmonary nodule count. Remember that The most common\\nconﬁdence levels are 90%, 95%, 99%, and 99.9%.\\n346Chapter 9 JOB INTER VIEW MOCK EXAM\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 9.1: Common conﬁdence levels\\nT able9.1 lists the z values for these levels.\\n9.1.4 Information theory\\nPRB-270 \\uf059 CH.PRB- 9.4. [INFORMATION THEORY]\\nThis question discusses the link between binary classiﬁcation, information gain and\\ndecision trees. Recent research suggests that the co-existence of inﬂuenza (Fig. 9.4) and\\nCOVID19 virus may decrease the survivability of humans infected with the COVID 19\\nvirus. The data (T able 9.2) comprises a training set of feature vectors with corresponding\\nclass labels which a researcher intents classifying using a decision tree.\\nT o study factors affecting COVID19 eradication, the deep-learning researcher collects\\ndata regrading two independent binary variables; θ1 (T/F) indicating whether the patient is\\na female, and θ2 (T/F) indicating whether the human tested positive for the inﬂuenza virus.\\nThe binary response variable, γ, indicates whether eradication was observed (e.g. eradica-\\ntion=+, no eradication=-).\\n3479.1. PROBLEMS\\nFIGURE 9.4: The inﬂuenza virus.\\nReferring to T able ( 9.2), each row indicates the observed values, columns ( θi) denote\\nfeatures and rows (< θ i, γi >) denote labelled instances while class label ( γ) denotes whether\\neradication was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 9.2: Decision trees and the COVID19 virus.\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\n348Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-271 \\uf059 CH.PRB- 9.5.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh) + p(xt) = 1 , what is the\\nformula for the average surprise?\\n6. What is the value of the average surprise in bits?\\nPRB-272 \\uf059 CH.PRB- 9.6.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\n9.1.5 Feature extraction\\nPRB-273 \\uf059 CH.PRB- 9.7. [FEATURE EXTRACTION]\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n3499.1. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 9.5: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\nCODE 9.2: An unknown algorithm in C++11\\n1 void xxx(std::vector<float>& arr){\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nWhich results in this vector ( 9.6):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 9.6: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n350Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-274 \\uf059 CH.PRB- 9.8.\\n[FEATURE EXTRACTION]\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture for the classiﬁcation of the COVID19 pathogen. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with it\\nby utilizing the same logic.\\nIn (Fig. 9.7), 2 different classes of human cells are displayed; infected and not-infected,\\nwhich were curated from a dataset of 4K images labelled by a majority vote of two expert\\nvirologists. Y our task is to use FE to correctly classify the images in the dataset.\\nFIGURE 9.7: A dataset of human cells infected by the COVID19 pathogen.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture. As depicted,\\nfor each layer the number of ﬁlters (i. e. neurons with unique set of parameters), learnable\\nparameters (e. g. weights and biases), and FV size are presented.\\n3519.1. PROBLEMS\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 9.3: Incomplete listing of the of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4k images from the dataset, how can\\nyou now classify the images into their respective categories?\\n9.1.6 Bayesian deep learning\\nPRB-275 \\uf059 CH.PRB- 9.9. [BAYESIAN DEEP LEARNING]\\nA recently published paper presents a new layer for Bayesian neural networks (BNNs).\\nThe layer behaves as follows. During the feed-forward operation, each of the hidden neurons\\nHn , n ∈ { 1, 2, } in the neural network in (Fig. 9.8) may, or may not ﬁre, independently\\nof each other, according to a known prior distribution.\\n352Chapter 9 JOB INTER VIEW MOCK EXAM\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 9.8: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ B(n, γ ) random variable and ﬁres\\nwith a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U (0, γ) random variable and ﬁres\\nwith a probability of γ.\\nPRB-276 \\uf059 CH.PRB- 9.10.\\nDuring pregnancy, the Placenta Chorion T est is commonly used for the diagnosis of\\nhereditary diseases (Fig. 9.9).\\nFIGURE 9.9: Foetal surface of the placenta\\nAssume, that a new test entitled the Placenta COVID19 T est has the exact same proper-\\nties as the Placenta Chorion T est. The test has a probability of 0.95 of being correct whether\\nor not a COVID19 pathogen is present. It is known that 1/100 of pregnancies result in\\n3539.1. PROBLEMS\\nCOVID19 virus being passed to foetal cells. Calculate the probability of a test indicating\\nthat a COVID19 virus is present.\\nPRB-277 \\uf059 CH.PRB- 9.11.\\nA person who was unknowingly infected with the COVID19 pathogen takes a walk in\\na park crowded with people. Let y be the number of successful infections in 5 independent\\nsocial interactions or infection attempts (trials), where the probability of “success\" (infecting\\nsomeone else) is θ in each trial. Suppose your prior distribution for θ is as follows: P (θ =\\n1/2) = 0 .25, P (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y).\\n2. Derive the prior predictive distribution for y.\\nPRB-278 \\uf059 CH.PRB- 9.12.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history with a death tool far exceeding all past\\noutbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976 in\\nSudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 9.10: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the centre for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\n354Chapter 9 JOB INTER VIEW MOCK EXAM\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y,\\nγ ∈ [0, 1], y = 1, 2, . . . , n ,\\n(9.1)\\nwhere: \\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 = n!\\n(n − y)!y!. (9.2)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ, the\\nproportion of infected humans in the entire population.\\nThe expectation and variance of the binomial are:\\nE(y|γ, n) = nγ, , V (y|γ, n) = nγ(1 − γ). (9.3)\\nAnswer the following:\\n1. For the likelihood function of the form lx(γ) = log Lx(γ) what is the log-likelihood\\nfunction?\\n2. Find the log-likelihood function ln (L(γ))\\n3. Find the gradient vector g(γ)\\n4. Find the Hessian matrix H(γ)\\n5. Find the Fisher information I(γ)\\n6. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\n3559.1. PROBLEMS\\n356VOLUME TWO\\nPART VICHAPTER\\n10\\nVOLUME TWO - PLAN\\nNothing exists until it is measured.\\n— Niels Bohr, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nV ariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . 36110.1. INTRODUCTION\\nT ext to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\n10.1 Introduction\\nI\\nT is important at the outset to understand we could not possibly include\\neverything we wanted to include in the ﬁrst VOLUME of this series. While\\nthe ﬁrst volume is meant to introduce many of the core subjects in AI, the\\nsecond volume takes another step down that road and includes numerous,\\nmore advanced subjects. This is a short glimpse into the plan for VOLUME-2 of this\\nseries. This second volume focuses on more advanced topics in AI\\n10.2 AI system design\\n10.3 Advanced CNN topologies\\n10.4 1D CNN’s\\n10.5 3D CNN’s\\n10.6 Data augmentations\\n10.7 Object detection\\n10.8 Object segmentation\\n10.9 Semantic segmentation\\n10.10 Instance segmentation\\n10.11 Image classification\\n10.12 Image captioning\\n10.13 NLP\\n360Chapter 10 VOLUME TWO - PLAN\\n10.14 RNN\\n10.15 LSTM\\n10.16 GANs\\n10.17 Adversarial attacks and defences\\n10.18 Variational auto encoders\\n10.19 FCN\\n10.20 Seq2Seq\\n10.21 Monte carlo, ELBO, Re-parametrization\\n10.22 Text to speech\\n10.23 Speech to text\\n10.24 CRF\\n10.25 Quantum computing\\n10.26 RL\\n36110.26. RL\\n362List of Tables\\nTumour eradication statistics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\nCommon conﬁdence levels. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nTumour shrinkage in rats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nProbability values of hereditary-disease detection. . . . . . . . . . . . . . . . . 67\\nDecision trees and frogs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\\nDecision trees and Cannabinoids administration . . . . . . . . . . . . . . . . . 96\\nDecision trees and star expansion. . . . . . . . . . . . . . . . . . . . . . . . . . 97\\nDecision trees and radiation therapy . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nSplitting on θ2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . 169\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute\\n∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\\nImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches. . . 193\\nIncomplete listing of the VGG19 architecture . . . . . . . . . . . . . . . . . . . 209\\nIncomplete listing of the VGG11 architecture. . . . . . . . . . . . . . . . . . . . 265\\nComputed values for the Sigmoid and the Sigmoid approximation. . . . . . . 310\\nCommon conﬁdence levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nDecision trees and the COVID19 virus. . . . . . . . . . . . . . . . . . . . . . . . 348\\nIncomplete listing of the of the VGG19 architecture . . . . . . . . . . . . . . . . 352LIST OF TABLES\\n364List of Figures\\nExamples of two sigmoid functions. . . . . . . . . . . . . . . . . . . . . . . . . 15\\nPulmonary nodules (left) and breast cancer (right). . . . . . . . . . . . . . . . . 16\\nA multi-detector positron scanner used to locate tumours. . . . . . . . . . . . 18\\nA dental amalgam. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nA chain of spherical bacteria. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nCannabis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nLogistic regression in CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nA linear model in PyTorch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 25\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 26\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds vs. probability values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\nBinary entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nLogistic regression in C++ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nHistopathology for pancreatic cancer cells. . . . . . . . . . . . . . . . . . . . . 44\\nBosons and fermions: particles with half-integer spin are fermions. . . . . . . 46\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe Dercum disease . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe New York Stock Exchange. . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\nHedge funds and monkeys. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nDialect detection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nThe Morse telegraph code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nOnOffLayer in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 57\\nThe Maxwell-Boltzmann distribution. . . . . . . . . . . . . . . . . . . . . . . . 58\\nA QuantumDrop layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nThe binomial distribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nZ-score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62LIST OF FIGURES\\nConditional probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\nV enn diagram of the intersected events A and B in probability space H . . . . 63\\nAnnotated components of the Bayes formula (eq. 3.23) . . . . . . . . . . . . . . 64\\nMutual information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nReﬂection on the motive power of ﬁre. . . . . . . . . . . . . . . . . . . . . . . . 87\\nNatural (ln), binary (log2) and common ( log10) logarithms. . . . . . . . . . . . . 88\\nA Frog in its natural habitat. Photo taken by my son. . . . . . . . . . . . . . . . 95\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\\nShannon\\'s ﬁve element communications system. . . . . . . . . . . . . . . . . . 99\\nAn octahedral dice. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in information theory . . . . . . . . . . . . . . . . . . . . . . . . . . 102\\nH vs. Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\nShannon information gain for a biased coin toss. . . . . . . . . . . . . . . . . . 107\\nAverage surprise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nFirst split. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nMutual Information between H(S) & H(D). . . . . . . . . . . . . . . . . . . . . 117\\nIntermediate value theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nA Computation graph with intermediate values as nodes and operations as\\narcs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nx2 Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\\nForward pass for the sigmoid function. . . . . . . . . . . . . . . . . . . . . . . . 135\\nPyTorch syntax for autograd. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 137\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 139\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 140\\nA computation graph for g(x) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nA Tangent line . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\n366Chapter 10 LIST OF FIGURES\\nForward and backward passes for the sigmoid activation function in pure\\nPython. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\\nForward and backward for the sigmoid function in Autograd. . . . . . . . . . 159\\nForward and backward for the ReLU function in Autograd. . . . . . . . . . . . 160\\nForward pass for equation ( 5.23) using pure Python. . . . . . . . . . . . . . . . 161\\nForward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . . 161\\nBackward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nInvoking arctanh using gradcheck . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nA Computation graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . 168\\nA derivative graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . . . 169\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 170\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 172\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSymPy gradient of the Sigmoid() function . . . . . . . . . . . . . . . . . . . . . 174\\nSymPy imports . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\\nLikelihood function using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . 176\\nBeta distribution using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\nA plot of the Posterior with the provided data samples. . . . . . . . . . . . . . 181\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 191\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 194\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 195\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 196\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 197\\nA learning rate schedule. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\n367LIST OF FIGURES\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depic-\\nted is the ResNet CNN architecture with 34 layers. . . . . . . . . . . . . . 206\\nPyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 206\\nA dataset of 4K histopathology WSI from three severity classes: A, B and C. . 209\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\\nSkin lesion categories. An exemplary visualization of melanoma. . . . . . . . 214\\nArtistic style transfer using the style of Francis Picabia’s Udnie painting. . . . 215\\nPyTorch declaration for a pre-trained ResNet34 CNN. . . . . . . . . . . . . . . 216\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\\nTwo CV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nStratiﬁed K-fold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nA speciﬁc CV approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\nA padding approach . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . 221\\nTwo CV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nStratiﬁed K-fold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nA speciﬁc CV approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 239\\nA 3 by 3 convolution kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 240\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 242\\nlisting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nAn unknown algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\\nJaccard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nA basic MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\n368Chapter 10 LIST OF FIGURES\\nA single layer perceptron. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nExamples of two sigmoid functions and an approximation. . . . . . . . . . . . 254\\nForward pass for the Sigmoid function using Libtorch . . . . . . . . . . . . . . 255\\nEvaluation of the sigmoid and its derivative using Libtorch . . . . . . . . . . . 255\\nExamples of two tanh functions. . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nA simple NN based on tanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 257\\nA small CNN composed of tanh blocks. . . . . . . . . . . . . . . . . . . . . . . 258\\nA small CNN composed of ReLU blocks. . . . . . . . . . . . . . . . . . . . . . 259\\nA confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 261\\nRUC AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\\nXGBOOST for binary classiﬁcation. . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics on the VGG11 CNN model. . . . . . . . . . . . . . . . . . . . 264\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nTwo consecutive Dropout layers . . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nA CNN based classiﬁcation system. . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nA small ﬁlter for a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nInput to MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . . . . 271\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 273\\nNormal distribution in Python. . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nA convolution and BN applied to an RGB image. . . . . . . . . . . . . . . . . . 275\\nA mistake in a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\\nA validation curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog-loss function curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\\nA problem with the log-loss curve. . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nManhattan distance function. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\n369LIST OF FIGURES\\nThe idea of hashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301\\nMLP operations- values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\\nHidden layer values, simple MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- values at the output. . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- Softmax. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\\nLogical AND: B=-2.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND: B=-0.25 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nBackward pass for the Sigmoid function using Libtorch. . . . . . . . . . . . . . 307\\nEvaluation of the sigmoid and its derivative in C++ using Libtorch. . . . . . . 308\\nForward pass for the Sigmoid function approximation in C++ using Libtorch. 309\\nPrinting the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\\nForward pass for tanh using pure Python. . . . . . . . . . . . . . . . . . . . . . 311\\nTanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\\nInvoking gradcheck on tanh. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313\\nA plot of the Swish activation function. . . . . . . . . . . . . . . . . . . . . . . 315\\nTP , TN, FP , FN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 317\\nConvolutional block from the VGG11 architecture. . . . . . . . . . . . . . . . . 319\\nEquivalence of two consecutive dropout layers . . . . . . . . . . . . . . . . . . 321\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nThe result of applying a ReLU activation. . . . . . . . . . . . . . . . . . . . . . 322\\nThe result of applying a MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . 322\\nOutput of the MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . 323\\nA single MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324\\nNormal distribution in Python: from scratch. . . . . . . . . . . . . . . . . . . . 325\\nThe derivative of a Normal distribution in Python. . . . . . . . . . . . . . . . . 325\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nSeveral image augmentation methods for TTA. . . . . . . . . . . . . . . . . . . 331\\nManhattan distance function in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 334\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 345\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346\\n370Chapter 10 LIST OF FIGURES\\nThe inﬂuenza virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 350\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\\nA dataset of human cells infected by the COVID19 pathogen. . . . . . . . . . . 351\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354\\n371LIST OF FIGURES\\n372Alphabetical Index\\nA\\nA 2D convolution . . . . . . . . . . . . . . . . . .235\\nA 512 dimension embedding . . . . . . . 206\\nA mathematical theory of\\ncommunication . . . . . . . . . . . . . 90\\nA random forest . . . . . . . . . . . . . . . . . . . 187\\nACC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .329\\nAccuracy . . . . . . . . . . . . . . . . .251, 283, 329\\nActivation functions . 125, 135 ff., 139 ff.,\\n157 f., 160, 163, 165, 168, 248,\\n256, 301, 306\\nActivation layer . . . . . . . . . . . . . . .253, 306\\nAD . . . . . . . . . . . . . . . . .123 f., 137, 140, 166\\nAdam . . . . . . . . . . . . . . . . . . . . . . . . . . . . .330\\nAdditivity property . . . . . . . . . . . . . . . .103\\nAlexNet . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nAlgorithmic differentiation . . . .125, 135,\\n137, 139 ff., 146, 157 f., 160, 163,\\n165, 168\\nAlzheimer’s disease . . . . . . . . . . . . . . . . . 20\\nAmalgam ﬁllings . . . . . . . . . . . . . . . . . . . 18\\nAnalytical gradients . . . . . . . . . . . . . . . 134\\nAnalyze a paper . . . . . . . . . . . . . . . . . . . 260\\nAND logic gate . . . . . . . . . . . . . . . . . . . . 252\\nANN . . . . . . . . . . . . . . . . . . . . . . . . . . .15, 135\\nAnnotated probabilities . . . . . . . . . . . . .62\\nAnnotations . . . . . . . . . . . . . . . . . . . . . . .282\\nANNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\\nANOV A . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nApproaches for combining predictors\\n190, 199\\nArithmetic operations . . . . . . . . . 138, 163\\nArithmetical methods . . . . . . . . . . . . . . .41\\nArtiﬁcial neural networks . . . . . . . 12, 15\\nAUC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nAugmentation . . . . . . . . . . . . . . . . . . . . .222\\nAugmentations . . . . . . . . . . . . . . . . . . . . . . 8\\nAuto correlation . . . . . . . . . . . . . . .235, 291\\nAutoAugment . . . . . . . . . . . . . . . . . . . . .223\\nAutoencoder . . . . . . . . . . . . . . . . . .279, 326\\nAutoGrad . . . . . . . . . . . . . . . . . . . . .158, 173\\nAutograd124 f., 135–141, 157 f., 160, 163,\\n165, 168, 310\\nAutomatic differentiation . . . .123 f., 173\\nAveraging and majority voting . . . . .202\\nB\\nBack-propagation in perceptrons . . 249,\\n301\\nBack-propogation . . . . . . . . . . . . . . . . . .247\\nBackprop learning . . . . . . . . . . . . . . . . .134\\nBackprop learning rule . . . . . . . . . . . . 134\\nBackpropagation . . . . . . . . . 123, 134, 158\\nBackpropagation algorithm . . . 135, 156\\nBackward pass125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nBagging . . . . . . . . . . . . . .186, 189, 193, 198\\nBasic laws of logarithms . . . . . . . . . . . . 88\\nBatch normalization . . . . . . . . . . .273, 324\\nBatchNorm2D . . . . . . . . . . . . . . . . 271, 343\\nBayes formulae . . . . . . . . . . . . . . . . . .45, 64\\nBayes rule . . . . . . . . . . . . . 45, 47, 66, 353 f.ALPHABETICAL INDEX\\nBayes theorem . . . . 42, 46–50, 65 f., 68 ff.\\nBayesian . . . . . . . . . . . . . . . . . . . . . . . . . . . .77\\nBayesian analysis . . . . . . . . . . . . . . . .65, 77\\nBayesian approximation . . . . . . . . . . . 192\\nBayesian deep learning . . . . . 55, 77, 352\\nBayesian dropout . . . . . . . . . . . . . . . . . .352\\nBayesian inference . . . . . . . . . . . . . . .42, 45\\nBayesian machine learning . . . . . . . . . .54\\nBayesian neural networks . . . . . .55 f., 79\\nBayesian paradigm . . . . . . . . . . . . . . . . . 42\\nBayesian statistical conclusions . . . . . 65\\nBayesian statistics . . . . . . . . . . . . . . . 42, 65\\nBernoulli . . . . . . . . . . . . . . . . . . . . . . .75, 277\\nBernoulli distribution . . . . . . . . . . . . . . .53\\nBernoulli random variable . . . . . . . . . . 18\\nBernoulli trial . . . . . . . . . . . . . . 42 f., 59, 62\\nBeta binomial . . . . . . . . . . . . . . . . . . . . . .146\\nBeta binomial distribution . . . . . . . . .54 f.\\nBeta distribution . . . . . . . 42, 55, 146, 176\\nBeta prior . . . . . . . . . . . . . . . . . . . . . . . . . . .55\\nBias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .282\\nBiased coin . . . . . . . . . . . . . . . . . . . . .92, 349\\nBiased coin toss . . . . . . . . . . . . . . . . . 64, 92\\nBiases . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nBinary class . . . . . . . . . . . . . . . . . . . . . . . . .38\\nBinary classiﬁcation 12, 15, 96, 137, 190,\\n193 f., 246\\nBinary code . . . . . . . . . . . . . . . . . . . . . . . . .90\\nBinary logistic regression . . . . . . . . 14, 31\\nBinary options . . . . . . . . . . . . . . . . . . . . 48 f.\\nBinary response . . . . . . . . . . . . . . . . . . . . .14\\nBinary response variable . . . . . 19, 94, 97\\nBinomial . . . . . . . . . . . . . . . . . . . .43, 53, 354\\nBinomial distribution31, 43, 52 f., 55, 59,\\n78\\nBinomial likelihood . . . . . . . . . . . . 54, 178\\nBinomial random variable . . . . . 43, 59 f.\\nBlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .318\\nBN . . . . . . . . . . . . . . . . . . .273 f., 277, 324 ff.\\nBNN . . . . . . . . . . . . . . . . . . . . . . . . . . 55 f., 79\\nBNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nBohm and Hiley . . . . . . . . . . . . . . . . . . . . 87\\nBoltzmann . . . . . . . . . . . .58, 86, 100 f., 118\\nBoltzmann entropy . . . . . . . . . . . . . . . . 118\\nBoltzmann’s constant . . . . . . . . . . . . . . 100\\nBoltzmanns entropy . . . . . . . . . . . . . . . 101\\nBoosting . . . . . . . . .186, 189, 193, 198, 200\\nBootstrap aggregation . . . . . . . . .189, 192\\nBosons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nBosons and fermions . . . . . . . . . . . . . . . .46\\nBottleneck . . . . . . . . . . . . . . . . . . . . 279, 326\\nBrazilian rain forest . . . . . . . . . . . . . . . . .94\\nBreast cancer . . . . . . . . . . . . . . . . . . . . . . . 17\\nC\\nCalculus . . . . . . . . . . . . . . . . .80, 122 f., 143\\nCalculus in deep learning . . . . . . . . . . 123\\nCancer . . . . . . . . . . . . . . . . . . . . . .16, 43, 208\\nCannabinoids . . . . . . . . . . . . . . . . . . . . . . .96\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . .96\\nCDC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354\\nCE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nChain of spherical bacteria . . . . . . . . . . 20\\nChain rule . . . . . . . . . . . . . . . . . . . . . . . . .163\\nChaotic distribution . . . . . . . . . . . . . . . . 38\\nCI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .35\\nClass probabilities . . . . . . . . . . . . .190, 199\\nClassic bagging . . . . . . . . . . . . . . . . . . . .199\\nClassic logistic regression . . . . . . . . . . . 35\\nClassic normalization . . . . . . . . . . . . . . .29\\nClassical committee machines . . . . . .189\\nClassical machine learning . . . . . . . . . 201\\nClassical probability . . . . . . . . . . . . . . . . 42\\n374Chapter 10 ALPHABETICAL INDEX\\nClassiﬁcation . . . . . 32, 206, 208, 289, 345\\nClassiﬁcation and information gain . 94,\\n110\\nClaud Shannon . . . . . . . . . . . . . . . . . . . . .90\\nCM . . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nCNN . . . 8, 190, 192, 205 f., 216, 272, 274,\\n318, 326, 344, 349\\nCNN arithmetics . . . . . . . . . . . . . . . . . . 318\\nCNN as Fixed Feature Extractor . . . 206,\\n216\\nCNN classiﬁers . . . . . . . . . . . . . . . . . . . .192\\nCNN feature extraction . . . . . . . . . . . . 206\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . .343\\nCNN model predictions . . . . . . . . . . . 190\\nCNN parameters . . . . . . . . . . . . . . . . . . 207\\nCNN residual blocks . . . . . . . . . . . . . . .326\\nCoefﬁcients . . . . . . . . . . . . . . . . . . 12, 16, 27\\nCoffee consumption . . . . . . . . . . . . . . . . 36\\nCoin toss . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nCoin toss probabillity . . . . . . . . . . . . . . . 93\\nCommon conﬁdence levels . . . . . . . . . .21\\nComplementary probability . . . . . . . . .63\\nComputational graph . . . . . . . . . . . . . .140\\nComputational graphs . . 127, 140 f., 165,\\n168\\nConcave . . . . . . . . . . . . . . . . . . . . . . 154, 202\\nConcave and Convex functions . . . . 101\\nConcavity . . . . . . . . . . . . . . . . . . . . .106, 154\\nConcavity of the logarithm . . . . . . . . 106\\nConditional entropy . . . . . . . . . . . . . . . 118\\nConditional independence . . . . . . . . . . 66\\nConditional probability42, 44–50, 62, 69\\nConﬁdence intervals . . . . . . . . . . . . . . . . 37\\nConfusion matrics . . . . . . . . . . . . .261, 316\\nConfusion matrix . . . . . . . . . . . . . . . . . .316\\nConjugate prior . . . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . .54 f., 77\\nContent loss . . . . . . . . . . . . 214, 216, 224 f.\\nConv2D . . . . . . . . . . . . . . . . . . . . . . .271, 343\\nConv2d layer . . . . . . . . . . . . . . . . . . . . . .223\\nConv4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nConvex . . . . . . . . . . . . . . . . . . . . . . . 132, 202\\nConvex down function . . . . . . . . . . . . 119\\nConvex functions . . . . . . . . . . . . . . . . . .132\\nConvNet’s as ﬁxed feature extractors\\n206\\nConvolution . . . . . . . . . . . . . .234, 277, 291\\nConvolution and correlation in python\\n294\\nConvolution complexity . . . . . . . . . . . 240\\nConvolution layer . . . . . . . . . . . . .268, 321\\nConvolutional layer . . . . . . . . . 268, 321 f.\\nConvolutional neural network . . . . . . . 8\\nConvolutional neural networks192, 198\\nCorrelation . . . . . . . . . . . . . . . . . .234 f., 291\\nCost . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nCost function . . . . . . . . . . . . . . . . . . . . . .247\\nCovariance . . . . . . . . . . . . . . . . . . . . . . . .189\\nCovariates . . . . . . . . . . . . . . . . . . . . . . . . . .17\\nCOVID19 . . . . . . . . . . . . . . . . . . . . .345, 351\\nCPP 23 f., 38 f., 142 f., 168 f., 242 f., 254 f.,\\n307 ff.\\nCPP hypothesis . . . . . . . . . . . . . . . . . . . . .23\\nCPU . . . . . . . . . . . . . . . . . . . . . . . . . .222, 289\\nCPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\nCross correlation . . . . . . . . . . . . . .235, 291\\nCross entropy . . . . . . . . . . . . . . . . 25 f., 251\\nCross entropy loss . . . . . . . . . . . . .214, 251\\nCross validation . . . . . . . . . . 231, 289, 328\\nCross validation approaches . . .231, 289\\nCUDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . .289\\nCV . . . . . . . . . . . . . . . . . . . . . . . . . . . .231, 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . 289\\n375ALPHABETICAL INDEX\\nD\\nDAG . . . . . . . . . . . . . . . . .123, 126, 141, 168\\nData Science . . . . . . . . . . . . . . . . . . . . . . . . .4\\nDecision boundary . . . . . . . . . . . . . . . . . .14\\nDecision tree . . . 94 f., 97 f., 111, 187, 198\\nDecision trees . . . . . . . . . . . . . 94, 96 f., 348\\nDecision trees and cannabinoids\\nadministration . . . . . . . . . . . . . . 96\\nDeep Learning . . . . . . . . . . . . . . . . . . . . . . .4\\nDeep learning . . . . . 22, 77, 123, 196, 352\\nDeep Learning Job Interviews . . . . . . . . 6\\nDeep learning pipelines . . . . . . . . . . . .221\\nDental amalgam . . . . . . . . . . . . . . . . . . . .19\\nDercum disease . . . . . . . . . . . . . . . . . . . . .47\\nDifferentiation . . . . . . . . . .122, 143 f., 150\\nDifferentiation in deep learning . . . . 123\\nDirect derivation . . . . . . . . . . . . . . . . . . . .32\\nDirected Acyclic Graph . . . . . . . . . . . . 168\\nDirected acyclic graph . . . . . . . . . . . . . 141\\nDirected acyclic graphs . . . . . . . .126, 147\\nDirectional derivative . . . . . . . . . . . . . .131\\nDirectional derivatives . . . . . . . . . . . . .125\\nDistribution . . . . . . . . . . . . . . . . . . . . . . . . 45\\nDL . . . . . . . . . . . . . . 123, 196, 206, 221, 352\\nDL classiﬁcation pipeline . . . . . . . . . . . 91\\nDL job interviews . . . . . . . . . . . . . . . . . .206\\nDN . . . . . . . . . . . . . . . . . . . . . . . . . .138 f., 163\\nDouble reading . . . . . . . . . . . . . .282 f., 329\\nDPN CNN . . . . . . . . . . . . . . . . . . . . . . . . .223\\nDropout8, 57, 267 f., 277, 319 f., 326, 352\\nDropout as a bayesian approximation\\n192\\nDropout in PyTorch . . . . . . . . . . . . . . . . .56\\nDropout layer . . . . . . . . . . 57, 267 f., 319 f.\\nDropped out neurons . . . . . . . . . . . . . . . 57\\nDual numbers . . . . . . . . . .138 ff., 163, 165\\nDual numbers in AD . . . . . . . . . . 138, 163\\nE\\nEbola . . . . . . . . . . . . . . . . . . . . . . . . .53, 354 f.\\nEmbedding . . . . . . . . . . . . . . . . . . . . . . . .206\\nEncoded messages . . . . . . . . . . . . . . . . . .51\\nEncrypted communications . . . . . . . . . 50\\nEnigma machine . . . . . . . . . . . . . . . . . . . .50\\nEnsemble averaging . . . . . . . . . . . . . . . 193\\nEnsemble learning . . . . . . . .186, 194, 201\\nEnsemble methods . . . . . . . . . . . . 190, 195\\nEnsembling . . . . . .186 ff., 190, 194 f., 197\\nEntropy 22, 38, 86 f., 89, 93, 95, 97 f., 106,\\n108, 214, 349\\nEntry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .186\\nEpidemic . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nEquiprobable events . 90 f., 103, 105, 118\\nEquiprobable sample . . . . . . . . . . . . . . 189\\nEquivocation . . . . . . . . . . . . . . . . . . . . . . . 99\\nEradication . . . . . . . . . . . . . . . . . . . . . . . .347\\nEradication probabillity . . . . . . . . . . . . .18\\nEuclidean . . . . . . . . . . . . . . . . . . . . .288, 333\\nExpansion of stars . . . . . . . . . . . . . . . . . . 97\\nExpectation . . . . . . . . . . . . . . . . . . . . . . . . .62\\nExpectation and variance . . . . . . . . 42, 59\\nExplanatory variable . . . . . . . . . . . . . . . .17\\nExponential family . . . . . . . . . . . . . . . . . .78\\nF\\nFc7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nFeature extraction 214 f., 224 f., 349, 351\\nFeature vector . . . . . . . . . . . . . . . . .205, 350\\nFeature vectors . . . . . . . . . . . . . . . . . . . . . 96\\nFeed forward neural networks 135, 158\\nFermions . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nFFNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\n376Chapter 10 ALPHABETICAL INDEX\\nFiltering . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nFiltering kernel . . . . . . . . . . . . . . . . . . . . 234\\nFilters . . . . . . . . . . . . . . . . . . . . . . . . .239, 293\\nFinancial mathematics . . . . . . . . . . . . . . 42\\nFine tuning CNNs . . . . . . . . . . . . 213, 222\\nFinite difference rule . . . . . . . . . . 125, 147\\nFisher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nFisher information . . . . . . . . . 51, 53, 73 f.\\nFisher score . . . . . . . . . . . . . . . . . . . . . . . . .73\\nFliping . . . . . . . . . . . . . . . . . . . . . . . . . . . .294\\nForward mode . . . . . . . . . .131, 140 f., 168\\nForward mode AD . 140 f., 163, 166, 168\\nForward mode AD table construction\\n142, 168\\nForward pass . 125'),\n",
              " Document(metadata={}, page_content=' . . 213, 222\\nFinite difference rule . . . . . . . . . . 125, 147\\nFisher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nFisher information . . . . . . . . . 51, 53, 73 f.\\nFisher score . . . . . . . . . . . . . . . . . . . . . . . . .73\\nFliping . . . . . . . . . . . . . . . . . . . . . . . . . . . .294\\nForward mode . . . . . . . . . .131, 140 f., 168\\nForward mode AD . 140 f., 163, 166, 168\\nForward mode AD table construction\\n142, 168\\nForward pass . 125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nG\\nGausiian distribution . . . . . . . . . .241, 295\\nGaussian . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nGaussian bell . . . . . . . . . . . . . . . . . . . . . .241\\nGaussian distribution . . . . . . . . . 274, 324\\nGaussian PDF . . . . . . . . . . . . . . . . . . . . . 324\\nGeneral concepts . . . . . . . . . . . . . . . . 12, 27\\nGeneralization . . . . . . . . . . . . . . . . 186, 206\\nGeneralized delta rule . . . . . . . . . . . . . 135\\ngeneralized linear models . . . . . . . . . . .14\\nGLM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\\nGLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\nGPU . . . . . . . . . . . . . . . . .222, 281, 289, 327\\nGPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\ngradcheck . . . . . . . . . . . . . . . . . . . . . . . . .310\\nGradient . . . . . . . . . . . . . . . . . . . . . .130, 247\\nGradient descent 123, 130, 146, 158, 247\\nGradient descent algorithm . . . . . . . . 132\\nGradient descent and backpropagation\\n124\\nGradients . . . . . . . . . . . . . . . . . . . . . . . . . .222\\nGram matrix . . . . . . . . . . . . . . . . . . . . . . .225\\nGrid search . . . . . . . . . . . . . . . . . . . 282, 328\\nGum bacteria . . . . . . . . . . . . . . . . . . . . . . .20\\nGUR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\nH\\nHereditary disease . . . . . . . . . . . . . . . . . .66\\nHereditary diseases . . . . . . . . . . . . . . . . .47\\nHessian . . . . . . . . . . . . . . . . . . . . . . . . . . . . .74\\nHessian matrix . . . . . . . . . . . . . . . . . . . . . 52\\nHeterogeneous ensembling . . . .191, 200\\nHidden layer . . . . . . . . . . . . . . . . . . .78, 248\\nHidden layers . . . . . . . . . . . . . . . . . . . . . 250\\nHidden node . . . . . . . . . . . . . 248, 252, 343\\nHinton . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nHistopathology . . . . . . . . . . . .43, 217, 351\\nHuang1704snapshot . . . . . . . . . . . . . . .202\\nHuman voice activity . . . . . . . . . . . . . . . 31\\nHyperbolic tangent . . . . . . . . . . . . . . . . 134\\nHyperbolig tangent . . . . . . . . . . . . . . . .138\\nHyperparameter optimization . . . . . 282,\\n327 f.\\nHyperparameters . . . . . . . . . . . . . . . . . .328\\nHypotheis . . . . . . . . . . . . . . . . . . . . . . . . . .16\\nI\\nIdeal classiﬁer . . . . . . . . . . . . . . . . .262, 317\\nIdentity connection . . . . . . . . . . . . . . . . 326\\nImage analysis . . . . . . . . . . . . . . . . . . . . .110\\nImage and text similarity . . . . . . . . . . 296\\nImage processing . . . . . . . . . . . . . . . . . .234\\nImageNet . . . . . . . . . . . . . . . . . .206 f., 222 f.\\nImageNet pre trained CNNs . . . . . . . 213\\n377ALPHABETICAL INDEX\\nImageNet pretrained CNN classiﬁers\\n192\\nImproper prior . . . . . . . . . . . . . . . . . . . . . 54\\nIndependent binary co variates . . . . . 94\\nIndependent events . . . . . . . . . . . . . . . . .45\\nIndependent variables . . . . . . . . . . .19, 97\\nIndividual predictions . . . . . . . . . . . . . 192\\nInductive inference . . . . . . . . . . . . . . . . . 86\\nInference . . . . . . . . . . . . . . . . . . . . . .286, 330\\nInformation gain . . . . . . . . . . 94–98, 106 f.\\nInformation gain values . . . . . . . . . . . . .95\\nInformation matrix . . . . . . . . . . . . . . . . . 53\\nInformation theory . . . . . . . 58, 86, 88–93,\\n98–101, 106, 347\\nInteractions . . . . . . . . . . . . . . . . . . . . . . . . .13\\nIntermediate value theorem . . . . . . . .124\\nIntersected events . . . . . . . . . . . . . . . . . . .63\\nIntroduction . . . .12, 42, 86, 122, 186, 205\\nJ\\nJacard similarity . . . . . . . . . . . . . . . . . . .297\\nJAX . . . . . . . . . . . . . . . . . . . . . . . . . . .136, 158\\nJensen . . . . . . . . . . . . . . . . . . . . . . . . 101, 119\\nJensen’s inequality . . . . . . . . . . . . 101, 118\\nJob Interview . . . . . . . . . . . . . . . . . . . . . . . . 4\\nJohn von Neumann . . . . . . . . . . . . . . . . . 41\\nJoint distribution . . . . . . . . . . . . . . . . . . 110\\nJupyter notebook . . . . . . . . . . . . . . . . . . 143\\nK\\nK Fold cross validation . . . . . . . . . . . . 289\\nK way FC layer . . . . . . . . . . . . . . . . . . . . 217\\nK-Fold cross validation . . . . . . . . . . . . 232\\nKaggle . . . . . . . . . . . . . . . . . . . . . . . .186, 201\\nKaggle competitions . . . . . . . . . . . . . . .201\\nKaiming . . . . . . . . . . . . . . . . . . . . . . . . . . .258\\nKernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nKernels . . . . . . . . . . . . . . . . . . . . . . . 239, 293\\nKL divergence . . . . . . . .53, 93, 100 f., 109\\nKLD . . . . . . . . . . . . . . . . . . . . . . .93, 119, 297\\nKullback Leibler . . . . . . . . . . . . . . . . . . .297\\nKullback Leibler divergence 87, 93, 108\\nL\\nL1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288, 333\\nL2 . . . . . . . . . . . . . . . . . . . . . . . . . . .288, 333 f.\\nLabelling and bias . . . . . . . . . . . . . . . . . 328\\nLaTeX . . . . . . . . . . . . . . . . . . . . . . . . .174, 176\\nLaw of total probability42, 46–50, 66–70\\nLaws of data compression . . . . . . . . . . 86\\nLDCT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nLeaky ReLU . . . . . . . . . . . . . . . . . . . . . . .259\\nLearning logical gates . . . . . . . . . . . . . .305\\nLearning rate schedules in ensembling\\n197, 202\\nLeave one out CV . . . . . . . . . . . . . . . . . .290\\nLeave-one-out CV . . . . . . . . . . . . . . . . . 234\\nLibtorch . . . . . . . . . . . . . .254 f., 257, 307 ff.\\nLikelihood . . . . . . . . . . . . . . . . . . . .44 f., 353\\nLikelihood function . . . 51, 53, 56, 73, 79\\nLikelihood parameter . . . . . . . . . . . . . . .45\\nLimits and continuity . . . . . . . . . 130, 151\\nLinear classiﬁers . . . . . . . . . . . . . . . . . . .219\\nLinear combination of regression . . 201\\nLinear decision boundary . . . . . . . . . . . 14\\nLinear logistic regression model . . . . . 33\\nLinear model in PyTorch . . . . . . . . . . . .24\\nLinear regression . . . . . . . . . . . . . . . . . . 133\\nLinear transformation . . . . . . . . . . . . . 343\\nLinearity . . . . . . . . . . . . . . . . . . . . . . . . . . 235\\nLink function . . . . . . . . . . . . . . . . . . . . . . .31\\nLocal minima . . . . . . . . . . . . . . . . . 198, 202\\n378Chapter 10 ALPHABETICAL INDEX\\nLog likelihood . . . . . . . . . . . . . . . . . . . . . .13\\nLog likelihood function . . 51, 53, 73, 355\\nLog loss . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog odds . . . . . . . . . . . . 13 f., 17 f., 20 f., 29\\nLogarithm . . . . . . . . . . . . . . . . . . . 35, 53, 72\\nLogarithmic function . . . . . . . . . . . . . . 166\\nLogarithms . . . . . . . . . . . .88 f., 101 ff., 172\\nLogarithms in information theory . . . 87\\nLogic gate . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical gates . . . . . . . . . . . . . . . . . .251, 305\\nLogistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogistic inverse . . . . . . . . . . . . . . . . . . . . .14\\nLogistic regression 12–16, 24 ff., 28 f., 31,\\n36, 137, 345\\n• Sigmoid . . . . . . . . . . . . . . . . . . . . . .253\\nLogistic regression classiﬁer . . . . . . . . .19\\nLogistic regression coefﬁcients . . . . . . 16\\nLogistic regression implementation23 f.\\nLogistic regression in C++ . . . . . . . . . . 39\\nLogistic regression in Python . . . . . . . 26\\nLogistic regression model . . . . . . . .27, 35\\nLogistic regression predictor variable12\\nLogistic regression threashold . . . . . . .39\\nLogistic response function . . . . . . . . . . 33\\nLogit . . . . . . . . . . . . . . . . . . . . . . . . . . . .14, 32\\nLogit equation . . . . . . . . . . . . . . . . . . . . . .16\\nLogit function . . . . . . . . . . . . . . . .14, 22, 31\\nLogit inverse . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogit transformation . . . . . . . . . . . . . . . .14\\nLogit value . . . . . . . . . . . . . . . . . . . . . . . . . 33\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . .234, 290\\nLoss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .334\\nLoss function . . . . . . . . . . . . . . . . . . . . . .133\\nLow model generalization . . . . . . . . . 109\\nLow standard error . . . . . . . . . . . . . . . . . 75\\nLower entropy . . . . . . . . . . . . . . . . . . . . . .38\\nLR . . . . . . . . . . . . . 16, 27, 33, 133, 137, 345\\nLR coefﬁcients . . . . . . . . . . . . . . . . . . . . . .16\\nLung cancer . . . . . . . . . . . . . . . . . . . .17, 282\\nM\\nM.Sc in Artiﬁcial Intelligence . . . . . . . . . 4\\nMachine learning . . . . . . 13 f., 25, 28, 316\\nMachine learning terminology . . . . . . 13\\nMacLaurin expansion . . . . . . . . . . . . . .128\\nMacLaurin series . . . . . . . . . . . . . . . . .128 f.\\nMagna Carta . . . . . . . . . . . . . . . . . . . . . . . .90\\nMajority voting . . . . . . . . . . .186, 190, 202\\nMalignant tumour . . . . . . . . . . . . . . . . . . 17\\nMalignant tumours . . . . . . . . . . . . . . . . . 96\\nManhattan . . . . . . . . . . . . . . . . . . . .288, 333\\nManual differentiation . . . . . . . . 124, 170\\nMaster’s programme in Artiﬁcial\\nIntelligence . . . . . . . . . . . . . . . . . . .4\\nMasters programme . . . . . . . . . . . . . . . . . 4\\nMathJax . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nMaximum likelihood estimatator . . . .73\\nMaximum likelihood estimation . 51, 71\\nMaxpool2D . . . . . . . . . . . . . . . . . . .271, 343\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxwell Boltzmann distribution . . . . 57\\nMaxwell distribution . . . . . . . . . . . . . . . 58\\nMean ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .241\\nMean square error . . . . . . . . . . . . . . . . . 225\\nMeasurement vector . . . . . . . . . . . . . . . . 16\\nMechanical statistics . . . . . . . 42, 100, 118\\nMedical AI . . . . . . . . . . . . . . . . . . . . . . . . 217\\nMelanoma . . . . . . . . . . . . . . . . . . . . . . . . .213\\nMigraine probabillity . . . . . . . . . . . . . . . 20\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . .298\\nML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .316\\nMLE . . . . . . . . . . . . . . . . . . .51, 53, 72 f., 355\\nMLP . . . . . . . . . . . . . . .246 ff., 252, 299, 343\\n379ALPHABETICAL INDEX\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . .332\\nMonolithic and heterogeneous\\nensembling . . . . . . . . . . . .191, 200\\nMonolithic architectures . . . . . . . . . . . 200\\nMonolithic ensembling . . . . . . . . . . . . 191\\nMonotonically increasing function . . 72\\nMonte Carlo dropout . . . . . . . . . . . . . . 192\\nMSE . . . . . . . . . . . . . . . . . . . . . .225, 288, 333\\nMulti class responses . . . . . . . . . . . . . . . 29\\nMulti Layer Perceptrons . . . . . . . . . . . 246\\nMulti layer perceptrons . . . . . . . . . . . . 299\\nMulti model ensembling . . . . . . 196, 202\\nMulticlass classiﬁcation . . . . . . . . . . . . . 12\\nMulticlass classiﬁcation problems . . . 12\\nMultivariable . . . . . . . . . . . . . . . . . . . . . . .12\\nMultivariable methods . . . . . . . . . . . . . .12\\nMutual information . . .86, 94, 98 ff., 110,\\n116\\nMutual information formulae . . . . . . 117\\nN\\nN dimensional feature vector . . . . . . 205\\nNatural logistic function . . . . . . . . . . . . 14\\nNatural logistic sigmoid . . . . . . . . . . . . 14\\nNegative log likelihood . . . . . . . . . . . . . 13\\nNeural network . . . . . . . . . . . . . . .195, 202\\nNeural network ensembles . . . . 186, 191\\nNeural networks . . 55, 57, 127, 135, 158,\\n186\\nNeural style transfer . . . . . . . . . . . . . 214 f.\\nNeuron activation function . . . . . . . . . 15\\nNew York stock exchange . . . . . . . . . . .48\\nNLL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .13\\nNN . . . . . . . . . . 55, 127, 135, 158, 186, 202\\nNN Layers . . . . . . . . . . . . . . . . . . . . . . . . 318\\nNoise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99\\nNon convex neural networks . . . . . . 203\\nNon informative prior . . . . . . . . . . . . . . 54\\nNon informative priors . . . . . . . . . . . . . 77\\nNon interacting identical particles . 118\\nNon linearity . . . . . . . . . . . . . . . . . . . . . .301\\nNon-differentiable . . . . . . . . . . . . . . . . .301\\nNon-linearity . . . . . . . . . . . . . . . . . . . . . .248\\nNonlinear layer . . . . . . . . . . . . . . . 253, 306\\nNormal distribution . . . . . . . . . . .274, 324\\nNormalization constant . . . . . . . . . . . . .64\\nNST . . . . . . . . . . . . . . . . . . . . . . . . . . . . .214 f.\\nNumerical Differentiation . . . . . . . . . .147\\nNumerical differentiation . . .124 ff., 146,\\n173\\nNumerical instability . . . . . . . . . . . . . . 146\\nNumpy . . . . . . . . . . . . . . . . . . . . . . . . . . . .221\\nO\\nOctahedral dice . . . . . . . . . . . . . . . . . . . .101\\nOdds . . . . . . . . . . . . . . . . . . . . . . . . . .12 f., 29\\nOdds of success in a binary response 14\\nOnOffLayer . . . . . . . . . . . . . . . . . . . . .56, 78\\nOOM . . . . . . . . . . . . . . . . . . . . . . . . .281, 327\\nOptimization . . . . . . . . . . . . . . . . . .131, 153\\nOptimization loss . . . . . . . . . . . . . . . . . .331\\nOrdinary predictors . . . . . . . . . . . . . . . . .28\\nOut of memory . . . . . . . . . . . . . . . 281, 327\\nOverﬁtting . . . . . . . . . . . . . . . . . .12, 27, 194\\nP\\nP value . . . . . . . . . . . . . . . . . . . . . . . . . . . . .36\\nPadding . . . . . . . . . . . . . . . . . . . . . . 236, 292\\nPancreactic cancer . . . . . . . . . . . . . . . . . . 43\\nPancreatic cancer classiﬁcation . . . . . 208\\nPartial derivative . . . . . . . . . . . . . . . . . . . 53\\nPartial derivatives . . . . . .130 ff., 142, 152\\n380Chapter 10 ALPHABETICAL INDEX\\nParticle physics . . . . . . . . . . . . . . . . . . . . .45\\nPDF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nPerceptron . . . . . . . . . . . . . . . . . . . .246, 299\\nPerceptron learning rule . . . . . . . . . . . 252\\nPerceptrons . . . . . . . . . .299, 301, 304, 343\\nPerformance metrics . . . . . . . . . . . . . . .316\\nPhysical constants . . . . . . . . . . . . . . . . . 100\\nPlacenta Chorion Test . . . . . . . . . . . . . .353\\nPlacenta chorion test . . . . . . . . . . . . . . 46 f.\\nPlanck’s constant . . . . . . . . . . . . . . . . . . 100\\nPlateau . . . . . . . . . . . . . . . . . . . . . . . . . . . .284\\nPMF . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43, 59\\nPoisson . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75\\nPoisson distribution . . . . . . . . . . . . . . . . 53\\nPooling Layer . . . . . . . . . . . . . . . . . . . . . 270\\nPooling layer . . . . . . . . . . . . . . . . . . . . . . 322\\nPosterior . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPosterior and prior predictive\\ndistributions . . . . . . . . . . . . . . . . 54\\nPosterior distribution . 54, 146, 180, 354\\nPosterior predictive distributions . . . 76\\nPre trained CNN . . . . . . . . . . . . . . . . . . 349\\nPre trained CNNs . . . . . . . . . . . . . . . . . .205\\nPre trained VGG19 CNN model . . . . 220\\nPrecision . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nPredictor variables . . . . . . . . . . . . . . . . . .28\\nPrior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPrior distribution . . . . . . . . . . . . . . . . . . . 45\\nPrior distributions . . . . . . . . . . . . . . . . . . 77\\nPrior predictive distribution . . . . 54, 354\\nProbabilistic programming . . . . . . . . . .42\\nProbability distribution . . . . . . . . . .13, 94\\nProbability mass function . . . . . . . .43, 60\\nProbability of failure . . . . . . . . . . . . . . . .28\\nProbability space . . . . . . . . . . . . . . . . . . . 44\\nProbability statements . . . . . . . . . . . . . . 65\\nProblems . . . . . . . . . . . . . . . . . .12, 186, 206\\nProton theraphy . . . . . . . . . . . . . . . . . . . . 43\\nProton therapy . . . . . . . . . . . . . . . . . . 16, 43\\nPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .16, 43\\nPulmonary nodules . . . . . . . . . . . 282, 345\\nPyMc3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nPython . 7, 23–27, 38 ff., 42, 56 f., 88, 102,\\n107 f., 112, 114, 123, 134, 136,\\n138, 140, 143 f., 157, 159 f., 163,\\n165 f., 170, 172 f., 175 ff., 179,\\n181, 191, 195–198, 202, 206,\\n210 f., 218, 221, 223 f., 232,\\n239 ff., 250 f., 256 f., 263 f., 266 ff.,\\n272, 282, 288, 294 f., 300–304,\\n312, 319 f., 330, 343 f., 349\\nPython coin toss . . . . . . . . . . . . . . . . . . . 108\\nPython interpreter . . . . . . . . . . . . . . . . . . 88\\nPyTorch . 7, 23–26, 38, 40, 56 f., 123, 134,\\n136, 138, 140, 143, 157, 159 f.,\\n163, 165 f., 170, 173, 176 f., 181,\\n191, 195 ff., 202, 206, 210 f., 218,\\n221, 223 f., 254–257, 267 f., 272,\\n288, 307 ff., 319 f., 343 f., 349\\nPytorch . . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nPyTorch code snippet for an ensemble\\n191\\nPyTorch sequential . . . . . . . . . . . . . . . . 257\\nPyTorch tanh . . . . . . . . . . . . . . . . . . . . . .257\\nQ\\nQuadratic equation . . . . . . . . . . . . . . . . . 80\\nQuantum drop . . . . . . . . . . . . . . . . . . . . . .57\\nQuantum physics . . . . . . . . . . . . . . . . . .100\\nQuantum states . . . . . . . . . . . . . . . . . . . . .45\\nQuantum term speed . . . . . . . . . . . . . . . 79\\n381ALPHABETICAL INDEX\\nR\\nRadiation therapy . . . . . . . . . . . . . . . 17, 98\\nRadiation therapy planning . . . . . . . . . 17\\nRadiology . . . . . . . . . . . . . . . . . . . . . . . . .282\\nRandom guess classiﬁer . . . . . . . 262, 317\\nRandom number seeds . . . . . . . . . . . . 186\\nRandom search . . . . . . . . . . . . . . . 282, 328\\nRecall . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic . . 261\\nReceiver operating characteristic . . . 316\\nRectiﬁcation . . . . . . . . . . . . . . . . . . . . . . .306\\nRelative entropy . . . . .98 f., 109, 117, 349\\nRelative maxima and minima . . . . . . 132\\nRelative risk . . . . . . . . . . . . . . . . . . . . . . . .34\\nRelative shrinkage frequency . . . . . . 112\\nRelative star expansion frequency . . 115\\nReLU . . . .248 f., 253, 258 f., 301, 306, 314\\nRendering sympy in Google colab . 143\\nResNet . . . . . . . . . . 205, 207, 211, 217, 223\\nResNet152 . . . . . . . . . . . . . . . . . . . . . . . . .205\\nResNet18 . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nResNet34 . . . . . . . . . . . . . . . . .205, 211, 349\\nResNet34 CNN . . . . . . . . . . . . . . . . . . . .211\\nResNetBottom . . . . . . . . . . . . . . . . . . . . .211\\nResNets . . . . . . . . . . . . . . . . . . . . . . . . . . .326\\nResponse variable . . . . . . . . . . 12 f., 17, 29\\nReversing probabilities . . . . . . . . . . . . . 47\\nROC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nROC AUC . . . . . . . . . . . . . . . . . . . . . . . . .316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . .261\\nRosenblatt . . . . . . . . . . . . . . . . . . . . . . . . .252\\nRR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34\\nRussakovsky . . . . . . . . . . . . . . . . . . . . . . 206\\nRussakovsky 2015 . . . . . . . . . . . . . . . . . 206\\nS\\nSaddle points . . . . . . . . . . . . . . . . . . . . . .155\\nSame padding . . . . . . . . . . . . 236, 238, 292\\nSample odds ratio . . . . . . . . . . . . . . . . . . 37\\nSampling approaches . . . . . . . . . . . . . .189\\nSampling with replacement . . . 189, 199\\nSampling without replacement 189, 199\\nSearch space . . . . . . . . . . . . . . . . . . 282, 328\\nSecond derivative test . . . . . . . . . . . . . 132\\nSeed values in AD . . . . . . . . . . . . .142, 170\\nSequential . . . . . . . . . . . . . . . . . . . . . . . . .221\\nSGD . . . . . . . . . . . . . . . . . . . . . .286 f., 330 ff.\\nShannon . . . . . . . 86 f., 89, 100, 103 f., 117\\nShannon bit . . . . . . . . . . . . . . . . . . . . . . . . .90\\nShannon’s famous general formulae\\n103\\nShannon’s general formulae . . . . . . . . 89\\nShift-invariance . . . . . . . . . . . . . . . . . . . .235\\nSigmoid . . . 15, 23, 32, 134, 137, 144, 160,\\n253, 306\\nSigmoid activation function . . . . 33, 137,\\n157 f., 160\\nSigmoid derivative . . . . . . . . . . . . . . . . . 15\\nSigmoid function . . . . . . . . . . . . . . . . . . 157\\nSigmoid gradient . . . . . . . . . . . . . .144, 173\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . 173\\nSigmoidal neuron . . . . . . . . . . . . . . . . . .247\\nSigmoidal perceptron . . . . . . . . . . . . . .246\\nSimilarity measures . . . . . . . . . . . . . . . .296\\nSimple differentiation . . . . . . . . . 144, 172\\nSingle Layer Perceptrons . . . . . . . . . . .246\\nSingle layer perceptrons . . . . . . . . . . . 299\\nSingle model based AI systems . . . . 186\\nSingle predictors . . . . . . . . . . . . . . . . . . .201\\nSkip connection . . . . . . . . . . . . . . . . . . . .326\\nSnapshot ensembling . . . 189 f., 195, 201\\n382Chapter 10 ALPHABETICAL INDEX\\nSobel ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .294\\nSoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nsoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . . .217\\nSoftmax activation . . . . . . . . . . . . . . . . .251\\nSoftmax activation function . . . . . . . . . 32\\nSoftmax derivation . . . . . . . . . . . . . . . . . 32\\nSoftmax function . . . . . . . . . . . . . . . . 32, 40\\nSoftmax layers . . . . . . . . . . . . . . . . . . . . . .29\\nSoftmax neurons . . . . . . . . . . . . . . . . . . .214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . .198\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . .49\\nSpeed of light in vacum . . . . . . . . . . . . 100\\nSperable convolutions . . . . . . . . .241, 295\\nSplitting criterion . . . . . . . . . . . . . . . . . .111\\nStacking . . . . . . . . . . . . . . . . . .186, 189, 198\\nStacking and bagging . . . . . . . . . . . . . .187\\nStan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nStandard deviation . . . . . . . . . . . . . . . . . 61\\nStar density . . . . . . . . . . . . . . . . . . . . . . . . .97\\nStar expansion . . . . . . . . . . . . . . . . . . . . .115\\nStatic committee machines . . . . . . . . . 201\\nStatistical distribution . . . . . . . . . . . . . . .44\\nStatistical independence . . . . . . . . . . . . 45\\nStatistical mechanics . . . . . . . . . . . . .11, 86\\nStochastic . . . . . . . . . . . . . . . . . . . . . . . . . .287\\nStochastic gradient descent . . . . 247, 331\\nStochastic gradient descent, SGD . . 286\\nStock markets . . . . . . . . . . . . . . . . . . . . . . .48\\nStocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .48\\nStratiﬁcation . . . . . . . . . . . . . . . . . . 233, 290\\nStratiﬁed K fold . . . . . . . . . . . . . . . . . . . 290\\nStratiﬁed K-Fold . . . . . . . . . . . . . . . . . . .233\\nStride . . . . . . . . . . . . . . . . . . . . 236, 292, 323\\nSTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\nStyle loss . . . . . . . . . . . . . . . 214, 216, 224 f.\\nStyle transfer . . . . . . . . . . . . . . 214 f., 224 f.\\nSupervised learning . . . . . . . . . . . . . . . . 28\\nSupervised machine learning . . . . . . . 12\\nSurprise . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nSwish . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . 236, 292, 323\\nSTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\nStyle loss . . . . . . . . . . . . . . . 214, 216, 224 f.\\nStyle transfer . . . . . . . . . . . . . . 214 f., 224 f.\\nSupervised learning . . . . . . . . . . . . . . . . 28\\nSupervised machine learning . . . . . . . 12\\nSurprise . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . .260, 315\\nSymbolic differentiation . . . 123 f., 143 f.,\\n172 f.\\nSymPy . . . . . . . . .124, 143 f., 146, 173, 177\\nT\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310\\ntanh . . . . . . . . . . . . . . . . . . . . 253, 256 f., 306\\nTaylor series . . . . . . . . . . . . . . . . .122, 128 f.\\nTaylor series and dual numbers . . . . 163\\nTaylor series expansion . . . . . . 128 f., 150\\nTest set . . . . . . . . . . . . . . . . . . . . . . . . . . . .328\\nThe backpropagation algorithm . . . . 134\\nThe bayesian school of thought . . . . . 42\\nThe beta binomial model . . . . . . 144, 174\\nThe chain rule . . . . . . . . . . . . . . . . .127, 149\\nThe convolution operator . . . . . 234, 291\\nThe correlation operator . . . . . . .234, 291\\nThe gaussian distribution . . . . . . . . . . 324\\nThe gradient descent algorithm . . . . 155\\nThe gram matrix . . . . . . . . . . . . . . . . . . .225\\nThe hyperplane . . . . . . . . . . . . . . . . . 14, 31\\nThe Kullback Leibler distance . . . . . . 297\\nThe Likelihood function . . . . . . . . . . . 174\\nThe logit function and entropy . . . . . . 38\\nThe multi layer perceptron . . . . . . . . . 300\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . .32\\nThe sigmoid . . . . . . . . . . . . . . . . . . . . . . . . 15\\nThe sigmoid function . . . . . . . . . . . . . . . 29\\nThe theory of perceptrons . . . . . . . . . .304\\nTheory of CNN design . . . . . . . . . . . . .326\\nThermodynamics . . . . . . . . . . 86, 100, 103\\nTopologies . . . . . . . . . . . . . . . . . . . . . . . . .318\\nToxic mercury fumes . . . . . . . . . . . . . .18 f.\\n383ALPHABETICAL INDEX\\nTrain validation split . . . . . . . . . . . . . . .281\\nTraining corpus . . . . . . . . . . . . . . . 189, 200\\nTraining curve curve . . . . . . . . . . 283, 329\\nTraining hyperparameters . . . . . . . . . 327\\nTraining validation epoch . . . . . . . . . .196\\nTransformation . . . . . . . . . . . . . . . . . . . .222\\nTriangle inequality . . . . . . . . . . . . . . . . .109\\nTrue probability distribution . . . . . . . . 93\\nTruly understanding LR . . . . . . . . . 16, 33\\nTTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .69\\nTumors . . . . . . . . . . . . . . . . . . . . . . . . . . . . .98\\nTumour eradication . . . . . . . . . . . . . 17, 34\\nTumour shrinkage . . . . . . . . . . . . . . . . . .96\\nTumour shrinkage in rats . . . . . . . . . . . 22\\nTwo dimensional matrix . . . . . . . . . . . . 24\\nU\\nUncertainty . . . . . . . . . . . . . . . . . . . . . . .89 f.\\nUniversal function approximators . 251\\nV\\nValid padding . . . . . . . . . . . . 236, 238, 292\\nValidation curve . . . . . . . . . . . . . . 283, 329\\nValidation curve ACC . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . .329\\nValidation set . . . . . . . . . . . . . . . . . . . . . .328\\nVanilla linear regression . . . . . . . . . . . . .14\\nVanishing gradients . . . . . . . . . . . . . . . .258\\nVariance . . . . . . . . . . . .42 f., 59, 62, 74, 201\\nV enn diagram . . . . . . . . . . . . . . . . .44 f., 99\\nVGG . . . . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nVGG conv43 layer . . . . . . . . . . . . . . . . . 209\\nVGG fc7 layer . . . . . . . . . . . . . . . . . . . . . 209\\nVGG Net . . . . . . . . . . . . . . . . . . . . . .205, 216\\nVGG16 . . . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nVGG19 . . . . . . . . . . . . . . . . . . . 209, 221, 351\\nVGG19 architecture . . . . . . . . . . . . . . . .208\\nVGG19 CNN . . . . . . . . . . . . . 208, 218, 351\\nV oting power . . . . . . . . . . . . . . . . . . . . . .201\\nVumulative distribution . . . . . . . . . . . . .62\\nW\\nWald chi squared test . . . . . . . . . . . . . . . 28\\nWeight initialization247, 253, 258, 299 f.,\\n314\\nWest African ebola . . . . . . . . . . . . . . . . . .52\\nWSI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .208\\nWW2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .50\\nX\\nXavier . . . . . . . . . . . . . . . . . . . . . . . . 258, 330\\n384')]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(document_question_gen[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "TkaxeSyzBvMV",
        "outputId": "eb431e03-98b5-496d-a994-70e77dc3b962"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "langchain_core.documents.base.Document"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>langchain_core.documents.base.Document</b><br/>def __init__(page_content: str, **kwargs: Any) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/langchain_core/documents/base.py</a>Class for storing a piece of text and associated metadata.\n",
              "\n",
              "!!! note\n",
              "\n",
              "    `Document` is for **retrieval workflows**, not chat I/O. For sending text\n",
              "    to an LLM in a conversation, use message types from `langchain.messages`.\n",
              "\n",
              "Example:\n",
              "    ```python\n",
              "    from langchain_core.documents import Document\n",
              "\n",
              "    document = Document(\n",
              "        page_content=&quot;Hello, world!&quot;, metadata={&quot;source&quot;: &quot;https://example.com&quot;}\n",
              "    )\n",
              "    ```</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 288);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "splitter_ans_gen=TokenTextSplitter(\n",
        "  encoding_name=\"cl100k_base\",\n",
        "  chunk_size=1000,\n",
        "  chunk_overlap=100\n",
        ")"
      ],
      "metadata": {
        "id": "QQ3RwMkGBxPR"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_ans_gen=splitter_ans_gen.split_documents(\n",
        "    document_question_gen\n",
        ")"
      ],
      "metadata": {
        "id": "_hMawTlBCI6d"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_ans_gen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B83FduWZCUXH",
        "outputId": "7e1594a6-2c55-4ed1-fb19-c25e8fe692f5"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='SHLOMO KASHANI\\nDeep Learning Interviews is home to hundreds of fully-solved problems, \\nfrom a wide range of key topics in AI. It is designed to both rehearse \\ninterview or exam-specific topics and provide machine learning M.Sc./Ph.D. \\nstudents, and those awaiting an interview a well-organized overview of the \\nfield. The problems it poses are tough enough to cut your teeth on and to \\ndramatically improve your skills-but they’re framed within thought-\\nprovoking questions and engaging stories.\\nThat is what makes the volume so specifically valuable to students and job \\nseekers: it provides them with the ability to speak confidently and quickly on \\nany relevant topic, to answer technical questions clearly and correctly, and to \\nfully understand the purpose and meaning \\nof interview questions and \\nanswers. These are powerful, indispensable advantages to have when walking \\ninto the interview room.\\nThe book’s contents is a large inventory of numerous topics relevant to DL \\njob interviews and graduate-level exams. That places \\nthis work at the \\nforefront \\nof the growing trend in science to teach a core set of practical \\nmathematical and computational \\nskills. It is widely accepted that the \\ntraining of every computer scientist must include the fundamental theorems \\nof ML, and AI appears in the curriculum of \\nnearly every \\nuniversity. This \\nvolume is designed as an excellent reference for graduates of \\nsuch programs.\\nShlomo Kashani, Author. \\nwww.interviews.ai\\nDEEP LEARNING INTERVIEWS\\nDEEP LEARNING \\nINTERVIEWS\\nSHLOMO KASHANI deep learning interviews\\nAmir Ivry, Chief Editor.\\n    REAL-WORLD DEEP LEARNING INTERVIEW \\nPROBLEMS & SOLUTIONS\\n• Logistic Regression\\n• Information Theory\\n• Calculus\\n• Algorithmic Differentiation\\n• Bayesian Deep Learning\\n• Probabilistic Programming\\n• Ensemble Learning\\n• CNN Feature Extraction\\n• Deep Learning: Expanded Chapter\\nsecond editionSHLOMO KASHANI\\nDEEP LEARNING INTERVIEWS\\nBy Shlomo Kashani, M.Sc, QMUL, UK.\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nPublished by Shlomo Kashani, Tel-Aviv , ISRAEL.\\nVisit: http://www.interviews.ai\\nCopyright, 2020\\nThis book is protected by copyright.\\nNo part may be reproduced in any manner without written permission from the publisher.\\nPrinting version: VER . 26 TH OCTOBER 2021\\nPrinted in the United States of America.\\nLibrary of Congress Cataloging-in-Publication Data\\nA catalog record for this book is available from the Library of CongressCOPYRIGHT.\\n© 2016-2020 Shlomo Kashani, entropy@interviews.ai\\nA\\nLL RIGHTS RESERVED .The content contained within this book may not be\\nreproduced, duplicated or transmitted without direct written permission\\nfrom the author or the publisher. Under no circumstances will any blame\\nor legal responsibility be held against the publisher, or author, for any dam-\\nages, reparation, or monetary loss due to the information contained within this book.\\nEither directly or indirectly . This book is copyright protected. This book is only for\\npersonal use. You cannot amend, distribute, sell, use, quote or paraphrase any part, or\\nthe content within this book, without the consent of the author or publisher.\\nPlease note the information contained within this document is for educational and\\nentertainment purposes only . All effort has been executed to present accurate, up to\\ndate, and reliable, complete information. No warranties of any kind are declared or\\nimplied. Readers acknowledge that the author is not engaging in the rendering of\\nlegal, ﬁnancial, medical or professional advice. The content within this book has been\\nderived from various sources. Please consult a licensed professional before attempt-\\ning any techniques outlined in this book. By reading this document, the reader agrees\\nthat under no circumstances is the author responsible for any losses, direct or indirect,\\nwhich are incurred as a result of the use of information contained within this docu-\\nment, including, but not limited to errors, omissions, or inaccuracies.\\nNo part of this publication may be reproduced, stored in a retrieval system, or trans-\\nmitted in any form or by any means, electronic, mechanical, photocopying, record-\\ning, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976\\nUnited States Copyright Act, without the prior written permission of the Publisher.\\nLimit of Liability/Disclaimer of Warranty . While the publisher and author have used\\ntheir best efforts in preparing this book, they make no representations or warranties\\nwith respect to the accuracy or completeness of the contents of this book and spe-\\nciﬁcally'),\n",
              " Document(metadata={}, page_content=', electronic, mechanical, photocopying, record-\\ning, scanning, or otherwise, except as permitted under Section 107 or 108 of the 1976\\nUnited States Copyright Act, without the prior written permission of the Publisher.\\nLimit of Liability/Disclaimer of Warranty . While the publisher and author have used\\ntheir best efforts in preparing this book, they make no representations or warranties\\nwith respect to the accuracy or completeness of the contents of this book and spe-\\nciﬁcally disclaim any implied warranties of merchantability or ﬁtness for a particular\\npurpose. No warranty may be created or extended by sales representatives or writ-\\nten sales materials. The advice and strategies contained herein may not be suitable\\nfor your situation. You should consult with a professional where appropriate. Neitherthe publisher nor author shall be liable for any loss of proﬁt or any other commer-\\ncial damages, including but not limited to special, incidental, consequential, or other\\ndamages.\\nNotices. Knowledge and best practice in this ﬁeld are constantly changing. As new\\nresearch and experience broaden our understanding, changes in research methods,\\nprofessional practices, or medical treatment may become necessary . Practitioners and\\nresearchers must always rely on their own experience and knowledge in evaluating\\nand using any information, methods, compounds, or experiments described herein.\\nIn using such information or methods they should be mindful of their own safety and\\nthe safety of others, including parties for whom they have a professional responsibil-\\nity . To the fullest extent of the law, neither the Publisher nor the authors, contributors,\\nor editors, assume any liability for any injury and/or damage to persons or property\\nas a matter of products liability , negligence or otherwise, or from any use or operation\\nof any methods, products, instructions, or ideas contained in the material herein.FOREWORD.\\nWe will build a machine that will ﬂy.\\n— Joseph Michael Montgolﬁer, French Inventor/Aeronaut (1740-1810)\\nD\\nEEP learning interviews are technical, dense, and thanks to the ﬁelds com-\\npetitiveness, often high-stakes. The prospect of preparing for one can be\\ndaunting, and the fear of failure can be paralyzing and many interviewees\\nﬁnd their ideas slipping away alongside their conﬁdence.\\nThis book was written for you: an aspiring data scientist with a quantitative back-\\nground, facing down the gauntlet of the interview process in an increasingly competit-\\nive ﬁeld. For most of you, the interview process is the most signiﬁcant hurdle between\\nyou and a dream job. Even though you have the ability , the background, and the mo-\\ntivation to excel in your target position, you might need some guidance on how to get\\nyour foot in the door.\\nThough this book is highly technical it is not too dense to work through quickly . It\\naims to be comprehensive, including many of the terms and topics involved in modern\\ndata science and deep learning. That thoroughness makes it unique; no other single\\nwork offers such breadth of learning targeted so speciﬁcally at the demands of the\\ninterview.\\nMost comparable information is available in a variety of formats, locations, struc-\\ntures, and resourcesblog posts, tech articles, and short books scattered across the inter-\\nnet. Those resources are simply not adequate to the demands of deep learning inter-\\nview or exam preparation and were not assembled with this explicit purpose in mind.\\nIt is hoped that this book does not suffer the same shortcomings.\\nT\\nHIS books creation was guided by a few key principles: clarity and depth,\\nthoroughness and precision, interest and accuracy . The volume was de-\\nsigned for use by job seekers in the ﬁelds of machine learning and deep\\nlearning whose abilities and background locate them ﬁrmly within STEM\\n(science, technology , engineering, and mathematics). The book will still be of use to\\nother readers, such as those still undergoing their initial education in a STEM ﬁeld.\\nHowever, it is tailored most directly to the needs of active job seekers and stu-\\ndents attending M.Sc/Ph.D programmes in AI . It is, in any case, a book for engineers,\\nmathematicians, and computer scientists: nowhere does it include the kind of very\\nbasic background material that would allow it to be read by someone with no priorknowledge of quantitative and mathematical processes.\\nThe books contents are a large inventory of numerous topics relevant to deep learn-\\ning job interviews and graduate level exams. Ideas that are interesting or pertinent\\nhave been excluded if they are not valuable in that context. That places this work at\\nthe forefront of the growing trend in education and in business to emphasize a core\\nset of practical mathematical and computational skills. It is now widely understood'),\n",
              " Document(metadata={}, page_content='basic background material that would allow it to be read by someone with no priorknowledge of quantitative and mathematical processes.\\nThe books contents are a large inventory of numerous topics relevant to deep learn-\\ning job interviews and graduate level exams. Ideas that are interesting or pertinent\\nhave been excluded if they are not valuable in that context. That places this work at\\nthe forefront of the growing trend in education and in business to emphasize a core\\nset of practical mathematical and computational skills. It is now widely understood\\nthat the training of every computer scientist must include a course dealing with the\\nfundamental theorems of machine learning in a rigorous manner; Deep Learning ap-\\npears in the curriculum of nearly every university; and this volume is designed as a\\nconvenient ongoing reference for graduates of such courses and programs.\\nThe book is grounded in both academic expertise and on-the-job experience and\\nthus has two goals. First, it compresses all of the necessary information into a coher-\\nent package. And second, it renders that information accessible and makes it easy to\\nnavigate. As a result, the book helps the reader develop a thorough understanding of\\nthe principles and concepts underlying practical data science. None of the textbooks I\\nread met all of those needs, which are:\\n1. Appropriate presentation level. I wanted a friendly introductory text accessible\\nto graduate students who have not had extensive applied experience as data\\nscientists.\\n2. A text that is rigorous and builds a solid understanding of the subject without\\ngetting bogged down in too many technicalities.\\n3. Logical and notational consistency among topics . There are intimate connec-\\ntions between calculus, logistic regression, entropy , and deep learning theory ,\\nwhich I feel need to be emphasized and elucidated if the reader is to fully under-\\nstand the ﬁeld. Differences in notation and presentation style in existing sources\\nmake it very difﬁcult for students to appreciate these kinds of connections.\\n4. Manageable size. It is very useful to have a text compact enough that all of the\\nmaterial in it can be covered in few weeks or months of intensive review. Most\\ncandidates will have only that much time to prepare for an interview, so a longer\\ntext is of no use to them.\\nThe text that follows is an attempt to meet all of the above challenges. It will\\ninevitably prove more successful at handling some of them than others, but it\\nhas at least made a sincere and devoted effort.A note about Bibliography\\nThe book provides a carefully curated bibliography to guide further study , whether\\nfor interview preparation or simply as a matter of interest or job-relevant research. A\\ncomprehensive bibliography would be far too long to include here, and would be of\\nlittle immediate use, so the selections have been made with deliberate attention to the\\nvalue of each included text.\\nOnly the most important books and articles on each topic have been included, and\\nonly those written in English that I personally consulted. Each is given a brief annota-\\ntion to indicate its scope and applicability . Many of the works cited will be found to\\ninclude very full bibliographies of the particular subject treated, and I recommend\\nturning there if you wish to dive deeper into a speciﬁc topic, method, or process.\\nWe have a web page for this book, where we list errata, examples, and any ad-\\nditional information. You can access this page at: http://www.interviews.ai.\\nTo comment or ask technical questions about this book, send email to: entropy@\\ninterviews.ai.\\nI would also like to solicit corrections, criticisms, and suggestions from students\\nand other readers. Although I have tried to eliminate errors over the multi year\\nprocess of writing and revising this text, a few undoubtedly remain. In particular,\\nsome typographical infelicities will no doubt ﬁnd their way into the ﬁnal version. I\\nhope you will forgive them .\\nTHE AUTHOR .\\nTEL AVIV ISRAEL, D ECEMBER , 2020. F IRST PRINTING , D ECEMBER 2020.ACKNOWLEDGEMENTS.\\nThe thanks and acknowledgements of the publisher are due to the following:\\nMy dear son, Amir Ivry , Matthew Isaac Harvey , Sandy Noymer, Steve foot and V elimir\\nGayevskiy .AUTHOR ’S BIOGRAPHY .\\nWhen Shlomo typed his book in LATEX, he wanted it to\\nreﬂect some of his passions: AI, design, typography , and\\nmost notably coding. On a typical day , his two halves - the\\nscientist and the artist - spend hours meticulously design-\\ning AI systems, from epilepsy prediction and pulmonary\\nnodule detection, to training a computer-vision model on\\na cluster.\\nShlomo spends whole days in a lab full of GPUs work-\\n'),\n",
              " Document(metadata={}, page_content=' Shlomo typed his book in LATEX, he wanted it to\\nreﬂect some of his passions: AI, design, typography , and\\nmost notably coding. On a typical day , his two halves - the\\nscientist and the artist - spend hours meticulously design-\\ning AI systems, from epilepsy prediction and pulmonary\\nnodule detection, to training a computer-vision model on\\na cluster.\\nShlomo spends whole days in a lab full of GPUs work-\\ning on his many interesting research projects. Though re-\\nsearch satisﬁes his itch for discovery , his most important\\nscientiﬁc contribution, he says, is helping other researchers.\\nAnd the results are evident in his publications. But, al-\\nthough theoretical studies are important, practical experi-\\nence has many great virtues. As the Head of AI at DeepOncology , he developed uses\\nof Deep Learning for precise tumour detection, expanding and reﬁning what human\\nexperts are capable of. The work, which relies on CNN’s, marks the culmination of a\\ncareer spent applying AI techniques to problems in medical AI. Shlomo holds an MSc\\nin Digital Signal Processing (Distinction) from the University of London.\\nA PERSONAL NOTE : In this ﬁrst volume, I purposely present a coherent, cumu-\\nlative, and content-speciﬁc core curriculum of the data science ﬁeld, including topics\\nsuch as information theory , Bayesian statistics, algorithmic differentiation, logistic re-\\ngression, perceptrons, and convolutional neural networks.\\nI hope you will ﬁnd this book stimulating. It is my belief that you the postgradu-\\nate students and job-seekers for whom the book is primarily meant will beneﬁt from\\nreading it; however, it is my hope that even the most experienced researchers will ﬁnd\\nit fascinating as well.\\nSHLOMO KASHANI ,T EL-AVIV,ISRAEL.ABOUT\\nTHE CHIEF\\nEDITOR .\\nAmir Ivry has been an applied research scientist in the ﬁelds\\nof deep learning and speech signal processing since 2015. A direct\\nPhD candidate in the Electrical and Computer Engineering Fac-\\nulty in the Technion - Israel Institute of Technology , Amir is the\\nauthor of over a dozen academic papers in leading IEEE journ-\\nals and top-tier conferences. For his contribution to the ﬁeld of\\nhands-free speech communication using deep neural networks,\\nAmir has received more than a dozen awards and honors, in-\\ncluding back-to-back Jacobs citations for research excellence, and\\nmost recently the international speech communication associ-\\nation grant. Being only 28 years old, he has been cemented as a popular lecturer in the\\nmachine learning community , and delivered technological sessions for MIT, Google\\nfor startups, Alibaba, and more. Amir is currently holding a position as an applied\\nresearch intern in Microsoft Advanced Technology Labs.Contents\\nI Rusty Nail 1\\nHOW-TO USE THIS BOOK 3\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\nII Kindergarten 9\\nLOGISTIC REGRESSION 11\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe S'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38PROBABILISTIC PROGRAMMING & BA YESIAN DL 41\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule'),\n",
              " Document(metadata={}, page_content=\" . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nIII High School 83\\nINFORMATION THEORY 85\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 87\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . . 101\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103Kullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION 121\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . .\"),\n",
              " Document(metadata={}, page_content=\" . . . . . . . . . . . . . . 118\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION 121\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . .\"),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . . 155The Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\nIV Bachelors 183\\nDEEP LEARNING: NN ENSEMBLES 185\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . . 202\\nDEEP LEARNING: CNN FEATURE EXTRACTION 205\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213Neural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\nDEEP LEARNING 227\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 253\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nOptimization, Loss . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . 260\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . . 306\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nV Practice Exam 339\\nJOB INTERVIEW MOCK EXAM 341\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343Classiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nVI V olume two 357\\nVOLUME TWO - PLAN 359\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nVariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . . . 361\\nText to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL'),\n",
              " Document(metadata={}, page_content='ization . . . . . . . . . . . . . . . . . . . . . . 361\\nText to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nxviRUSTY NAIL\\nPART ICHAPTER\\n1\\nHOW-TO USE THIS BOOK\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\nWhat makes this book so valuable . . . . . . . . . . . . . . . . . . . . . 3\\nWhat will I learn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nStarting Your Career . . . . . . . . . . . . . . . . . . . . . . . . . 4\\nAdvancing Your Career . . . . . . . . . . . . . . . . . . . . . . . 5\\nDiving Into Deep Learning . . . . . . . . . . . . . . . . . . . . . 5\\nHow to Work Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\nTypes of Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n1.1 Introduction\\nFirst of all, welcome to world of Deep Learning Interviews.\\n1.1.1 What makes this book so valuable\\nT\\nARGETED advertising. Deciphering dead languages. Detecting malignant\\ntumours. Predicting natural disasters. Every year we see dozens of new\\nuses for deep learning emerge from corporate R&R, academia, and plucky\\nentrepreneurs. Increasingly , deep learning and artiﬁcial intelligence are in-\\ngrained in our cultural consciousness. Leading universities are dedicating programs\\nto teaching them, and they make the headlines every few days.\\nThat means jobs. It means intense demand and intense competition. It means a\\ngeneration of data scientists and machine learning engineers making their way into1.1. INTRODUCTION\\nthe workforce and using deep learning to change how things work. This book is for\\nthem, and for you. It is aimed at current or aspiring experts and students in the ﬁeld\\npossessed of a strong grounding in mathematics, an active imagination, engaged cre-\\nativity , and an appreciation for data. It is hand-tailored to give you the best possible\\npreparation for deep learning job interviews by guiding you through hundreds of\\nfully solved questions.\\nThat is what makes the volume so speciﬁcally valuable to students and job seekers:\\nit provides them with the ability to speak conﬁdently and quickly on any relevant\\ntopic, to answer technical questions clearly and correctly , and to fully understand the\\npurpose and meaning of interview questions and answers.\\nThose are powerful, indispensable advantages to have when walking into the in-\\nterview room.\\nThe questions and problems the book poses are tough enough to cut your teeth\\non-and to dramatically improve your skills but theyre framed within thought provok-\\ning questions, powerful and engaging stories, and cutting edge scientiﬁc information.\\nWhat are bosons and fermions? What is choriionic villus? Where did the Ebola virus\\nﬁrst appear, and how does it spread? Why is binary options trading so dangerous?\\nYour curiosity will pull you through the book’s problem sets, formulas,'),\n",
              " Document(metadata={}, page_content=' the book poses are tough enough to cut your teeth\\non-and to dramatically improve your skills but theyre framed within thought provok-\\ning questions, powerful and engaging stories, and cutting edge scientiﬁc information.\\nWhat are bosons and fermions? What is choriionic villus? Where did the Ebola virus\\nﬁrst appear, and how does it spread? Why is binary options trading so dangerous?\\nYour curiosity will pull you through the book’s problem sets, formulas, and in-\\nstructions, and as you progress, you’ll deepen your understanding of deep learning.\\nThere are intricate connections between calculus, logistic regression, entropy , and deep\\nlearning theory; work through the book, and those connections will feel intuitive.\\n1.1.2 What will I learn\\nStarting Your Career\\nAre you actively pursuing a career in deep learning and data science, or hoping to do\\nso? If so, you’re in luck everything from deep learning to artiﬁcial intelligence is in\\nextremely high demand in the contemporary workforce. Deep learning professionals\\nare highly sought after and also ﬁnd themselves among the highest-paid employee\\ngroups in companies around the world.\\nSo your career choice is spot on, and the ﬁnancial and intellectual beneﬁts of land-\\ning a solid job are tremendous. But those positions have a high barrier to entry: the\\ndeep learning interview. These interviews have become their own tiny industry , with\\nHR employees having to specialize in the relevant topics so as to distinguish well-\\nprepared job candidates from those who simply have a loose working knowledge of\\nthe material. Outside the interview itself, the difference doesn’t always feel import-\\n4Chapter 1 HOW-TO USE THIS BOOK\\nant. Deep learning libraries are so good that a machine learning pipeline can often be\\nassembled with little high-skill input from the researcher themselves. But that level\\nof ability won’t cut it in the interview. You’ll be asked practical questions, technical\\nquestions, and theoretical questions, and expected to answer them all conﬁdently and\\nﬂuently .\\nFor unprepared candidates, that’s the end of the road. Many give up after repeated\\npost-interview rejections.\\nAdvancing Your Career\\nSome of you will be more conﬁdent. Those of you with years on the job will be highly\\nmotivated, exceptionally numerate, and prepared to take an active, hands-on role in\\ndeep learning projects. You probably already have extensive knowledge in applied\\nmathematics, computer science, statistics, and economics. Those are all formidable\\nadvantages.\\nBut at the same time, it’s unlikely that you will have prepared for the interview\\nitself. Deep learning interviews especially those for the most interesting, autonom-\\nous, and challenging positions demand that you not only know how to do your job\\nbut that you display that knowledge clearly , eloquently , and without hesitation. Some\\nquestions will be straightforward and familiar, but others might be farther aﬁeld or\\ndraw on areas you haven’t encountered since college.\\nThere is simply no reason to leave that kind of thing to chance. Make sure you’re\\nprepared. Conﬁrm that you are up-to-date on terms, concepts, and algorithms. Refresh\\nyour memory of fundamentals, and how they inform contemporary research practices.\\nAnd when the interview comes, walk into the room knowing that you’re ready for\\nwhat’s coming your way .\\nDiving Into Deep Learning\\n\"Deep Learning Job Interviews\" is organized into chapters that each consist of an Intro-\\nduction to a topic, Problems illustrating core aspects of the topic, and complete Solu-\\ntions. You can expect each question and problem in this volume to be clear, practical,\\nand relevant to the subject. Problems fall into two groups, conceptual and application-\\nbased. Conceptual problems are aimed at testing and improving your knowledge of\\nbasic underlying concepts, while applications are targeted at practicing or applying\\nwhat you’ve learned (most of these are relevant to Python and PyTorch). The chapters\\nare followed by a reference list of relevant formulas and a selective bibliography for\\nguide further reading.\\n51.1. INTRODUCTION\\n1.1.3 How to Work Problems\\nIn real life, like in exams, you will encounter problems of varying difﬁculty . A good\\nskill to practice is recognizing the level of difﬁculty a problem poses. Job interviews\\nwill have some easy problems, some standard problems, and some much harder prob-\\nlems.\\nEach chapter of this book is usually organized into three sections: Introduction,\\nProblems, and Solutions. As you are attempting to tackle problems, resist the tempta-\\ntion to prematurely peek at the solution; It is vital to allow yourself to struggle for\\na time with the material. Even professional data scientists do not always know right\\naway how to resolve'),\n",
              " Document(metadata={}, page_content='ﬁculty a problem poses. Job interviews\\nwill have some easy problems, some standard problems, and some much harder prob-\\nlems.\\nEach chapter of this book is usually organized into three sections: Introduction,\\nProblems, and Solutions. As you are attempting to tackle problems, resist the tempta-\\ntion to prematurely peek at the solution; It is vital to allow yourself to struggle for\\na time with the material. Even professional data scientists do not always know right\\naway how to resolve a problem. The art is in gathering your thoughts and ﬁguring\\nout a strategy to use what you know to ﬁnd out what you don’t.\\nPRB-1 \\uf059 CH.PRB- 1.1.\\nProblems outlined in grey make up the representative question set . This set of prob-\\nlems is intended to cover the most essential ideas in each section. These problems are usually\\nhighly typical of what you’d see on an interview, although some of them are atypical but\\ncarry an important moral. If you ﬁnd yourself unconﬁdent with the idea behind one of these,\\nit’s probably a good idea to practice similar problems. This representative question set is our\\nsuggestion for a minimal selection of problems to work on. Y ou are highly encouraged to\\nwork on more.\\nSOL-1 \\uf14b CH.SOL- 1.1. I am a solution. \\x04\\nIf you ﬁnd yourself at a real stand-off, go ahead and look for a clue in one of the\\nrecommended theory books. Think about it for a while, and don’t be afraid to read\\nback in the notes to look for a key idea that will help you proceed. If you still can’t\\nsolve the problem, well, we included the Solutions section for a reason! As you’re\\nreading the solutions, try hard to understand why we took the steps we did, instead\\nof memorizing step-by-step how to solve that one particular problem.\\nIf you struggled with a question quite a lot, it’s probably a good idea to return to it\\nin a few days. That might have been enough time for you to internalize the necessary\\nideas, and you might ﬁnd it easily conquerable. If you’re still having troubles, read\\nover the solution again, with an emphasis on understanding why each step makes\\nsense. One of the reasons so many job candidates are required to demonstrate their\\nability to resolves data science problems on the board, is that it hiring managers as-\\nsume it reﬂects their true problem-solving skills.\\n6Chapter 1 HOW-TO USE THIS BOOK\\nIn this volume, you will learn lots of concepts, and be asked to apply them in\\na variety of situations. Often, this will involve answering one really big problem by\\nbreaking it up into manageable chunks, solving those chunks, then putting the pieces\\nback together. When you see a particularly long question, remain calm and look for a\\nway to break it into pieces you can handle.\\n1.1.4 Types of Problems\\nTwo main types of problems are presented in this book.\\nCONCEPTUAL : The ﬁrst category is meant to test and improve your understanding\\nof basic underlying concepts. These often involve many mathematical calculations.\\nThey range in difﬁculty from very basic reviews of deﬁnitions to problems that require\\nyou to be thoughtful about the concepts covered in the section.\\nAn example in Information Theory follows.\\nPRB-2 \\uf059 CH.PRB- 1.2.\\nWhat is the distribution of maximum entropy, that is, the distribution which has the\\nmaximum entropy among all distributions on the bounded interval [a, b],(−∞, +∞)\\nSOL-2 \\uf14b CH.SOL- 1.2.\\nThe uniform distribution has the maximum entropy among all distributions on the\\nbounded interval: [a, b],(−∞, +∞).\\nThe variance of U (a, b) is σ2 = 1/12(b − a)2.\\nTherefore the entropy is:\\n1/2 log 12 + log σ. (1.1)\\n\\x04\\nAPPLICATION : Problems in this category are for practicing skills. It’s not enough to\\nunderstand the philosophical grounding of an idea: you have to be able to apply it in\\nappropriate situations. This takes practice! mostly in Python or in one of the available\\nDeep Learning Libraries such as PyTorch.\\nAn example in PyTorch follows.\\n71.1. INTRODUCTION\\nPRB-3 \\uf059 CH.PRB- 1.3.\\nDescribe in your own words, what is the purpose of the following code in the context of\\ntraining a Convolutional Neural Network.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n'),\n",
              " Document(metadata={}, page_content='appropriate situations. This takes practice! mostly in Python or in one of the available\\nDeep Learning Libraries such as PyTorch.\\nAn example in PyTorch follows.\\n71.1. INTRODUCTION\\nPRB-3 \\uf059 CH.PRB- 1.3.\\nDescribe in your own words, what is the purpose of the following code in the context of\\ntraining a Convolutional Neural Network.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\nSOL-3 \\uf14b CH.SOL- 1.3.\\nDuring the training of a Convolutional Neural Network, data augmentation, and to some\\nextent dropout are used as core methods to decrease overﬁtting. Data augmentation is a regu-\\nlarization scheme that synthetically expands the data-set by utilizing label-preserving trans-\\nformations to add more invariant examples of the same data samples. It is most commonly\\nperformed in real time on the CPU during the training phase whilst the actual training mode\\ntakes place on the GPU. This may consist for instance, random rotations, random ﬂips, zoom-\\ning, spatial translations etc. \\x04\\n8KINDERGARTEN\\nPART IICHAPTER\\n2\\nLOGISTIC REGRESSION\\nY ou should call it entropy for two reasons. In the ﬁrst place, your uncertainty\\nfunction has been used in statistical mechanics under that name. In the second\\nplace, and more importantly, no one knows what entropy really is, so in a debate\\nyou will always have the advantage.\\n— John von Neumann to Claude Shannon\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 16\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 22\\nPython/PyTorch/CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nGeneral Concepts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds, Log-odds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32\\nTruly Understanding Logistic Regression . . . . . . . . . . . . . . . . . 33\\nThe Logit Function and Entropy . . . . . . . . . . . . . . . . . . . . . . 38\\nPython, PyTorch, CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382.1. INTRODUCTION\\n2.1 Introduction\\nM\\nUltivariable methods are routinely utilized in statistical analyses across a\\nwide range of domains. Logistic regression is the most frequently used\\nmethod for modelling binary response data and binary classiﬁcation.\\nWhen the response variable is binary , it characteristically takes the form of 1/0,\\nwith 1 normally indicating a success and 0 a failure. Multivariable methods usually\\nassume a relationship between two or more independent, predictor variables,'),\n",
              " Document(metadata={}, page_content=' INTRODUCTION\\n2.1 Introduction\\nM\\nUltivariable methods are routinely utilized in statistical analyses across a\\nwide range of domains. Logistic regression is the most frequently used\\nmethod for modelling binary response data and binary classiﬁcation.\\nWhen the response variable is binary , it characteristically takes the form of 1/0,\\nwith 1 normally indicating a success and 0 a failure. Multivariable methods usually\\nassume a relationship between two or more independent, predictor variables, and\\none dependent, response variable. The predicted value of a response variable may be\\nexpressed as a sum of products, wherein each product is formed by multiplying the\\nvalue of the variable and its coefﬁcient. How the coefﬁcients are computed? from a\\nrespective data set. Logistic regression is heavily used in supervised machine learning\\nand has become the workhorse for both binary and multiclass classiﬁcation problems.\\nMany of the questions introduced in this chapter are crucial for truly understanding\\nthe inner-workings of artiﬁcial neural networks.\\n2.2 Problems\\n2.2.1 General Concepts\\nPRB-4 \\uf059 CH.PRB- 2.1.\\nTrue or False: For a ﬁxed number of observations in a data set, introducing more vari-\\nables normally generates a model that has a better ﬁt to the data. What may be the drawback\\nof such a model ﬁtting strategy?\\nPRB-5 \\uf059 CH.PRB- 2.2.\\nDeﬁne the term “odds of success” both qualitatively and formally. Give a numerical\\nexample that stresses the relation between probability and odds of an event occurring.\\nPRB-6 \\uf059 CH.PRB- 2.3.\\n1. Deﬁne what is meant by the term \"interaction\", in the context of a logistic regression\\npredictor variable.\\n12Chapter 2 LOGISTIC REGRESSION\\n2. What is the simplest form of an interaction? Write its formulae.\\n3. What statistical tests can be used to attest the signiﬁcance of an interaction term?\\nPRB-7 \\uf059 CH.PRB- 2.4.\\nTrue or False: In machine learning terminology, unsupervised learning refers to the\\nmapping of input covariates to a target response variable that is attempted at being predicted\\nwhen the labels are known.\\nPRB-8 \\uf059 CH.PRB- 2.5.\\nComplete the following sentence: In the case of logistic regression, the response vari-\\nable is the log of the odds of being classiﬁed in [...].\\nPRB-9 \\uf059 CH.PRB- 2.6.\\nDescribe how in a logistic regression model, a transformation to the response variable is\\napplied to yield a probability distribution. Why is it considered a more informative repres-\\nentation of the response?\\nPRB-10 \\uf059 CH.PRB- 2.7.\\nComplete the following sentence: Minimizing the negative log likelihood also means\\nmaximizing the [...] of selecting the [...] class.\\n2.2.2 Odds, Log-odds\\nPRB-11 \\uf059 CH.PRB- 2.8.\\nAssume the probability of an event occurring is p = 0.1.\\n1. What are the odds of the event occurring?.\\n2. What are the log-odds of the event occurring?.\\n132.2. PROBLEMS\\n3. Construct the probability of the event as a ratio that equals 0.1.\\nPRB-12 \\uf059 CH.PRB- 2.9.\\nTrue or False: If the odds of success in a binary response is 4, the corresponding probab-\\nility of success is 0.8.\\nPRB-13 \\uf059 CH.PRB- 2.10.\\nDraw a graph of odds to probabilities , mapping the entire range of probabilities to\\ntheir respective odds.\\nPRB-14 \\uf059 CH.PRB- 2.11.\\nThe logistic regression model is a subset of a broader range of machine learning models\\nknown as generalized linear models (GLMs), which also include analysis of variance (AN-\\nOV A), vanilla linear regression, etc. There are three components to a GLM; identify these\\nthree components for binary logistic regression.\\nPRB-15 \\uf059 CH.PRB- 2.12.\\nLet us consider the logit transformation, i.e., log-odds. Assume a scenario in which the\\nlogit forms the linear decision boundary:\\nlog\\n(\\nPr(Y = 1|X)\\nPr(Y = 0|X)\\n)\\n= θ0 + θT X, (2.1)\\nfor a given vector of systematic components X and predictor variables'),\n",
              " Document(metadata={}, page_content='three components for binary logistic regression.\\nPRB-15 \\uf059 CH.PRB- 2.12.\\nLet us consider the logit transformation, i.e., log-odds. Assume a scenario in which the\\nlogit forms the linear decision boundary:\\nlog\\n(\\nPr(Y = 1|X)\\nPr(Y = 0|X)\\n)\\n= θ0 + θT X, (2.1)\\nfor a given vector of systematic components X and predictor variables θ. Write the mathem-\\natical expression for the hyperplane that describes the decision boundary.\\nPRB-16 \\uf059 CH.PRB- 2.13.\\nTrue or False: The logit function and the natural logistic (sigmoid) function are inverses\\nof each other.\\n14Chapter 2 LOGISTIC REGRESSION\\n2.2.3 The Sigmoid\\nThe sigmoid (Fig. 2.1) also known as the logistic function, is widely used in binary\\nclassiﬁcation and as a neuron activation function in artiﬁcial neural networks.\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−4x\\nσ(x) = 1\\n1+e−15x\\nFIGURE 2.1: Examples of two sigmoid functions.\\nPRB-17 \\uf059 CH.PRB- 2.14.\\nCompute the derivative of the natural sigmoid function:\\nσ(x) = 1\\n1 + e−x ∈ (0, 1). (2.2)\\nPRB-18 \\uf059 CH.PRB- 2.15.\\nRemember that in logistic regression, the hypothesis function for some parameter vector\\nβ and measurement vector x is deﬁned as:\\nhβ(x) = g(βT x) = 1\\n1 + e−βT x\\n= P (y = 1|x; β), (2.3)\\n152.2. PROBLEMS\\nwhere y holds the hypothesis value.\\nSuppose the coefﬁcients of a logistic regression model with independent variables are as\\nfollows: β0 = −1.5, β1 = 3, β2 = −0.5.\\nAssume additionally, that we have an observation with the following values for the dependent\\nvariables: x1 = 1, x2 = 5. As a result, the logit equation becomes:\\nlogit = β0 + β1x1 + β2x2. (2.4)\\n1. What is the value of the logit for this observation?\\n2. What is the value of the odds for this observation?\\n3. What is the value of P (y = 1) for this observation?\\n2.2.4 Truly Understanding Logistic Regression\\nPRB-19 \\uf059 CH.PRB- 2.16.\\nProton therapy (PT) [ 2] is a widely adopted form of treatment for many types of cancer\\nincluding breast and lung cancer (Fig. 2.2).\\nFIGURE 2.2: Pulmonary nodules (left) and breast cancer (right).\\nA PT device which was not properly calibrated is used to simulate the treatment of\\ncancer. As a result, the PT beam does not behave normally. A data scientist collects inform-\\nation relating to this simulation. The covariates presented in T able 2.1 are collected during\\n16Chapter 2 LOGISTIC REGRESSION\\nthe experiment. The columns Yes and No indicate if the tumour was eradicated or not, re-\\nspectively.\\nTumour eradication\\nCancer Type Yes No\\nBreast 560 260\\nLung 69 36\\nTABLE 2.1: Tumour eradication statistics.\\nReferring to T able2.1:\\n1. What is the explanatory variable and what is the response variable?\\n2. Explain the use of relative risk and odds ratio for measuring association.\\n3. Are the two variables positively or negatively associated?\\nFind the direction and strength of the association using both relative risk and odds\\nratio.\\n4. Compute a 95% conﬁdence interval (CI) for the measure of association.\\n5. Interpret the results and explain their signiﬁcance.\\nPRB-20 \\uf059 CH.PRB- 2.17.\\nConsider a system for radiation therapy planning (Fig. 2.3). Given a patient with a ma-\\nlignant tumour, the problem is to select the optimal radiation exposure time for that patient.\\nA key element in this'),\n",
              " Document(metadata={}, page_content='.\\n4. Compute a 95% conﬁdence interval (CI) for the measure of association.\\n5. Interpret the results and explain their signiﬁcance.\\nPRB-20 \\uf059 CH.PRB- 2.17.\\nConsider a system for radiation therapy planning (Fig. 2.3). Given a patient with a ma-\\nlignant tumour, the problem is to select the optimal radiation exposure time for that patient.\\nA key element in this problem is estimating the probability that a given tumour will be erad-\\nicated given certain covariates. A data scientist collects information relating to this radiation\\ntherapy system.\\n172.2. PROBLEMS\\nFIGURE 2.3: A multi-detector positron scanner used to locate tumours.\\nThe following covariates are collected; X1 denotes time in milliseconds that a patient is\\nirradiated with, X2 = holds the size of the tumour in centimeters, and Y notates a binary re-\\nsponse variable indicating if the tumour was eradicated. Assume that each response’ variable\\nYi is a Bernoulli random variable with success parameter pi, which holds:\\npi = eβ0+β1x1+β2x2\\n1 + eβ0+β1x1+β2x2\\n. (2.5)\\nThe data scientist ﬁts a logistic regression model to the dependent measurements and pro-\\nduces these estimated coefﬁcients:\\nˆβ0 = −6,\\nˆβ1 = 0.05,\\nˆβ2 = 1.\\n(2.6)\\n1. Estimate the probability that, given a patient who undergoes the treatment for 40\\nmilliseconds and who is presented with a tumour sized 3.5 centimetres, the system\\neradicates the tumour.\\n2. How many milliseconds the patient in part (a) would need to be radiated with to have\\nexactly a 50% chance of eradicating the tumour?\\n18Chapter 2 LOGISTIC REGRESSION\\nPRB-21 \\uf059 CH.PRB- 2.18.\\nRecent research [ 3] suggests that heating mercury containing dental amalgams may\\ncause the release of toxic mercury fumes into the human airways. It is also presumed that\\ndrinking hot coffee, stimulates the release of mercury vapour from amalgam ﬁllings (Fig.\\n2.4).\\nFIGURE 2.4: A dental amalgam.\\nT o study factors that affect migraines, and in particular, patients who have at least four\\ndental amalgams in their mouth, a data scientist collects data from 200K users with and\\nwithout dental amalgams. The data scientist then ﬁts a logistic regression model with an\\nindicator of a second migraine within a time frame of one hour after the onset of the ﬁrst mi-\\ngraine, as the binary response variable (e.g., migraine=1, no migraine=0). The data scientist\\nbelieves that the frequency of migraines may be related to the release of toxic mercury fumes.\\nThere are two independent variables:\\n1. X1 = 1 if the patient has at least four amalgams; 0 otherwise.\\n2. X2 = coffee consumption (0 to 100 hot cups per month).\\nThe output from training a logistic regression classiﬁer is as follows:\\nAnalysis of LR Parameter Estimates\\nParameter Estimate Std.Err Z-val Pr>|Z|\\nIntercept -6.36347 3.21362 -1.980 0.0477\\n$X_1$ -1.02411 1.17101 -0.875 0.3818\\n$X_2$ 0.11904 0.05497 2.165 0.0304\\n192.2. PROBLEMS\\n1. Using X1 and X2, express the odds of a patient having a migraine for a second time.\\n2. Calculate the probability of a second migraine for a patient that has at least four\\namalgams and drank 100 cups per month?\\n3. For users that have at least four amalgams, is high coffee intake associated with an\\nincreased probability of a second migraine?\\n4. Is there statistical evidence that having more than four amalgams is directly associ-\\nated with a reduction in the probability of a second migraine?\\nPRB-22 \\uf059 CH.PRB- 2.19.\\nT o study factors that affect Alzheimer’s disease using logistic regression, a researcher\\nconsiders the link between gum (periodontal) disease and Alzheimer as a plausible risk factor\\n[1]. The predictor variable is a count of gum bacteria (Fig. 2.5) in the mouth.\\nFIGURE 2.5: A chain'),\n",
              " Document(metadata={}, page_content=' directly associ-\\nated with a reduction in the probability of a second migraine?\\nPRB-22 \\uf059 CH.PRB- 2.19.\\nT o study factors that affect Alzheimer’s disease using logistic regression, a researcher\\nconsiders the link between gum (periodontal) disease and Alzheimer as a plausible risk factor\\n[1]. The predictor variable is a count of gum bacteria (Fig. 2.5) in the mouth.\\nFIGURE 2.5: A chain of spherical bacteria.\\nThe response variable, Y , measures whether the patient shows any remission (e.g. yes=1).\\nThe output from training a logistic regression classiﬁer is as follows:\\nParameter DF Estimate Std\\nIntercept 1 -4.8792 1.2197\\ngum bacteria 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of gum bacteria of a patient\\nis 33.\\n20Chapter 2 LOGISTIC REGRESSION\\n2. Find out the gum bacteria count at which the estimated probability of improvement is\\n0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1 in the total gum\\nbacteria count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total gum bacteria count. Remember that the most common conﬁdence levels\\nare 90%, 95%, 99%, and 99.9%. T able9.1 lists the z values for these levels.\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 2.2: Common conﬁdence levels.\\nPRB-23 \\uf059 CH.PRB- 2.20.\\nRecent research [ 4] suggests that cannabis (Fig. 2.6) and cannabinoids administration\\nin particular, may reduce the size of malignant tumours in rats.\\nFIGURE 2.6: Cannabis.\\n212.2. PROBLEMS\\nT o study factors affecting tumour shrinkage, a deep learning researcher collects data from\\ntwo groups; one group is administered with placebo (a substance that is not medicine) and\\nthe other with cannabinoids. His main research revolves around studying the relationship\\n(T able2.3) between the anticancer properties of cannabinoids and tumour shrinkage:\\nTumour Shrinkage In Rats\\nGroup Yes No Sum\\nCannabinoids 60 6833 6893\\nPlacebo 130 6778 6909\\nSum 190 13611 13801\\nTABLE 2.3: Tumour shrinkage in rats.\\nFor the true odds ratio:\\n1. Find the sample odds ratio.\\n2. Find the sample log-odds ratio.\\n3. Compute a 95% conﬁdence interval ( z0.95 = 1.645; z0.975 = 1.96) for the true log odds\\nratio and true odds ratio.\\n2.2.5 The Logit Function and Entropy\\nPRB-24 \\uf059 CH.PRB- 2.21.\\nThe entropy (see Chapter 4) of a single binary outcome with probability p to receive 1 is\\ndeﬁned as:\\nH(p) ≡ −p log p − (1 − p) log(1 − p). (2.7)\\n1. At what p does H(p) attain its maximum value?\\n2. What is the relationship between the entropy H(p) and the logit function, given p?\\n22Chapter 2 LOGISTIC REGRESSION\\n2.2.6 Python/PyTorch/CPP\\nPRB-25 \\uf059 CH.PRB- 2.22.\\nThe following C++ code (Fig. 2.7) is part of a (very basic) logistic regression implement-\\nation module. For a theoretical discussion underlying this question, refer to problem 2.17.\\n1 #include ...\\n2 std::vector<double> theta { -6,0.05,1.0};\\n3 double sigmoid(double x) {\\n4 double tmp =1.0 / (1.0 + exp(-x));\\n5 std::cout << \"prob=\" << tmp<<std::endl;\\n6 return tmp;\\n7 }\\n8 double hypothesis(std::vector<double> x){\\n9 double z;\\n10 z=std::inner_product(std::begin(x), std ::end(x),\\nstd::begin(theta), 0.0);↪→\\n11 std::cout << \"inner_product=\" << z<<std::endl;\\n12 return sigmoid(z);\\n13 }\\n14 int classify(std::vector<double> x){\\n15 int hypo=hypo'),\n",
              " Document(metadata={}, page_content=' << \"prob=\" << tmp<<std::endl;\\n6 return tmp;\\n7 }\\n8 double hypothesis(std::vector<double> x){\\n9 double z;\\n10 z=std::inner_product(std::begin(x), std ::end(x),\\nstd::begin(theta), 0.0);↪→\\n11 std::cout << \"inner_product=\" << z<<std::endl;\\n12 return sigmoid(z);\\n13 }\\n14 int classify(std::vector<double> x){\\n15 int hypo=hypothesis(x) > 0.5f;\\n16 std::cout << \"hypo=\" << hypo<<std::endl;\\n17 return hypo;\\n18 }\\n19 int main() {\\n20 std::vector<double> x1 { 1,40,3.5};\\n21 classify(x1);\\n22 }\\nFIGURE 2.7: Logistic regression in CPP\\n1. Explain the purpose of line 10, i.e., inner_product.\\n2. Explain the purpose of line 15, i.e., hypo(x) > 0.5f.\\n232.2. PROBLEMS\\n3. What does θ (theta) stand for in line 2?\\n4. Compile and run the code, you can use:\\nhttps://repl.it/languages/cpp11 to evaluate the code.\\nWhat is the output?\\nPRB-26 \\uf059 CH.PRB- 2.23.\\nThe following Python code (Fig. 2.8) runs a very simple linear model on a two-dimensional\\nmatrix.\\n1 import torch\\n2 import torch.nn as nn\\n3\\n4 lin = nn.Linear(5, 7)\\n5 data = (torch.randn(3, 5))\\n6\\n7 print(lin(data).shape)\\n8 >?\\nFIGURE 2.8: A linear model in PyTorch\\nWithout actually running the code, determine what is the size of the matrix printed as a\\nresult of applying the linear model on the matrix.\\nPRB-27 \\uf059 CH.PRB- 2.24.\\nThe following Python code snippet (Fig. 2.9) is part of a logistic regression implementa-\\ntion module in Python.\\n24Chapter 2 LOGISTIC REGRESSION\\n1 from scipy.special import expit\\n2 import numpy as np\\n3 import math\\n4\\n5 def Func001(x):\\n6 e_x = np.exp(x - np.max(x))\\n7 return e_x / e_x.sum()\\n8\\n9 def Func002(x):\\n10 return 1 / (1 + math.exp(-x))\\n11\\n12 def Func003(x):\\n13 return x * (1-x)\\nFIGURE 2.9: Logistic regression methods in Python.\\nAnalyse the methods Func001 , Func002 and Func003 presented in Fig. 2.9, ﬁnd their\\npurposes and name them.\\nPRB-28 \\uf059 CH.PRB- 2.25.\\nThe following Python code snippet (Fig. 2.10) is part of a machine learning module in\\nPython.\\n252.2. PROBLEMS\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5 ^^I^^I\\n6 def Func006(y_hat, y):\\n7 if y == 1:\\n8 return -np.log(y_hat)\\n9 else:\\n10 return -np.log(1 - y_hat)^^I\\nFIGURE 2.10: Logistic regression methods in Python.\\nAnalyse the method Func006 presented in Fig. 2.10. What important concept in machine-\\nlearning does it implement?\\nPRB-29 \\uf059 CH.PRB- 2.26.\\nThe following Python code snippet (Fig. 2.11) presents several different variations of the\\nsame function.\\n26Chapter 2 LOGISTIC REGRESSION\\n1 ^^I^^I\\n2 from scipy.special import expit\\n3 import numpy as np\\n4 import math\\n5\\n6 def Ver001(x):\\n7 return 1 / (1 + math.exp(-x))\\n8\\n9 def Ver002(x):\\n10 return 1 / (1 + (np.exp(-x)))\\n11\\n12 WHO_AM_I = 709\\n13\\n14 def Ver003(x):\\n15 return 1 / (1 + np.exp(-(np.clip(x, -WHO_AM_I, None))))\\nFIGURE 2.11: Logistic regression methods in Python.\\n1. Which mathematical function do these methods implement?\\n2. What is signiﬁcant about the number 709 in line 11?\\n3. Given a choice, which method would you use?\\n2.3 Solutions\\n2.3.1 General Concepts\\nSOL-4 \\uf14b CH.SOL- 2.1.\\nTrue. However, when an excessive and unnecessary number of variables is used in a lo-\\ngistic regression model'),\n",
              " Document(metadata={}, page_content='11: Logistic regression methods in Python.\\n1. Which mathematical function do these methods implement?\\n2. What is signiﬁcant about the number 709 in line 11?\\n3. Given a choice, which method would you use?\\n2.3 Solutions\\n2.3.1 General Concepts\\nSOL-4 \\uf14b CH.SOL- 2.1.\\nTrue. However, when an excessive and unnecessary number of variables is used in a lo-\\ngistic regression model, peculiarities (e.g., speciﬁc attributes) of the underlying data set dis-\\nproportionately affect the coefﬁcients in the model, a phenomena commonly referred to as\\n“overﬁtting”. Therefore, it is important that a logistic regression model does not start training\\nwith more variables than is justiﬁed for the given number of observations. \\x04\\n272.3. SOLUTIONS\\nSOL-5 \\uf14b CH.SOL- 2.2.\\nThe odds of success are deﬁned as the ratio between the probability of success p ∈ [0, 1]\\nand the probability of failure 1 − p. Formally:\\nOdds(p) ≡\\n(\\np\\n1 − p\\n)\\n. (2.8)\\nFor instance, assuming the probability of success of an event is p = 0 .7. Then, in our\\nexample, the odds of success are 7/3, or 2.333 to 1. Naturally, in the case of equal probabilities\\nwhere p = 0.5, the odds of success is 1 to 1.\\n\\x04\\nSOL-6 \\uf14b CH.SOL- 2.3.\\n1. An interaction is the product of two single predictor variables implying a non-additive\\neffect.\\n2. The simplest interaction model includes a predictor variable formed by multiplying two\\nordinary predictors. Let us assume two variables X and Z. Then, the logistic regression\\nmodel that employs the simplest form of interaction follows:\\nβ0 + β1X + β2Z + β3XZ, (2.9)\\nwhere the coefﬁcient for the interaction term XZ is represented by predictor β3.\\n3. For testing the contribution of an interaction, two principal methods are commonly\\nemployed; the Wald chi-squared test or a likelihood ratio test between the model with\\nand without the interaction term. Note: How does interaction relates to information\\ntheory? What added value does it employ to enhance model performance?\\n\\x04\\nSOL-7 \\uf14b CH.SOL- 2.4.\\nFalse. This is exactly the deﬁnition of supervised learning; when labels are known then\\nsupervision guides the learning process. \\x04\\n28Chapter 2 LOGISTIC REGRESSION\\nSOL-8 \\uf14b CH.SOL- 2.5.\\nIn the case of logistic regression, the response variable is the log of the odds of being clas-\\nsiﬁed in a group of binary or multi-class responses. This deﬁnition essentially demonstrates\\nthat odds can take the form of a vector. \\x04\\nSOL-9 \\uf14b CH.SOL- 2.6.\\nWhen a transformation to the response variable is applied, it yields a probability distribu-\\ntion over the output classes, which is bounded between 0 and 1; this transformation can be\\nemployed in several ways, e.g., a softmax layer, the sigmoid function or classic normalization.\\nThis representation facilitates a soft-decision by the logistic regression model, which permits\\nconstruction of probability-based processes over the predictions of the model. Note: What are\\nthe pros and cons of each of the three aforementioned transformations? \\x04\\nSOL-10 \\uf14b CH.SOL- 2.7.\\nMinimizing the negative log likelihood also means maximizing the likelihood of selecting\\nthe correct class. \\x04\\n2.3.2 Odds, Log-odds\\nSOL-11 \\uf14b CH.SOL- 2.8.\\n1. The odds of the event occurring are, by deﬁnition:\\nodds = ( 0.1\\n0.9 ) = 0 .11. (2.10)\\n2. The log-odds of the event occurring are simply taken as the log of the odds:\\nlog-odds = ln(0.1/0.9) = −2.19685. (2.11)\\n3. The probability may be constructed by the following representation:\\nprobability = odds\\nodds + 1 = 0.11\\n1.11 = 0.1, (2.12)\\n292.3. SOLUTIONS\\nor, alternatively:\\np = exp (ln odds)\\nexp (ln odds) + 1 = 0.'),\n",
              " Document(metadata={}, page_content=' odds:\\nlog-odds = ln(0.1/0.9) = −2.19685. (2.11)\\n3. The probability may be constructed by the following representation:\\nprobability = odds\\nodds + 1 = 0.11\\n1.11 = 0.1, (2.12)\\n292.3. SOLUTIONS\\nor, alternatively:\\np = exp (ln odds)\\nexp (ln odds) + 1 = 0.11\\n1.11 = 0.1. (2.13)\\nNote: What is the intuition behind this representation?\\n\\x04\\nSOL-12 \\uf14b CH.SOL- 2.9.\\nTrue. By deﬁnition of odds, it is easy to notice that p = 0.8 satisﬁes the following relation:\\nodds = ( 0.8\\n0.2) = 4 (2.14)\\n\\x04\\nSOL-13 \\uf14b CH.SOL- 2.10.\\nThe graph of odds to probabilities is depicted in Figure 2.12.\\n0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 0,9\\n2,0\\n4,0\\n6,0\\n8,0\\n10,0\\nProbability\\nOdds odds(p) = p\\n1−p\\nFIGURE 2.12: Odds vs. probability values.\\n\\x04\\n30Chapter 2 LOGISTIC REGRESSION\\nSOL-14 \\uf14b CH.SOL- 2.11.\\nA binary logistic regression GLM consists of there components:\\n1. Random component: refers to the probability distribution of the response variable (Y ),\\ne.g., binomial distribution for Y in the binary logistic regression, which takes on the\\nvalues Y = 0 or Y = 1.\\n2. Systematic component: describes the explanatory variables:\\n(X1, X2, ...) as a combination of linear predictors. The binary case does not constrain\\nthese variables to any degree.\\n3. Link function: speciﬁes the link between random and systematic components. It says\\nhow the expected value of the response relates to the linear predictor of explanatory\\nvariables.\\nNote: Assume that Y denotes whether a human voice activity was detected ( Y = 1 )\\nor not ( Y = 0 ) in a give time frame. Propose two systematic components and a link\\nfunction adjusted for this task.\\n\\x04\\nSOL-15 \\uf14b CH.SOL- 2.12.\\nThe hyperplane is simply deﬁned by:\\nθ0 + θT X = 0. (2.15)\\nNote: Recall the use of the logit function and derive this decision boundary rigorously. \\x04\\nSOL-16 \\uf14b CH.SOL- 2.13.\\nTrue. The logit function is deﬁned as:\\nz(p) = logit(p) = log\\n(\\np\\n1 − p\\n)\\n, (2.16)\\n312.3. SOLUTIONS\\nfor any p ∈ [0, 1]. A simple set of algebraic equations yields the inverse relation:\\np(z) = exp z\\n1 + exp z , (2.17)\\nwhich exactly describes the relation between the output and input of the logistic function, also\\nknown as the sigmoid. \\x04\\n2.3.3 The Sigmoid\\nSOL-17 \\uf14b CH.SOL- 2.14.\\nThere are various approaches to solve this problem, here we provide two; direct derivation\\nor derivation via the softmax function.\\n1. Direct derivation:\\nd\\ndx σ(x) = d\\ndx ((1 + e−x)−1) = −((1 + e−x)(−2)) d\\ndx (1 + e−x) = e−x\\n(1+e−x)2 .\\n2. Softmax derivation:\\nIn a classiﬁcation problem with mutually exclusive classes, where all of the values are\\npositive and sum to one, a softmax activation function may be used. By deﬁnition, the\\nsoftmax activation function consists of n terms, such that ∀i ∈ [1, n]:\\nf (θi) = eθi\\n∑\\nk evk\\n= 1\\n1 + e−θi\\n∑\\nk̸=i eθk\\n. (2.18)\\nT o compute the partial derivative of 2.18, we treat all θk where k ̸= i as constants and\\nthen differentiate θi using regular differentiation rules. For a given θi, let us deﬁne:\\nβ =\\n∑\\nk̸=i\\n'),\n",
              " Document(metadata={}, page_content='\\ndx (1 + e−x) = e−x\\n(1+e−x)2 .\\n2. Softmax derivation:\\nIn a classiﬁcation problem with mutually exclusive classes, where all of the values are\\npositive and sum to one, a softmax activation function may be used. By deﬁnition, the\\nsoftmax activation function consists of n terms, such that ∀i ∈ [1, n]:\\nf (θi) = eθi\\n∑\\nk evk\\n= 1\\n1 + e−θi\\n∑\\nk̸=i eθk\\n. (2.18)\\nT o compute the partial derivative of 2.18, we treat all θk where k ̸= i as constants and\\nthen differentiate θi using regular differentiation rules. For a given θi, let us deﬁne:\\nβ =\\n∑\\nk̸=i\\neθk, (2.19)\\nand\\nf (θi) = 1\\n1 + βe−θi\\n= (1 + βe−θi)−1. (2.20)\\nIt can now be shown that the derivative with respect to θi holds:\\nf ′(θi) =\\n(\\n1 + βe−θi\\n) −2\\nβe−θi, (2.21)\\n32Chapter 2 LOGISTIC REGRESSION\\nwhich can take on the informative form of:\\nf ′(θi) = f (θi)(1 − f (θi)). (2.22)\\nIt should be noted that 2.21 holds for any constant β, and for β = 1 it clearly reduces\\nto the sigmoid activation function.\\nNote: Characterize the sigmoid function when its argument approaches 0, ∞ and −∞.\\nWhat undesired properties of the sigmoid function do this values entail when considered as an\\nactivation function?\\n\\x04\\nSOL-18 \\uf14b CH.SOL- 2.15.\\n1. The logit value is simply obtained by substituting the values of the dependent variables\\nand model coefﬁcients into the linear logistic regression model, as follows:\\nlogit = β0 + β1x1 + β2x2 = −1.5 + 3 · 1 + −0.5 · 5 = −1. (2.23)\\n2. According to the natural relation between the logit and the odds, the following holds:\\nodds = elogit = eβ0+β1x1+β2x2 = e−1 = 0.3678794. (2.24)\\n3. The odds ratio is, by deﬁnition:\\nodds = P (y = 1)\\nP (y = 0) , (2.25)\\nso the logistic response function is:\\nP (y = 1) = 1\\n1 + e−logit = 1\\n1 + e1 = 0.2689414. (2.26)\\n\\x04\\n2.3.4 Truly Understanding Logistic Regression\\n332.3. SOLUTIONS\\nSOL-19 \\uf14b CH.SOL- 2.16.\\n1. T umour eradication (Y ) is the response variable and cancer type ( X) is the explanatory\\nvariable.\\n2. Relative risk (RR) is the ratio of risk of an event in one group (e.g., exposed group)\\nversus the risk of the event in the other group (e.g., non-exposed group). The odds ratio\\n(OR) is the ratio of odds of an event in one group versus the odds of the event in the\\nother group.\\n3. If we calculate odds ratio as a measure of association:\\nˆθ = 560 × 36\\n69 × 260 = 1.23745. (2.27)\\nAnd the log-odds ratio is (log(1.23745)) = 0 .213052:\\nThe odds ratio is larger than one, indicating that the odds for a breast cancer is more\\nthan the odds for a lung cancer to be eradicated. Notice however, that this result is too\\nclose to one, which prevents conclusive decision regarding the odds relation.\\nAdditionally, if we calculate relative risk as a measure of association:\\nRR =\\n560\\n560+260\\n69\\n69+36\\n= 1.0392. (2.28)\\n4. The 95% conﬁdence interval for the odds-ratio, θ is computed from the sample conﬁd-\\nence interval for log odds ratio:\\nˆσ\\n(\\nlog(ˆθ)\\n)\\n=\\n√\\n1\\n560 + 1\\n260 + 1\\n69'),\n",
              " Document(metadata={}, page_content=' relative risk as a measure of association:\\nRR =\\n560\\n560+260\\n69\\n69+36\\n= 1.0392. (2.28)\\n4. The 95% conﬁdence interval for the odds-ratio, θ is computed from the sample conﬁd-\\nence interval for log odds ratio:\\nˆσ\\n(\\nlog(ˆθ)\\n)\\n=\\n√\\n1\\n560 + 1\\n260 + 1\\n69 + 1\\n36 = 0.21886. (2.29)\\nTherefore, the 95% CI for log (θ) is:\\n0.213052 ± 1.95 × 0.21886 = (0 .6398298, −0.2137241). (2.30)\\n34Chapter 2 LOGISTIC REGRESSION\\nTherefore, the 95% CI for θ is:\\n(e−0.210, e0.647) = (0 .810, 1.909). (2.31)\\n5. The CI (0.810, 1.909) contains 1, which indicates that the true odds ratio is not signi-\\nﬁcantly different from 1 and there is not enough evidence that tumour eradication is\\ndependent on cancer type.\\n\\x04\\nSOL-20 \\uf14b CH.SOL- 2.17.\\n1. By using the deﬁned values for X1 and X2, and the known logistic regression model,\\nsubstitution yields:\\nˆp(X) = e−6+0.05X1+X2\\n(1 + e−6+0.05X1+X2) = 0.3775. (2.32)\\n2. The equation for the predicted probability tells us that:\\ne−6+0.05X1+3.5\\n(1 + e−6+0.05X1+3.5) = 0.5, (2.33)\\nwhich is equivalent to constraining:\\ne−6+0.05X1+3.5 = 1. (2.34)\\nBy taking the logarithm of both sides, we get that the number of milliseconds needed is:\\nX1 = 2.5\\n0.05 = 50. (2.35)\\n\\x04\\nSOL-21 \\uf14b CH.SOL- 2.18.\\n352.3. SOLUTIONS\\nFor the purpose of this exercise, it is instructive to pre-deﬁne z as:\\nz (X1, X2) = −6.36 − 1.02 × X1 + 0.12 × X2. (2.36)\\n1. By employing the classic logistic regression model:\\nodds = exp(z (X1, X2)). (2.37)\\n2. By substituting the given values of X1, X2 into z (X1, X2), the probability holds:\\np = exp(z (1, 100))/(1 + exp(z (1, 100))) = 0 .99. (2.38)\\n3. Y es. The coefﬁcient for coffee consumption is positive ( 0.119) and the p-value is less\\nthan 0.05 (0.0304).\\nNote: Can you describe the relation between these numerical relations and the positive\\nconclusion?\\n4. No. The p-value for this predictor is 0.3818 > 0.05.\\nNote: Can you explain why this inequality implicates a lack of statistical evidence?\\n\\x04\\nSOL-22 \\uf14b CH.SOL- 2.19.\\n1. The estimated probability of improvement is:\\nˆπ(gum bacteria) =\\nexp(−4.8792 + 0.0258 × gum bacteria)\\n1 + exp(−4.8792 + 0.0258 × gum bacteria).\\nHence, ˆπ(33) = 0 .01748.\\n36Chapter 2 LOGISTIC REGRESSION\\n2. For ˆπ(gum bacteria) = 0 .5 we know that:\\nˆπ(gum) = exp( ˆα + ˆβx)\\n1 + exp( ˆα + ˆβx)\\n= 0.5 (2.39)\\ngum bacteria = −ˆα/ ˆβ = 4.8792/0.0258 = 189 .116. (2.40)\\n3. The estimated odds ratio are given by:\\nexp( ˆβ) = exp(0 .0258) = 1 .0504. (2.41)\\n4. A 99% conﬁdence interval for β is calculated as follows:\\nˆ'),\n",
              " Document(metadata={}, page_content='.5 (2.39)\\ngum bacteria = −ˆα/ ˆβ = 4.8792/0.0258 = 189 .116. (2.40)\\n3. The estimated odds ratio are given by:\\nexp( ˆβ) = exp(0 .0258) = 1 .0504. (2.41)\\n4. A 99% conﬁdence interval for β is calculated as follows:\\nˆβ ± z0.005 × ASE( ˆβ) = (2.42)\\n0.0258 ± 2.576 × 0.0194 (2.43)\\n= (−0.00077, 0.9917). (2.44)\\nTherefore, a 99% conﬁdence interval for the true odds ratio exp(β) is given by:\\n(exp(−0.00077), exp(0.9917)) = (0 .99923, 2.6958). (2.45)\\n\\x04\\nSOL-23 \\uf14b CH.SOL- 2.20.\\n1. The sample odds ratio is:\\nˆθ = 130 × 6833\\n60 × 6778 = 2.1842. (2.46)\\n372.3. SOLUTIONS\\n2. The estimated standard error for log\\n(\\nˆθ\\n)\\nis:\\nˆσ\\n(\\nlog ˆθ\\n)\\n=\\n√\\n1\\n60 + 1\\n6833 + 1\\n130 + 1\\n6778 = 0.1570. (2.47)\\n3. According to previous sections, the 95% CI for the true log odds ratio is:\\n0.7812 ± 1.96 × 0.1570 = (0 .4734, 1.0889). (2.48)\\nCorrespondingly, the 95% CI for the true odds ratio is:\\n(e0.4734, e1.0889) = (1 .6060, 2.9710). (2.49)\\n\\x04\\n2.3.5 The Logit Function and Entropy\\nSOL-24 \\uf14b CH.SOL- 2.21.\\n1. The entropy (Fig. 2.13) has a maximum value of log2(2) for probability p = 1/2, which\\nis the most chaotic distribution. A lower entropy is a more predictable outcome, with\\nzero providing full certainty.\\n2. The derivative of the entropy with respect to p yields the negative of the logit func-\\ntion:\\ndH(p)\\ndp = −logit(p). (2.50)\\nNote: The curious reader is encouraged to rigorously prove this claim.\\n\\x04\\n2.3.6 Python, PyTorch, CPP\\nSOL-25 \\uf14b CH.SOL- 2.22.\\n38Chapter 2 LOGISTIC REGRESSION\\nFIGURE 2.13: Binary entropy .\\n1. During inference, the purpose of inner_product is to multiply the vector of logistic re-\\ngression coefﬁcients with the vector of the input which we like to evaluate, e.g., calculate\\nthe probability and binary class.\\n2. The line hypo(x) > 0.5f is commonly used for the evaluation of binary classiﬁcation\\nwherein probability values above 0.5 (i.e., a threshold) are regarded as TRUE whereas\\nvalues below 0.5 are regarded as F ALSE.\\n3. The term θ (theta) stands for the logistic regression coefﬁcients which were evaluated\\nduring training.\\n4. The output is as follows:\\n1 > inner_product=-0.5\\n2 > prob=0.377541\\n3 > hypo=0\\nFIGURE 2.14: Logistic regression in C++\\n\\x04\\nSOL-26 \\uf14b CH.SOL- 2.23.\\n392.3. SOLUTIONS\\nBecause the second dimension of lin is 7, and the ﬁrst dimension of data is 3, the result-\\ning matrix has a shape of torch.Size([3, 7]) .\\n\\x04\\nSOL-27 \\uf14b CH.SOL- 2.24.\\nIdeally, you should be able to recognize these functions immediately upon a request from\\nthe interviewer.\\n1. A softmax function.\\n2. A sigmoid function.\\n3. A derivative of a sigmoid function.\\n\\x04\\nSOL-28 \\uf14b CH.SOL- 2.25.\\nThe function implemented in Fig. 2.10 is the binary cross-entropy function. \\x04\\nSOL-29 \\uf14b CH.SOL- 2.26.\\n1. All the methods are variations of the sigmoid function'),\n",
              " Document(metadata={}, page_content=' to recognize these functions immediately upon a request from\\nthe interviewer.\\n1. A softmax function.\\n2. A sigmoid function.\\n3. A derivative of a sigmoid function.\\n\\x04\\nSOL-28 \\uf14b CH.SOL- 2.25.\\nThe function implemented in Fig. 2.10 is the binary cross-entropy function. \\x04\\nSOL-29 \\uf14b CH.SOL- 2.26.\\n1. All the methods are variations of the sigmoid function.\\n2. In Python, approximately 1.797e + 308 holds the largest possible valve for a ﬂoating\\npoint variable. The logarithm of which is evaluated at 709.78. If you try to execute the\\nfollowing expression in Python, it will result in inf : np.log(1.8e + 308).\\n3. I would use Ver003 because of its stability. Note: Can you entail why is this method\\nmore stable than the others?\\n\\x04\\n40CHAPTER\\n3\\nPROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAnyone who considers arithmetical methods of producing random digits is, of\\ncourse, in a state of sin.\\n— John von Neumann (1903-1957)\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 51\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54\\nThe Beta-Binomial distribution . . . . . . . . . . . . . . . . . . . 54\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nExpectation and Variance . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nConditional Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nBayes Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66\\nMaximum Likelihood Estimation . . . . . . . . . . . . . . . . . . . . . . 71\\nFisher Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nPosterior & prior predictive distributions . . . . . . . . . . . . . . . . . 76\\nConjugate priors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 773.1. INTRODUCTION\\n3.1 Introduction\\nT\\nHE Bayesian school of thought has permeated ﬁelds such as mechanical\\nstatistics, classical probability , and ﬁ'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\nBayesian Deep Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . 773.1. INTRODUCTION\\n3.1 Introduction\\nT\\nHE Bayesian school of thought has permeated ﬁelds such as mechanical\\nstatistics, classical probability , and ﬁnancial mathematics [ 13]. In tandem,\\nthe subject matter itself has gained attraction, particularly in the ﬁeld of\\nBML. It is not surprising then, that several new Python based probabilistic\\nprogramming libraries such as PyMc3 and Stan [ 11] have emerged and have become\\nwidely adopted by the machine learning community .\\nThis chapter aims to introduce the Bayesian paradigm and apply Bayesian infer-\\nences in a variety of problems. In particular, the reader will be introduced with real-\\nlife examples of conditional probability and also discover one of the most important\\nresults in Bayesian statistics: that the family of beta distributions is conjugate to a bi-\\nnomial likelihood . It should be stressed that Bayesian inference is a subject matter\\nthat students evidently ﬁnd hard to grasp, since it heavily relies on rigorous probab-\\nilistic interpretations of data. Speciﬁcally , several obstacles hamper with the prospect\\nof learning Bayesian statistics:\\n1. Students typically undergo merely basic introduction to classical probability and\\nstatistics. Nonetheless, what follows requires a very solid grounding in these\\nﬁelds.\\n2. Many courses and resources that address Bayesian learning do not cover essen-\\ntial concepts.\\n3. A strong comprehension of Bayesian methods involves numerical training and\\nsophistication levels that go beyond ﬁrst year calculus.\\nConclusively , this chapter may be much harder to understand than other chapters.\\nThus, we strongly urge the readers to thoroughly solve the following questions and\\nverify their grasp of the mathematical concepts in the basis of the solutions [ 8].\\n3.2 Problems\\n3.2.1 Expectation and Variance\\nPRB-30 \\uf059 CH.PRB- 3.1.\\nDeﬁne what is meant by a Bernoulli trial.\\n42Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPRB-31 \\uf059 CH.PRB- 3.2.\\nThe binomial distribution is often used to model the probability that k out of a group of n\\nobjects bare a speciﬁc characteristic. Deﬁne what is meant by a binomial random variable\\nX.\\nPRB-32 \\uf059 CH.PRB- 3.3.\\nWhat does the following shorthand stand for?\\nX ∼ Binomial(n, p ) (3.1)\\nPRB-33 \\uf059 CH.PRB- 3.4.\\nFind the probability mass function (PMF) of the following random variable:\\nX ∼ Binomial(n, p ) (3.2)\\nPRB-34 \\uf059 CH.PRB- 3.5.\\nAnswer the following questions:\\n1. Deﬁne what is meant by (mathematical) expectation.\\n2. Deﬁne what is meant by variance.\\n3. Derive the expectation and variance of a the binomial random variable X ∼ Binomial(n, p )\\nin terms of p and n.\\nPRB-35 \\uf059 CH.PRB- 3.6.\\nProton therapy (PT) is a widely adopted form of treatment for many types of cancer [ 6].\\nA PT device which was not properly calibrated is used to treat a patient with pancreatic\\ncancer (Fig. 3.1). As a result, a PT beam randomly shoots 200 particles independently and\\ncorrectly hits cancerous cells with a probability of 0.1.\\n433.2. PROBLEMS\\nFIGURE 3.1: Histopathology for pancreatic cancer cells.\\n1. Find the statistical distribution of the number of correct hits on cancerous cells in\\nthe described experiment. What are the expectation and variance of the corresponding\\nrandom variable?\\n2. A radiologist using the device claims he was able to hit exactly 60 cancerous cells.\\nHow likely is it that he is wrong?\\n3.2.2 Conditional Probability\\nPRB-36 \\uf059 CH.PRB- 3.7.\\nGiven two events A and B in probability space H, which occur with probabilities P (A)\\nand P (B), respectively:\\n1. Deﬁne the conditional probability of A given B. Mind singular cases.\\n2. Annotate each part of the conditional probability formulae.\\n3. Draw an instance of Venn diagram, depicting the intersection of the events A and B.\\nAssume that A �'),\n",
              " Document(metadata={}, page_content='\\nPRB-36 \\uf059 CH.PRB- 3.7.\\nGiven two events A and B in probability space H, which occur with probabilities P (A)\\nand P (B), respectively:\\n1. Deﬁne the conditional probability of A given B. Mind singular cases.\\n2. Annotate each part of the conditional probability formulae.\\n3. Draw an instance of Venn diagram, depicting the intersection of the events A and B.\\nAssume that A ⋃ B = H.\\nPRB-37 \\uf059 CH.PRB- 3.8.\\nBayesian inference amalgamates data information in the likelihood function with known\\nprior information. This is done by conditioning the prior on the likelihood using the Bayes\\nformulae. Assume two events A and B in probability space H, which occur with probabilities\\n44Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nP (A) and P (B), respectively. Given that A ⋃ B = H, state the Bayes formulae for this case,\\ninterpret its components and annotate them.\\nPRB-38 \\uf059 CH.PRB- 3.9.\\nDeﬁne the terms likelihood and log-likelihood of a discrete random variable X given\\na ﬁxed parameter of interest γ. Give a practical example of such scenario and derive its\\nlikelihood and log-likelihood.\\nPRB-39 \\uf059 CH.PRB- 3.10.\\nDeﬁne the term prior distribution of a likelihood parameter γ in the continuous case.\\nPRB-40 \\uf059 CH.PRB- 3.11.\\nShow the relationship between the prior, posterior and likelihood probabilities.\\nPRB-41 \\uf059 CH.PRB- 3.12.\\nIn a Bayesian context, if a ﬁrst experiment is conducted, and then another experiment is\\nfollowed, what does the posterior become for the next experiment?\\nPRB-42 \\uf059 CH.PRB- 3.13.\\nWhat is the condition under which two events A and B are said to be statistically\\nindependent?\\n3.2.3 Bayes Rule\\nPRB-43 \\uf059 CH.PRB- 3.14.\\nIn an experiment conducted in the ﬁeld of particle physics (Fig. 3.2), a certain particle\\nmay be in two distinct equally probable quantum states: integer spin or half-integer spin.\\nIt is well-known that particles with integer spin are bosons, while particles with half-integer\\nspin are fermions [ 4].\\n453.2. PROBLEMS\\nFIGURE 3.2: Bosons and fermions: particles with half-integer spin are fermions.\\nA physicist is observing two such particles, while at least one of which is in a half-integer\\nstate. What is the probability that both particles are fermions?\\nPRB-44 \\uf059 CH.PRB- 3.15.\\nDuring pregnancy, the Placenta Chorion T est [1] is commonly used for the diagnosis of\\nhereditary diseases (Fig. 3.3). The test has a probability of 0.95 of being correct whether or\\nnot a hereditary disease is present.\\n46Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.3: Foetal surface of the placenta\\nIt is known that 1% of pregnancies result in hereditary diseases. Calculate the probability\\nof a test indicating that a hereditary disease is present.\\nPRB-45 \\uf059 CH.PRB- 3.16.\\nThe Dercum disease [ 3] is an extremely rare disorder of multiple painful tissue growths.\\nIn a population in which the ratio of females to males is equal, 5% of females and 0.25% of\\nmales have the Dercum disease (Fig. 3.4).\\nFIGURE 3.4: The Dercum disease\\nA person is chosen at random and that person has the Dercum disease. Calculate the\\nprobability that the person is female.\\nPRB-46 \\uf059 CH.PRB- 3.17.\\nThere are numerous fraudulent binary options websites scattered around the Internet,\\nand for every site that shuts down, new ones are sprouted like mushrooms. A fraudulent AI\\n473.2. PROBLEMS\\nbased stock-market prediction algorithm utilized at the New Y ork Stock Exchange, (Fig. 3.6)\\ncan correctly predict if a certain binary option [ 7] shifts states from 0 to 1 or the other way\\naround, with 85% certainty.\\nFIGURE 3.5: The New York Stock Exchange.\\nA ﬁnancial engineer has created a portfolio consisting twice as many state-1 options then\\nstate-'),\n",
              " Document(metadata={}, page_content='\\n473.2. PROBLEMS\\nbased stock-market prediction algorithm utilized at the New Y ork Stock Exchange, (Fig. 3.6)\\ncan correctly predict if a certain binary option [ 7] shifts states from 0 to 1 or the other way\\naround, with 85% certainty.\\nFIGURE 3.5: The New York Stock Exchange.\\nA ﬁnancial engineer has created a portfolio consisting twice as many state-1 options then\\nstate-0 options. A stock option is selected at random and is determined by said algorithm to\\nbe in the state of 1. What is the probability that the prediction made by the AI is correct?\\nPRB-47 \\uf059 CH.PRB- 3.18.\\nIn an experiment conducted by a hedge fund to determine if monkeys (Fig. 3.6) can\\noutperform humans in selecting better stock market portfolios, 0.05 of humans and 1 out of\\n15 monkeys could correctly predict stock market trends correctly.\\n48Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nFIGURE 3.6: Hedge funds and monkeys.\\nFrom an equally probable pool of humans and monkeys an “expert” is chosen at ran-\\ndom. When tested, that expert was correct in predicting the stock market shift. What is the\\nprobability that the expert is a human?\\nPRB-48 \\uf059 CH.PRB- 3.19.\\nDuring the cold war, the U.S.A developed a speech to text (STT) algorithm that could\\ntheoretically detect the hidden dialects of Russian sleeper agents. These agents (Fig. 3.7),\\nwere trained to speak English in Russia and subsequently sent to the US to gather intelli-\\ngence. The FBI was able to apprehend ten such hidden Russian spies [ 9] and accused them\\nof being \"sleeper\" agents.\\nFIGURE 3.7: Dialect detection.\\n493.2. PROBLEMS\\nThe Algorithm relied on the acoustic properties of Russian pronunciation of the word\\n(v-o-k-s-a-l) which was borrowed from English V-a-u-x-h-a-l-l. It was alleged that it is im-\\npossible for Russians to completely hide their accent and hence when a Russian would\\nsay V-a-u-x-h-a-l-l, the algorithm would yield the text \"v-o-k-s-a-l\". T o test the algorithm\\nat a diplomatic gathering where 20% of participants are Sleeper agents and the rest Americ-\\nans, a data scientist randomly chooses a person and asks him to say V-a-u-x-h-a-l-l. A single\\nletter is then chosen randomly from the word that was generated by the algorithm, which\\nis observed to be an \"l\". What is the probability that the person is indeed a Russian sleeper\\nagent?\\nPRB-49 \\uf059 CH.PRB- 3.20.\\nDuring World War II, forces on both sides of the war relied on encrypted communica-\\ntions. The main encryption scheme used by the German military was an Enigma machine\\n[5], which was employed extensively by Nazi Germany. Statistically, the Enigma machine\\nsent the symbols X and Z Fig. ( 3.8) according to the following probabilities:\\nP (X) = 2\\n9 (3.3)\\nP (Z) = 7\\n9 (3.4)\\nFIGURE 3.8: The Morse telegraph code.\\nIn one incident, the German military sent encoded messages while the British army used\\ncountermeasures to deliberately tamper with the transmission. Assume that as a result of the\\nBritish countermeasures, an X is erroneously received as a Z (and mutatis mutandis) with a\\n50Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nprobability 1\\n7. If a recipient in the German military received a Z, what is the probability that\\na Z was actually transmitted by the sender?\\n3.2.4 Maximum Likelihood Estimation\\nPRB-50 \\uf059 CH.PRB- 3.21.\\nWhat is likelihood function of the independent identically distributed (i.i.d) random\\nvariables:\\nX1, · · · , Xn where Xi ∼ binomial(n, p ), ∀i ∈ [1, n],\\nand where p is the parameter of interest?\\nPRB-51 \\uf059 CH.PRB- 3.22.\\nHow can we derive the maximum likelihood estimator (MLE) of the i.i.d samples\\nX1, · · · , Xn introduced in Q. 3.21?\\nPRB-52 \\uf059 CH.PRB- 3.23.\\nWhat is the relationship between the likelihood function and the log-likelihood function?\\nPRB-53 \\uf059'),\n",
              " Document(metadata={}, page_content='],\\nand where p is the parameter of interest?\\nPRB-51 \\uf059 CH.PRB- 3.22.\\nHow can we derive the maximum likelihood estimator (MLE) of the i.i.d samples\\nX1, · · · , Xn introduced in Q. 3.21?\\nPRB-52 \\uf059 CH.PRB- 3.23.\\nWhat is the relationship between the likelihood function and the log-likelihood function?\\nPRB-53 \\uf059 CH.PRB- 3.24.\\nDescribe how to analytically ﬁnd the MLE of a likelihood function?\\nPRB-54 \\uf059 CH.PRB- 3.25.\\nWhat is the term used to describe the ﬁrst derivative of the log-likelihood function?\\nPRB-55 \\uf059 CH.PRB- 3.26.\\nDeﬁne the term Fisher information.\\n3.2.5 Fisher Information\\n513.2. PROBLEMS\\nPRB-56 \\uf059 CH.PRB- 3.27.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history [ 2] with a death tool far exceeding all\\npast outbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976\\nin Sudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 3.9: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the center for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ | y) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y, γ ∈ [0, 1], y = 1, 2, . . . , n (3.5)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ,\\nthe proportion of infected humans in the entire population. The expectation and variance of\\nthe binomial distribution are:\\nE(y|γ, n) = nγ, V (y|γ, n) = nγ(1 − γ) (3.6)\\nAnswer the following; for the likelihood function of the form Lx(γ):\\n1. Find the log-likelihood function lx(γ) = ln Lx(γ).\\n52Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. Find the gradient of lx(γ).\\n3. Find the Hessian matrix H(γ).\\n4. Find the Fisher information I(γ).\\n5. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\nPRB-57 \\uf059 CH.PRB- 3.28.\\nIn this question, you are going to derive the Fisher information function for several\\ndistributions. Given a probability density function (PDF) f (X|γ), you are provided with\\nthe following deﬁnitions:\\n1. The natural logarithm of the PDF ln f (X|γ) = Φ(X|γ).\\n2. The ﬁrst partial derivative Φ′(X|γ).\\n3. The second partial derivative Φ′′(X|γ).\\n4. The Fisher Information for a continuous random variable:\\nI(γ) = −Eγ\\n[\\nΦ′(X|γ)2\\n]\\n. (3.7)\\nFind the Fisher Information I(γ) for the following distributions:\\n1. The Bernoulli Distribution X ∼ B(1, γ).\\n2. The Poisson Distribution X ∼ P oiss(θ).\\nPRB-58 \\uf059 CH.PRB- 3.29.\\n1. True or False: The Fisher Information is used to compute the Cramer-Rao bound on\\nthe variance of any unbiased maximum likelihood estimator.\\n2. True or False: The Fisher Information matrix is also the Hessian of the symmetrized\\nKL divergence.\\n533.2. PROBLEMS\\n3.2.6 Posterior & prior predictive distributions\\nPRB-59 \\uf059 CH.PRB- 3.30.\\nIn chapter 3 we discussed the notion of a prior and a posterior distribution.\\n1. Deﬁne the term posterior distribution.\\n2'),\n",
              " Document(metadata={}, page_content=' on\\nthe variance of any unbiased maximum likelihood estimator.\\n2. True or False: The Fisher Information matrix is also the Hessian of the symmetrized\\nKL divergence.\\n533.2. PROBLEMS\\n3.2.6 Posterior & prior predictive distributions\\nPRB-59 \\uf059 CH.PRB- 3.30.\\nIn chapter 3 we discussed the notion of a prior and a posterior distribution.\\n1. Deﬁne the term posterior distribution.\\n2. Deﬁne the term prior predictive distribution.\\nPRB-60 \\uf059 CH.PRB- 3.31.\\nLet y be the number of successes in 5 independent trials, where the probability of success\\nis θ in each trial. Suppose your prior distribution for θ is as follows: P (θ = 1 /2) = 0 .25,\\nP (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y) after observing y.\\n2. Derive the prior predictive distribution for y.\\n3.2.7 Conjugate priors\\nPRB-61 \\uf059 CH.PRB- 3.32.\\nIn chapter 3 we discussed the notion of a prior and a posterior.\\n1. Deﬁne the term conjugate prior.\\n2. Deﬁne the term non-informative prior.\\nThe Beta-Binomial distribution\\nPRB-62 \\uf059 CH.PRB- 3.33.\\nThe Binomial distribution was discussed extensively in chapter 3. Here, we are going to\\nshow one of the most important results in Bayesian machine learning. Prove that the family\\nof beta distributions is conjugate to a binomial likelihood , so that if a prior is in that\\n54Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nfamily then so is the posterior. That is, show that:\\nx ∼ Ber(γ), γ ∼ B (α, β) ⇒ γ|x ∼ B (α′, β′) (3.8)\\nFor instance, for h heads and t tails, the posterior is:\\nB(h + α, t + β) (3.9)\\n3.2.8 Bayesian Deep Learning\\nPRB-63 \\uf059 CH.PRB- 3.34.\\nA recently published paper presents a new layer for a new Bayesian neural network\\n(BNN). The layer behaves as follows. During the feed-forward operation, each of the hidden\\nneurons Hn , n ∈ 1, 2 in the neural network (Fig. 3.10) may, or may not ﬁre independently\\nof each other according to a known prior distribution.\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 3.10: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ binomial(n, γ ) random variable\\nand ﬁres with a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U nif orm(0, γ) random variable\\nand ﬁres with a probability of γ.\\nPRB-64 \\uf059 CH.PRB- 3.35.\\nY our colleague, a veteran of the Deep Learning industry, comes up with an idea for for\\n553.2. PROBLEMS\\na BNN layer entitled OnOffLayer. He suggests that each neuron will stay on (the other\\nstate is off) following the distribution f (x) = e−x for x > 0 and f (x) = 0 otherwise\\n(Fig. 3.11). X indicates the time in seconds the neuron stays on . In a BNN, 200 such\\nneurons are activated independently in said OnOffLayer. The OnOffLayer is set to off (e.g.\\nnot active) only if at least 150 of the neurons are shut down . Find the probability that\\nthe OnOffLayer will be active for at least 20 seconds without being shut down.\\non offtime = f (x) = e−x\\nFIGURE 3.11: OnOffLayer in a BNN model.\\nPRB-65 \\uf059 CH.PRB- 3.36.\\nA Dropout layer [12] (Fig. 3.12) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ'),\n",
              " Document(metadata={}, page_content=' for at least 20 seconds without being shut down.\\non offtime = f (x) = e−x\\nFIGURE 3.11: OnOffLayer in a BNN model.\\nPRB-65 \\uf059 CH.PRB- 3.36.\\nA Dropout layer [12] (Fig. 3.12) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 3.12: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [10], a Dropout layer is declared as follows ( 3.1):\\n56Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 3.1: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 3.1) indicates that the probability of zeroing an\\nelement is 0.2.\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 3.13: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 3.12). Here, for illustration purposes, all two\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\nY ou are interested in the proportionθ of dropped-out neurons. Assume that the chance of\\ndrop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the posterior\\nof θ.\\nPRB-66 \\uf059 CH.PRB- 3.37.\\nA new data scientist in your team, who was formerly a Quantum Physicist, suggests\\nthe following procedure for a Dropout layer entitled QuantumDrop which is based on\\nQuantum principles and the Maxwell Boltzmann distribution. In the Maxwell-Boltzmann\\n573.2. PROBLEMS\\ndistribution, the likelihood of ﬁnding a particle with a particular velocity v is provided by:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.10)\\n0 1 000 2 000 3 000 4 000 5 000\\n0\\n2\\n4\\n·10−4\\nv in m·s−1\\nP (v)\\nHelium\\nFIGURE 3.14: The Maxwell-Boltzmann distribution.\\nIn the suggested QuantumDrop layer ( 3.15), each of the neurons behaves like a molecule\\nand is distributed according to the Maxwell-Boltzmann distribution and ﬁres only when\\nthe most probable speed is reached . This speed is the velocity associated with the highest\\npoint in the Maxwell distribution ( 3.14). Using calculus, brain power and some mathem-\\natical manipulation, ﬁnd the most likely value (speed) at which the neuron will ﬁre .\\noff firedneuron − f ires\\nFIGURE 3.15: A QuantumDrop layer.\\n58Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3.3 Solutions\\n3.3.1 Expectation and Variance\\nSOL-30 \\uf14b CH.SOL- 3.1.\\nThe notion of a Bernoulli trial refers to an experiment with two dichotomous binary out-\\ncomes; success (x = 1), and failure (x = 0). \\x04\\nSOL-31 \\uf14b CH.SOL- 3.2.\\nA binomial random variable X = k represents k successes in n mutually independent\\nBernoulli trials. \\x04\\nSOL-32 \\uf14b CH.SOL- 3.3.\\nThe shorthand X ∼ Binomial(n, p ) indicates that the random variable X has the bi-\\nnomial distribution (Fig. 3.16). The positive integer parameter n indicates the number of\\nBernoulli trials and the real parameter p, 0 < p < 1 holds the probability of success in each of\\nthese trials.\\n0 10 20 30 40 50\\n0,0\\n0,2\\n0,4\\np(x = k) =\\n( n\\n'),\n",
              " Document(metadata={}, page_content='� Binomial(n, p ) indicates that the random variable X has the bi-\\nnomial distribution (Fig. 3.16). The positive integer parameter n indicates the number of\\nBernoulli trials and the real parameter p, 0 < p < 1 holds the probability of success in each of\\nthese trials.\\n0 10 20 30 40 50\\n0,0\\n0,2\\n0,4\\np(x = k) =\\n( n\\nk\\n)\\n· pk · (1 − p)n−k\\nx\\np(x)\\nn = 50, p = 0.3\\nn = 50, p = 0.7\\nn = 50, p = 0.9\\nFIGURE 3.16: The binomial distribution.\\n\\x04\\nSOL-33 \\uf14b CH.SOL- 3.4.\\n593.3. SOLUTIONS\\nThe random variable X ∼ Binomial(n, p ) has the following PMF:\\nP (X = k) =\\n(\\nn\\nk\\n)\\npk (1 − p)n−k ; k = 0, 1, 2, . . . , n. (3.11)\\n\\x04\\nSOL-34 \\uf14b CH.SOL- 3.5.\\nThe answers below regard a discrete random variable. The curious reader is encouraged to\\nexpend them to the continuous case.\\n1. For a random variable X with probability mass function P (X = k) and a set of out-\\ncomes K, the expected value of X is deﬁned as:\\nE[X] :=\\n∑\\nk∈K\\nkP (X = k). (3.12)\\nNote: The expectation of X may also be denoted by µX.\\n2. The variance of X is deﬁned as:\\nVar[X] := E\\n[\\n(X − E[X])2\\n]\\n. (3.13)\\nNote: The variance of X may also be denoted by σ2\\nX, while σX itself denotes the stand-\\nard deviation of X.\\n3. The population mean and variance of a binomial random variable with parameters n\\nand p are:\\nE[X] = np V [X] = np(1 − p) (3.14)\\nNote: Why is this solution intuitive? What information theory-related phenomenon\\noccurs when p = 1/2?\\n\\x04\\nSOL-35 \\uf14b CH.SOL- 3.6.\\n60Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n1. This scenario describes an experiment that is repeated 200 times independently with a\\nsuccess probability of 0.1. Thus, if the random variable X denotes the number of times\\nsuccess was obtained, then it is best characterized by the binomial distribution with\\nparameters n = 200 and p = 0.1. Formally:\\nX ∼ Binomial(200, 0.1). (3.15)\\nThe expectation of X is given by:\\nx = E(x) = 200 × 0.1 = 20 , (3.16)\\nand its respective variance is:\\nV ar = 200 × 0.10(1 − 0.10) = 18 .0. (3.17)\\n2. Here we propose two distinguished methods to answer the question.\\nPrimarily, the straightforward solution is to employ the deﬁnition of the binomial dis-\\ntribution and substitute the value of X in it. Namely:\\nP (X = 60; n = 200, p = 0.1)\\n=\\n(\\n200\\n60\\n)\\n0.160 (1 − 0.1)200−60\\n=≈ 2.7 × e−15.\\n(3.18)\\nThis leads to an extremely high probability that the radiologist is mistaken.\\nThe following approach is longer and more advanced, but grants the reader with insights\\nand intuition regarding the results. T o derive how wrong the radiologist is, we can\\nemploy an approximation by considering the standard normal distribution. In statistics,\\nthe Z-score allows us to understand how far from the mean is a data point in units of\\nstandard deviation, thus revealing how likely it is to occur (Fig. 3.17).\\n613.3. SOLUTIONS\\nZ-score\\nz =\\nData point\\nx − µ\\nExpectation\\nσ\\nStandard dev .\\n. (3.19)\\nFIGURE 3.17: Z-score\\nTherefore, the probability of correctly hitting 60 cells is:\\nP (X ≥ 60) = P (Z ≥ 60 − 20√\\n18.0 ) = P (Z ≥ 9.428) ≈ 0. (3.20)\\nAgain, the outcome'),\n",
              " Document(metadata={}, page_content=' extremely high probability that the radiologist is mistaken.\\nThe following approach is longer and more advanced, but grants the reader with insights\\nand intuition regarding the results. T o derive how wrong the radiologist is, we can\\nemploy an approximation by considering the standard normal distribution. In statistics,\\nthe Z-score allows us to understand how far from the mean is a data point in units of\\nstandard deviation, thus revealing how likely it is to occur (Fig. 3.17).\\n613.3. SOLUTIONS\\nZ-score\\nz =\\nData point\\nx − µ\\nExpectation\\nσ\\nStandard dev .\\n. (3.19)\\nFIGURE 3.17: Z-score\\nTherefore, the probability of correctly hitting 60 cells is:\\nP (X ≥ 60) = P (Z ≥ 60 − 20√\\n18.0 ) = P (Z ≥ 9.428) ≈ 0. (3.20)\\nAgain, the outcome shows the likelihood that the radiologist was wrong approaches 1.\\nNote: Why is the relation depicted in Fig. 3.17 deduces that Z is a standard Gaussian?\\nUnder what terms is this conclusion valid? Why does eq. (3.20) employs the cumulative\\ndistribution function and not the probability mass function?\\n\\x04\\n3.3.2 Conditional Probability\\nSOL-36 \\uf14b CH.SOL- 3.7.\\n1. For two events A and B with P (B) > 0, the conditional probability of A given that\\nB has occurred is deﬁned as:\\nP (A|B) = P (A ∩ B)\\nP (B) . (3.21)\\nIt is easy to note that if P (B) = 0 , this relation is not deﬁned mathematically. In this\\ncase, P (A|B) = P (A ∩ B) = P (A).\\n2. The annotated probabilities are displayed in Fig. 3.18:\\n62Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nA given B\\nP (A|B) =\\nA and B\\nP (A ∩ B)\\nP (B)\\nB only\\n. (3.22)\\nFIGURE 3.18: Conditional probability\\n3. An example of a diagram depicting the intersected events A and B is displayed in Fig.\\n3.19:\\nA B\\nH\\nFIGURE 3.19: V enn diagram of the intersected events A and B in probability space H\\n\\x04\\nSOL-37 \\uf14b CH.SOL- 3.8.\\nThe Bayes formulae reads:\\nP (A|B) = P (B|A)P (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac), (3.23)\\nwhere P (Ac) is the complementary probability of P (A). The interpretation of the elements in\\n633.3. SOLUTIONS\\nBayes formulae is as follows:\\nposterior probability = likelihood of the data × prior probability\\nnormalization constant . (3.24)\\nNote: What is the important role of the normalization constant? Analyze the cases where\\nP (B) → 0 and P (B) → 1. The annotated probabilities are displayed in (Fig. 3.20):\\nPosterior\\nP (A|B) =\\nLikelihood\\nP (B|A)\\nPrior\\nP (A)\\nP (B|A)P (A) + P (B|Ac)P (Ac)\\nB only\\n. (3.25)\\nFIGURE 3.20: Annotated components of the Bayes formula (eq. 3.23)\\n\\x04\\nSOL-38 \\uf14b CH.SOL- 3.9.\\nGiven X as a discrete randomly distributed variable and given γ as the parameter of\\ninterest, the likelihood and the log-likelihood of X given γ follows respectively:\\nLγ(X = x) = p(X = x|γ) (3.26)\\nℓγ(X = x) = ln ( p(X = x|γ)) (3.27)\\nThe term likelihood can be intuitively understood from this deﬁnition; it deduces how likely is\\nto obtain a value x when a prior information is given regarding its distribution, namely the\\nparameter γ. For example, let us consider a biased coin toss with ph = γ. Then:\\nLγ(X = “h′′) = p(X = “h′′|γ) = γ. (3.28)\\nℓγ(X = “h′′) = ln ( p(X = “h′′|γ)) = ln ( γ) . (3.29)\\n64Chapter 3'),\n",
              " Document(metadata={}, page_content=' x when a prior information is given regarding its distribution, namely the\\nparameter γ. For example, let us consider a biased coin toss with ph = γ. Then:\\nLγ(X = “h′′) = p(X = “h′′|γ) = γ. (3.28)\\nℓγ(X = “h′′) = ln ( p(X = “h′′|γ)) = ln ( γ) . (3.29)\\n64Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nNote: The likelihood function may also follow continuous distributions such as the normal\\ndistribution. In the latter, it is recommended and often obligatory to employ the log-likelihood.\\nWhy? We encourage the reader to modify the above to the continuous case of normal distribu-\\ntion and derive the answer. \\x04\\nSOL-39 \\uf14b CH.SOL- 3.10.\\nThe continuous prior distribution, f (Γ = γ) represents what is known about the probab-\\nility of the value γ before the experiment has commenced. It is termed as being subjective,\\nand therefore may vary considerably between researchers. By proceeding the previous example,\\nf (Γ = 0.8) holds the probability of randomly ﬂipping a coin that yields “heads” with chance\\nof 80% of times. \\x04\\nSOL-40 \\uf14b CH.SOL- 3.11.\\nThe essence of Bayesian analysis is to draw inference of unknown quantities or quantiles\\nfrom the posterior distribution p(Γ = γ|X = x), which is traditionally derived from prior\\nbeliefs and data information. Bayesian statistical conclusions about chances to obtain the para-\\nmeter Γ = γ or unobserved values of random variable X = x, are made in terms of prob-\\nability statements. These probability statements are conditional on the observed values of X,\\nwhich is denoted as p(Γ = γ|X = x), called posterior distributions of parameter γ. Bayesian\\nanalysis is a practical method for making inferences from data and prior beliefs using probab-\\nility models for quantities we observe and for quantities which we wish to learn. Bayes rule\\nprovides a relationship of this form:\\nposterior ∝ p(x|γ)p(γ) ∝ data given prior × chance of prior . (3.30)\\n\\x04\\nSOL-41 \\uf14b CH.SOL- 3.12.\\nThe posterior density summarizes what is known about the parameter of interest γ after\\nthe data is observed. In Bayesian statistics, the posterior density p(Γ = γ|X = x) becomes\\nthe prior for this next experiment. This is part of the well-known Bayesian updating mech-\\nanism wherein we update our knowledge to reﬂect the actual distribution of data that we\\nobserved. T o summarize, from the perspective of Bayes Theorem, we update the prior distri-\\nbution to a posterior distribution after seeing the data. \\x04\\n653.3. SOLUTIONS\\nSOL-42 \\uf14b CH.SOL- 3.13.\\nTwo events A and B are statistically independent if (and only if):\\nP (A ∩ B) = P (A)P (B). (3.31)\\nNote: Use conditional probability and rationalize this outcome. How does this property be-\\ncome extremely useful in practical researches that consider likelihood of normally distributed\\nfeatures? \\x04\\n3.3.3 Bayes Rule\\nSOL-43 \\uf14b CH.SOL- 3.14.\\nLet γ stand for the number of half-integer spin states, and given the prior knowledge that\\nboth states are equally probable:\\nP (γ = 2|γ ≥ 1) (3.32)\\n= P (γ = 2, γ ≥ 1)\\nP (γ ≥ 1) (3.33)\\n= P (γ = 2)\\n1 − P (γ = 0) = 1/4\\n1 − 1/4 = 1\\n3 (3.34)\\nNote: Under what statistical property do the above relations hold? \\x04\\nSOL-44 \\uf14b CH.SOL- 3.15.\\nLet event A indicate present hereditary-disease and let event B to hold a positive test result.\\nThe calculated probabilities are presented in T able 3.1. We were asked to ﬁnd the probability\\nof a test indicating that hereditary-disease is present, namely P (B). According to the law of\\ntotal probability:\\nP (B) = P (B|A) ∗ P (A) + P (B|A) ∗ P (A)\\n= [0.95 ∗ 0.01] + [0.05 ∗ 0.99'),\n",
              " Document(metadata={}, page_content=' probabilities are presented in T able 3.1. We were asked to ﬁnd the probability\\nof a test indicating that hereditary-disease is present, namely P (B). According to the law of\\ntotal probability:\\nP (B) = P (B|A) ∗ P (A) + P (B|A) ∗ P (A)\\n= [0.95 ∗ 0.01] + [0.05 ∗ 0.99] = 0 .059 (3.35)\\nNote: In terms of performance evaluation, P (B|A) is often referred to as the probability of\\n66Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nPROBABILITY EXPLANATION\\nP(A)= 0.01 The probability of hereditary-disease.\\nP(A)=1-0.01=.99 The probability of no hereditary-disease.\\nP(B|A)=0.95 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is NOT present [Ã].\\nP(B|B)=1-0.95=.05 The probability that the test will yield a positive result [B]\\nif hereditary-disease is NOT present [Ã] (probability of false\\nalarm).\\nP(B|A)=0.95 The probability that the test will yield a positive result [B] if\\nhereditary-disease is present [A] (probability of detection).\\nP(B|A)=1-0.95=.05 The probability that the test will yield a negative result [ ˜B] if\\nhereditary-disease is present [A].\\nTABLE 3.1: Probability values of hereditary-disease detection.\\ndetection and P (B|A) is considered the probability of false alarm. Notice that these measures\\ndo not, neither logically nor mathematically, combine to probability of 1. \\x04\\nSOL-45 \\uf14b CH.SOL- 3.16.\\nWe ﬁrst enumerate the probabilities one by one:\\nP (Dercum|f emale) = 0 .05, (3.36)\\nP (Dercum|male) = 0 .0025, (3.37)\\nP (male) = P (f emale) = 0 .5. (3.38)\\nWe are asked to ﬁnd P (f emale|Dercum). Using Bayes Rule:\\nP (f emale|Dercum) = P (Dercum|f emale)P (f emale)\\nP (Dercum) . (3.39)\\n673.3. SOLUTIONS\\nHowever we are missing the term P (Dercum). T o ﬁnd it, we apply the Law of T otal Probab-\\nility:\\nP (Dercum) = P (Dercum|f emale)P (f emale)\\n+P (Dercum|male)P (male)\\n=\\n0.05 · 0.5 + 0.0025 · 0.5 = 0 .02625.\\nAnd ﬁnally, returning to eq. ( 3.39):\\nP (f emale|Dercum) = 0.05 · 0.5\\n0.02625 ≈ 0.9524 (3.40)\\nNote: How could this result be reached with one mathematical equation? \\x04\\nSOL-46 \\uf14b CH.SOL- 3.17.\\nIn order to solve this problem, we introduce the following events:\\n1. AI: the AI predicts that the state of the stock option is 1.\\n2. State1: the state of the stock option is 1.\\n3. State0: the state of the stock option is 0.\\nA direct application of Bayes formulae yields:\\nP (State1|AI) = (3.41)\\nP (AI|State1)P (State1)\\nP (AI|State1)P (State1)+P (AI|State0)P (State0) (3.42)\\n= 0.85·2/3\\n0.85·2/3+0.15·1/3 ≈ 0.9189.\\n\\x04\\nSOL-47 \\uf14b CH.SOL- 3.18. In order to solve this problem, we introduce the following events:\\n1. H: a human.\\n68Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. M : a monkey.\\n3. C: a correct prediction.\\nBy employing Bayes theorem and the Law of T otal probability:\\nP (H|C) = P (H ∩ C)\\nP ('),\n",
              " Document(metadata={}, page_content='\\x04\\nSOL-47 \\uf14b CH.SOL- 3.18. In order to solve this problem, we introduce the following events:\\n1. H: a human.\\n68Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n2. M : a monkey.\\n3. C: a correct prediction.\\nBy employing Bayes theorem and the Law of T otal probability:\\nP (H|C) = P (H ∩ C)\\nP (C)\\n= P (C|H)P (H)\\nP (C|H)P (H) + P (C|M )P (M )\\n=\\n1\\n20 · 1\\n2\\n1\\n20 · 1\\n2 + 1\\n15 · 1\\n2\\n≈ 0.42.\\n(3.43)\\nNote: If something seems off in this outcome, do not worry - it is a positive sign for\\nunderstanding of conditional probability. \\x04\\nSOL-48 \\uf14b CH.SOL- 3.19.\\nIn order to solve this problem, we introduce the following events:\\n1. RU S: a Russian sleeper agent is speaking.\\n2. AM : an American is speaking.\\n3. L: the TTS system generates an “l”.\\nWe are asked to ﬁnd the value of P (RU S|L). Using Bayes Theorem we can write:\\nP (RU S|L) = P (L|RU S)P (RU S)\\nP (L) . (3.44)\\nWe were told that the Russians consist 1/5 of the attendees at the gathering, therefore:\\nP (RU S) = 1\\n5. (3.45)\\n693.3. SOLUTIONS\\nAdditionally, because \"v-o-k-s-a-l\" has a single l out of a total of six letters:\\nP (L|RU S) = 1\\n6. (3.46)\\nAdditionally, because \"V-a-u-x-h-a-l-l\" has two l’s out of a total of eight letters:\\nP (L|AM ) = 2\\n8. (3.47)\\nAn application of the Law of T otal Probability yields:\\nP (L) = P (AM )P (L|AM ) + P (RU S)P (L|RU S) (3.48)\\n=\\n( 4\\n5\\n) ( 2\\n8\\n)\\n+\\n( 1\\n5\\n) ( 1\\n6\\n)\\n= 7\\n30.\\nUsing Bayes Theorem we can write:\\nP (RU S|L) =\\n1\\n5\\n(\\n1\\n6\\n)\\n7\\n30\\n= 1\\n7. (3.49)\\nNote: What is the letter by which the algorithm is most likely to discover a Russian sleeper\\nagent? \\x04\\nSOL-49 \\uf14b CH.SOL- 3.20.\\nWe are given that:\\nP (X is erroneously received as a Z ) = 1 /7. Using Bayes Theorem we can write:\\nP (Z trans |Z received ) =\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received ) . (3.50)\\n70Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nAn application of the Law of T otal Probability yields:\\nP (Z received ) =\\nP (Z received |Z trans )P (Z trans )\\n+P (Z received |X trans )P (X trans )\\n= 6\\n7 · 7\\n9 + 1\\n7 · 2\\n9\\n= 44\\n63.\\nSo, using Bayes Rule, we have that\\nP (Z trans |Z received )\\n= P (Z received |Z trans )P (Z trans )\\nP (Z received )\\n=\\n6\\n7\\n7\\n9\\n44\\n63\\n= 44\\n63 = 0.95.\\n(3.51)\\n\\x04\\n3.3.4 Maximum Likelihood Estimation\\nSOL-50 \\uf14b CH.SOL- 3.21.\\nFor the set of i.i.d samples X1, · · · , Xn, the likelihood function is the product of the\\nprobability functions:\\nL(p) = p(X1 = x1; p)p(X2 = x2; p) · · ·p(Xn = xn; p)\\n=\\nn∏\\ni=1\\n(\\nn\\nxi\\n)\\npxi(1 − p)n−xi. (3.52)\\nNote: What is the distribution of X n when X is a Bernoulli distributed random variable?\\n\\x04\\n713.3. SOLUTIONS\\nSOL-51 \\uf14b CH.SOL- 3.22.\\n'),\n",
              " Document(metadata={}, page_content=' = x1; p)p(X2 = x2; p) · · ·p(Xn = xn; p)\\n=\\nn∏\\ni=1\\n(\\nn\\nxi\\n)\\npxi(1 − p)n−xi. (3.52)\\nNote: What is the distribution of X n when X is a Bernoulli distributed random variable?\\n\\x04\\n713.3. SOLUTIONS\\nSOL-51 \\uf14b CH.SOL- 3.22.\\nThe maximum likelihood estimator (MLE) of p is the value of all possible p values that\\nmaximizes L(p). Namely, the p value that renders the set of measurements X1, · · · , Xn as the\\nmost likely. Formally:\\nˆp = arg max0≤p≤1L(p) (3.53)\\nNote: The curious student is highly encouraged to derive ˆp from L(p). Notice that L(p) can\\nbe extremely simpliﬁed. \\x04\\nSOL-52 \\uf14b CH.SOL- 3.23.\\nThe log-likelihood is the logarithm of the likelihood function. Intuitively, maximizing\\nthe likelihood function L(γ) is equivalent to maximizing ln L(γ) in terms of ﬁnding the MLE\\nˆγ, since ln is a monotonically increasing function. Often, we maximize ln(f (γ)) instead of\\nthe f (γ). A common example is when L(γ) is comprised of normally distribution random\\nvariables.\\nFormally, if X1, · · · , Xn are i.i.d, each with probability mass function (PMF) of fXi(xi | γ),\\nthen\\nf (γ) =\\nn∏\\ni=1\\nfXi(xi | γ), (3.54)\\nln(f (γ)) =\\nn∑\\ni=1\\nln fXi(xi | γ). (3.55)\\n\\x04\\nSOL-53 \\uf14b CH.SOL- 3.24.\\nThe general procedure for ﬁnding the MLE, given that the likelihood function is differen-\\ntiable, is as follows:\\n1. Start by differentiating the log-likelihood function ln (L(γ)) with respect to a parameter\\nof interest γ.\\n2. Equate the result to zero.\\n72Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n3. Solve the equation to ﬁnd ˆγ that holds:\\n∂ ln L(ˆγ | x1, · · ·xn)\\n∂γ = 0 (3.56)\\n4. Compute the second derivative to verify that you indeed have a maximum rather than\\na minimum.\\n\\x04\\nSOL-54 \\uf14b CH.SOL- 3.25.\\nThe ﬁrst derivative of the log-likelihood function is commonly known as the Fisher score\\nfunction, and is deﬁned as:\\nu(γ) = ∂ ln L(γ | x1, · · ·xn)\\n∂γ (3.57)\\n\\x04\\nSOL-55 \\uf14b CH.SOL- 3.26.\\nFisher information, is the term used to describe the expected value of the second derivat-\\nives (the curvature) of the log-likelihood function, and is deﬁned by:\\nI(γ) = −E\\n[\\n∂2 ln L(γ | x1, · · ·xn)\\n∂γ2\\n]\\n(3.58)\\n\\x04\\n3.3.5 Fisher Information\\nSOL-56 \\uf14b CH.SOL- 3.27.\\n1. Given L(γ):\\nln L(γ) = ln\\n(\\nny\\n)\\n+ y ∗ ln(γ) + (n − y) ln(1 − γ). (3.59)\\n733.3. SOLUTIONS\\n2. T o ﬁnd the gradient, we differentiate once:\\ng(γ) = yγ −1 − (n − y)(1 − γ)−1 =\\n(γ(1 − γ))−1y − n(1 − γ)−1. (3.60)\\n3. The Hessian is generated by differentiating g(γ):\\nH(γ) = −yγ −2 − (n − y)(1 − γ)−2 (3.61)\\n4. The Fisher information is calculated as follows:\\nI(γ) = −E(H(γ)) = n\\nγ(1 − γ), (3.62)\\nsince:\\nE(y|γ, n) = n ∗ γ (3.63)\\n5. Equating the gradient to zero and solving for our parameter γ, we get:\\nˆγ = y\\nn (3'),\n",
              " Document(metadata={}, page_content=' −2 − (n − y)(1 − γ)−2 (3.61)\\n4. The Fisher information is calculated as follows:\\nI(γ) = −E(H(γ)) = n\\nγ(1 − γ), (3.62)\\nsince:\\nE(y|γ, n) = n ∗ γ (3.63)\\n5. Equating the gradient to zero and solving for our parameter γ, we get:\\nˆγ = y\\nn (3.64)\\nIn our case this equates to: 300/10000 = 0 .03. Regarding the error, there is a close\\nrelationship between the variance of γ and the Fisher information, as the former is the\\ninverse of the latter:\\nvar(γ) = [ I(γ)]−1\\nV (γ) = γ(1 − γ)\\nn\\n(3.65)\\nPlugging the numbers from our question:\\nˆV (ˆγ) = 0.03(1 − 0.03)\\n10000 = 2.9 × 10−7. (3.66)\\n74Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nStatistically, the standard error that we are asked to ﬁnd is the square root of eq. 3.66\\nwhich equals 5.3 × 10−4. Note: What desired property is revealed in this experiment?\\nAt was cost could we ensure a low standard error?\\n\\x04\\nSOL-57 \\uf14b CH.SOL- 3.28.\\nThe Fisher Information for the distributions is as follows:\\n1. Bernoulli:\\nΦ(x|γ) = x log γ + (1 − x) log(1 − γ), (3.67)\\nΦ′(x|γ) = x\\nγ − 1 − x\\n1 − γ , (3.68)\\nΦ′′(x|γ) = − x\\nγ2 − 1 − x\\n(1 − γ)2 , (3.69)\\nI(γ) = −Eγ\\n[\\nX(1 − γ)2 + (1 − X)γ2\\nγ2(1 − γ)2\\n]\\n= 1\\nγ(1 − γ). (3.70)\\n2. Poisson:\\nλ(x|θ) = x log θ − log x! − θ,\\nλ′(x|θ) = x − θ\\nθ ,\\nλ′′(x|θ) = − x\\nθ2 ,\\nI(θ) = −Eθ\\n[\\n(X − θ)2\\nθ2\\n]\\n= 1\\nθ .\\n(3.71)\\n\\x04\\nSOL-58 \\uf14b CH.SOL- 3.29.\\n753.3. SOLUTIONS\\n1. T rue.\\n2. T rue.\\n\\x04\\n3.3.6 Posterior & prior predictive distributions\\nSOL-59 \\uf14b CH.SOL- 3.30.\\n1. Given a sample of the form x = ( x1, · · · , xn) drawn from a density p(θ; x) and θ is\\nrandomly generated according to a prior density of p(θ). Then the posterior density is\\ndeﬁned by:\\np(θ|x) = p(θ; x)p(θ)\\np(x) . (3.72)\\n2. The prior predictive density is:\\np(x) =\\n∫\\nθ∈Θ p(θ; x)p(θ)dθ (3.73)\\n\\x04\\nSOL-60 \\uf14b CH.SOL- 3.31.\\n1. The posterior p(θ|y) ∝ p(y|θ)p(θ) is:\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f4\\uf8f3\\n( 5\\ny\\n)\\n(1/2)y(1/2)5−y0.25, θ = 1/2( 5\\ny\\n)\\n(1/6)y(5/6)5−y0.5, θ = 1/6( 5\\ny\\n)\\n(1/4)y(3/4)5−y0.25, θ = 1/4\\n0, otherwise\\n2. The prior predictive distribution p(y):\\n(\\n5\\ny\\n)\\n((1/2)y(1/2)5−y0.25 (3.74)\\n76Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n+\\n(1/6)y(5/6)5'),\n",
              " Document(metadata={}, page_content=' 5\\ny\\n)\\n(1/4)y(3/4)5−y0.25, θ = 1/4\\n0, otherwise\\n2. The prior predictive distribution p(y):\\n(\\n5\\ny\\n)\\n((1/2)y(1/2)5−y0.25 (3.74)\\n76Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n+\\n(1/6)y(5/6)5−y0.5 + (1/4)y(3/4)5−y0.25). (3.75)\\n\\x04\\n3.3.7 Conjugate priors\\nSOL-61 \\uf14b CH.SOL- 3.32.\\n1. A class F of prior distributions is said to form a conjugate family if the posterior density\\nis in F for all each sample, whenever the prior density is in F.\\n2. Often we would like a prior that favours no particular values of the parameter over\\nothers. Bayesian analysis requires prior information, however sometimes there is no\\nparticularly useful information before data is collected. In these situations, priors with\\n“no information” are expected. Such priors are called non-informative priors.\\n\\x04\\nSOL-62 \\uf14b CH.SOL- 3.33.\\nIf x ∼ B(n, γ) so\\np(x|γ) ∝ γx(1 − γ)n−x\\nand the prior for γ is B(α, β) so\\np(γ) ∝ γα−1(1 − γ)β−1\\nthen the posterior is\\nγ|x ∼ B (α + x, β + n − x)\\nIt is immediately clear the family of beta distributions is conjugate to a\\nbinomial likelihood.\\n\\x04\\n3.3.8 Bayesian Deep Learning\\n773.3. SOLUTIONS\\nSOL-63 \\uf14b CH.SOL- 3.34.\\n1. The hidden neuron is distributed according to:\\nX ∼ binomial(n, γ ) random variable and ﬁres with a probability of γ. There are 100\\nneurons and only 20 are ﬁred.\\nP (x = 20|θ) =\\n\\uf8eb\\n\\uf8ed 100\\n20\\n\\uf8f6\\n\\uf8f8 θ20(1 − θ)80 (3.76)\\n2. The hidden neuron is distributed according to:\\nX unif orm(0, γ) random variable and ﬁres with a probability of γ.\\nThe uniform distribution is, of course, a very simple case:\\nf (x; a, b) = 1\\nb − a for a ≤ x ≤ b (3.77)\\nTherefore:\\nf (x|γ) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0 if γ < x or x < 0\\n1/γ if 0 ≤ x ≤ θ\\n(3.78)\\n\\x04\\nSOL-64 \\uf14b CH.SOL- 3.35.\\nThe provided distribution is from the exponential family. Therefore, a single neuron be-\\ncomes inactive with a probability of:\\np = P (X < 20) =\\n∫ 20\\n0\\ne−x dx = 1 − e−20. (3.79)\\nThe OnOffLayer is off only if at least 150 out of 200 neurons are off. Therefore, this may be\\nrepresented as a Binomial distribution and the probability for the layer to be off is:\\nV =\\n∑\\nn≥150\\n\\uf8eb\\n\\uf8ed 200\\nn\\n\\uf8f6\\n\\uf8f8 ˜pn(1 − ˜p)200−n (3.80)\\n78Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\nHence, the probability of the layer being active for at least 20 seconds is 1 minus this value:\\n[1 − V ]. (3.81)\\n\\x04\\nSOL-65 \\uf14b CH.SOL- 3.36.\\nThe observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (3.82)\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (3.83)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (3.84)\\nHence, the prior density is:\\np(θ) = 1\\nB'),\n",
              " Document(metadata={}, page_content=' s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (3.83)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (3.84)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (3.85)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(3.86)\\n\\x04\\nSOL-66 \\uf14b CH.SOL- 3.37.\\nNeurons are dropped whenever their value (or the equivalent quantum term- speed) reach\\n79REFERENCES\\nthe most likely value:\\nn(v)dv = 4πN\\nV\\n( m\\n2πkT\\n) 3/2\\nv2e− mv2\\n2kT dv (3.87)\\nFrom calculus, we know that in order to maximize a function, we have to equate its ﬁrst\\nderivative to zero:\\nd\\ndv n(v) = 0 (3.88)\\nThe constants can be taken out as follows:\\nd\\ndv v2e− mv2\\n2kT = 0 (3.89)\\nApplying the chain rule from calculus:\\n2ve− mv2\\n2kT + v2\\n(\\n− m\\n2kT 2v\\n)\\ne− mv2\\n2kT = 0 (3.90)\\nWe notice that several terms cancel out:\\nv2 m\\n2kT = 1 (3.91)\\nNow the quadratic equation can be solved yielding:\\nvmost_probable =\\n√\\n2kT\\nm\\n(3.92)\\nTherefore, this is the most probable value at which the dropout layer will ﬁre.\\n\\x04\\nReferences\\n[1] M. Barati and P . ‘Comparison of complications of chorionic villus sampling and\\namniocentesis’. In: 5.4 (2012), pp. 241–244 (cit. on p. 46).\\n[2] J. D. e. a. Bell BP Damon IK. ‘Overview, Control Strategies, and Lessons Learned\\nin the CDC Response to the 20142016 Ebola Epidemic.’ In: Morbidity and Mortal-\\nity Weekly Report 65.3 (2016), pp. 4–11 (cit. on p. 52).\\n80Chapter 3 PROBABILISTIC PROGRAMMING & BAYESIAN DL\\n[3] J. C. Cook and G. P . Gross. Adiposis Dolorosa (Dercum, Anders Disease) . StatPearls\\n[Internet], 2019 (cit. on p. 47).\\n[4] G. Ecker. Particles, Field, From Quantum Mechanics to the Standard Model of Particle\\nPhysics. Springer., 2019 (cit. on p. 45).\\n[5] K. Gaj and A. Orlowski. ‘Facts and Myths of Enigma: Breaking Stereotypes’. In:\\nInternational Conference on the Theory and Applications of Cryptographic T echniques .\\n2003 (cit. on p. 50).\\n[6] B. Gottschalk. ‘Techniques of Proton Radiotherapy: Transport Theory’. In: arXiv\\n(2012) (cit. on p. 43).\\n[7] T. S. O. of Investor Education and Advocacy. Binary options and Fraud (cit. on\\np. 48).\\n[8] E. T. Jaynes. Probability Theory as Logic . Ed. by P . F. Fougère. Maximum-Entropy\\nand Bayesian Methods. Kluwer, Dordrecht, 1990 (cit. on p. 42).\\n[9] D. o. J. National Security Division. Conspiracy to Act as Unregistered Agents of a\\nForeign Government. 2010 (cit. on p. 49).\\n[10] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on p. 56).\\n[11] J. Salvatier, T. V . Wiecki'),\n",
              " Document(metadata={}, page_content=\"42).\\n[9] D. o. J. National Security Division. Conspiracy to Act as Unregistered Agents of a\\nForeign Government. 2010 (cit. on p. 49).\\n[10] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on p. 56).\\n[11] J. Salvatier, T. V . Wiecki and C. Fonnesbeck. ‘Probabilistic programming in Py-\\nthon using PyMC3’. In: PeerJ Computer Science 2 (Jan. 2016), e55 (cit. on p. 42).\\n[12] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 56).\\n[13] E. B. Starikov. ‘Bayesian Statistical Mechanics: Entropy Enthalpy Compensation\\nand Universal Equation of State at the Tip of Pen’. In: Frontiers in Physics 6 (2018),\\np. 2 (cit. on p. 42).\\n81REFERENCES\\n82HIGH SCHOOL\\nPART IIICHAPTER\\n4\\nINFORMATION THEORY\\nA basic idea in information theory is that information can be treated very much\\nlike a physical quantity, such as mass or energy.\\n— Claude Shannon, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 87\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89\\nKullback-Leibler Divergence (KLD) . . . . . . . . . . . . . . . . . . . . . 93\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 94\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in Information Theory . . . . . . . . . . . . . . . . . . . . . 101\\nShannon's Entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\\nKullback-Leibler Divergence . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nClassiﬁcation and Information Gain . . . . . . . . . . . . . . . . . . . . 110\\nMutual Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116\\nMechanical Statistics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118\\nJensen's inequality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1184.1. INTRODUCTION\\n4.1 Introduction\\nI\\nNDUCTIVE inference, is the problem of reasoning under conditions of in-\\ncomplete information, or uncertainty. According to Shannon’s theory [ 2],\\ninformation and uncertainty are two sides of the same coin: the more uncer-\\ntainty there is, the more information we\"),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1184.1. INTRODUCTION\\n4.1 Introduction\\nI\\nNDUCTIVE inference, is the problem of reasoning under conditions of in-\\ncomplete information, or uncertainty. According to Shannon’s theory [ 2],\\ninformation and uncertainty are two sides of the same coin: the more uncer-\\ntainty there is, the more information we gain by removing the uncertainty .\\nEntropy plays central roles in many scientiﬁc realms ranging from physics and statist-\\nics to data science and economics. A basic problem in information theory is encoding\\nlarge quantities of information [ 2].\\nShannon’s discovery of the fundamental laws of data compression and transmis-\\nsion marked the birth of information theory . In his fundamental paper of 1948, “ A\\nMathematical Theory of Communication ” [4], Shannon proposed a measure of the uncer-\\ntainty associated with a random memory-less source, called Entropy.\\nH(X) H(Y )\\nH(Z)\\nH(Y |X)\\nH(Z|XY )\\nI(X; Z|Y )\\nFIGURE 4.1: Mutual information\\nEntropy ﬁrst emerged in thermodynamics in the 18 th century by\\nCarnot, [1] in his pioneering work on steam entitled “ Reﬂection on the Motive Power of\\nFire” (Fig. 4.2). Subsequently it appeared in statistical mechanics where it was viewed\\nas a measure of disorder. However, it was Boltzmann ( 4.30) who found the connection\\nbetween entropy and probability , and the notion of information as used by Shannon is\\na generalization of the notion of entropy . Shannon’s entropy shares some instinct with\\nBoltzmann’s entropy , and likewise the mathematics developed in information theory\\nis highly relevant in statistical mechanics.\\n86Chapter 4 INFORMATION THEORY\\nFIGURE 4.2: Reﬂection on the motive power of ﬁre.\\nThe majority of candidates I interview fail to come up with an answer to the fol-\\nlowing question: what is the entropy of tossing a non-biased coin? Surprisingly , even after\\nI explicitly provide them with Shannon’s formulae for calculating entropy ( 4.4), many\\nare still unable to calculate simple logarithms. The purpose of this chapter is to present\\nthe aspiring data scientist with some of the most signiﬁcant notions of entropy and\\nto elucidate its relationship to probability . Therefore, it is primarily focused on basic\\nquantities in information theory such as entropy , cross-entropy , conditional entropy ,\\nmutual information and Kullback-Leibler divergence, also known as relative entropy .\\nIt does not however, discuss more advanced topics such as the concept of ’active in-\\nformation’ introduced by Bohm and Hiley [ 3].\\n4.2 Problems\\n4.2.1 Logarithms in Information Theory\\nIt is important to note that all numerical calculations in this chapter use the binary\\nlogarithm log2. This speciﬁc logarithm produces units of bits, the commonly used units\\nof information in the ﬁeld on information theory .\\n874.2. PROBLEMS\\nPRB-67 \\uf059 CH.PRB- 4.1.\\nRun the following Python code ( 4.3) in a Python interpreter. What are the results?\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n5\\n6 print (math.log10(1.0/0.98)) # Common log (base 10)\\n7 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n8\\n9 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n10 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\nFIGURE 4.3: Natural ( ln), binary (log2) and common ( log10) logarithms.\\nPRB-68 \\uf059 CH.PRB- 4.2.\\nThe three basic laws of logarithms:\\n1. First law\\nlog A + log B = log AB. (4.1)\\nCompute the following expression:\\nlog10 3 + log10 4.\\n2. Second law\\nlog An = n log A. (4.2)\\n88Chapter 4 INFORMATION THEORY\\nCompute the following expression:\\nlog2 46.\\n3. Third law\\nlog A − log B = log A\\nB . (4.3)\\n'),\n",
              " Document(metadata={}, page_content=\".2.\\nThe three basic laws of logarithms:\\n1. First law\\nlog A + log B = log AB. (4.1)\\nCompute the following expression:\\nlog10 3 + log10 4.\\n2. Second law\\nlog An = n log A. (4.2)\\n88Chapter 4 INFORMATION THEORY\\nCompute the following expression:\\nlog2 46.\\n3. Third law\\nlog A − log B = log A\\nB . (4.3)\\nTherefore, subtracting log B from log A results in log A\\nB .\\nCompute the following expression:\\nloge 15 − loge 3.\\n4.2.2 Shannon's Entropy\\nPRB-69 \\uf059 CH.PRB- 4.3.\\nWrite Shannon's famous general formulae for uncertainty.\\nPRB-70 \\uf059 CH.PRB- 4.4.\\nChoose exactly one, and only one answer.\\n1. For an event which is certain to happen, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N ), N being the number of possible events\\n894.2. PROBLEMS\\n2. For N equiprobable events, what is the entropy?\\n(a) 1.0\\n(b) 0.0\\n(c) The entropy is undeﬁned\\n(d) −1\\n(e) 0.5\\n(f) log2(N )\\nPRB-71 \\uf059 CH.PRB- 4.5.\\nShannon found that entropy was the only function satisfying three natural properties.\\nEnumerate these properties.\\nPRB-72 \\uf059 CH.PRB- 4.6.\\nIn information theory, minus the logarithm of the probability of a symbol (essentially\\nthe number of bits required to represent it efﬁciently in a binary code) is deﬁned to be the\\ninformation conveyed by transmitting that symbol. In this context, the entropy can be\\ninterpreted as the expected information conveyed by transmitting a single symbol from an\\nalphabet in which the symbols occur with the probabilities πk.\\nMark the correct answer : Information is a/an [decrease/increase] in uncertainty.\\nPRB-73 \\uf059 CH.PRB- 4.7.\\nClaud Shannon's paper “A mathematical theory of communication” [ 4], marked the\\nbirth of information theory. Published in 1948, it has become since the Magna Carta of the\\ninformation age. Describe in your own words what is meant by the term Shannon bit.\\nPRB-74 \\uf059 CH.PRB- 4.8.\\nWith respect to the notion of surprise in the context of information theory:\\n1. Deﬁne what it actually meant by being surprised.\\n90Chapter 4 INFORMATION THEORY\\n2. Describe how it is related to the likelihood of an event happening.\\n3. True or False: The less likely the occurrence of an event, the smaller information it\\nconveys.\\nPRB-75 \\uf059 CH.PRB- 4.9.\\nAssume a source of signals that transmits a given message a with probability Pa. Assume\\nfurther that the message is encoded into an ordered series of ones and zeros (a bit string) and\\nthat a receiver has a decoder that converts the bit string back into its respective message.\\nShannon devised a formulae that describes the size that the mean length of the bit string can\\nbe compressed to. Write the formulae.\\nPRB-76 \\uf059 CH.PRB- 4.10.\\nAnswer the following questions:\\n1. Assume a source that provides a constant stream of N equally likely symbols\\n{x1, x2, . . . , xN }. What does Shannon's formulae ( 4.4) reduce to in this particular\\ncase?\\n2. Assume that each equiprobable pixel in a monochrome image that is fed to a DL classi-\\nﬁcation pipeline, can have values ranging from 0 to 255. Find the entropy in bits.\\nPRB-77 \\uf059 CH.PRB- 4.11.\\nGiven Shannon's famous general formulae for uncertainty ( 4.4):\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.4)\\n1. Plot a graph of the curve of probability vs. uncertainty.\\n2. Complete the sentence: The curve is [symmetrical/asymmetrical].\\n914.2. PROBLEMS\\n3. Complete the sentence: The curve rises to a [minimum/maximum] when the two\\nsymbols are equally likely ( Pa = 0.5).\\nPRB-78 \\uf059 CH.PRB- 4\"),\n",
              " Document(metadata={}, page_content=\"e ( 4.4) reduce to in this particular\\ncase?\\n2. Assume that each equiprobable pixel in a monochrome image that is fed to a DL classi-\\nﬁcation pipeline, can have values ranging from 0 to 255. Find the entropy in bits.\\nPRB-77 \\uf059 CH.PRB- 4.11.\\nGiven Shannon's famous general formulae for uncertainty ( 4.4):\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.4)\\n1. Plot a graph of the curve of probability vs. uncertainty.\\n2. Complete the sentence: The curve is [symmetrical/asymmetrical].\\n914.2. PROBLEMS\\n3. Complete the sentence: The curve rises to a [minimum/maximum] when the two\\nsymbols are equally likely ( Pa = 0.5).\\nPRB-78 \\uf059 CH.PRB- 4.12.\\nAssume we are provided with biased coin for which the event ‘heads’ is assigned probab-\\nility p, and ‘tails’ - a probability of 1 − p. Using (4.4), the respective entropy is:\\nH(p) = −p log p − (1 − p) log (1 − p) . (4.5)\\nTherefore, H ≥ 0 and the maximum possible uncertainty is attained when p = 1 /2, is\\nHmax = log 2 2.\\nGiven the above formulation, describe a helpful property of the entropy that follows from\\nthe concavity of the logarithmic function.\\nPRB-79 \\uf059 CH.PRB- 4.13.\\nTrue or False: Given random variables X, Y and Z where Y = X + Z then:\\nH(X, Y ) = H(X, Z). (4.6)\\nPRB-80 \\uf059 CH.PRB- 4.14.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n92Chapter 4 INFORMATION THEORY\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh)+ p(xt) = 1 , what is formulae\\nfor the average surprise?\\n6. What is the value of the average surprise in bits?\\n4.2.3 Kullback-Leibler Divergence (KLD)\\nPRB-81 \\uf059 CH.PRB- 4.15.\\nWrite the formulae for the Kullback-Leibler divergence between two discrete probability\\ndensity functions P and Q.\\nPRB-82 \\uf059 CH.PRB- 4.16.\\nDescribe one intuitive interpretation of the KL-divergence with respect to bits.\\nPRB-83 \\uf059 CH.PRB- 4.17.\\n1. True or False: The KL-divergence is not a symmetric measure of similarity, i.e.:\\nDKL(P ∥Q) ̸= D KL(Q∥P ).\\n2. True or False: The KL-divergence satisﬁes the triangle inequality.\\n3. True or False: The KL-divergence is not a distance metric.\\n4. True or False: In information theory, KLD is regarded as a measure of the informa-\\ntion gained when probability distribution Q is used to approximate a true probability\\ndistribution P .\\n5. True or False: The units of KL-divergence are units of information.\\n6. True or False: The KLD is always non-negative, namely:\\nDKL(P ∥Q) ≥ 0.\\n934.2. PROBLEMS\\n.\\n7. True or False: In a decision tree, high information gain indicates that adding a split\\nto the decision tree results in a less accurate model.\\nPRB-84 \\uf059 CH.PRB- 4.18.\\nGiven two distributions f1 and f2 and their respective joint distribution f , write the\\nformulae for the mutual information of f1 and f2.\\nPRB-85 \\uf059 CH.P\"),\n",
              " Document(metadata={}, page_content=' ≥ 0.\\n934.2. PROBLEMS\\n.\\n7. True or False: In a decision tree, high information gain indicates that adding a split\\nto the decision tree results in a less accurate model.\\nPRB-84 \\uf059 CH.PRB- 4.18.\\nGiven two distributions f1 and f2 and their respective joint distribution f , write the\\nformulae for the mutual information of f1 and f2.\\nPRB-85 \\uf059 CH.PRB- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem.\\n4.2.4 Classification and Information Gain\\nPRB-86 \\uf059 CH.PRB- 4.20.\\nThere are several measures by which one can determine how to optimally split attributes\\nin a decision tree. List the three most commonly used measures and write their formulae.\\nPRB-87 \\uf059 CH.PRB- 4.21.\\nComplete the sentence: In a decision tree, the attribute by which we choose to split is\\nthe one with [minimum/maximum] information gain.\\nPRB-88 \\uf059 CH.PRB- 4.22.\\nT o study factors affecting the decision of a frog to jump (or not), a deep learning re-\\nsearcher from a Brazilian rain-forest, collects data pertaining to several independent binary\\nco-variates.\\n94Chapter 4 INFORMATION THEORY\\nFIGURE 4.4: A Frog in its natural habitat. Photo taken by my son.\\nThe binary response variable Jump indicates whether a jump was observed. Referring to\\nT able (4.1), each row indicates the observed values, columns denote features and rows denote\\nlabelled instances while class label ( Jump) denotes whether the frog had jumped.\\nObservation Green Rain Jump\\nx1 1 0 +\\nx2 1 1 +\\nx3 1 0 +\\nx4 1 1 +\\nx5 1 0 +\\nx6 0 1 +\\nx7 0 0 −\\nx8 0 1 −\\nTABLE 4.1: Decision trees and frogs.\\nWithout explicitly determining the information gain values for each of the three attrib-\\nutes, which attribute should be chosen as the attribute by which the decision tree should be\\nﬁrst partitioned? e.g which attribute has the highest predictive power regarding the decision\\nof the frog (Fig. 4.4) to jump.\\n954.2. PROBLEMS\\nPRB-89 \\uf059 CH.PRB- 4.23.\\nThis question discusses the link between binary classiﬁcation, information gain and de-\\ncision trees. Recent research [ 5] suggests that Cannabis (Fig. 4.5), and Cannabinoids ad-\\nministration in particular may reduce the size of malignant tumours in rodents. The data\\n(T able9.2) comprises a training set of feature vectors with corresponding class labels which\\na researcher intents classifying using a decision tree.\\nFIGURE 4.5: Cannabis\\nT o study factors affecting tumour shrinkage, the deep learning researcher collects data\\nregrading two independent binary variables; θ1 (T/F) indicating whether the rodent is a fe-\\nmale, and θ2 (T/F) indicating whether the rodent was administrated with Cannabinoids. The\\nbinary response variable, γ, indicates whether tumour shrinkage was observed (e.g. shrink-\\nage=+, no shrinkage=-). Referring to T able ( 9.2), each row indicates the observed values,\\ncolumns (θi) denote features and class label ( γ) denotes whether shrinkage was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 4.2: Decision trees and Cannabinoids administration\\n96Chapter 4 INFORMATION THEORY\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\nPRB-90 \\uf059 CH.PRB- 4.24.\\nT o study factors affecting the expansion of stars, a physicist is provided with data re-\\ngrading two independent variables; θ1 (T/F) indicating whether a star is dense, and θ2 (T/F)\\nindicating whether a star is adjacent to a black-hole. He is told that the binary response vari-\\nable, γ, indicates whether expansion was observed.\\ne.g.:\\nexpansion=+, no expansion=-. Referring to table ( 4.3'),\n",
              " Document(metadata={}, page_content='.24.\\nT o study factors affecting the expansion of stars, a physicist is provided with data re-\\ngrading two independent variables; θ1 (T/F) indicating whether a star is dense, and θ2 (T/F)\\nindicating whether a star is adjacent to a black-hole. He is told that the binary response vari-\\nable, γ, indicates whether expansion was observed.\\ne.g.:\\nexpansion=+, no expansion=-. Referring to table ( 4.3), each row indicates the observed val-\\nues, columns (θi) denote features and class label (γ) denotes whether expansion was observed.\\nγ (expansion) θ1 (dense) θ2 (black-hole)\\n+ F T\\n+ T T\\n+ T T\\n- F T\\n+ T F\\n- F F\\n- F F\\nTABLE 4.3: Decision trees and star expansion.\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (expansion)\\nbefore splitting.\\n2. Using log2 and the provided dataset, calculate the information gain of H(γ|θ1).\\n974.2. PROBLEMS\\n3. Using log2 and the provided dataset, calculate the information gain of H(γ|θ2).\\nPRB-91 \\uf059 CH.PRB- 4.25.\\nT o study factors affecting tumour shrinkage in humans, a deep learning researcher is\\nprovided with data regrading two independent variables; θ1 (S/M/L) indicating whether the\\ntumour is small(S), medium(M) or large(L), and θ2 (T/F) indicating whether the tumour\\nhas undergone radiation therapy. He is told that the binary response variable, γ, indicates\\nwhether tumour shrinkage was observed (e.g. shrinkage=+, no shrinkage=-).\\nReferring to table ( 4.4), each row indicates the observed values, columns ( θi) denote\\nfeatures and class label ( γ) denotes whether shrinkage was observed.\\nγ (shrinkage) θ1 θ2\\n- S F\\n+ S T\\n- M F\\n+ M T\\n+ H F\\n+ H T\\nTABLE 4.4: Decision trees and radiation therapy .\\n1. Using log2 and the provided dataset, calculate the sample entropy H(γ) (shrinkage).\\n2. Using log2 and the provided dataset, calculate the entropy of H(γ|θ1).\\n3. Using log2 and the provided dataset, calculate the entropy of H(γ|θ2).\\n4. True or false: We should split on a speciﬁc variable that minimizes the information\\ngain, therefore we should split on θ2 (radiation therapy).\\n4.2.5 Mutual Information\\nPRB-92 \\uf059 CH.PRB- 4.26.\\n98Chapter 4 INFORMATION THEORY\\nShannon described a communications system consisting ﬁve elements (4.6), two of which\\nare the source S and the destination D.\\nSourse S Trans\\nT\\nChannel\\nCH\\nReceiver\\nR\\nDest\\nD\\nMESSAGE\\nSIGNAL\\nSIGNAL\\nMESSAGE\\nFIGURE 4.6: Shannon\\'s ﬁve element communications system.\\n1. Draw a Venn diagram depicting the relationship between the entropies of the source\\nH(S) and of the destination H(D).\\n2. Annotate the part termed equivocation.\\n3. Annotate the part termed noise.\\n4. Annotate the part termed mutual information.\\n5. Write the formulae for mutual information.\\nPRB-93 \\uf059 CH.PRB- 4.27.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\n994.2. PROBLEMS\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\nPRB-94 \\uf059 CH.PRB- 4.28.\\nComplete the sentence: Mutual information is a Shannon entropy-based measure of\\ndependence between random variables. The mutual information between X and Z can be\\nunderstood as the (a) [___] of the (b) [___] in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.7)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X.\\n4.2.6 Mechanical Statistics\\nSome books have a tendency of sweeping \"unseen\" problems under the rug. We will\\nnot do that here. This subsection may look intimidating and for a good reason; it\\ninvolves equations that, unless you'),\n",
              " Document(metadata={}, page_content=' in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.7)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X.\\n4.2.6 Mechanical Statistics\\nSome books have a tendency of sweeping \"unseen\" problems under the rug. We will\\nnot do that here. This subsection may look intimidating and for a good reason; it\\ninvolves equations that, unless you are a physicists, you have probably never en-\\ncountered before. Nevertheless, the ability to cope with new concepts lies at the heart\\nof every job interview.\\nFor some of the questions, you may need these constants:\\nPHYSICAL CONSTANTS\\nk Boltzmanns constant 1.381 × 10−23 J K−1\\nc Speed of light in vacum 2.998 × 108m s−1\\nh Planck’s constant 6.626 × 10−34 J s\\nPRB-95 \\uf059 CH.PRB- 4.29.\\nWhat is the expression for the Boltzmann probability distribution?\\nPRB-96 \\uf059 CH.PRB- 4.30.\\nInformation theory, quantum physics and thermodynamics are closely interconnected.\\nThere are several equivalent formulations for the second law of thermodynamics. One ap-\\nproach to describing uncertainty stems from Boltzmanns fundamental work on entropy in\\n100Chapter 4 INFORMATION THEORY\\nstatistical mechanics. Describe what is meant by Boltzmanns entropy.\\nPRB-97 \\uf059 CH.PRB- 4.31.\\nFrom Boltzmanns perspective, what is the entropy of an octahedral dice ( 4.7)?\\nFIGURE 4.7: An octahedral dice.\\n4.2.7 Jensen\\'s inequality\\nPRB-98 \\uf059 CH.PRB- 4.32.\\n1. Deﬁne the term concave function.\\n2. Deﬁne the term convex function.\\n3. State Jensen\\'s inequality and its implications.\\nPRB-99 \\uf059 CH.PRB- 4.33.\\nTrue or False: Using Jensen\\'s inequality, it is possible to show that the KL divergence\\nis always greater or equal to zero.\\n4.3 Solutions\\n4.3.1 Logarithms in Information Theory\\n1014.3. SOLUTIONS\\nSOL-67 \\uf14b CH.SOL- 4.1.\\nNumerical results (4.8) are provided using Python interpreter version 3.6.\\n1 import math\\n2 import numpy\\n3 print (math.log(1.0/0.98)) # Natural log (ln)\\n4 > 0.02020270731751947\\n5 print (numpy.log(1.0/0.02)) # Natural log (ln)\\n6 > 3.912023005428146\\n7 print (math.log10(1.0/0.98)) # Common log (base 10)\\n8 > 0.008773924307505152\\n9 print (numpy.log10(1.0/0.02)) # Common log (base 10)\\n10 > 1.6989700043360187\\n11 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n12 > 0.02914634565951651\\n13 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n14 > 5.643856189774724\\nFIGURE 4.8: Logarithms in information theory .\\n\\x04\\nSOL-68 \\uf14b CH.SOL- 4.2.\\nThe logarithm base is explicitly written in each solution.\\n1.\\nlog10 3 + log10 4 = log 10(3 × 4) = log 10 12.\\n2.\\nlog2 46 = 6 log2 4.\\n3.\\nloge 15 − loge 3 = log e\\n15\\n3 = log e 5.\\n102Chapter 4 INFORMATION THEORY\\n\\x04\\n4.3.2 Shannon\\'s Entropy\\nSOL-69 \\uf14b CH.SOL- 4.3.\\nShannons famous general formulae for uncertainty is:\\nH = −\\nN∑\\na=1\\nPa log2 Pa (bits per symbol). (4.8)\\n\\x04\\nSOL-70 \\uf14b CH.SOL- 4.4.\\n1. No information is conveyed by an event which is a-priori known to occur for certain\\n(Pa = 1), therefore the entropy is 0.\\n2. Equiprobable events mean that Pi = 1 /N ∀i ∈ [1, N]. Therefore for N equally-'),\n",
              " Document(metadata={}, page_content=\"∑\\na=1\\nPa log2 Pa (bits per symbol). (4.8)\\n\\x04\\nSOL-70 \\uf14b CH.SOL- 4.4.\\n1. No information is conveyed by an event which is a-priori known to occur for certain\\n(Pa = 1), therefore the entropy is 0.\\n2. Equiprobable events mean that Pi = 1 /N ∀i ∈ [1, N]. Therefore for N equally-likely\\nevents, the entropy is log2(N ).\\n\\x04\\nSOL-71 \\uf14b CH.SOL- 4.5.\\nThe three properties are as follows:\\n1. H(X) is always non-negative, since information cannot be lost.\\n2. The uniform distribution maximizes H(X), since it also maximizes uncertainty.\\n3. The additivity property which relates the sum of entropies of two independent events.\\nFor instance, in thermodynamics, the total entropy of two isolated systems which co-\\nexist in equilibrium is the sum of the entropies of each system in isolation.\\n\\x04\\n1034.3. SOLUTIONS\\nSOL-72 \\uf14b CH.SOL- 4.6.\\nInformation is an [increase] in uncertainty. \\x04\\nSOL-73 \\uf14b CH.SOL- 4.7.\\nThe Shannon bit has two distinctive states; it is either 0 or 1, but never both at the same\\ntime. Shannon devised an experiment in which there is a question whose only two possible\\nanswers were equally likely to happen .\\nHe then deﬁned one bit as the amount of information gained (or alternatively, the amount\\nof entropy removed) once an answer to the question has been learned. He then continued to\\nstate that when the a-priori probability of any one possible answer is higher than the other, the\\nanswer would have conveyed less than one bit of information. \\x04\\nSOL-74 \\uf14b CH.SOL- 4.8.\\nThe notion of surprise is directly related to the likelihood of an event happening. Mathem-\\natically is it inversely proportional to the probability of that event.\\nAccordingly, learning that a high-probability event has taken place, for instance the sun rising,\\nis much less of a surprise and gives less information than learning that a low-probability\\nevent, for instance, rain in a hot summer day, has taken place. Therefore, the less likely the\\noccurrence of an event, the greater information it conveys.\\nIn the case where an event is a-priori known to occur for certain ( Pa = 1 ), then no inform-\\nation is conveyed by it. On the other hand, an extremely intermittent event conveys a lot of\\ninformation as it surprises us and informs us that a very improbable state exists. Therefore,\\nthe statement in part 3 is false.\\n\\x04\\nSOL-75 \\uf14b CH.SOL- 4.9.\\nThis quantity ISh, represented in the formulae is called the Shannon information of the\\nsource:\\nISh = −\\n∑\\na\\npa log2 pa. (4.9)\\nIt refers to the mean length in bits, per message, into which the messages can be compressed\\n104Chapter 4 INFORMATION THEORY\\nto. It is then possible for a communications channel to transmit ISh bits per message with a\\ncapacity of ISh. \\x04\\nSOL-76 \\uf14b CH.SOL- 4.10.\\n1. For N equiprobable events it holds that Pi = 1 /N, ∀i ∈ [1, N]. Therefore if we substi-\\ntute this into Shannon's equation we get:\\nHequiprobable = −\\nN∑\\ni=1\\n1\\nN log2\\n1\\nN . (4.10)\\nSince N does not depend on i, we can pull it out of the sum:\\nHequiprobable = −( 1\\nN log2\\n1\\nN )\\nN∑\\ni=1\\n1 (4.11)\\n= −\\n( 1\\nN log2\\n1\\nN\\n)\\nN\\n= − log2\\n1\\nN (4.12)\\n= log 2 N.\\nIt can be shown that for a given number of symbols (i.e., N is ﬁxed) the uncertainty H\\nhas its largest value only when the symbols are equally probable.\\n2. The probability for each pixel to be assigned a value in the given range is:\\npi = 1/256. (4.13)\\nTherefore the entropy is:\\nH = −(256)(1/256)(−8) = 8 [bits/symbol]. (4.14)\\n\\x04\\nSOL-77 \\uf14b CH.SOL- 4.11.\\n105\"),\n",
              " Document(metadata={}, page_content=' ﬁxed) the uncertainty H\\nhas its largest value only when the symbols are equally probable.\\n2. The probability for each pixel to be assigned a value in the given range is:\\npi = 1/256. (4.13)\\nTherefore the entropy is:\\nH = −(256)(1/256)(−8) = 8 [bits/symbol]. (4.14)\\n\\x04\\nSOL-77 \\uf14b CH.SOL- 4.11.\\n1054.3. SOLUTIONS\\nRefer to Fig. 4.9 for the corresponding illustration of the graph, where information is\\nshown as a function of p. It is equal to 0 for p = 0 and for p = 1. This is reasonable because for\\nsuch values of p the outcome is certain, so no information is gained by learning the outcome.\\nThe entropy in maximal uncertainty equals to 1 bit for p = 0 .5. Thus, the information gain\\nis maximal when the probabilities of two possible events are equal. Furthermore, for the entire\\nrange of probabilities between p = 0.4 and p = 0.6 the information is close to 1 bit. \\x04\\nFIGURE 4.9: H vs. Probability\\nSOL-78 \\uf14b CH.SOL- 4.12.\\nAn important set of properties of the entropy follows from the concavity of the entropy,\\nwhich follows from the concavity of the logarithm. Suppose that in an experiment, we cannot\\ndecide whether the actual probability of ‘heads’ is p1 or p2. We may decide to assign probability\\nq to the ﬁrst alternative and probability 1 − q to the second. The actual probability of ‘heads’\\nthen is the mixture qp1 + (1 − q)p2. The corresponding entropies satisfy the inequality:\\nS (qp1 + (1 − q)p2) ≥ qS (p1) + (1 − q) S (p2) , (4.15)\\n106Chapter 4 INFORMATION THEORY\\nThese probabilities, are equal in the extreme cases where p1 = p2, or q = 0, or q = 1. \\x04\\nSOL-79 \\uf14b CH.SOL- 4.13.\\nGiven (X, Y ), we can determine X and Z = Y − X. Conversely, given (X, Z), we can\\ndetermine X and Y = X + Z. Hence, H(X, Y ) = H(X, Z) due to the existence of this\\nbijection. \\x04\\nSOL-80 \\uf14b CH.SOL- 4.14.\\nThe solution and numerical calculations are provided using log2.\\n1. We can predict ‘heads’ for each ﬂip with an accuracy of p(xh) = 98 %.\\n2. According to Fig. ( 4.10), if the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is log2(1/0.98) [bits] .\\n1 import math\\n2 import numpy\\n3 print (math.log2(1.0/0.98)) # Binary log (base 2)\\n4 > 0.02914634565951651\\n5 print (numpy.log2(1.0/0.02)) # Binary log (base 2)\\n6 > 5.643856189774724\\nFIGURE 4.10: Shannon information gain for a biased coin toss.\\n3. Likewise, if the result of the coin toss is ‘tails’, the amount of Shannon information\\ngained is log2(1/0.02) [bits] .\\n4. It is always true that the more information is associated with an outcome, the more\\nsurprising it is.\\n5. The formulae for the average surprise is:\\nH(x) = p(xh) log 1\\np(xh) + p(xt) log 1\\np(xt). (4.16)\\n1074.3. SOLUTIONS\\n6. The value of the average surprise in bits is ( 4.11):\\nH(x) = [0 .98 × 0.0291] + [0.02 × 5.643] (4.17)\\n= 0.1414 [bits].\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4 print (\"binaryEntropy(p) is:{}\\nbits\".format(binaryEntropy(0.98)))↪→\\n5 > binaryEntropy(p) is:0.1414 bits\\nFIGURE 4.11: Average surprise\\n\\x04\\n4.3.3 Kullback-Leibler Divergence'),\n",
              " Document(metadata={}, page_content='].\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4 print (\"binaryEntropy(p) is:{}\\nbits\".format(binaryEntropy(0.98)))↪→\\n5 > binaryEntropy(p) is:0.1414 bits\\nFIGURE 4.11: Average surprise\\n\\x04\\n4.3.3 Kullback-Leibler Divergence\\nSOL-81 \\uf14b CH.SOL- 4.15.\\nFor discrete probability distributions P and Q, the Kullback-Leibler divergence from P\\nto Q, the KLD is deﬁned as:\\nD(P ∥ Q) =\\n∑\\nx\\nP (x) log P (x)\\nQ(x) (4.18)\\n= EP\\n[\\nlog 1\\nQ(x) − log 1\\nP (x)\\n]\\n= HP (Q)\\ued19 \\ued18\\ued17 \\ued1a\\nCross Entropy\\n− H(P )\\ued19 \\ued18\\ued17 \\ued1a\\nEntropy\\n.\\n\\x04\\n108Chapter 4 INFORMATION THEORY\\nSOL-82 \\uf14b CH.SOL- 4.16.\\nOne interpretation is the following: the KL-divergence indicates the average number of\\nadditional bits required for transmission of values x ∈ X which are distributed according\\nto P (x), but we erroneously encoded them according to distribution Q(x). This makes sense\\nsince you have to “pay” for additional bits to compensate for not knowing the true distribution,\\nthus using a code that was optimized according to other distribution. This is one of the reason\\nthat the KL-divergence is also known as relative entropy. Formally, the cross entropy has an\\ninformation interpretation quantifying how many bits are wasted by using the wrong code:\\nHP (Q) =\\n∑\\nx\\nP (x)\\ued19 \\ued18\\ued17 \\ued1a\\nSending P\\ncode for Q\\n\\ued17 \\ued1a\\ued19 \\ued18\\nlog 1\\nQ(x) . (4.19)\\n\\x04\\nSOL-83 \\uf14b CH.SOL- 4.17.\\n1. True KLD is a non-symmetric measure, i.e. D(P ∥ Q) ̸= D(Q ∥ P ).\\n2. False KLD does not satisfy the triangle inequality.\\n3. True KLD is not a distance metric.\\n4. True KLD is regarded as a measure of the information gain. Notice that, however, KLD\\nis the amount of information lost.\\n5. True The units of KL divergence are units of information (bits, nats, etc.).\\n6. True KLD is a non-negative measure.\\n7. True Performing splitting based on highly informative event usually leads to low model\\ngeneralization and a less accurate one as well.\\n\\x04\\nSOL-84 \\uf14b CH.SOL- 4.18.\\n1094.3. SOLUTIONS\\nFormally, mutual information attempts to measure how correlated two variables are with\\neach other:\\nI(X; Y ) =\\n∑\\nx,y\\nP (x, y) log P (x, y)\\nP (x)P (y) (4.20)\\n= E\\n[\\nlog 1\\nP (x) + log 1\\nP (y) − log 1\\nP (x, y)\\n]\\n= H(X) + H(Y ) − H(X, Y ).\\nRegarding the question at hand, given two distributions f1 and f2 and their joint distri-\\nbution f , the mutual information of f1 and f2 is deﬁned as I(f1, f2) = H(f, f1f2). If the\\ntwo distributions are independent, i.e. f = f1 · f2, the mutual information will vanish. This\\nconcept has been widely used as a similarity measure in image analysis. \\x04\\nSOL-85 \\uf14b CH.SOL- 4.19.\\nThe question was commented out but remained here for the consistency of the numbering\\nsystem. \\x04\\n4.3.4 Classification and Information Gain\\nSOL-86 \\uf14b CH.SOL- 4.20.\\nThe three most widely used methods are:\\n1.\\nEntropy (t) = −\\nc−1∑\\ni=0\\np(i) log2 p(i). (4.21)\\n2.\\n1 −\\nc−1∑\\ni=0\\n[p(i)]2 (4.22)\\n110Chapter 4 INFORMATION THEORY\\n3.\\nClassiﬁcation error (t) = 1 − max\\ni'),\n",
              " Document(metadata={}, page_content='�� CH.SOL- 4.20.\\nThe three most widely used methods are:\\n1.\\nEntropy (t) = −\\nc−1∑\\ni=0\\np(i) log2 p(i). (4.21)\\n2.\\n1 −\\nc−1∑\\ni=0\\n[p(i)]2 (4.22)\\n110Chapter 4 INFORMATION THEORY\\n3.\\nClassiﬁcation error (t) = 1 − max\\ni\\n[p(i)]. (4.23)\\n\\x04\\nSOL-87 \\uf14b CH.SOL- 4.21.\\nIn a decision tree, the attribute by which we choose to split is the one with [maximum]\\ninformation gain. \\x04\\nSOL-88 \\uf14b CH.SOL- 4.22.\\nIt is clear that the entropy will be decreased more by ﬁrst splitting on Green rather than\\non Rain.\\nFIGURE 4.12: First split.\\n\\x04\\nSOL-89 \\uf14b CH.SOL- 4.23.\\n1. Information gain is the expected reduction in entropy caused by partitioning values in\\na dataset according to a given attribute.\\n2. A decision tree learning algorithm chooses the next attribute to partition the currently\\nselected node, by ﬁrst computing the information gain from the entropy, for instance,\\nas a splitting criterion.\\n3. There are 3 positive examples corresponding to Shrinkage=+, and 2 negative examples\\n1114.3. SOLUTIONS\\ncorresponding to Shrinkage=-. Using the formulae:\\nH(Y ) = −\\nk∑\\ni=1\\nP (Y = yi) log2 P (Y = yi) (4.24)\\nand the probabilities:\\nP (γ = +) = 3\\n5 , (4.25)\\nP (γ = −) = 2\\n5 , (4.26)\\nthe overall entropy before splitting is ( 4.13):\\nEorig = −(3/5) log(3/5) − (2/5) log(2/5)\\n= H(γ) ≈ 0.97095[bits/symbol]. (4.27)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is: 0.97095 bits\\nFIGURE 4.13: Entropy before splitting.\\n4. If we split on θ1, (4.5) the relative shrinkage frequency is:\\n112Chapter 4 INFORMATION THEORY\\nTotal θ1 = T θ1 = F\\n+ 3 0\\n- 1 1\\nTABLE 4.5: Splitting on θ1.\\nT o compute the information gain (IG) based on feature θ1, we must ﬁrst compute the\\nentropy of γ after a split based on θ1, H(γ|θ1):\\nH(γ|θ1)\\n= −\\nv∑\\nj=1\\n[ k∑\\ni=1\\nP (γ = γi|θ1 = θj) log2 P (γ = γi|θ1 = θj)\\n]\\nP (θ1 = θj).\\nTherefore, using the data for the the relative shrinkage frequency ( 4.5), the information\\ngain after splitting on θ1 is:\\nEθ1=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.8112,\\nEθ1=F = −0\\n1 log 0\\n1 − 1\\n1 log 1\\n1 = 0.0.\\n(4.28)\\nNow we know that P (θ1 = T ) = 4/5 and P (θ1 = F ) = 1/5 , therefore:\\n∆ = Eorig − (4/5) Eθ1=T − (1/5) Eθ1=F\\n= 0.97095 − (4/5) ∗ 0.8112 − (1/5) ∗ (0.0)\\n=≈ 0.32198 [bits/symbol].\\n(4.29)\\n\\x04\\nSOL-90 \\uf14b CH.SOL- 4.24.\\nThere are 4 positive examples corresponding to Expansion=+, and 3 negative examples\\n1134.3. SOLUTIONS\\ncorresponding to Expansion=-.\\n1. The overall entropy before splitting is ( 4.14):\\nEorig = −(4/7) log(4/'),\n",
              " Document(metadata={}, page_content=' (0.0)\\n=≈ 0.32198 [bits/symbol].\\n(4.29)\\n\\x04\\nSOL-90 \\uf14b CH.SOL- 4.24.\\nThere are 4 positive examples corresponding to Expansion=+, and 3 negative examples\\n1134.3. SOLUTIONS\\ncorresponding to Expansion=-.\\n1. The overall entropy before splitting is ( 4.14):\\nEorig = −(4/7) log(4/7) − (3/7) log(3/7)\\n= 0.9852281 [bits/symbol]. (4.30)\\n1 import autograd.numpy as np\\n2 def binaryEntropy (p):\\n3 return -p*np.log2(p) -(1-p)*np.log2(1-p)\\n4\\n5 print (\"binaryEntropy(p) is:{} bits\" .format(binaryEntropy(4/7)))\\n6 > binaryEntropy(p) is:0.9852281 bits\\nFIGURE 4.14: Entropy before splitting.\\n2. If we split on θ1, (4.6) the relative star expansion frequency is:\\nTotal θ1 = T θ1 = F\\n+ 3 1\\n- 0 3\\nTABLE 4.6: Splitting on θ1.\\nTherefore, the information gain after splitting on A is:\\nEθ1=T = −3\\n3 log 3\\n3 − 0\\n3 log 0\\n3 = 0.0,\\nEθ1=F = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.81127.\\n(4.31)\\n114Chapter 4 INFORMATION THEORY\\nNow we know that P (θ1 = T ) = 3/7 and P (θ1 = F ) = 4/7 , therefore:\\n∆ = Eorig − (3/7) Eθ1=T − (4/7) Eθ1=F\\n= 0.98522 − (3/7) ∗ 0.0 − (4/7) ∗ (0.81127)\\n= 0.52163 [bits/symbol].\\n(4.32)\\n3. If we split on θ2, (4.7) the relative star expansion frequency is:\\nTotal θ2 = T θ2 = F\\n+ 3 1\\n- 1 2\\nTABLE 4.7: Splitting on θ2.\\nThe information gain after splitting on B is:\\nEθ2=T = −3\\n4 log 3\\n4 − 1\\n4 log 1\\n4 = 0.0.8112,\\nEθ2=F = −1\\n3 log 1\\n3 − 2\\n3 log 2\\n3 = 0.9182.\\n(4.33)\\nNow we know that P (θ2 = T ) = 4/7 and P (θ2 = F ) = 3/7 , therefore:\\n∆ = Eorig − (4/7) Eθ2=T − (3/7) Eθ2=F\\n= 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol].\\n∆ = 0.98522 − (4/7) ∗ 0.8122 − (3/7) ∗ (0.9182)\\n0.1275 [bits/symbol]. (4.34)\\n\\x04\\n1154.3. SOLUTIONS\\nSOL-91 \\uf14b CH.SOL- 4.25.\\n1.\\nH(γ) = −\\n( 2\\n6 log2\\n2\\n6 + 4\\n6 log2\\n4\\n6\\n)\\nH(γ) = −\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n≈ 0.92 [bits/symbol].\\n(4.35)\\n2.\\nH(γ|θ1) = −1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n−\\n1\\n3\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n− 1\\n3 (1 log2 1) .\\nH(γ|θ1) = 1\\n3(1) + 1\\n3(1) + 1\\n3 (0).\\nH(γ|θ1) = 2\\n3 ≈ 0.66[bits/symbol].\\n(4.36)\\n3.\\nH'),\n",
              " Document(metadata={}, page_content=\"\\n( 1\\n2 log2\\n1\\n2 + 1\\n2 log2\\n1\\n2\\n)\\n− 1\\n3 (1 log2 1) .\\nH(γ|θ1) = 1\\n3(1) + 1\\n3(1) + 1\\n3 (0).\\nH(γ|θ1) = 2\\n3 ≈ 0.66[bits/symbol].\\n(4.36)\\n3.\\nH(γ|θ2) = −1\\n2\\n( 1\\n3 log2\\n1\\n3 + 2\\n3 log2\\n2\\n3\\n)\\n− 1\\n2 (1 log2 1) .\\nH(γ|θ2) = 1\\n2\\n(\\nlog2 3 − 2\\n3\\n)\\n.\\nH(γ|θ2) = 1\\n2 log2 3 − 1\\n3 ≈ 0.46 [bits/symbol].\\n(4.37)\\n4. False.\\n\\x04\\n4.3.5 Mutual Information\\nSOL-92 \\uf14b CH.SOL- 4.26.\\n1. The diagram is depicted in Fig. 4.15.\\n116Chapter 4 INFORMATION THEORY\\nE N\\nH(S) H(D)\\nFIGURE 4.15: Mutual Information between H(S) & H(D).\\n2. Equivocation is annotated by E.\\n3. Noise is annotated by N .\\n4. The intersection (shaded area) in (4.15) corresponds to mutual information of the source\\nH(S) and of the destination H(D).\\n5. The formulae for mutual information is:\\nH(S; D) = H(S) − E = H(D) − N. (4.38)\\n\\x04\\nSOL-93 \\uf14b CH.SOL- 4.27.\\nThe relative entropy D(p||q) is the measure of difference between two distributions. It\\ncan also be expressed like a measure of the inefﬁciency of assuming that the distribution is q\\nwhen the true distribution is p. \\x04\\nSOL-94 \\uf14b CH.SOL- 4.28.\\nMutual information is a Shannon entropy-based measure of dependence between random\\nvariables. The mutual information between X and Z can be understood as the reduction of\\n1174.3. SOLUTIONS\\nthe uncertainty in X given Z:\\nI(X; Z) := H(X) − H(X | Z), (4.39)\\nwhere H is the Shannon entropy, and H(X | Z) is the conditional entropy of Z given X. \\x04\\n4.3.6 Mechanical Statistics\\nSOL-95 \\uf14b CH.SOL- 4.29.\\nIs this question valuable? \\x04\\nSOL-96 \\uf14b CH.SOL- 4.30.\\nBoltzmann related the degree of disorder of the state of a physical system to the logarithm\\nof its probability. If, for example, the system has n non-interacting and identical particles,\\neach capable of existing in each of K equally likely states, the leading term in the logarithm of\\nthe probability of ﬁnding the system in a conﬁguration with n1 particles in state 1, n2 in state\\n2, etc, is given by the Boltzmann entropy Hπ = − ∑K\\n1 πi log(πi), where πi = ni/n. \\x04\\nSOL-97 \\uf14b CH.SOL- 4.31.\\nThere are 8 equiprobable events in each roll of the dice, therefore:\\nH = −\\n8∑\\ni=1\\n1\\n8 log2\\n1\\n8 = 3 [bits] . (4.40)\\n\\x04\\n4.3.7 Jensen's inequality\\nSOL-98 \\uf14b CH.SOL- 4.32.\\n1. A function f is concave in the range [a, b] if f φ2 is negative in the range [a, b].\\n2. A function f is convex in the range [a, b] if f φ2 is positive in the range [a, b].\\n118Chapter 4 INFORMATION THEORY\\n3. The following inequality was published by J.L. Jensen in 1906:\\n(Jensen’s Inequality)Let f be a function convex up on (a, b). Then for any n ≥ 2\\nnumbers xi ∈ (a, b):\\nf\\n( ∑n\\ni=1 xi\\nn\\n)\\n≤\\n∑n\\ni=1 f (xi)\\nn ,\\nand that the equality is attained if and only if f is linear or all xi are equal.\\nFor a convex down function, the sign of the inequality\"),\n",
              " Document(metadata={}, page_content=\" 1906:\\n(Jensen’s Inequality)Let f be a function convex up on (a, b). Then for any n ≥ 2\\nnumbers xi ∈ (a, b):\\nf\\n( ∑n\\ni=1 xi\\nn\\n)\\n≤\\n∑n\\ni=1 f (xi)\\nn ,\\nand that the equality is attained if and only if f is linear or all xi are equal.\\nFor a convex down function, the sign of the inequality changes to ≥.\\nJensen’s inequality states that if f is convex in the range [a, b], then:\\nf (a) + f (b)\\n2 ≥ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b. Jensen’s inequality states that if f is concave in the\\nrange [a, b], then:\\nf (a) + f (b)\\n2 ≤ f\\n(\\na + b\\n2\\n)\\n.\\nEquality holds if and only if a = b.\\n\\x04\\nSOL-99 \\uf14b CH.SOL- 4.33.\\nTrue The non-negativity of KLD can be proved using Jensen's inequality. \\x04\\nReferences\\n[1] S. Carnot. Reﬂections on the Motive Power of Fire: And Other Papers on the Second\\nLaw of Thermodynamics . Dover books on physics. Dover Publications, 2012 (cit.\\non p. 86).\\n[2] T. M. Cover and J. A. Thomas. Elements of Information Theory . John Wiley and\\nSons, Inc., 2006 (cit. on p. 86).\\n[3] B. J. Hiley. ‘From the Heisenberg Picture to Bohm: a New Perspective on Active\\nInformation and its relation to Shannon Information’. In: Proc. Conf. Quantum\\nTheory: reconsideration of foundations (2002), pp. 141–162 (cit. on p. 87).\\n119REFERENCES\\n[4] C. Shannon. ‘A mathematical theory of communication’. In: Bell System T echnical\\nJournal 27 (1948), pp. 379–423 (cit. on pp. 86, 90).\\n[5] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on p. 96).\\n120CHAPTER\\n5\\nDEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe true logic of this world is in the calculus of probabilities.\\n— James C. Maxwell\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nAD, Gradient descent & Backpropagation . . . . . . . . . . . . . . . . . 124\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 126\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . .\"),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . 128\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 132\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 134\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 135\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 136\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 142\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 143\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 144\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1465.1. INTRODUCTION\\nAlgorithmic differentiation, Gradient descent . . . . . . . . . . . . . . . 146\\nNumerical differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . 146\\nDirected Acyclic Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\nThe chain rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149\\nTaylor series expansion . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150\\nLimits and continuity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151\\nPartial derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152\\nOptimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153\\nThe Gradient descent algorithm . . . . . . . . . . . . . . . . . . . . . . . 155\\nThe Backpropagation algorithm . . . . . . . . . . . . . . . . . . . . . . . 156\\nFeed forward neural networks . . . . . . . . . . . . . . . . . . . . . . . 158\\nActivation functions, Autograd/JAX . . . . . . . . . . . . . . . . . . . . 158\\nDual numbers in AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . . . . 163\\nForward mode AD . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nForward mode AD table construction . . . . . . . . . . . . . . . . . . . 168\\nSymbolic differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nSimple differentiation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172\\nThe Beta-Binomial model . . . . . . . . . . . . . . . . . . . . . . . . . . 174\\n5.1 Introduction\\nC\\nALCULUS is the mathematics of change; the differentiation of a function is\\nkey to almost every domain in the scientiﬁc and engineering realms and\\ncalculus is also very much central to DL. A standard curriculum of ﬁrst year\\ncalculus includes topics such as limits, differentiation, the derivative, Taylor\\nseries, integration, and the integral. Many aspiring data scientists who lack a relevant\\nmathematical background and are shifting careers, hope to easily enter the ﬁeld but\\nfrequently encounter a mental barricade.\\n122Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nf (x) f ′(x)\\nsin(x) cos(x)\\ncos(x) − sin(x)\\nlog(x) 1\\nx\\nex ex\\nThanks to the rapid advances in processing power and the proliferation of GPUs,\\nit is possible to lend the burden of computation to a computer with high efﬁciency\\nand precision. For instance, extremely fast implementations of backpropagation, the\\ngradient descent algorithm, and automatic differentiation (AD) [5] brought artiﬁcial in-\\ntelligence from a mere concept to reality .\\nCalculus is frequently taught in a way that is very burdensome to the student,\\ntherefore I tried incorporating the writing of Python code snippets into the learning\\nprocess and the usage of:\\nDAGs (Directed Acyclic Graphs). Gradient descent is the essence of optimization in\\ndeep learning, which requires efﬁcient access to ﬁrst and second order derivatives that\\nAD frameworks provide. While older AD frameworks were written in C++ ([ 4]), the\\nnewer ones are Python-based such as Autograd ([ 10]) and JAX ([ 3], [1]).\\nDerivatives are also crucial in graphics applications. For example, in a render-\\ning technique entitled global illumination, photons bounce in a synthetically generated\\nscene while their direction and colour has to be determined using derivatives based\\non the speciﬁc material each photon hits. In ray tracing algorithms, the colour of the\\npixels is determined by tracing the trajectory the photons travel from the eye of the\\nobserver through a synthetic 3D scene.\\nA function is usually represented by a DAG. For instance, one commonly used\\nform is to represent intermediate values as nodes and operations as arcs ( 5.2). One\\nother commonly used form is to represent not only the values but also the operations\\nas nodes ( 5.11).\\nThe ﬁrst representation of a function by a DAG goes back to [ 7].\\n1235.2. PROBLEMS\\nx\\ny\\nk\\nf (a)\\nf (b)\\na bc\\nFIGURE 5.1: Intermediate value theorem\\nManual differentiation is tedious and error-prone and practically unusable for real-\\ntime graphics applications wherein numerous successive derivatives have to be re-\\npeatedly calculated. Symbolic differentiation on the other hand, is a computer based\\nmethod that uses a collection of differentiation rules to analytically calculate an exact\\nderivative of a function resulting in a purely symbolic derivatives. Many symbolic\\ndifferentiation libraries utilize what is known as operator-overloading ([9]) for both the\\nforward and reverse forms of differentiation, albeit they are not quite as fast as AD.\\n5.2 Problems\\n5.2.1 AD, Gradient descent & Backpropagation\\nAD [5] is the application of the chain rule to functions by computers in order to auto-\\nmatically compute derivatives. AD plays a signiﬁcant role in training deep learning\\nalgorithms and in order to understand AD you need a solid grounding in Calculus. As\\nopposed to numerical differentiation, AD is a procedure for establishing exact deriv-\\natives without any truncation errors. AD breaks a computer program into a series of\\nfundamental mathematical operations, and the gradient'),\n",
              " Document(metadata={}, page_content='agation\\nAD [5] is the application of the chain rule to functions by computers in order to auto-\\nmatically compute derivatives. AD plays a signiﬁcant role in training deep learning\\nalgorithms and in order to understand AD you need a solid grounding in Calculus. As\\nopposed to numerical differentiation, AD is a procedure for establishing exact deriv-\\natives without any truncation errors. AD breaks a computer program into a series of\\nfundamental mathematical operations, and the gradient or Hessian of the computer\\nprogram is found by successive application of the chain rule ( 5.1) to it’s elementary\\nconstituents.\\n124Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nFor instance, in the C++ programming language, two techniques ([ 4]) are com-\\nmonly utilized in transforming a program that calculates numerical values of a func-\\ntion into a program which calculates numerical values for derivatives of that function;\\n(1) an operator overloading approach and (2) systematic source code transformation.\\n∂\\n∂t f (g(t))\\n⏐⏐⏐⏐⏐\\nt=t0\\n=\\n\\uf8eb\\n\\uf8ed ∂\\n∂s f (s)\\n⏐⏐⏐⏐⏐\\ns=g(t0)\\n\\uf8f6\\n\\uf8f8\\n(\\n∂\\n∂t g(t)\\n⏐⏐⏐⏐⏐\\nt=t0\\n)\\n(5.1)\\nOne notable feature of AD is that the values of the derivatives produced by apply-\\ning AD, as opposed to numerical differentiation (ﬁnite difference formulas), are exact\\nand accurate. Two variants of AD are widely adopted by the scientiﬁc community: the\\nforward mode or the reverse mode where the underlying distinction between them is\\nthe order in which the chain rule is being utilized. The forward mode, also entitled\\ntangent mode, propagates derivatives from the dependent towards the independent\\nvariables, whereas the reverse or adjoint mode does exactly the opposite. AD makes\\nheavy use of a concept known as dual numbers (DN) ﬁrst introduced by Clifford ([ 2]).\\nx1 v1 v2 f\\n(x)2\\nln(1 + v1)\\nexp(v1)\\nv2 + 1\\nFIGURE 5.2: A Computation graph with intermediate values as nodes and operations as\\narcs.\\n5.2.2 Numerical differentiation\\nPRB-100 \\uf059 CH.PRB- 5.1.\\n1. Write the formulae for the ﬁnite difference rule used in numerical differentiation.\\n2. What is the main problem with this formulae?\\n1255.2. PROBLEMS\\n3. Indicate one problem with software tools which utilize numerical differentiation and\\nsuccessive operations on ﬂoating point numbers.\\nPRB-101 \\uf059 CH.PRB- 5.2.\\n1. Given a function f (x) and a point a, deﬁne the instantaneous rate of change of\\nf (x) at a.\\n2. What other commonly used alternative name does the instantaneous rate of change\\nhave?\\n3. Given a function f (x) and a point a, deﬁne the tangent line of f (x) at a.\\n5.2.3 Directed Acyclic Graphs\\nThere are two possible ways to traverse a DAG (Directed Acyclic Graph). One\\nmethod is simple. Start at the bottom and go through all nodes to the top of the com-\\nputational tree. That is nothing else than passing the corresponding computation se-\\nquence top down. Based on this method, the so called forward mode or of AD was\\ndeveloped [ 8]. In contrast to this forward mode the reverse mode was ﬁrst used by\\nSpeelpenning [ 13] who passed the underlying graph top down and propagated the\\ngradient backwards.\\nPRB-102 \\uf059 CH.PRB- 5.3.\\n1. State the deﬁnition of the derivative f (c) of a function f (x) at x = c.\\n2. With respect to the DAG depicted in 5.3:\\n126Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx √x\\n1\\n/\\ng(x)\\nFIGURE 5.3: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.3 and ﬁnd the function g(x) it represents.\\n(b) Using the deﬁnition of the derivative, ﬁnd g'),\n",
              " Document(metadata={}, page_content=' LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx √x\\n1\\n/\\ng(x)\\nFIGURE 5.3: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.3 and ﬁnd the function g(x) it represents.\\n(b) Using the deﬁnition of the derivative, ﬁnd g′(9).\\nPRB-103 \\uf059 CH.PRB- 5.4.\\n1. With respect to the expression graph depicted in 5.4, traverse the graph and ﬁnd the\\nfunction g(x) it represents.\\nx\\n**2\\n2\\n*\\n-\\n+\\n1\\ng(x)\\nFIGURE 5.4: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n2. Using the deﬁnition of the derivative ﬁnd the derivative of g(x).\\n5.2.4 The chain rule\\nPRB-104 \\uf059 CH.PRB- 5.5.\\n1275.2. PROBLEMS\\n1. The chain rule is key concept in differentiation. Deﬁne it.\\n2. Elaborate how the chain rule is utilized in the context of neural networks.\\n5.2.5 Taylor series expansion\\nThe idea behind a Taylor series is that if you know a function and all its derivatives\\nat one point x = a, you can approximate the function at other points near a. As an\\nexample, take f (x) = √x. You can use Taylor series to approximate\\n√\\n10 by knowing\\nf (9) and all the derivatives f ′(9), f ′′(9).\\nThe MacLaurin series ( 5.2) is a special case of Taylor series when f (0), f ′(0) are\\nknown:\\nf (x) = f (0) + xf ′(0) + x2\\n2! f ′′(0) + x3\\n3! f ′′′(0) + · · · =\\n∞∑\\np=0\\nxp\\np! f (p)(0) (5.2)\\nFor instance, the Maclaurin expansion of cos(x) is:\\nf (x) = cos x, f ′(x) = − sin x,\\nf ′′(x) = − cos x, f ′′′(x) = sin x (5.3)\\nWhen evaluated at 0 results in:\\ncos x = 1 − x2\\n2! + x4\\n4! − x6\\n6! + · · · (5.4)\\nPRB-105 \\uf059 CH.PRB- 5.6.\\nFind the T aylor series expansion for:\\n1.\\n1\\n1 − x (5.5)\\n128Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2.\\nex (5.6)\\n3.\\nsin(x) (5.7)\\n4.\\ncos(x) (5.8)\\nPRB-106 \\uf059 CH.PRB- 5.7.\\nFind the T aylor series expansion for:\\nlog(x) (5.9)\\nPRB-107 \\uf059 CH.PRB- 5.8.\\nFind the T aylor series expansion centered at x = −3 for:\\nf (x) = 5 x2 − 11x + 1 (5.10)\\nPRB-108 \\uf059 CH.PRB- 5.9.\\nFind the 101th degree T aylor polynomial centered at x = 0 for:\\nf (x) = cos( x) (5.11)\\nPRB-109 \\uf059 CH.PRB- 5.10.\\nAt x = 1, compute the ﬁrst 7 terms of the T aylor series expansion of:\\nf (x) = ln 3 x. (5.12)\\n1295.2. PROBLEMS\\n5.2.6 Limits and continuity\\nTheorem 1 (L’Hopital’s rule) .\\n[limx→a\\nf (x)\\ng(x) = limx→a\\nf ′(x)\\ng′(x) ]. (5.13)\\nPRB-110 \\uf059 CH.PRB- 5.11.\\nFind the following limits:\\n1. lim\\nx→3\\nex3\\n− e27\\n3x − 9\\n2. lim\\nx→0\\nex2\\n− x − 1\\n3'),\n",
              " Document(metadata={}, page_content='’s rule) .\\n[limx→a\\nf (x)\\ng(x) = limx→a\\nf ′(x)\\ng′(x) ]. (5.13)\\nPRB-110 \\uf059 CH.PRB- 5.11.\\nFind the following limits:\\n1. lim\\nx→3\\nex3\\n− e27\\n3x − 9\\n2. lim\\nx→0\\nex2\\n− x − 1\\n3 cos x − x − 3\\n3. limx→∞\\nx − ln x\\n100√x + 4\\n5.2.7 Partial derivatives\\nPRB-111 \\uf059 CH.PRB- 5.12.\\n1. True or false: When applying a partial derivative, there are two variables considered\\nconstants - the dependent and independent variable.\\n2. Given g(x, y), ﬁnd its partial derivative with respect to x:\\ng(x, y) = x2y + yx + 8y. (5.14)\\nPRB-112 \\uf059 CH.PRB- 5.13.\\n130Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nThe gradient of a two-dimensional function is given by\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j (5.15)\\n1. Find the gradient of the function:\\nf (x, y) = xy2 − y2 + x3 (5.16)\\n2. Given the function:\\ng(x, y) = x2y = xy2 − y − 1, (5.17)\\nevaluate it at (−1, 0), directed at (1, 1).\\nPRB-113 \\uf059 CH.PRB- 5.14.\\nFind the partial derivatives of:\\nf (x, y) = 3 sin 2(x − y) (5.18)\\nPRB-114 \\uf059 CH.PRB- 5.15.\\nFind the partial derivatives of:\\nz = 2 sin(x) sin(y) (5.19)\\n5.2.8 Optimization\\nPRB-115 \\uf059 CH.PRB- 5.16.\\nConsider f (x) = x2 + 1\\n(x + 2)2 .\\n1. Where is f (x) well deﬁned?\\n1315.2. PROBLEMS\\n2. Where is f (x) increasing and decreasing?\\n3. Where is f (x) reaching minimum and maximum values.\\nPRB-116 \\uf059 CH.PRB- 5.17.\\nConsider f (x) = 2 x3 − x.\\n1. Derive f (x) and conclude on its behavior.\\n2. Derive once again and discuss the concavity of the function f (x).\\nPRB-117 \\uf059 CH.PRB- 5.18.\\nConsider the function\\nf (x, y) = 2 x2 − xy + y2,\\nand ﬁnd maximum, minimum, and saddle points.\\n5.2.9 The Gradient descent algorithm\\nPRB-118 \\uf059 CH.PRB- 5.19.\\nThe gradient descent algorithm can be utilized for the minimization of convex functions.\\nStationary points are required in order to minimize a convex function. A very simple ap-\\nproach for ﬁnding stationary points is to start at an arbitrary point, and move along the\\ngradient at that point towards the next point, and repeat until converging to a stationary\\npoint.\\n1. What is the term used to describe the vector of all partial derivatives for a function\\nf (x)?\\n2. Complete the sentence: when searching for a minima, if the derivative is positive, the\\nfunction is increasing/decreasing.\\n132Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n3. The function x2 as depicted in 5.5, has a derivative of f ′(x) = 2 x. Evaluated at x =\\n−1, the derivative equals f ′(x = −1) = −2. At x = −1, the function is decreasing\\nas x gets larger. We will happen if we wish to ﬁnd a minima using gradient descent,\\nand increase (decrease) x by the size of the gradient , and then again repeatedly keep\\njumping?\\n4. How this phenomena can be alleviated?\\n5. True or False: The gradient descent algorithm is guaranteed to ﬁnd a local minimum\\nif the learning rate is correctly decreased and a ﬁnite local minimum exists.\\n−4,0 −3,0 −2,0 −1,'),\n",
              " Document(metadata={}, page_content=' will happen if we wish to ﬁnd a minima using gradient descent,\\nand increase (decrease) x by the size of the gradient , and then again repeatedly keep\\njumping?\\n4. How this phenomena can be alleviated?\\n5. True or False: The gradient descent algorithm is guaranteed to ﬁnd a local minimum\\nif the learning rate is correctly decreased and a ﬁnite local minimum exists.\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−1,0\\n1,0\\n2,0\\n3,0\\n4,0\\nx = −1\\nx\\ny\\nx2\\nFIGURE 5.5: x2 Function\\nPRB-119 \\uf059 CH.PRB- 5.20.\\n1. Is the data linearly separable?\\nX1 X2 Y\\n1 1 +\\n12 12 −\\n4 5 −\\n12 12 +\\n(5.20)\\n1335.2. PROBLEMS\\n2. What is loss function for linear regression?\\n3. What is the gradient descent algorithm to minimize a function f (x)?\\n5.2.10 The Backpropagation algorithm\\nThe most important, expensive and hard to implement part of any hardware realiz-\\nation of ANNs is the non-linear activation function of a neuron. Commonly applied\\nactivation functions are the sigmoid and the hyperbolic tangent. In the most used\\nlearning algorithm in present day applications, back-propagation, the derivatives of\\nthe sigmoid function are needed when back propagating the errors.\\nThe backpropagation algorithm looks for the minimum of the error function in\\nweight space using the method of gradient descent.\\nPRB-120 \\uf059 CH.PRB- 5.21.\\n1. During the training of an ANN, a sigmoid layer applies the sigmoid function to every\\nelement in the forward pass, while in the backward pass the chain rule is being util-\\nized as part of the backpropagation algorithm. With respect to the backpropagation\\nalgorithm, given a sigmoid σ(x) = ex\\n1+ex activation function, and a J as the cost func-\\ntion, annotate each part of equation (5.21):\\ndZ = dJ\\ndσ(x)\\ndσ(x)\\ndx = dA · σ(x) ·\\n(\\n1 − σ(x)\\n)\\n(5.21)\\n2. Code snippet 5.6 provides a pure Python-based (e.g. not using Autograd) implement-\\nation of the forward pass for the sigmoid function. Complete the backward pass that\\ndirectly computes the analytical gradients.\\n134Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5 def backward(self, grad):\\n6 grad_input = [???]\\n7 return grad_input\\nFIGURE 5.6: Forward pass for the sigmoid function.\\nPRB-121 \\uf059 CH.PRB- 5.22.\\nThis question deals with the effect of customized transfer functions. Consider a neural\\nnetwork with hidden units that use x3 and output units that use sin(2x) as transfer func-\\ntions. Using the chain rule, starting from ∂E/∂yk, derive the formulas for the weight updates\\n∆wjk and ∆wij. Notice - do not include partial derivatives in your ﬁnal answer.\\n5.2.11 Feed forward neural networks\\nUnderstanding the inner-workings of Feed Forward Neural Networks (FFNN) is\\ncrucial to the understanding of other, more advanced Neural Networks such as CNN’s.\\nA Neural Network (NN) is an interconnected assembly of simple processing\\nelements, units or nodes, whose functionality is loosely based on the animal\\nneuron. The processing ability of the network is stored in the inter-unit\\nconnection strengths, or weights, obtained by a process of adaptation to, or\\nlearning from, a set of training patterns. [ 6]\\nThe Backpropagation Algorithm is the most widely used learning algorithm for\\nFFNN. Backpropagation is a training method that uses the Generalized Delta Rule . Its\\nbasic idea is to perform a gradient descent on the total squared error of the network\\noutput, considered as a function of the weights. It was ﬁrst described by Werbos and\\nmade popular by Rumelhart’s, Hinton’s and Williams’ paper [ 12].\\n1355.2. PROBLEMS\\n5.2.12 Activation functions, Autograd/JAX\\nActivation functions, and most commonly the sigmoid activation function, are\\nheavily used for the construction of NNs. We utilize Autograd'),\n",
              " Document(metadata={}, page_content=' descent on the total squared error of the network\\noutput, considered as a function of the weights. It was ﬁrst described by Werbos and\\nmade popular by Rumelhart’s, Hinton’s and Williams’ paper [ 12].\\n1355.2. PROBLEMS\\n5.2.12 Activation functions, Autograd/JAX\\nActivation functions, and most commonly the sigmoid activation function, are\\nheavily used for the construction of NNs. We utilize Autograd ([ 10]) and the recently\\npublished JAX ([ 1]) library to learn about the relationship between activation func-\\ntions and the Backpropagation algorithm.\\nUsing a logistic, or sigmoid, activation function has some beneﬁts in being able\\nto easily take derivatives and then interpret them using a logistic regression model.\\nAutograd is a core module in PyTorch ([ 11]) and adds inherit support for automatic\\ndifferentiation for all operations on tensors and functions. Moreover, one can imple-\\nment his own custom Autograd function by sub classing the autograd F unction and\\nimplementing the forward and backward passes which operate on PyTorch tensors.\\nPyTorch provides a simple syntax ( 5.7) which is transparent to both CPU/GPU sup-\\nport.\\nimport torch\\nfrom torch.autograd import Function\\nclass DLFunction(Function):\\n@staticmethod\\ndef forward(ctx, input):\\n...\\n@staticmethod\\ndef backward(ctx, grad_output):\\n...\\nFIGURE 5.7: PyTorch syntax for autograd.\\nPRB-122 \\uf059 CH.PRB- 5.23.\\n1. True or false:In Autograd, if any input tensor of an operation has requires_grad=T rue,\\nthe computation will be tracked. After computing the backward pass, a gradient w.r.t.\\nthis tensor is accumulated into .grad attribute\\n136Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. True or false: In Autograd, multiple calls to backward will sum up previously com-\\nputed gradients if they are not zeroed.\\nPRB-123 \\uf059 CH.PRB- 5.24.\\nY our friend, a veteran of the DL community wants to use logistic regression and im-\\nplement custom activation functions using Autograd. Logistic regression is used when the\\nvariable y that we want to predict can only take on discrete values (i.e. classiﬁcation). Con-\\nsidering a binary classiﬁcation problem (y = 0 or y = 1) ( 5.8), the hypothesis function could\\nbe deﬁned so that it is bounded between [0, 1] in which we use some form of logistic function,\\nsuch as the sigmoid function. Other, more efﬁcient functions exist such as the ReLU (Rec-\\ntiﬁed Linear Unit) which we discussed later. Note: The weights in ( 5.8) are only meant for\\nillustration purposes and are not part of the solution.\\nxn\\nx2\\nx1\\n1\\n∑\\nwn\\nw2\\nw1\\nw0\\n0\\n1\\n0\\n1\\nSummation Activation\\nyk =f(netk)\\ninputs weights\\nFIGURE 5.8: A typical binary classiﬁcation problem.\\n1. Given the sigmoid function: g(x) = 1\\n1+e−z what is the expression for the corresponding\\nhypothesis in logistic regression?\\n2. What is the decision boundary?\\n3. What does hΘ(x) = 0 .8 mean?\\n4. Using an Autograd based Python program, implement both the forward and backward\\npass for the sigmoid activation function and evaluate it’s derivative at x = 1\\n1375.2. PROBLEMS\\n5. Using an Autograd based Python program, implement both the forward and backward\\npass for the ReLU activation function and evaluate it’s derivative at x = 1\\nPRB-124 \\uf059 CH.PRB- 5.25.\\nFor real values, −1 < x < 1 the hyperbolic tangent function is deﬁned as:\\ntanh−1 x = 1\\n2 [ln(1 + x) − ln(1 − x)] (5.22)\\nOn the other hand, the artanh function, which returns the inverse hyperbolic tangent of\\nits argument x, is implemented in numpy as arctanh().\\nIts derivative is given by:\\n(arctanh(x))′ = 1\\n1 − x2 (5.23)\\nY our friend, a veteran of the DL community wants to implement a custom activation\\nfunction for the arctanh function using Autograd. Help him in realize the method.\\n1. Use this numpy array as an input [[0'),\n",
              " Document(metadata={}, page_content=', the artanh function, which returns the inverse hyperbolic tangent of\\nits argument x, is implemented in numpy as arctanh().\\nIts derivative is given by:\\n(arctanh(x))′ = 1\\n1 − x2 (5.23)\\nY our friend, a veteran of the DL community wants to implement a custom activation\\nfunction for the arctanh function using Autograd. Help him in realize the method.\\n1. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n2. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the forward pass for the arctanh function in Python.\\n3. Use the PyT orch based torch.autograd.F unction class to implement a custom Func-\\ntion that implements the backward pass for the arctanh function in Python.\\n4. Name the class ArtanhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\n5.2.13 Dual numbers in AD\\nDual numbers (DN) are analogous to complex numbers and augment real numbers\\n138Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nwith a dual element by adjoining an inﬁnitesimal element d, for which d2 = 0.\\nPRB-125 \\uf059 CH.PRB- 5.26.\\n1. Explain how AD uses ﬂoating point numerical rather than symbolic expressions.\\n2. Explain the notion of DN as introduced by ([ 2]).\\n3. What arithmetic operations are possible on DN?.\\n4. Explain the relationship between a T aylor series and DN.\\nPRB-126 \\uf059 CH.PRB- 5.27.\\n1. Expand the following function using DN:\\nsin(x + ˙xd) (5.24)\\n2. With respect to the expression graph depicted in 5.9:\\nx\\n3\\n* +\\n2\\ng(x)\\nFIGURE 5.9: An expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands.\\n(a) T raverse the graph5.9 and ﬁnd the function g(x) it represents.\\n(b) Expand the function g(x) using DN.\\n3. Show that the general identity :\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.25)\\n1395.2. PROBLEMS\\nholds in this particular case too.\\n4. Using the derived DN, evaluate the function g(x) at x = 2.\\n5. Using an Autograd based Python program implement the function and evaluate it’s\\nderivative at x = 2.\\nPRB-127 \\uf059 CH.PRB- 5.28.\\nWith respect to the expression graph depicted in 5.10:\\nx\\n**2\\n5\\n*\\n*\\n+\\n14\\ng(x)\\nFIGURE 5.10: An expression graph for g(x). Constants are shown in gray , crossed-out\\nsince derivatives should not be propagated to constant operands.\\n1. T raverse the graph5.10 and ﬁnd the function g(x) it represents.\\n2. Expand the function g(x) using DN.\\n3. Using the derived DN, evaluate the function g(x) at x = 5.\\n4. Using an AutoGrad based Python program implement the function and evaluate it’s\\nderivative at x = 5.\\n5.2.14 Forward mode AD\\nPRB-128 \\uf059 CH.PRB- 5.29.\\n140Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nWhen differentiating a function using forward-mode AD, the computation of such an\\nexpression can be computed from its corresponding directed a-cyclical graph by propagating\\nthe numerical values.\\n1. Find the function, g(A, B, C) represented by the expression graph in 5.11.\\nA\\nB\\nC\\nln\\n+* g (A, B, C))\\nFIGURE 5.11: A computation graph for g(x)\\n2. Find the partial derivatives for the function g(x).\\nPRB-129 \\uf059 CH.PRB- 5.30.\\nAnswer the following given that a computational graph of a function has N inputs and\\nM outputs.\\n1. True or False?:\\n(a) Forward and reverse mode AD always yield the same result.\\n(b) In reverse mode AD there are fewer operations (time) and less space'),\n",
              " Document(metadata={}, page_content=', C))\\nFIGURE 5.11: A computation graph for g(x)\\n2. Find the partial derivatives for the function g(x).\\nPRB-129 \\uf059 CH.PRB- 5.30.\\nAnswer the following given that a computational graph of a function has N inputs and\\nM outputs.\\n1. True or False?:\\n(a) Forward and reverse mode AD always yield the same result.\\n(b) In reverse mode AD there are fewer operations (time) and less space for interme-\\ndiates (memory).\\n(c) The cost for forward mode grows with N.\\n(d) The cost for reverse mode grows with M.\\nPRB-130 \\uf059 CH.PRB- 5.31.\\n1415.2. PROBLEMS\\n1. T ransform the source code in code snippet 5.1 into a function g(x1, x2).\\nCODE 5.1: A function, g(x1, x2) in the C programming language.\\n1 float g( float x1 , float x2) {\\n2 float v1, v2, v3 , v4 , v5;\\n3 v1=x1;\\n4 v2=x2;\\n5 v3 = v1 * v2;\\n6 v4 = ln (v1 );\\n7 v5 = v3 + v4;\\n8 return v5;\\n9 }\\n2. T ransform the functiong(x1, x2) into an expression graph.\\n3. Find the partial derivatives for the function g(x1, x2).\\n5.2.15 Forward mode AD table construction\\nPRB-131 \\uf059 CH.PRB- 5.32.\\n1. Given the function:\\nf (x1, x2) = x1x2 + ln (x1) (5.26)\\nand the graph 5.1, annotate each vertex (edge) of the graph with the partial derivatives\\nthat would be propagated in forward mode AD.\\n2. T ransform the graph into a table that computes the function:\\ng(x1, x2) evaluated at (x1; x2) = ( e2; π) using forward-mode AD.\\n3. Write and run a Python code snippet to prove your results are correct.\\n4. Describe the role of seed values in forward-mode AD.\\n142Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n5. T ransform the graph into a table that computes the derivative of g(x1, x2) evalu-\\nated at (x1; x2) = ( e2; π) using forward-mode AD for x1 as the chosen independent\\nvariable.\\n6. Write and run a Python code snippet to prove your results are correct.\\n5.2.16 Symbolic differentiation\\nIn this section, we introduce the basic functionality of the SymPy (SYMbolic Python)\\nlibrary commonly used for symbolic mathematics as a means to deepen your under-\\nstanding in both Python and calculus. If you are using Sympy in a Jupyter notebook\\nin Google Colab (e.g. https://colab.research.google.com/) then rendering\\nsympy equations requires MathJax to be available within each cell output. The follow-\\ning is a hook function that will make this possible:\\nCODE 5.2: Sympy in Google Colab\\n1 from IPython.display import Math, HTML\\n2 def enable_sympy_in_cell():\\n3 display(HTML(\"<script\\nsrc=\\'https://cdnjs.cloudflare.com/ajax/libs/\"↪→\\n4 \"mathjax/2.7.3/latest.js?config=default\\'>\\n5 </script>\"))\\n6 get_ipython().events.register(\\'pre_run_cell\\' ,\\nenable_sympy_in_cell)↪→\\nAfter successfully registering this hook, SymPy rendering ( 5.3) will work correctly:\\nCODE 5.3: Rendering Sympy in Google Colab\\n1 import sympy\\n2 from sympy import *\\n3 init_printing()\\n4 x, y, z = symbols(\\'x y z\\' )\\n5 Integral(sqrt(1/x), (x, 0, oo))\\n1435.2. PROBLEMS\\nIt is also recommended to use the latest version of Sympy:\\nCODE 5.4: Updating Sympy\\n> pip install --upgrade sympy\\n5.2.17 Simple differentiation\\nPRB-132 \\uf059 CH.PRB- 5.33.\\nAnswer the following questions:\\n1. Which differentiation method is inherently prone to rounding errors?\\n2. Deﬁne the term symbolic differentiation.\\nPRB-133 \\uf059 CH.PRB- 5.34.\\nAnswer the following questions:\\n1. Implement the sigmoid function σ(x) = 1\\n1+e−x symbolically using a Python'),\n",
              " Document(metadata={}, page_content='upgrade sympy\\n5.2.17 Simple differentiation\\nPRB-132 \\uf059 CH.PRB- 5.33.\\nAnswer the following questions:\\n1. Which differentiation method is inherently prone to rounding errors?\\n2. Deﬁne the term symbolic differentiation.\\nPRB-133 \\uf059 CH.PRB- 5.34.\\nAnswer the following questions:\\n1. Implement the sigmoid function σ(x) = 1\\n1+e−x symbolically using a Python based\\nSymPy program.\\n2. Differentiate the sigmoid function using SymPy and compare it with the analytical\\nderivation σ′(x) = σ(x)(1 − σ(x)).\\n3. Using SymPy, evaluate the gradient of the sigmoid function at x = 0.\\n4. Using SymPy, plot the resulting gradient of the sigmoid function.\\n5.2.18 The Beta-Binomial model\\nPRB-134 \\uf059 CH.PRB- 5.35.\\n144Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nY ou will most likely not be given such a long programming task during a face-to-face\\ninterview. Nevertheless, an extensive home programming assignment is typically given at\\nmany of the start-ups I am familiar with. Y ou should allocate around approximately four to\\nsix hours to completely answer all questions in this problem.\\nWe discussed the Beta-Binomial model extensively in chapter 3. Recall that the Beta-\\nBinomial distribution is frequently used in Bayesian statistics to model the number of suc-\\ncesses in n trials. We now employ SymPy to do the same; demonstrate computationally how\\na prior distribution is updated to develop into a posterior distribution after observing the\\ndata via the relationship of the Beta-Binomial distribution.\\nProvided the probability of success, the number of successes after n trials follows a bino-\\nmial distribution. Note that the beta distribution is a conjugate prior for the parameter of\\nthe binomial distribution. In this case, the likelihood function is binomial, and a beta prior\\ndistribution yields a beta posterior distribution.\\nRecall that for the Beta-Binomial distribution the following relationships exist:\\nPrior of θ Beta(a,b)\\nLikelihood binomial (n, θ)\\nPosterior of θ Beta (a + x, b + n − x)\\nPosterior Mean (a + x)/(a + b + n − x)\\n(5.27)\\n1. Likelihood: The starting point for our inference problem is the Likelihood, the prob-\\nability of the observed data. Find the Likelihood function symbolically using sympy.\\nConvert the SymPy representation to a purely Numpy based callable function with a\\nLambda expression. Evaluate the Likelihood function at θ = 0 .5 with 50 successful\\ntrials out of 100.\\n2. Prior: The Beta Distribution. Deﬁne the Beta distribution which will act as our prior\\ndistribution symbolically using sympy. Convert the SymPy representation to a purely\\nNumpy based callable function. Evaluate the Beta Distribution at θ : 0.5, a : 2, b : 7\\n3. Plot the Beta distribution, using the Numpy based function.\\n4. Posterior: Find the posterior distribution by multiplying our Beta prior by the Bi-\\nnomial Likelihood symbolically using sympy. Convert the SymPy representation to\\n1455.3. SOLUTIONS\\na purely Numpy based callable function. Evaluate the Posterior Distribution at θ :\\n0.5, a : 2, b : 7\\n5. Plot the posterior distribution, using the Numpy based function.\\n6. Show that the posterior distribution has the same functional dependence on θ as the\\nprior, and it is just another Beta distribution.\\n7. Given:\\nPrior : Beta(θ|a = 2, b = 7) = 56 θ (−θ + 1)6 and:\\nLikelihood : Bin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47 ﬁnd the resulting posterior\\ndistribution and plot it.\\n5.3 Solutions\\n5.3.1 Algorithmic differentiation, Gradient descent\\n5.3.2 Numerical differentiation\\nSOL-100 \\uf14b CH.SOL- 5.1.\\n1. The formulae is:\\nf ′(x) ≈ f (x + h) − f (x)\\nh . (5.28)\\n2. The main problem with this formulae is that it suffers from numerical instability for\\nsmall values of h.\\n3. In some numerical software systems, the number\\n√\\n2 may be represented as the a ﬂoat-\\ning point number ≈ 1.414213562'),\n",
              " Document(metadata={}, page_content='- 5.1.\\n1. The formulae is:\\nf ′(x) ≈ f (x + h) − f (x)\\nh . (5.28)\\n2. The main problem with this formulae is that it suffers from numerical instability for\\nsmall values of h.\\n3. In some numerical software systems, the number\\n√\\n2 may be represented as the a ﬂoat-\\ning point number ≈ 1.414213562. Therefore, the result of:\\nf loat\\n( √\\n(2)\\n)\\n∗ f loat\\n( √\\n(2)\\n)\\nmay equal ≈ 2.000000446.\\n\\x04\\nSOL-101 \\uf14b CH.SOL- 5.2.\\n146Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The instantaneous rate of change equals:\\nlim\\nh→0\\nf (a + h) − f (a)\\na + h − a . (5.29)\\n2. The instantaneous rate of change of f (x) at a is also commonly known as the tangent\\nline of f (x) at a.\\n3. Given a function f (x) and a point a, the tangent (Fig. 5.12) line of f (x) at a is a line\\nthat touches f (a) but does not cross f (x) (sufﬁciently close to a).\\nFIGURE 5.12: A Tangent line\\n\\x04\\n5.3.3 Directed Acyclic Graphs\\nSOL-102 \\uf14b CH.SOL- 5.3.\\n1475.3. SOLUTIONS\\n1. The deﬁnition is:\\nf ′(c) = lim\\nh→0\\nf (c + h) − f (c)\\nh .\\n2. If we traverse the graph 5.3 from left to right we derive the following function:\\ng(x) = 1√x . (5.30)\\nf ′(9) = lim\\nh→0\\n1/\\n√\\n9 + h − 1/\\n√\\n9\\nh\\n= lim\\nh→0\\n√\\n9 −\\n√\\n9 + h√\\n9 ·\\n√\\n9 + h · h\\n= lim\\nh→0\\n(3 −\\n√\\n9 + h)(3 +\\n√\\n9 + h)\\n3\\n√\\n9 + h · (3 +\\n√\\n9 + h) · h\\n= lim\\nh→0\\n9 − (9 + h)\\n9\\n√\\n9 + h · h + 3 · (9 + h) · h\\n= − 1\\n9 · 3 + 3 · 9\\n= − 1\\n54\\n\\x04\\nSOL-103 \\uf14b CH.SOL- 5.4.\\n1. The function g(x) = 2 x2 − x + 1 represents the expression graph depicted in 5.4.\\n148Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n2. By the deﬁnition:\\nf ′(x) = lim\\nh→0\\nf (x + h) − f (x)\\nx + h − x\\n= lim\\nh→0\\n2(x + h)2 − (x + h) + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2(x2 + 2xh + h2) − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n2x2 + 4xh + 2h2 − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n4xh + 2h2 − h\\nh\\n= lim\\nh→0\\n4x + 2h − 1\\n= 4x − 1.\\n(5.31)\\nf (x) = 2 x2 − x + 1\\nf ′(x) = 4 x − 1\\n\\x04\\n5.3.4 The chain rule\\nSOL-104 \\uf14b CH.SOL- 5.5.\\n1. The chain rule states that the partial derivative of E = E(x, y) with respect to x can be\\ncalculated via another variable y = y(x), as follows:\\n∂E\\n∂x = ∂E\\n∂y · ∂y\\n∂x (5.'),\n",
              " Document(metadata={}, page_content=' + 4xh + 2h2 − x − h + 1 − 2x2 + x − 1\\nh\\n= lim\\nh→0\\n4xh + 2h2 − h\\nh\\n= lim\\nh→0\\n4x + 2h − 1\\n= 4x − 1.\\n(5.31)\\nf (x) = 2 x2 − x + 1\\nf ′(x) = 4 x − 1\\n\\x04\\n5.3.4 The chain rule\\nSOL-104 \\uf14b CH.SOL- 5.5.\\n1. The chain rule states that the partial derivative of E = E(x, y) with respect to x can be\\ncalculated via another variable y = y(x), as follows:\\n∂E\\n∂x = ∂E\\n∂y · ∂y\\n∂x (5.32)\\n2. For instance, the chain rule [ 8] is applied in neural networks to calculate the change in\\n1495.3. SOLUTIONS\\nits weights resulting from tuning the cost function. This derivative is calculated via a\\nchain of partial derivatives (e.g. of the activation functions).\\n\\x04\\n5.3.5 Taylor series expansion\\nSOL-105 \\uf14b CH.SOL- 5.6.\\n1.\\n1\\n1 − x =\\n∞∑\\nn=0\\nxn = 1 + x + x2 + x3\\n(when −1 < x < 1) (5.33)\\n2.\\nex =\\n∞∑\\nn=0\\nxn\\nn! = 1 + x + x2\\n2! + x3\\n3! + · · · (5.34)\\n3.\\nsin x =\\n∞∑\\nn=0\\n(−1)n\\n(2n + 1)! x2n+1 = x − x3\\n3! + x5\\n5! − · · · (5.35)\\n4.\\ncos x =\\n∞∑\\nn=0\\n(−1)n\\n(2n)! x2n = 1 − x2\\n2! + x4\\n4! − · · · (5.36)\\n\\x04\\nSOL-106 \\uf14b CH.SOL- 5.7.\\n150Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nlog x =\\n∞∑\\nn=1\\n(−1)n+1 (x − 1)n\\nn = (x − 1) − (x − 1)2\\n2 +\\n(x − 1)3\\n3 − (x − 1)4\\n4 + · · ·\\n(5.37)\\n\\x04\\nSOL-107 \\uf14b CH.SOL- 5.8.\\nIn this case, all derivatives can be computed:\\nf 0(x) = 5 x2 − 11x + 1,\\nf 0(−3) = 79 ,\\nf 1(x) = 10 x − 11,\\nf 1(−3) = −41,\\nf 2(x) = 10 ,\\nf 2(−3) = 10 ,\\nf n(x) = 0, ∀n ≥ 3.\\n(5.38)\\n\\x04\\nSOL-108 \\uf14b CH.SOL- 5.9.\\nThe immediate answer is 1. Refer to eq. 5.36 to verify this logical consequence. \\x04\\nSOL-109 \\uf14b CH.SOL- 5.10.\\nBy employing eq. 5.37, one can substitute x by 3 − x and generate the ﬁrst 7 terms of the\\nx-dependable outcome before assigning the point x = 1.\\n\\x04\\n5.3.6 Limits and continuity\\nSOL-110 \\uf14b CH.SOL- 5.11.\\n1515.3. SOLUTIONS\\n1. With an indeterminate form 0/0, L’Hopital’s rule holds. We look at\\nlim\\nx→3\\n3x2ex3\\n3 = 9e27,\\nwhich equals to the original limit.\\n2. Again, we yield 0/0 at interim, so we look at the ﬁrst order derivative\\nlim\\nx→0\\n2xex − 1\\n−3 sin x − 1 = 1.\\nThe original limit is also equal to 1.\\n3. This time, the intermediate form is of ∞/∞ and L’Hopital applies as well. The quotient\\nof the derivatives is\\n1 − 1\\nx\\n0.01x'),\n",
              " Document(metadata={}, page_content='. Again, we yield 0/0 at interim, so we look at the ﬁrst order derivative\\nlim\\nx→0\\n2xex − 1\\n−3 sin x − 1 = 1.\\nThe original limit is also equal to 1.\\n3. This time, the intermediate form is of ∞/∞ and L’Hopital applies as well. The quotient\\nof the derivatives is\\n1 − 1\\nx\\n0.01x−99/100 = 100(x − 1)x1/99\\nAs x → ∞, this goes to ∞, so the original limit is equal to ∞ also.\\n\\x04\\n5.3.7 Partial derivatives\\nSOL-111 \\uf14b CH.SOL- 5.12.\\n1. T rue.\\n2. By treating y as constant, one can derive that\\n∂g\\n∂x = 2xy + y. (5.39)\\n\\x04\\nSOL-112 \\uf14b CH.SOL- 5.13.\\n152Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1.\\n∇f (x, y) = ∂f\\n∂x i + ∂f\\n∂y j\\n=\\n(\\ny2 + 3x2\\n)\\ni + (2xy − 2y) j\\n(5.40)\\n2. It can be shown that ∇g(x, y) = (2 xy + y2) i + (x2 + 2xy − 1) j at (−1, 0) equals\\n(0, 0). According to the deﬁnition of directional derivative:\\n(0, 0) · (1, 1)\\n|(1, 1)| = 0 (5.41)\\n\\x04\\nSOL-113 \\uf14b CH.SOL- 5.14.\\n∂f\\n∂x = 6 sin(x − y) cos(x − y)\\n∂f\\n∂y = −6 sin(x − y) cos(x − y)\\n(5.42)\\n\\x04\\nSOL-114 \\uf14b CH.SOL- 5.15.\\n∂z\\n∂x = 2 cos x sin y\\n∂z\\n∂y = 2 sin x cos y\\n(5.43)\\n\\x04\\n5.3.8 Optimization\\nSOL-115 \\uf14b CH.SOL- 5.16.\\n1535.3. SOLUTIONS\\n1. The function is only deﬁned where x ̸= −2, in the domain of:\\n(−∞, −2) ∪ (−2, +∞).\\n2. By a simple quotient-based derivation:\\nf ′(x) = 2(x + 2)(2x − 1)\\n(x + 2)4 . (5.44)\\nNamely, expect for the ill-deﬁned x = −2, the critical point of x = 0 .5 should be\\nconsidered. For x > 0.5, the derivative is positive and the function increases, in contrast\\nto x < 0.5.\\n3. The requested coordinate is (0.5, 0.2).\\n\\x04\\nSOL-116 \\uf14b CH.SOL- 5.17.\\n1. f ′(x) = 6 x2 − 1, which entails the behavior of the function changes around the points\\nx = ± 1√\\n6. The derivative is negative between x = − 1√\\n6 and x = 1√\\n6, i.e., it decreases\\nin the domain, and increases otherwise.\\n2. The second derivative is f ′′(x) = 12 x, which means the function is concave for negative\\nx values and convex otherwise.\\n\\x04\\nSOL-117 \\uf14b CH.SOL- 5.18.\\nThe function should be derived according to each variable separately and be equated to 0,\\nas follows:\\nfx(x, y) = 4 x − y = 0 , f y(x, y) = −y + 2y = 0 .\\nSo, the solution to these equations yield the coordinate (0, 0), and f (0, 0) = 0 .\\nLet us derive the second order derivative, as follows:\\n∂2f\\n∂x2 (x, y) = 4 , ∂2f\\n∂y2 (x, y) = 2 , ∂2f\\n∂x∂y (x, y) = −1 ,\\n154Chapter 5 DEEP LE'),\n",
              " Document(metadata={}, page_content=' the solution to these equations yield the coordinate (0, 0), and f (0, 0) = 0 .\\nLet us derive the second order derivative, as follows:\\n∂2f\\n∂x2 (x, y) = 4 , ∂2f\\n∂y2 (x, y) = 2 , ∂2f\\n∂x∂y (x, y) = −1 ,\\n154Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nAlso, the following relation exists:\\nD(x, y) = ∂2f\\n∂x2\\n∂2f\\n∂y2 −\\n(\\n∂2f\\n∂x∂y\\n) 2\\n= 7 ,\\nThus, the critical point (0, 0) is a minimum. \\x04\\n5.3.9 The Gradient descent algorithm\\nSOL-118 \\uf14b CH.SOL- 5.19.\\n1. It is the gradient of a function which is mathematically represented by:\\n∇f (x, y) =\\n\\uf8eb\\n\\uf8ec\\uf8ed\\n∂f (x,y)\\n∂x\\n∂f (x,y)\\n∂y\\n\\uf8f6\\n\\uf8f7\\uf8f8 (5.45)\\n2. Increasing.\\n3. We will keep jumping between the same two points without ever reaching a minima.\\n4. This phenomena can be alleviated by using a learning rate or step size . For instance,\\nx+ = 2 ∗ η where η is a learning rate with small value such as η = 0.25.\\n5. T rue.\\n\\x04\\nSOL-119 \\uf14b CH.SOL- 5.20.\\n1. The point (12,12) has two classes, so the classes cannot be separated by any line.\\n2.\\nJ(θ) = 1\\n2m\\nm∑\\ni=1\\n(ˆyi − yi)2\\n(5.46)\\n1555.3. SOLUTIONS\\n3. Simple but fundamental algorithm for minimizing f . Just repeatedly move in the direc-\\ntion of the negative gradient\\n(a) Start with initial guess θ(0), step size η\\n(b) For k = 1, 2, 3, . . .:\\ni. Compute the gradient ∇f (θ(k−1))\\nii. Check if gradient is close to zero; is so stop, otherwise continue\\niii. Update θ(k) = θ(k−1) − η∇f (θ(k−1))\\n(c) Return ﬁnal θ(k) as approximate solution θ∗\\n\\x04\\n5.3.10 The Backpropagation algorithm\\nSOL-120 \\uf14b CH.SOL- 5.21.\\n1. The annotated parts of equation (5.21) appear in (5.47):\\nσ(x) = ex\\n1 + ex = The Sigmoid activation function\\nσ(x) ·\\n(\\n1 − σ(x)\\n)\\nThe deriviative of the Sigmoid activation function =\\n1Z = The input\\ndZ = The error introduced by input Z.\\nA = The output\\ndA = The error introduced by output A.\\n(5.47)\\n2. Code snippet 5.13 provides an implementation of both the forward and backward passes\\nfor the sigmoid function.\\n156Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 class Sigmoid:\\n2 def forward(self,x):\\n3 self.x = x\\n4 return 1/(1+np.exp(-x))\\n5\\n6 def backward(self, grad):\\n7 grad_input = self.x*(1-self.x) * grad\\n8 return grad_input\\nFIGURE 5.13: Forward and backward passes for the sigmoid activation function in pure\\nPython.\\n\\x04\\nSOL-121 \\uf14b CH.SOL- 5.22.\\nThe key concept in this question is merely understanding that the transfer function and\\nits derivatives are changing compared to traditional activation functions, namely:\\n∂E\\n∂yk\\n= (yk − dk) (5.48)\\n∂E\\n∂netk\\n= ∂E\\n∂yk\\n· ∂yk\\n∂netk\\n= (yk − dk) · 2 cos(2netk) (5.49)\\n∆wjk = −η ∂E\\n∂wjk\\n= −η ∂E\\n∂netk\\n· ∂netk\\n∂wjk\\n= −η · (yk − dk) · 2 cos(2netk) · yj ('),\n",
              " Document(metadata={}, page_content='= ∂E\\n∂yk\\n· ∂yk\\n∂netk\\n= (yk − dk) · 2 cos(2netk) (5.49)\\n∆wjk = −η ∂E\\n∂wjk\\n= −η ∂E\\n∂netk\\n· ∂netk\\n∂wjk\\n= −η · (yk − dk) · 2 cos(2netk) · yj (5.50)\\n∂E\\n∂yj\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\n· ∂netk\\n∂yj\\n)\\n=\\n∑\\nk\\n(\\n∂E\\n∂netk\\nwjk\\n)\\n(5.51)\\n∂E\\n∂netj\\n= ∂E\\n∂yj\\n· ∂yj\\n∂netj\\n= ∂E\\n∂yj\\n· 3net2\\nj (5.52)\\n1575.3. SOLUTIONS\\n∆wij = −η ∂E\\n∂wij\\n= −η ∂E\\n∂netj\\n· ∂netj\\n∂wij\\n= −η · (∑\\nk [(yk − dk) · 2 cos(2netk) · wjk]) · 3net2\\nj · yi\\n(5.53)\\n\\x04\\n5.3.11 Feed forward neural networks\\n5.3.12 Activation functions, Autograd/JAX\\nSOL-122 \\uf14b CH.SOL- 5.23.\\n1. T rue.\\n2. T rue.\\n\\x04\\nSOL-123 \\uf14b CH.SOL- 5.24.\\nThe answers are as follows:\\n1. hΘ(x) = g(ΘT x) = 1\\n1+e−Θ\\nT\\nx\\n.\\n2. The decision boundary for the logistic sigmoid function is where hΘ(x) = 0 .5 (values\\nless than 0.5 mean false, values equal to or more than 0.5 mean true).\\n3. That there is a 80% chance that the instance is of the corresponding class, therefore:\\n• hΘ(x) = g(Θ0 + Θ1x1 + Θ2x2). We can predict y = 1 if x0 + x1 + x2 ≥ 0.\\n4. The code snippet in 5.14 implements the function using Autograd.\\n158Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 from torch.autograd import Function\\n2 class Sigmoid(Function):\\n3 @staticmethod\\n4 def forward(ctx, x):\\n5 output = 1 / (1 + torch.exp(-x))\\n6 ctx.save_for_backward(output)\\n7 return output\\n8\\n9 @staticmethod\\n10 def backward(ctx, grad_output):\\n11 output, = ctx.saved_tensors\\n12 grad_x = output * (1 - output) * grad_output\\n13 return grad_x\\nFIGURE 5.14: Forward and backward for the sigmoid function in Autograd.\\n5. The code snippet in 5.15 implements the function using Autograd.\\n1595.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ReLU(torch.autograd.Function):\\n3 @staticmethod\\n4 def forward(ctx, input):\\n5 ctx.save_for_backward(input)\\n6 return input.clamp(min=0)\\n7\\n8 @staticmethod\\n9 def backward(ctx, grad_output):\\n10 input, = ctx.saved_tensors\\n11 grad_input = grad_output.clone()\\n12 grad_input[input < 0] = 0\\n13 return grad_input\\nFIGURE 5.15: Forward and backward for the ReLU function in Autograd.\\n\\x04\\nSOL-124 \\uf14b CH.SOL- 5.25. The answers are as follows:\\n1. Code snippet 5.16 implements the forward pass using pure Python.\\n160Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n3 requires_grad=True)).type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 arctanh_values = np.arctanh(xT_np)\\n7 print (\"Numpy:\", arctanh_values)\\n8 > Numpy: [[ 0.38842311 0.1944129 0.64900533]]\\nFIGURE 5.16: Forward pass for equation ( 5.23) using pure Python.\\n'),\n",
              " Document(metadata={}, page_content='type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 arctanh_values = np.arctanh(xT_np)\\n7 print (\"Numpy:\", arctanh_values)\\n8 > Numpy: [[ 0.38842311 0.1944129 0.64900533]]\\nFIGURE 5.16: Forward pass for equation ( 5.23) using pure Python.\\n2. Code snippet 5.17 implements the forward pass using Autograd.\\n1 import torch\\n2 from torch.autograd import Function\\n3 class ArtanhFunction(Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward(x)\\n7 r = (torch.log_(1 + x).sub_(torch.log_(1 - x))).mul_(0.5)\\n8 return r\\nFIGURE 5.17: Forward pass for equation ( 5.23).\\n3. Code snippet 5.18 implements the backward pass using Autograd.\\n1615.3. SOLUTIONS\\n1 from torch.autograd import Function\\n2 class ArtanhFunction(Function):\\n3 @staticmethod\\n4 input, = ctx.saved_tensors\\n5 out= grad_output / (1 - input ** 2)\\n6 print (\"backward:{}\".format(out))\\n7 return out\\nFIGURE 5.18: Backward pass for equation ( 5.23).\\n4. Code snippet 5.19 veriﬁes the correctness of the implementation using gradcheck.\\n1 import numpy as np\\n2\\n3 xT =\\ntorch.abs(torch.tensor([[0.11,0.19,0.57]],requires_grad=True))↪→\\n4 .type(torch.DoubleTensor)\\n5 arctanh_values_torch = arctanhPyTorch(xT)\\n6 print (\"Torch:\", arctanh_values_torch)\\n7 from torch.autograd import gradcheck, Variable\\n8 f = ArtanhFunction.apply\\n9 test=gradcheck(lambda t: f(t), xT)\\n10 print(test)\\n11\\n12 > PyTorch version: 1.7.0\\n13 > Torch: tensor([[ 0.3884, 0.1944, 0.6490]], dtype =torch.float64,\\n14 > grad_fn=<ArtanhFunctionBackward>)\\n15 > backward:tensor([[1.1586, 1.0383,1.4838]], dtype =torch.float64,\\n16 grad_fn=<CopyBackwards>)\\nFIGURE 5.19: Invoking arctanh using gradcheck\\n162Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n\\x04\\n5.3.13 Dual numbers in AD\\nSOL-125 \\uf14b CH.SOL- 5.26.\\nThe answers are as follows:\\n1. The procedure of AD is to use verbatim text of a computer program which calculates\\na numerical value and to transform it into the text of a computer program called the\\ntransformed program which calculates the desired derivative values. The transformed\\ncomputer program carries out these derivative calculations by repeated use of the chain\\nrule however applied to actual ﬂoating point values rather than to a symbolic rep-\\nresentation.\\n2. Dual numbers extend all numbers by adding a second component x ↦→ x + ˙xd where\\nx + ˙x is the dual part.\\n3. The following arithmetic operations are possible on DN:\\n(a) d2 = 0\\n(b) (x + ˙xd) + (y + ˙yd) = x + y + ( ˙x + ˙y)d\\n(c) −(x + ˙xd) = −x − ˙xd\\n(d) 1\\nx+ ˙xd = 1\\nx − ˙x\\nx2 d\\n4. For f (x + ˙xd) the T aylor series expansion is:\\nf (x + ˙xd) = f (x) + f ′(x)\\n1! ˙xd + . . .0 (5.54)\\nThe immediate and important result is that all higher-order terms (n >= 2) disappear\\nwhich provides closed-form mathematical expression that represents a function and its\\nderivative.\\n\\x04\\nSOL-126 \\uf14b CH.SOL- 5.27.\\n1635.3. SOLUTIONS\\nThe answers are as follows:\\n1.\\nsin(x + ˙xd) = sin( x) + cos(x) ˙xd (5.55)\\n2. If we traverse the graph 5.9 from left to right we drive the following simple function:\\ng(x) = 3 ∗ x + '),\n",
              " Document(metadata={}, page_content=' function and its\\nderivative.\\n\\x04\\nSOL-126 \\uf14b CH.SOL- 5.27.\\n1635.3. SOLUTIONS\\nThe answers are as follows:\\n1.\\nsin(x + ˙xd) = sin( x) + cos(x) ˙xd (5.55)\\n2. If we traverse the graph 5.9 from left to right we drive the following simple function:\\ng(x) = 3 ∗ x + 2 (5.56)\\n3. We know that:\\ng(x) = 3 ∗ x + 2 (5.57)\\ng′(x) = 3 (5.58)\\nNow if we expand the function using DN:\\ng(x + ˙xd) = 3 ∗ (x + ˙xd) + 2 = (5.59)\\n3 ∗ x + 3 ∗ ( ˙xd) + 2 (5.60)\\nRearranging:\\n3 ∗ x + 2 + 3 ∗ ( ˙xd) (5.61)\\nBut since g(x) = 3 ∗ x + 2 then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.62)\\n4. Evaluating the function g(x) at x = 2 using DN we get:\\ng(x = 2) = (3 ∗ 2 + 2) + (3) ˙xd = (5.63)\\n8 + (3) ˙xd (5.64)\\n5. The code snippet in 5.20 implements the function using Autograd.\\n164Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([2.0], dtype =float)\\n4 def f1(x):\\n5 return 3*x + 2\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 8.0\\n8 print(grad_f1(x)) # > 3.0\\nFIGURE 5.20: Autograd\\n\\x04\\nSOL-127 \\uf14b CH.SOL- 5.28. The answers are as follows:\\n1. If we traverse the graph 5.9 from left to right we drive the following function:\\ng(x) = 5 ∗ x2 + 4 ∗ x + 1 (5.65)\\n2. We know that:\\ng(x1) = 5 ∗ x2 + 4 ∗ x + 1 (5.66)\\ng′(x1) = 10 ∗ x1 + 4 (5.67)\\nNow if we expand the function using DN we get:\\ng(x + ˙xd) = 5 ∗ (x + ˙xd)2 + 4 ∗ (x + ˙xd) + 1 = (5.68)\\n5 ∗ (x2 + 2 ∗ x + ˙xd + ( ˙xd)2) + 4 ∗ x + 4 ∗ ( ˙xd) + 1 (5.69)\\n1655.3. SOLUTIONS\\nHowever by deﬁnition (d2) = 0 and therefore that term vanishes. Rearranging the\\nterms:\\n(5 ∗ x2 + 4 ∗ x + 1) + (10 ∗ x + 4) ˙xd (5.70)\\nBut since g(x) = (5 ∗ x2 + 4 ∗ x + 1) then:\\ng(x + ˙xd) = g(x) + g′(x) ˙xd (5.71)\\n3. Evaluating the function g(x) at x = 5 using DN we get:\\ng(x = 4) = (5 ∗ 52 + 4 ∗ 5 + 1) + (10 ∗ 5 + 4) ˙xd =\\n146 + (54) ˙xd (5.72)\\n4. The code snippet in 5.21 implements the function using Autograd.\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([5.0], dtype =float)\\n4 def f1(x):\\n5 return 5*x**2 + 4*x +1\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 146.0\\n8 print(grad_f1(x)) # > 54.0\\nFIGURE 5.21: Aut'),\n",
              " Document(metadata={}, page_content=' implements the function using Autograd.\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 x = np.array([5.0], dtype =float)\\n4 def f1(x):\\n5 return 5*x**2 + 4*x +1\\n6 grad_f1 = grad(f1)\\n7 print(f1(x)) # > 146.0\\n8 print(grad_f1(x)) # > 54.0\\nFIGURE 5.21: Autograd\\n\\x04\\n5.3.14 Forward mode AD\\nSOL-128 \\uf14b CH.SOL- 5.29.\\nThe answers are as follows:\\n166Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1. The function g(x) represented by the expression graph in 5.11 is:\\ng(x) = A + B ∗ ln(C) (5.73)\\n2. For a logarithmic function:\\nd\\ndx ln(x) = 1\\nx (5.74)\\nTherefore, the partial derivatives for the function g(x) are:\\n∂f\\n∂A = 1\\n∂f\\n∂B = ln(C)\\n∂f\\n∂C = B ∗ 1\\nC\\n(5.75)\\n\\x04\\nSOL-129 \\uf14b CH.SOL- 5.30. The answers are as follows:\\n1. T rue. Both directions yield the exact same results.\\n2. T rue. Reverse mode is more efﬁcient than forward mode AD (why?).\\n3. T rue.\\n4. T rue.\\n\\x04\\nSOL-130 \\uf14b CH.SOL- 5.31.\\nThe answers are as follows:\\n1675.3. SOLUTIONS\\n1. The function is\\nf (x1, x2) = x1x2 + ln (x1) (5.76)\\n2. The graph associated with the forward mode AD is as follows:\\nx1\\nx2\\n*\\n+\\nln\\nf (x1, x2)\\nFIGURE 5.22: A Computation graph for g(x1, x2) in 5.1\\n3. The partial derivatives are:\\n∂f\\n∂x1\\n= x2 − 1\\n(x1)\\n∂f\\n∂x2\\n= x1\\n(5.77)\\n\\x04\\n5.3.15 Forward mode AD table construction\\nSOL-131 \\uf14b CH.SOL- 5.32.\\nThe answers are as follows:\\n1. The graph with the intermediate values is depicted in ( 5.23)\\n168Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nx1\\nx2\\n*\\n+\\nln\\ng(x1, x2)\\nv1\\nv2\\nv1 v4\\nv3\\nv5\\nFIGURE 5.23: A derivative graph for g(x1, x2) in 5.1\\n2. Forward mode AD for g (x1, x2) = ln ( x1) + x1x2 evaluated at (x1, x2) = ( e2, π).\\nForward-mode function evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\nv1 = ln v−1 = ln (e2) = 2\\nv2 = v−1 × v0 = e2 × π = 23.2134\\nv3 = v1 + v2 2 + 23.2134 = 25 .2134\\nf = v3 =≈ 25.2134\\nTABLE 5.1: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n3. The following Python code ( 5.24) proves that the numerical results are correct:\\n1695.3. SOLUTIONS\\n1 import math\\n2 print (math.log(math.e*math.e) + math.e*math.e*math.pi)\\n3 > 25.2134^^I\\nFIGURE 5.24: Python code- AD of the function g(x1, x2)\\n4. Seed values indicate the values by which the dependent and independent variables are\\ninitialized to before being propagated in a computation graph. For instance:\\n˙v1 = ∂x1\\n∂x1\\n= 1\\n˙v2 = ∂x2\\n∂x1\\n= 0\\nTherefore we set ˙x1 = 1'),\n",
              " Document(metadata={}, page_content='\\nFIGURE 5.24: Python code- AD of the function g(x1, x2)\\n4. Seed values indicate the values by which the dependent and independent variables are\\ninitialized to before being propagated in a computation graph. For instance:\\n˙v1 = ∂x1\\n∂x1\\n= 1\\n˙v2 = ∂x2\\n∂x1\\n= 0\\nTherefore we set ˙x1 = 1 to compute ∂y\\n∂x1\\n.\\n5. Here we construct a table for the forward-mode AD for the derivative of f (x1, x2) =\\nln (x1) + x1x2 evaluated at (x1, x2) = ( e2, π) while setting ˙x1 = 1 to compute ∂y\\n∂x1\\n.. In\\nforward-mode AD a derivative is called a tangent.\\nIn the derivation that follows, note that mathematically using manual differentiation:\\nd\\ndx1\\n[ln(x) + x2x]\\n= d\\ndx1\\n[ln(x1)] + x2 · d\\ndx1\\n[x1]\\n= 1\\nx1\\n+ x2 · 1\\n= 1\\nx1\\n+ x2\\nand also since d\\ndx ln(x) = 1\\nx then ˙v1 = 1\\nv−1\\n∗ ˙v−1 = ˙v−1/v−1 = 1\\ne2 ∗ 1 = 1 /e2.\\n170Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nForward-mode AD derivative evaluation\\nv−1 = x1 = e2\\nv0 = x2 = π\\n˙v−1 = ˙x1 = 1\\n˙v0 = ˙x2 = 0\\n˙v1 = ˙v−1/v−1 = 1/e2\\n˙v2 = ˙v−1 × v0 + ˙v0 ×\\nv−1 = 1 × π + 0 ×\\ne2 = π\\n˙v4 = ˙v1 + ˙v2 = 1/e2 +\\nπ\\n˙f = ˙v4 = 1 /e2 +\\nπ =≈ 3.2769\\nTABLE 5.3: Forward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute ∂y\\n∂x1\\n.\\n6. The following Python code ( 5.25) proves that the numerical results are correct:\\n1715.3. SOLUTIONS\\n1 import autograd.numpy as np\\n2 from autograd import grad\\n3 import math\\n4\\n5 x1 = math.e* math.e\\n6 x2 = math.pi\\n7\\n8 def f1(x1,x2):\\n9 return (np.log(x1) + x1*x2)\\n10\\n11 grad_f1 = grad(f1)\\n12\\n13 print(f1(x1,x2)) # > 25.2134\\n14 print(grad_f1(x1,x2)) # > 3.2769\\nFIGURE 5.25: Python code- AD of the function g(x1, x2)\\n\\x04\\n5.3.16 Symbolic differentiation\\n5.3.17 Simple differentiation\\nSOL-132 \\uf14b CH.SOL- 5.33.\\nThe answers are as follows:\\n1. Approximate methods such as numerical differentiation suffer from numerical instabil-\\nity and truncation errors.\\n2. In symbolic differentiation, a symbolic expression for the derivative of a function is\\ncalculated. This approach is quite slow and requires symbols parsing and manipulation.\\nFor example, the number\\n√\\n2 is represented in SymPy as the object Pow(2,1/2). Since\\nSymPy employees exact representations Pow(2,1/2)*Pow(2,1/2) will always equal 2.\\n\\x04\\n172Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nSOL-133 \\uf14b CH.SOL- 5.34.\\n1. First:\\n1 import sympy\\n2 sympy.init_printing()\\n3 from sympy import Symbol\\n4 from sympy import diff, exp, sin, sqrt\\n5 y = Symbol(\\'y\\' )\\n6 y = sympy.Symbol(\"y'),\n",
              " Document(metadata={}, page_content='2) will always equal 2.\\n\\x04\\n172Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\nSOL-133 \\uf14b CH.SOL- 5.34.\\n1. First:\\n1 import sympy\\n2 sympy.init_printing()\\n3 from sympy import Symbol\\n4 from sympy import diff, exp, sin, sqrt\\n5 y = Symbol(\\'y\\' )\\n6 y = sympy.Symbol(\"y\")\\n7 sigmoid = 1/(1+sympy.exp(-y))^^I\\nFIGURE 5.26: Sigmoid in SymPy\\n2. Second:\\n1 sig_der=sym.diff(sigmoid, y)\\nFIGURE 5.27: Sigmoid gradient in SymPy\\n3. Third:\\n1 sig_der.evalf(subs={y:0})\\n2 > 0.25\\nFIGURE 5.28: Sigmoid gradient in SymPy\\n1735.3. SOLUTIONS\\n4. The plot is depicted in 5.29.\\n1 p = sym.plot(sig_der);\\n10.0\\n 7.5\\n 5.0\\n 2.5\\n 0.0 2.5 5.0 7.5 10.0\\ny\\n0.00\\n0.05\\n0.10\\n0.15\\n0.20\\n0.25f(y)\\nFIGURE 5.29: SymPy gradient of the Sigmoid() function\\n\\x04\\n5.3.18 The Beta-Binomial model\\nSOL-134 \\uf14b CH.SOL- 5.35.\\nT o correctly render the generated LaT eX in this problem, we import and conﬁgure several\\nlibraries as depicted in 5.30.\\n174Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 import numpy as np\\n2 import scipy.stats as st\\n3 import matplotlib.pyplot as plt\\n4 import sympy as sp\\n5 sp.interactive.printing.\\n6 init_printing(use_latex=True)\\n7 from IPython.display import display, Math, Latex\\n8 maths = lambda s: display(Math(s))\\n9 latex = lambda s: display(Latex(s)) ^^I\\nFIGURE 5.30: SymPy imports\\n1. The Likelihood function can be created as follows. Note the speciﬁc details of generating\\nthe Factorial function in SymPy.\\n1755.3. SOLUTIONS\\n1 n = sp.Symbol(\\'n\\' , integer =True, positive =True)\\n2 r = sp.Symbol(\\'r\\' , integer =True, positive =True)\\n3 theta = sp.Symbol(\\'theta\\' )\\n4 # Create the function symbolically\\n5 from sympy import factorial\\n6 cNkSym= (factorial(n))/ (factorial(r) *factorial(n-r))\\n7 cNkSym.evalf()\\n8 binomSym= cNkSym*((theta **r)*(1-theta)**(n-r))\\n9 binomSym.evalf()\\n10 #Convert it to a Numpy-callable function\\n11 binomLambda = sp.Lambda((theta,r,n), binomSym)\\n12 maths(r\"\\\\operatorname{Bin}(r|n,\\\\theta) = \" )\\n13 display (binomLambda .expr)\\n14 #Evaluating the SymPy version results in:\\n15 > binomSym.subs({theta:0.5,r:50,n:100})\\n16 #Evaluating the pure Numpy version results in:\\n17 > binomLambda(0.5,50,100)= 0.07958923\\nFIGURE 5.31: Likelihood function using SymPy\\nThe Symbolic representation results in the following LaT eX:\\nBin(r|n, θ) = θr (−θ + 1)n−r n!\\nr! (n − r)! (5.78)\\n2. The Beta distribution can be created as follows.\\n176Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 #mu = sp.Symbol(\\'mu\\', integer=False, positive=True)\\n4 # Create the function symbolically\\n5 G = sp.gamma\\n6 # The normalisation factor\\n7 BetaNormSym = G(a + b)/(G(a)*G(b))\\n8 # The functional form\\n9 BetaFSym = theta**(a-1) * (1-theta)**(b-1)\\n10 BetaSym=BetaNormSym * BetaFSym\\n11 BetaSym.evalf() # this works\\n12 # Turn'),\n",
              " Document(metadata={}, page_content='.Symbol(\\'mu\\', integer=False, positive=True)\\n4 # Create the function symbolically\\n5 G = sp.gamma\\n6 # The normalisation factor\\n7 BetaNormSym = G(a + b)/(G(a)*G(b))\\n8 # The functional form\\n9 BetaFSym = theta**(a-1) * (1-theta)**(b-1)\\n10 BetaSym=BetaNormSym * BetaFSym\\n11 BetaSym.evalf() # this works\\n12 # Turn Beta into a function\\n13 BetaLambda = sp.Lambda((theta,a,b), BetaNormSym * BetaFSym)\\n14 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) = \" )\\n15 display(BetaSym)\\n16 #Evaluating the SymPy version results in:\\n17 > BetaLambda(0.5,2,7)=0.4375\\n18 #Evaluating the pure Numpy version results in:\\n19 > BetaSym.subs({theta:0.5,a:2,b:7})=0.4375\\nFIGURE 5.32: Beta distribution using SymPy\\nThe result is:\\nBeta(θ|a, b) = θa−1Γ(a + b)\\nΓ(a)Γ(b) (−θ + 1)b−1 (5.79)\\n3. The plot is depicted in 5.33.\\n1775.3. SOLUTIONS\\n1 %pylab inline\\n2 mus = arange(0,1,.01)\\n3 # Plot for various values of a and b\\n4 for ab in [(.1,.1),(.5,.5),(2,20),(2,3), ( 1,1)]:\\n5 plot(mus, vectorize(BetaLambda)(mus, *ab), label =\"a=%s b=%s\" % ab)\\n6 legend(loc=0)\\n7 xlabel(r\"$\\\\theta$\", size =22)\\nFIGURE 5.33: A plot of the Beta distribution\\n4. We can ﬁnd the posterior distribution by multiplying our Beta prior by the Binomial\\nLikelihood.\\n178Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 a = sp.Symbol(\\'a\\' , integer =False, positive =True)\\n2 b = sp.Symbol(\\'b\\' , integer =False, positive =True)\\n3 BetaBinSym=BetaSym * binomSym\\n4 # Turn Beta-bin into a function\\n5 BetaBinLambda = sp.Lambda((theta,a,b,n,r), BetaBinSym)\\n6 BetaBinSym=BetaBinSym.powsimp()\\n7 display(BetaBinSym)\\n8 maths(r\"\\\\operatorname{Beta}(\\\\theta|a,b) \\\\times\\n\\\\operatorname{Bin}(r|n,\\\\theta) \\\\propto %s\" %\\nsp.latex(BetaBinSym))\\n↪→\\n↪→\\n9 > BetaBinSym.subs({theta:0.5,a:2,b:7,n:10,r:3})= 0.051269\\n10 > BetaBinLambda ( 0.5,2,7, 10,3)= 0.051269\\nFIGURE 5.34: A plot of the Beta distribution\\nThe result is:\\nBeta(θ|a, b) × Bin(r|n, θ) ∝\\nθa+r−1 (−θ + 1)b+n−r−1 n!\\nr! (n − r)!Γ(a)Γ(b) Γ(a + b)\\nSo the posterior distribution has the same functional dependence on θ as the prior, it is\\njust another Beta distribution.\\n5. Mathematically, the relationship is as follows:\\n1795.3. SOLUTIONS\\nPrior :\\nBeta(θ|a = 2, b = 7)\\n= 56θ (−θ + 1)6\\nLikelihood :\\nBin(r = 3|n = 6, θ) = 19600 θ3 (−θ + 1)47\\nPosterior(normalised) :\\nBeta(θ|2, 7) × Bin(3|50, θ) = 1097600 θ4 (−θ + 1)53\\n(5.80)\\n180Chapter 5 DEEP LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 prior = BetaLambda(theta,2,7)\\n2 maths(\"\\\\mathbf{Prior}:\\\\operatorname{Beta}(\\\\theta|a=2,b=7) = %s\" %\\nsp.latex(prior))↪→\\n3 likelihood = binomLambda(theta,3,50) # = binomLambda(0.5,3,10)\\n4 maths(\"\\\\mathbf{Likelihood'),\n",
              " Document(metadata={}, page_content=' LEARNING: CALCULUS, ALGORITHMIC DIFFERENTIATION\\n1 prior = BetaLambda(theta,2,7)\\n2 maths(\"\\\\mathbf{Prior}:\\\\operatorname{Beta}(\\\\theta|a=2,b=7) = %s\" %\\nsp.latex(prior))↪→\\n3 likelihood = binomLambda(theta,3,50) # = binomLambda(0.5,3,10)\\n4 maths(\"\\\\mathbf{Likelihood}: \\\\operatorname{Bin}(r=3|n=6, \\\\theta) =\\n%s\" % sp.latex(likelihood))↪→\\n5 posterior = prior * likelihood\\n6 posterior=posterior.powsimp()\\n7 maths(r\"\\\\mathbf{Posterior\\n(normalised)}:\\\\operatorname{Beta}(\\\\theta|2,7) \\\\times\\n\\\\operatorname{Bin}(3|50,\\\\theta)=%s\"\\n↪→\\n↪→\\n8 posterior.subs({theta:0.5})\\n9 plt.plot(mus, (sp .lambdify(theta,posterior))(mus), \\'r\\' )\\n10 xlabel(\"$\\\\\\\\theta$\", size =22)\\nFIGURE 5.35: A plot of the Posterior with the provided data samples.\\n\\x04\\nReferences\\n[1] J. Bradbury et al. JAX: composable transformations of NumPy programs. 2018 (cit. on\\npp. 123, 136).\\n181REFERENCES\\n[2] W. K. Clifford. ‘Preliminary Sketch of Bi-quaternions’. In: Proceedings of the Lon-\\ndon Mathematical Society 4 (1873), pp. 381–95 (cit. on pp. 125, 139).\\n[3] R. Frostig et al. JAX: Autograd and XLA . 2018 (cit. on p. 123).\\n[4] A. Griewank, D. Juedes and J. Utke. ‘Algorithm 755; ADOL-C: a package for the\\nautomatic differentiation of algorithms written in C/C++’. In: ACM T ransactions\\non Mathematical Software 22.2 (June 1996), pp. 131–167 (cit. on pp. 123, 125).\\n[5] A. Griewank and A. Walther. Evaluating Derivatives: Principles and T echniques\\nof Algorithmic Differentiation . Second. USA: Society for Industrial and Applied\\nMathematics, 2008 (cit. on pp. 123, 124).\\n[6] K. Gurney. An Introduction to Neural Networks . 1 Gunpowder Square, London\\nEC4A 3DE, UK: UCL Press, 1998 (cit. on p. 135).\\n[7] L. V . Kantorovich. ‘On a mathematical symbolism convenient for performing\\nmachine calculations’. In: Dokl. Akad. Nauk SSSR . V ol. 113. 4. 1957, pp. 738–741\\n(cit. on p. 123).\\n[8] G. Kedem. ‘Automatic differentiation of computer programs’. In: ACM T ransac-\\ntions on Mathematical Software (TOMS) 6.2 (1980), pp. 150–165 (cit. on pp. 126,\\n149).\\n[9] S. Laue. On the Equivalence of Forward Mode Automatic Differentiation and Symbolic\\nDifferentiation. 2019. arXiv: 1904.02990 [cs.SC] (cit. on p. 124).\\n[10] D. Maclaurin, D. Duvenaud and R. P . Adams. ‘Autograd: Effortless gradients in\\nnumpy’. In: ICML 2015 AutoML Workshop . V ol. 238. 2015 (cit. on pp. 123, 136).\\n[11] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: (2017) (cit. on p. 136).\\n[12] D. Rumelhart, G. Hinton and R. Williams. ‘Learning representations by back\\npropagating errors’. In: Nature 323 (1986), pp. 533–536 (cit. on p. 135).\\n[13] B. Speelpenning. Compiling fast partial derivatives of functions given by algorithms .\\nTech. rep. Illinois Univ Urbana Dept of Computer Science, 1980 (cit. on p. 126).\\n182BACHELORS\\nPART IVCHAPTER\\n6\\nDEEP LEARNING: NN ENSEMBLES\\nThe saddest aspect of life right now is that gathers knowledge faster than society\\n'),\n",
              " Document(metadata={}, page_content='ML 2015 AutoML Workshop . V ol. 238. 2015 (cit. on pp. 123, 136).\\n[11] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: (2017) (cit. on p. 136).\\n[12] D. Rumelhart, G. Hinton and R. Williams. ‘Learning representations by back\\npropagating errors’. In: Nature 323 (1986), pp. 533–536 (cit. on p. 135).\\n[13] B. Speelpenning. Compiling fast partial derivatives of functions given by algorithms .\\nTech. rep. Illinois Univ Urbana Dept of Computer Science, 1980 (cit. on p. 126).\\n182BACHELORS\\nPART IVCHAPTER\\n6\\nDEEP LEARNING: NN ENSEMBLES\\nThe saddest aspect of life right now is that gathers knowledge faster than society\\ngathers wisdom.\\n— Isaac Asimov\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 186\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 190\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 191\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 196\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 197\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\nBagging, Boosting and Stacking . . . . . . . . . . . . . . . . . . . . . . . 198\\nApproaches for Combining Predictors . . . . . . . . . . . . . . . . . . . 199\\nMonolithic and Heterogeneous Ensembling . . . . . . . . . . . . . . . . 200\\nEnsemble Learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nSnapshot Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201\\nMulti-model Ensembling . . . . . . . . . . . . . . . . . . . . . . . . . . . 202\\nLearning-rate Schedules in Ensembling . . . . . . . . . . . . . . . . . . 2026.1. INTRODUCTION\\n6.1 Introduction\\nI\\nNtuition and practice demonstrate that a poor or an inferior choice may\\nbe altogether prevented merely by motivating a group (or an ensemble)\\nof people with diverse perspectives to make a mutually acceptable choice.\\nLikewise, in many cases, neural network ensembles signiﬁcantly improve\\nthe generalization ability of single-model based AI systems [ 5, 11]. Shortly follow-\\ning the foundation of Kaggle, research in the ﬁeld had started blooming; not only\\nbecause researchers are advocating and using advanced ensembling approaches in\\nalmost every competition, but also by the empirical success of the top winning mod-\\nels. Though the whole process of training ensembles typically involves the utilization\\nof dozens of GPUs and prolonged training periods, ensembling approaches enhance\\nthe predictive power of a single model. Though ensembling obviously has a signiﬁc-\\nant impact on the performance of AI systems in general, research shows its effect is\\nparticularly dramatic in the ﬁ'),\n",
              " Document(metadata={}, page_content='because researchers are advocating and using advanced ensembling approaches in\\nalmost every competition, but also by the empirical success of the top winning mod-\\nels. Though the whole process of training ensembles typically involves the utilization\\nof dozens of GPUs and prolonged training periods, ensembling approaches enhance\\nthe predictive power of a single model. Though ensembling obviously has a signiﬁc-\\nant impact on the performance of AI systems in general, research shows its effect is\\nparticularly dramatic in the ﬁeld of neural networks [ Russakovsky_2015, 1, 4, 7, 13].\\nTherefore, while we could examine combinations of any type of learning algorithms,\\nthe focus of this chapter is the combination of neural networks.\\n6.2 Problems\\n6.2.1 Bagging, Boosting and Stacking\\nPRB-135 \\uf059 CH.PRB- 6.1.\\nMark all the approaches which can be utilized to boost a single model performance:\\n(i) Majority Voting\\n(ii) Using K-identical base-learning algorithms\\n(iii) Using K-different base-learning algorithms\\n(iv) Using K-different data-folds\\n(v) Using K-different random number seeds\\n(vi) A combination of all the above approaches\\n186Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nPRB-136 \\uf059 CH.PRB- 6.2.\\nAn argument erupts between two senior data-scientists regarding the choice of an ap-\\nproach for training of a very small medical corpus. One suggest that bagging is superior\\nwhile the other suggests stacking. Which technique, bagging or stacking, in your opinion is\\nsuperior? Explain in detail.\\n(i) Stacking since each classier is trained on all of the available data.\\n(ii) Bagging since we can combine as many classiﬁers as we want by training each on a\\ndifferent sub-set of the training corpus.\\nPRB-137 \\uf059 CH.PRB- 6.3.\\nComplete the sentence: A random forest is a type of a decision tree which utilizes [bag-\\nging/boosting]\\nPRB-138 \\uf059 CH.PRB- 6.4.\\nThe algorithm depicted in Fig. 6.1 was found in an old book about ensembling. Name the\\nalgorithm.\\n1876.2. PROBLEMS\\nAlgorithm 1: Algo 1\\nData: A set of training data, Q with N elements has been established\\nwhile K times do\\nCreate a random subset of N ′ data by sampling from Q containing the N\\nsamples;\\nN ′ < N ;\\nExecute algorithm Algo 2;\\nReturn all N ′ back to Q\\nAlgorithm 2: Algo 2\\nChoose a learner hm;\\nwhile K times do\\nPick a training set and train with hm;\\nFIGURE 6.1: A speciﬁc ensembling approach\\nPRB-139 \\uf059 CH.PRB- 6.5.\\nFig. 6.2 depicts a part of a speciﬁc ensembling approach applied to the models x1, x2...xk.\\nIn your opinion, which approach is being utilized?\\nGenerelizerx3\\nx2\\nx1\\n...\\nxk\\nBase Learners\\nf\\n?\\nFIGURE 6.2: A speciﬁc ensembling approach\\n(i) Bootstrap aggregation\\n(ii) Snapshot ensembling\\n(iii) Stacking\\n188Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n(iv) Classical committee machines\\nPRB-140 \\uf059 CH.PRB- 6.6.\\nConsider training corpus consisting of balls which are glued together as triangles, each\\nof which has either 1, 3, 6, 10, 15, 21, 28, 36, or 45 balls.\\n1. We draw several samples from this corpus as presented in Fig. 6.3 wherein each sample\\nis equiprobable. What type of sampling approach is being utilized here?\\nFIGURE 6.3: Sampling approaches\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n2. Two samples are drawn one after the other. In which of the following cases is the\\ncovariance between the two samples equals zero?\\n(i) Sampling without replacement\\n(ii) Sampling with replacement\\n3. During training, the corpus sampled with replacement and is divided into several\\nfolds as presented in Fig. 6.4.\\nT1:\\nT2:\\nT3:\\nT4:\\nFIGURE 6.4: Sampling approaches\\n1896.2. PROBLEMS\\nIf 10 balls glued together is a sample event that we know is hard to correctly classify,\\nthen it is impossible that we are using:\\n(i) Bagging\\n(ii) Boost'),\n",
              " Document(metadata={}, page_content=\") Sampling with replacement\\n3. During training, the corpus sampled with replacement and is divided into several\\nfolds as presented in Fig. 6.4.\\nT1:\\nT2:\\nT3:\\nT4:\\nFIGURE 6.4: Sampling approaches\\n1896.2. PROBLEMS\\nIf 10 balls glued together is a sample event that we know is hard to correctly classify,\\nthen it is impossible that we are using:\\n(i) Bagging\\n(ii) Boosting\\n6.2.2 Approaches for Combining Predictors\\nPRB-141 \\uf059 CH.PRB- 6.7.\\nThere are several methods by which the outputs of base classiﬁers can be combined to\\nyield a single prediction. Fig. 6.5 depicts part of a speciﬁc ensembling approach applied to\\nseveral CNN model predictions for a labelled data-set. Which approach is being utilized?\\n(i) Majority voting for binary classiﬁcation\\n(ii) Weighted majority voting for binary classiﬁcation\\n(iii) Majority voting for class probabilities\\n(iv) Weighted majority class probabilities\\n(v) An algebraic weighted average for class probabilities\\n(vi) An adaptive weighted majority voting for combining multiple classiﬁers\\n190Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 l = []\\n2 for i,f in enumerate(filelist):\\n3 temp = pd.read_csv(f)\\n4 l.append(temp)\\n5 arr = np.stack(l,axis=-1)\\n6 avg_results = pd.DataFrame(arr[:,:-1,:].mean(axis=2))\\n7 avg_results['image' ] = l[0]['image' ]\\n8 avg_results.columns = l[0].columns\\nFIGURE 6.5: PyTorch code snippet for an ensemble\\nPRB-142 \\uf059 CH.PRB- 6.8.\\nRead the paper Neural Network Ensembles [3] and then complete the sentence: If the\\naverage error rate for a speciﬁc instance in the corpus is less than [...]% and the respective\\nclassiﬁers in the ensemble produce independent [...], then when the number of classiﬁers\\ncombined approaches inﬁnity, the expected error can be diminished to zero.\\nPRB-143 \\uf059 CH.PRB- 6.9.\\nTrue or false: A perfect ensemble comprises of highly correct classiﬁers that differ as\\nmuch as possible.\\nPRB-144 \\uf059 CH.PRB- 6.10.\\nTrue or false: In bagging, we re-sample the training corpus with replacement and there-\\nfore this may lead to some instances being represented numerous times while other instances\\nnot to be represented at all.\\n6.2.3 Monolithic and Heterogeneous Ensembling\\nPRB-145 \\uf059 CH.PRB- 6.11.\\n1916.2. PROBLEMS\\n1. True or false: T raining an ensemble of a single monolithic architecture results in\\nlower model diversity and possibly decreased model prediction accuracy.\\n2. True or false: The generalization accuracy of an ensemble increases with the number\\nof well-trained models it consists of.\\n3. True or false: Bootstrap aggregation (or bagging), refers to a process wherein a CNN\\nensemble is being trained using a random subset of the training corpus.\\n4. True or false: Bagging assumes that if the single predictors have independent errors,\\nthen a majority vote of their outputs should be better than the individual predictions.\\nPRB-146 \\uf059 CH.PRB- 6.12.\\nRefer to the papers: Dropout as a Bayesian Approximation [2] and Can Y ou Trust\\nY our Model’s Uncertainty? [12] and answer the following question: Do deep ensembles\\nachieve a better performance on out-of-distribution uncertainty benchmarks compared with\\nMonte-Carlo (MC)-dropout?\\nPRB-147 \\uf059 CH.PRB- 6.13.\\n1. In a transfer-learning experiment conducted by a researcher, a number of ImageNet-\\npretrained CNN classiﬁers, selected from T able 6.1 are trained on ﬁve different folds\\ndrawn from the same corpus. Their outputs are fused together producing a composite\\nmachine. Ensembles of these convolutional neural networks architectures have been\\nextensively studies an evaluated in various ensembling approaches [ 4, 9]. Is it likely\\nthat the composite machine will produce a prediction with higher accuracy than that\\nof any individual classiﬁer? Explain why.\\n192Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nCNN Model Classes Image Size Top-1 accuracy\\nResNet152 1000 224 78.428\\nDPN98 1000 224 79.224\\nSeNet\"),\n",
              " Document(metadata={}, page_content=\"\\nextensively studies an evaluated in various ensembling approaches [ 4, 9]. Is it likely\\nthat the composite machine will produce a prediction with higher accuracy than that\\nof any individual classiﬁer? Explain why.\\n192Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nCNN Model Classes Image Size Top-1 accuracy\\nResNet152 1000 224 78.428\\nDPN98 1000 224 79.224\\nSeNet154 1000 224 81.304\\nSeResneXT101 1000 224 80.236\\nDenseNet161 1000 224 77.560\\nInceptionV4 1000 299 80.062\\nTABLE 6.1: ImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches.\\n2. True or False: In a classiﬁcation task, the result of ensembling is always superior.\\n3. True or False: In an ensemble, we want differently trained models converge to differ-\\nent local minima.\\nPRB-148 \\uf059 CH.PRB- 6.14.\\nIn committee machines, mark all the combiners that do not make direct use of the input:\\n(i) A mixture of experts\\n(ii) Bagging\\n(iii) Ensemble averaging\\n(iv) Boosting\\nPRB-149 \\uf059 CH.PRB- 6.15.\\nTrue or False: Considering a binary classiﬁcation problem ( y = 0 or y = 1 ), ensemble\\naveraging, wherein the outputs of individual models are linearly combined to produce a fused\\noutput is a form of a static committee machine.\\n1936.2. PROBLEMS\\nMn\\nM2\\nM1\\n∑\\nwn\\nw2\\nw1\\n0\\n1\\n0\\n1\\nFIGURE 6.6: A typical binary classiﬁcation problem.\\nPRB-150 \\uf059 CH.PRB- 6.16.\\nTrue or false: When using a single model, the risk of overﬁtting the data increases when\\nthe number of adjustable parameters is large compared to cardinality (i.e., size of the set) of\\nthe training corpus.\\nPRB-151 \\uf059 CH.PRB- 6.17.\\nTrue or false:If we have a committee of K trained models and the errors are uncorrelated,\\nthen by averaging them the average error of a model is reduced by a factor of K.\\n6.2.4 Ensemble Learning\\nPRB-152 \\uf059 CH.PRB- 6.18.\\n1. Deﬁne ensemble learning in the context of machine learning.\\n2. Provide examples of ensemble methods in classical machine-learning.\\n3. True or false: Ensemble methods usually have stronger generalization ability.\\n4. Complete the sentence: Bagging is variance/bias reduction scheme while boosting\\nreduced variance/bias.\\n194Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n6.2.5 Snapshot Ensembling\\nPRB-153 \\uf059 CH.PRB- 6.19.\\nY our colleague, a well-known expert in ensembling methods, writes the following pseudo\\ncode in Python shown in Fig. 6.7 for the training of a neural network. This runs inside a\\nstandard loop in each training and validation step.\\n1 import torchvision.models as models\\n2 ...\\n3 models = ['resnext' ]\\n4 for m in models:\\n5 train ...\\n6 compute VAL loss ...\\n7 amend LR ...\\n8 if (val_acc > 90.0):\\n9 saveModel()\\nFIGURE 6.7: PyTorch code snippet for an ensemble\\n1. What type of ensembling can be used with this approach? Explain in detail.\\n2. What is the main advantage of snapshot ensembling? What are the disadvantages, if\\nany?\\nPRB-154 \\uf059 CH.PRB- 6.20.\\nAssume further that your colleague amends the code as follows in Fig. 6.8.\\n1956.2. PROBLEMS\\n1 import torchvision.models as models\\n2 import random\\n3 import np\\n4 ...\\n5 models = ['resnext' ]\\n6 for m in models:\\n7 train ...\\n8 compute loss ...\\n9 amend LR ...\\n10 manualSeed= draw a new random number\\n11 random.seed(manualSeed)\\n12 np.random.seed(manualSeed)\\n13 torch.manual_seed(manualSeed)\\n14 if (val_acc > 90.0):\\n15 saveModel()\\nFIGURE 6.8: PyTorch code snippet for an ensemble\\nExplain in detail what would be the possible effects of adding lines 10-13.\\n6.2.6 Multi-model Ensembling\\n\"),\n",
              " Document(metadata={}, page_content=\"8 compute loss ...\\n9 amend LR ...\\n10 manualSeed= draw a new random number\\n11 random.seed(manualSeed)\\n12 np.random.seed(manualSeed)\\n13 torch.manual_seed(manualSeed)\\n14 if (val_acc > 90.0):\\n15 saveModel()\\nFIGURE 6.8: PyTorch code snippet for an ensemble\\nExplain in detail what would be the possible effects of adding lines 10-13.\\n6.2.6 Multi-model Ensembling\\nPRB-155 \\uf059 CH.PRB- 6.21.\\n1. Assume your colleague, a veteran in DL and an expert in ensembling methods writes\\nthe following Pseudo code shown in Fig. 6.9 for the training of several neural networks.\\nThis code snippet is executed inside a standard loop in each and every training/valida-\\ntion epoch.\\n196Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1 import torchvision.models as models\\n2 ...\\n3 models = ['resnext' ,'vgg' ,'dense' ]\\n4 for m in models:\\n5 train ...\\n6 compute loss /acc ...\\n7 if (val_acc > 90.0):\\n8 saveModel()\\nFIGURE 6.9: PyTorch code snippet for an ensemble\\nWhat type of ensembling is being utilized in this approach? Explain in detail.\\n2. Name one method by which NN models may be combined to yield a single prediction.\\n6.2.7 Learning-rate Schedules in Ensembling\\nPRB-156 \\uf059 CH.PRB- 6.22.\\n1. Referring to Fig. ( 6.10) which depicts a speciﬁc learning rate schedule, describe the\\nbasic notion behind its mechanism.\\n1976.3. SOLUTIONS\\n1\\n0,5\\n1\\nx\\ny\\nFIGURE 6.10: A learning rate schedule.\\n2. Explain how cyclic learning rates [10] can be effective for the training of convolutional\\nneural networks such as the ones in the code snippet of Fig. 6.10.\\n3. Explain how a cyclic cosine annealing schedule as proposed by Loshchilov [ 10] and\\n[13] is used to converge to multiple local minima.\\n6.3 Solutions\\n6.3.1 Bagging, Boosting and Stacking\\nSOL-135 \\uf14b CH.SOL- 6.1.\\nAll the presented options are correct. \\x04\\nSOL-136 \\uf14b CH.SOL- 6.2.\\nThe correct choice would be stacking. In cases where the given corpus is small, we would\\nmost likely prefer training our models on the full data-set. \\x04\\nSOL-137 \\uf14b CH.SOL- 6.3.\\nA random forest is a type of a decision tree which utilizes bagging. \\x04\\n198Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-138 \\uf14b CH.SOL- 6.4.\\nThe presented algorithm is a classic bagging. \\x04\\nSOL-139 \\uf14b CH.SOL- 6.5.\\nThe approach which is depicted is the ﬁrst phase of stacking. In stacking, we ﬁrst (phase\\n0) predict using several base learners and then use a generalizer (phase 1) that learns on top\\nof the base learners predictions. \\x04\\nSOL-140 \\uf14b CH.SOL- 6.6.\\n1. Sampling with replacement\\n2. Sampling without replacement\\n3. This may be mostly a result of bagging, since in boosting we would have expected miss-\\ncorrectly classiﬁed observations to repeatedly appear in subsequent samples.\\n\\x04\\n6.3.2 Approaches for Combining Predictors\\nSOL-141 \\uf14b CH.SOL- 6.7.\\nAn Algebraic weighted average for class probabilities. \\x04\\nSOL-142 \\uf14b CH.SOL- 6.8.\\nThis is true, [ 3] provides a mathematical proof. \\x04\\nSOL-143 \\uf14b CH.SOL- 6.9.\\nThis is true. For extension, see instance [ 8]. \\x04\\nSOL-144 \\uf14b CH.SOL- 6.10.\\nThis is true. In a bagging approach, we ﬁrst randomly draw (with replacement), K ex-\\n1996.3. SOLUTIONS\\namples where K is the size of the original training corpus therefore leading to an imbalanced\\nrepresentation of the instances. \\x04\\n6.3.3 Monolithic and Heterogeneous Ensembling\\nSOL-145 \\uf14b CH.SOL- 6.11.\\n1. True Due to their lack of diversity, an ensemble of monolithic architectures tends\"),\n",
              " Document(metadata={}, page_content=' In a bagging approach, we ﬁrst randomly draw (with replacement), K ex-\\n1996.3. SOLUTIONS\\namples where K is the size of the original training corpus therefore leading to an imbalanced\\nrepresentation of the instances. \\x04\\n6.3.3 Monolithic and Heterogeneous Ensembling\\nSOL-145 \\uf14b CH.SOL- 6.11.\\n1. True Due to their lack of diversity, an ensemble of monolithic architectures tends to\\nperform worse than an heterogeneous ensemble.\\n2. True This has be consistently demonstrated in [ 11, 5].\\n3. True In [6] there is a discussion about both using the whole corpus and a subset much\\nlike in bagging.\\n4. True The total error decreases with the addition of predictors to the ensemble.\\n\\x04\\nSOL-146 \\uf14b CH.SOL- 6.12.\\nY es, they do. \\x04\\nSOL-147 \\uf14b CH.SOL- 6.13.\\n1. Y es, it is very likely, especially if their errors are independent.\\n2. True It may be proven that ensembles of models perform at least as good as each of the\\nensemble members it consists of.\\n3. True Different local minima add to the diversiﬁcation of the models.\\n\\x04\\nSOL-148 \\uf14b CH.SOL- 6.14.\\nBoosting is the only one that does not. \\x04\\n200Chapter 6 DEEP LEARNING: NN ENSEMBLES\\nSOL-149 \\uf14b CH.SOL- 6.15.\\nFalse By deﬁnition, static committee machines use only the output of the single predict-\\nors. \\x04\\nSOL-150 \\uf14b CH.SOL- 6.16.\\nTrue \\x04\\nSOL-151 \\uf14b CH.SOL- 6.17.\\nFalse Though this may be theoretically true, in practice the errors are rarely uncorrelated\\nand therefore the actual error can not be reduced by a factor of K. \\x04\\n6.3.4 Ensemble Learning\\nSOL-152 \\uf14b CH.SOL- 6.18.\\n1. Ensemble learning is an excellent machine learning idea which displays noticeable bene-\\nﬁts in many applications, one such notable example is the widespread use of ensembles\\nin Kaggle competitions. In an ensemble several individual models (for instance Res-\\nNet18 and VGG16) which were trained on the same corpus, work in tandem and during\\ninference, their predictions are fused by a pre-deﬁned strategy to yield a single predic-\\ntion.\\n2. In classical machine learning Ensemble methods usually refer to bagging, boosting and\\nthe linear combination of regression or classiﬁcation models.\\n3. True The stronger generalization ability stems from the voting power of diverse models\\nwhich are joined together.\\n4. Bagging is variance reduction scheme while boosting reduced bias.\\n\\x04\\n6.3.5 Snapshot Ensembling\\n2016.3. SOLUTIONS\\nSOL-153 \\uf14b CH.SOL- 6.19.\\n1. Since only a single model ie being utilized, this type of ensembling is known as snap-\\nshot ensembling. Using this approach, during the training of a neural network and\\nin each epoch, a snapshot, e.g. the weights of a trained instance of a model (a PTH\\nﬁle in PyT orch nomenclature) are persisted into permanent storage whenever a certain\\nperformance metrics, such as accuracy or loss is being surpassed. Therefore the name\\n“snapshot”; weights of the neural network are being snapshot at speciﬁc instances in\\ntime. After several such epochs the top-5 performing Snapshots which converged to\\nlocal minima [4] are combined as part of an ensemble to yield a single prediction.\\n2. Advantages: during a single training cycle, many model instances may be collected.\\nDisadvantages: inherent lack of diversity by virtue of the fact that the same models is\\nbeing repeatedly used.\\n\\x04\\nSOL-154 \\uf14b CH.SOL- 6.20.\\nChanging the random seed at each iteration/epoch, helps in introducing variation which\\nmay contribute to diversifying the trained neural network models. \\x04\\n6.3.6 Multi-model Ensembling\\nSOL-155 \\uf14b CH.SOL- 6.21.\\n1. Multi-model ensembling.\\n2. Both averaging and majority voting.\\n\\x04\\n6.3.7 Learning-rate Schedules in Ensembling\\nSOL-156 \\uf14b CH.SOL- 6.22.\\n202Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1. Capturing the best model of each training cycle allows to obtain multiple models settled\\non various'),\n",
              " Document(metadata={}, page_content='-model Ensembling\\nSOL-155 \\uf14b CH.SOL- 6.21.\\n1. Multi-model ensembling.\\n2. Both averaging and majority voting.\\n\\x04\\n6.3.7 Learning-rate Schedules in Ensembling\\nSOL-156 \\uf14b CH.SOL- 6.22.\\n202Chapter 6 DEEP LEARNING: NN ENSEMBLES\\n1. Capturing the best model of each training cycle allows to obtain multiple models settled\\non various local optima from cycle to cycle at the cost of training a single mode\\n2. The approach is based on the non-convex nature of neural networks and the ability to\\nconverge and escape from local minima using a speciﬁc schedule to adjust the learning\\nrate during training.\\n3. Instead of monotonically decreasing the learning rate, this method lets the learning rate\\ncyclically vary between reasonable boundary values.\\n\\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 186).\\n[2] Y . Gal and Z. Ghahramani. ‘Dropout as a Bayesian approximation’. In: arXiv\\npreprint arXiv:1506.02157 (2015) (cit. on p. 192).\\n[3] L. K. Hansen and P . Salamon. ‘Neural Network Ensembles’. In: IEEE T rans. Pat-\\ntern Anal. Mach. Intell. 12 (1990), pp. 993–1001 (cit. on pp. 191, 199).\\n[4] G. Huang et al. ‘Snapshot ensembles: Train 1, get M for free. arXiv 2017’. In:\\narXiv preprint arXiv:1704.00109 () (cit. on pp. 186, 192, 202).\\n[5] J. Huggins, T. Campbell and T. Broderick. ‘Coresets for scalable Bayesian logistic\\nregression’. In: Advances in Neural Information Processing Systems . 2016, pp. 4080–\\n4088 (cit. on pp. 186, 200).\\n[6] C. Ju, A. Bibaut and M. van der Laan. ‘The relative performance of ensemble\\nmethods with deep convolutional neural networks for image classiﬁcation’. In:\\nJournal of Applied Statistics 45.15 (2018), pp. 2800–2818 (cit. on p. 200).\\n[7] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on p. 186).\\n[8] A. Krogh and J. V edelsby. ‘Neural Network Ensembles, Cross Validation, and\\nActive Learning’. In: NIPS. 1994 (cit. on p. 199).\\n[9] S. Lee et al. ‘Stochastic multiple choice learning for training diverse deep en-\\nsembles’. In: Advances in Neural Information Processing Systems . 2016, pp. 2119–\\n2127 (cit. on p. 192).\\n203REFERENCES\\n[10] I. Loshchilov and F. Hutter. ‘Sgdr: Stochastic gradient descent with warm re-\\nstarts’. In: arXiv preprint arXiv:1608.03983 (2016) (cit. on p. 198).\\n[11] P . Oshiro et al.(2012)Oshiro and Baranauskas. ‘How many trees in a random\\nforest?’ In: International Workshop on Machine Learning and Data Mining in Pattern\\nRecognition. 2012 (cit. on pp. 186, 200).\\n[12] Y . Ovadia et al. ‘Can you trust your model’s uncertainty? Evaluating predict-\\nive uncertainty under dataset shift’. In: Advances in Neural Information Processing\\nSystems. 2019, p. 13991 (cit. on p. 192).\\n[13] L. N. Smith. ‘Cyclical learning rates for training neural networks’. In: 2017 IEEE\\nWinter Conference on Applications of Computer Vision (WACV). IEEE. 2017, pp. 464–\\n472 (cit. on pp. 186, 198).\\n204CHAPTER'),\n",
              " Document(metadata={}, page_content='ive uncertainty under dataset shift’. In: Advances in Neural Information Processing\\nSystems. 2019, p. 13991 (cit. on p. 192).\\n[13] L. N. Smith. ‘Cyclical learning rates for training neural networks’. In: 2017 IEEE\\nWinter Conference on Applications of Computer Vision (WACV). IEEE. 2017, pp. 464–\\n472 (cit. on pp. 186, 198).\\n204CHAPTER\\n7\\nDEEP LEARNING: CNN FEATURE EXTRACTION\\nWhat goes up must come down.\\n— Isaac Newton\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 206\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213\\nNeural style transfer, NST . . . . . . . . . . . . . . . . . . . . . . . . . . 214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 216\\nCNN as Fixed Feature Extractor . . . . . . . . . . . . . . . . . . . . . . . 216\\nFine-tuning CNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222\\nNeural style transfer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224\\n7.1 Introduction\\nT\\nHE extraction of an n-dimensional feature vector (FV) or an embedding from\\none (or more) layers of a pre-trained CNN, is termed feature extraction (FE).\\nUsually , FE works by ﬁrst removing the last fully connected (FC) layer from\\na CNN and then treating the remaining layers of the CNN as a ﬁxed FE. As\\nexempliﬁed in Fig. ( 7.1) and Fig. ( 7.2), applying this method to the ResNet34 archi-\\ntecture, the resulting FV consists of 512 ﬂoating point values. Likewise, applying the\\nsame logic on the ResNet152 architecture, the resulting FV has 2048 ﬂoating point ele-\\nments.7.2. PROBLEMS\\n1 2 3 4 · · · k = 512\\nA ﬁxed k-element FV .\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nActual values of a normalized k-element FV .\\nFIGURE 7.1: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depicted is\\nthe ResNet CNN architecture with 34 layers.\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.2: PyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed).\\nThe premise behind FE is that CNNs which were originally trained on the Im-\\nageNet Large Scale Visual Recognition Competition [ 7], can be adapted and used (for\\ninstance in a classiﬁcation task) on a completely different (target) domain without any\\nadditional training of the CNN layers. The power of a CNN to do so lies in its ability\\nto generalize well beyond the original data-set it was trained on, therefore FE on a\\nnew target data-set involves no training and requires only inference.\\n7.2 Problems\\n7.2.1 CNN as Fixed Feature Extractor\\nBefore attempting the problems in this chapter you are highly encouraged to read the\\nfollowing papers [ 1, 3, 7]. In many DL job interviews, you will be presented with a\\npaper you have never seen before and subsequently be asked questions about it; so\\nreading these references would be an excellent simulation of this real-life task.\\n206Chapter 7 DEEP'),\n",
              " Document(metadata={}, page_content=' no training and requires only inference.\\n7.2 Problems\\n7.2.1 CNN as Fixed Feature Extractor\\nBefore attempting the problems in this chapter you are highly encouraged to read the\\nfollowing papers [ 1, 3, 7]. In many DL job interviews, you will be presented with a\\npaper you have never seen before and subsequently be asked questions about it; so\\nreading these references would be an excellent simulation of this real-life task.\\n206Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-157 \\uf059 CH.PRB- 7.1.\\nTrue or False: While AlexNet [ 4] used 11 × 11 sized ﬁlters, the main novelty presented\\nin the VGG [ 8] architecture was utilizing ﬁlters with much smaller spatial extent, sized\\n3 × 3.\\nPRB-158 \\uf059 CH.PRB- 7.2.\\nTrue or False : Unlike CNN architectures such as AlexNet or VGG, ResNet does not\\nhave any hidden FC layers.\\nPRB-159 \\uf059 CH.PRB- 7.3.\\nAssuming the VGG-Net has 138, 357, 544 ﬂoating point parameters, what is the phys-\\nical size in Mega-Bytes (MB) required for persisting a trained instance of VGG-Net on\\npermanent storage?\\nPRB-160 \\uf059 CH.PRB- 7.4.\\nTrue or False : Most attempts at researching image representation using FE, focused\\nsolely on reusing the activations obtained from layers close to the output of the CNN, and\\nmore speciﬁcally the fully-connected layers.\\nPRB-161 \\uf059 CH.PRB- 7.5.\\nTrue or False: FE in the context of deep learning is particularly useful when the target\\nproblem does not include enough labeled data to successfully train CNN that generalizes\\nwell.\\nPRB-162 \\uf059 CH.PRB- 7.6.\\nWhy is a CNN trained on the ImageNet dataset [ 7] a good candidate for a source prob-\\nlem?\\nPRB-163 \\uf059 CH.PRB- 7.7.\\n2077.2. PROBLEMS\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of [...] layers.\\n2. It consists of [...] convolutional and 3 [...] layers.\\n3. The input image size is [...].\\n4. The number of input channels is [...].\\n5. Every image has it’s mean RGB value [subtracted / added].\\n6. Each convolutional layer has a [small/large] kernel sized [...].\\n7. The number of pixels for padding and stride is [...].\\n8. There are 5 [...] layers having a kernel size of [...] and a stride of [...] pixels.\\n9. For non-linearity a [rectiﬁed linear unit (ReLU [ 5])/sigmoid] is used.\\n10. The [...] FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of [...] features.\\n12. The last FC layer has only [...] features.\\n13. The last FC layer is terminated by a [...] activation layer.\\n14. Dropout [is / is not] being used between the FC layers.\\nPRB-164 \\uf059 CH.PRB- 7.8.\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture [ 8] for the classiﬁcation of pancreatic cancer. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with\\nit by utilizing the same logic. In Fig. ( 9.7) three different classes of pancreatic cancer are\\ndisplayed: A, B and C, curated from a dataset of 4K Whole Slide Images (WSI) labeled by\\na board certiﬁed pathologist. Y our task is to use FE to correctly classify the images in the\\ndataset.\\n208Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nFIGURE 7.3: A dataset of 4K histopathology WSI from three severity classes: A, B and C.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture [ 8]. As de-\\npicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters),\\nlearnable parameters (weights,biases), and FV size are presented.\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2'),\n",
              " Document(metadata={}, page_content=' histopathology WSI from three severity classes: A, B and C.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture [ 8]. As de-\\npicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters),\\nlearnable parameters (weights,biases), and FV size are presented.\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 7.1: Incomplete listing of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4K images from the dataset, how can\\nyou now classify the images into their respective categories?\\n2097.2. PROBLEMS\\nPRB-165 \\uf059 CH.PRB- 7.9.\\nStill referring to T able ( 9.3), a data scientist suggests using the output layer of the\\nVGG19 CNN as a ﬁxed FE. What is the main advantage of using this layer over using\\nfor instance, the f c7 layer? (Hint: think about an ensemble of feature extractors)\\nPRB-166 \\uf059 CH.PRB- 7.10.\\nStill referring to T able (9.3) and also to the code snippet in Fig. ( 7.4), which represents a\\nnew CNN derived from the VGG19 CNN:\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=[???])\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = [???]\\n11 self.classifier = torch.nn.Sequential([???])\\n12 self.num_feats = [???]\\n13\\n14 def forward(self, x):\\n15 f = self.features(x)\\n16 f = f.view(f.size(0), -1)\\n17 f = [???]\\n18 print (f.data.size())\\n19 return f\\nFIGURE 7.4: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n210Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. Complete line 6; what should be the value of pretrained ?\\n2. Complete line 10; what should be the value of self.features ?\\n3. Complete line 12; what should be the value of self.num_feats ?\\n4. Complete line 17; what should be the value of f ?\\nPRB-167 \\uf059 CH.PRB- 7.11.\\nWe are still referring to T able ( 9.3) and using the skeleton code provided in Fig. ( 7.5)\\nto derive a new CNN entitled ResNetBottom from the ResNet34 CNN, to extract a 512-\\ndimensional FV for a given input image. Complete the code as follows:\\n1. The value of self.features in line 7.\\n2. The forward method in line 11.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7\\n8 def forward(self, x):\\n9 x = [???]\\n10 x = x.view(x.size(0), -1)\\n11 return x\\nFIGURE 7.5: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\n2117.2. PROBLEMS\\nPRB-168 \\uf059 CH.PRB- 7.12.\\nStill referring to T able (9.3), the PyT orch based pseudo code snippet in Fig. (7.6) returns\\nthe 512-dimensional FV from the modiﬁed ResNet'),\n",
              " Document(metadata={}, page_content='\\nFIGURE 7.5: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\n2117.2. PROBLEMS\\nPRB-168 \\uf059 CH.PRB- 7.12.\\nStill referring to T able (9.3), the PyT orch based pseudo code snippet in Fig. (7.6) returns\\nthe 512-dimensional FV from the modiﬁed ResNet34 CNN, given a 3-channel RGB image\\nas an input.\\n1 import torchvision.models as models\\n2 from torchvision import transforms\\n3 ...\\n4\\n5 test_trans = transforms.Compose([\\n6 transforms.Resize(imgnet_size),\\n7 transforms.ToTensor(),\\n8 transforms.Normalize([0.485, 0.456, 0.406],\\n9 [0.229, 0.224, 0.225])])\\n10\\n11 def ResNet34FE(image, model):\\n12 f=None\\n13 image = test_trans(image)\\n14 image = Variable(image, requires_grad =False).cuda()\\n15 image= image.cuda()\\n16 f = model(image)\\n17 f = f.view(f.size(1), -1)\\n18 print (\"Size : {}\" .format(f.shape))\\n19 f = f.view(f.size(1),-1)\\n20 print (\"Size : {}\" .format(f.shape))\\n21 f =f.cpu().detach().numpy()[0]\\n22 print (\"Size : {}\" .format(f.shape))\\n23 return f\\nFIGURE 7.6: PyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model.\\nAnswer the following questions regarding the code in Fig. ( 7.6):\\n212Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. What is the purpose of test_trans in line 5?\\n2. Why is the parameter requires_grad set to False in line 14?\\n3. What is the purpose of f.cpu() in line 23?\\n4. What is the purpose of detach() in line 23?\\n5. What is the purpose of numpy()[0] in line 23?\\n7.2.2 Fine-tuning CNNs\\nPRB-169 \\uf059 CH.PRB- 7.13.\\nDeﬁne the term ﬁne-tuning (FT) of an ImageNet pre-trained CNN .\\nPRB-170 \\uf059 CH.PRB- 7.14.\\nDescribe three different methods by which one can ﬁne-tune an ImageNet pre-trained\\nCNN.\\nPRB-171 \\uf059 CH.PRB- 7.15.\\nMelanoma is a lethal form of malignant skin cancer, frequently misdiagnosed as a benign\\nskin lesion or even left completely undiagnosed.\\nIn the United States alone, melanoma accounts for an estimated 6, 750 deaths per annum\\n[6]. With a 5-year survival rate of 98%, early diagnosis and treatment is now more likely\\nand possibly the most suitable means for melanoma related death reduction. Dermoscopy\\nimages, shown in Fig. ( 7.7) are widely used in the detection and diagnosis of skin lesions.\\nDermatologists, relying on personal experience, are involved in a laborious task of manually\\nsearching dermoscopy images for lesions.\\nTherefore, there is a very real need for automated analysis tools, providing assistance to\\nclinicians screening for skin metastases. In this question, you are tasked with addressing\\nsome of the fundamental issues DL researchers face when building deep learning pipelines.\\nAs suggested in [ 3], you are going to use ImageNet pre-trained CNN to resolve a classiﬁca-\\ntion task.\\n2137.2. PROBLEMS\\nFIGURE 7.7: Skin lesion categories. An exemplary visualization of melanoma.\\n1. Given that the skin lesions fall into seven distinct categories, and you are training us-\\ning cross-entropy loss, how should the classes be represented so that a typical PyT orch\\ntraining loop will successfully converge?\\n2. Suggest several data augmentation techniques to augment the data.\\n3. Write a code snippet in PyT orch to adapt the CNN so that it can predict 7 classes\\ninstead of the original source size of 1000.\\n4. In order to ﬁne tune our CNN, the (original) output layer with 1000 classes was\\nremoved and the CNN was adjusted so that the (new) classiﬁcation layer comprised\\nseven softmax neurons emitting posterior probabilities of class membership for each\\nlesion type.\\n7.2.3 Neural style transfer, NST\\nBefore attempting the problems in the section, you are strongly recommended to read\\nthe paper: “A Neural Algorithm of Artistic Style ” [2].\\nPRB-172 �'),\n",
              " Document(metadata={}, page_content='.\\n1. Given that the skin lesions fall into seven distinct categories, and you are training us-\\ning cross-entropy loss, how should the classes be represented so that a typical PyT orch\\ntraining loop will successfully converge?\\n2. Suggest several data augmentation techniques to augment the data.\\n3. Write a code snippet in PyT orch to adapt the CNN so that it can predict 7 classes\\ninstead of the original source size of 1000.\\n4. In order to ﬁne tune our CNN, the (original) output layer with 1000 classes was\\nremoved and the CNN was adjusted so that the (new) classiﬁcation layer comprised\\nseven softmax neurons emitting posterior probabilities of class membership for each\\nlesion type.\\n7.2.3 Neural style transfer, NST\\nBefore attempting the problems in the section, you are strongly recommended to read\\nthe paper: “A Neural Algorithm of Artistic Style ” [2].\\nPRB-172 \\uf059 CH.PRB- 7.16.\\nBrieﬂy describe how neural style transfer (NST) [ 2] works.\\nPRB-173 \\uf059 CH.PRB- 7.17.\\nComplete the sentence : When using the VGG-19 CNN [ 8] for neural-style transfer,\\nthere different images are involved. Namely they are: [...], [...] and [...].\\n214Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nPRB-174 \\uf059 CH.PRB- 7.18.\\nRefer to Fig. 7.8 and answer the following questions:\\nFIGURE 7.8: Artistic style transfer using the style of Francis Picabia’s Udnie painting.\\n1. Which loss is being utilized during the training process?\\n2. Brieﬂy describe the use of activations in the training process.\\nPRB-175 \\uf059 CH.PRB- 7.19.\\nStill referring to Fig. 7.8:\\n1. How are the activations utilized in comparing the content of the content image to the\\ncontent of the combined image?.\\n2. How are the activations utilized in comparing the style of the content image to the\\n2157.3. SOLUTIONS\\nstyle of the combined image?.\\nPRB-176 \\uf059 CH.PRB- 7.20.\\nStill referring to Fig. 7.8. For a new style transfer algorithm, a data scientist extracts a\\nfeature vector from an image using a pre-trained ResNet34 CNN ( 7.9).\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 7.9: PyTorch declaration for a pre-trained ResNet34 CNN.\\nHe then deﬁnes the cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and :\\nv = {v1, v2, . . . , vN }\\nas:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures thecosine of the angle between\\nthe vectors irrespective of their magnitude. It is calculated as the dot product of two numeric\\nvectors, and is normalized by the product of the length of the vectors.\\nAnswer the following questions:\\n1. Deﬁne the term Gram matrix.\\n2. Explain in detail how vector similarity is utilised in the calculation of the Gram mat-\\nrix during the training of NST.\\n7.3 Solutions\\n7.3.1 CNN as Fixed Feature Extractor\\n216Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\nSOL-157 \\uf14b CH.SOL- 7.1.\\nT rue. The increased depth in VGG-Net was made possible using smaller ﬁlters without\\nsubstantially increasing the number of learnable parameters. Albeit an unwanted side effect\\nof the usage of smaller ﬁlters is the increase in the number of ﬁlters per-layer. \\x04\\nSOL-158 \\uf14b CH.SOL- 7.2.\\nT rue. The ResNet architecture terminates with a global average pooling layer followed\\nby a K-way FC layer with a softmax activation function, where K is the number of classes\\n(ImageNet has 1000 classes). Therefore, the ResNet has no hidden FC layers. \\x04\\nSOL-159 \\uf14b CH.SOL- 7.3. Note that 1bit = 0.000000125 MB, therefore:\\n138, 357544 × 32 = 4427441408 bits = 553'),\n",
              " Document(metadata={}, page_content=' with a global average pooling layer followed\\nby a K-way FC layer with a softmax activation function, where K is the number of classes\\n(ImageNet has 1000 classes). Therefore, the ResNet has no hidden FC layers. \\x04\\nSOL-159 \\uf14b CH.SOL- 7.3. Note that 1bit = 0.000000125 MB, therefore:\\n138, 357544 × 32 = 4427441408 bits = 553.430176 MB. (7.1)\\n\\x04\\nSOL-160 \\uf14b CH.SOL- 7.4.\\nT rue. There are dozens of published papers supporting this claim. Y ou are encouraged to\\nsearch them on Arxiv or Google Scholar. \\x04\\nSOL-161 \\uf14b CH.SOL- 7.5.\\nT rue. One of the major hurdles of training a medical AI system is the lack of annotated\\ndata. Therefore, extensive research is conducted to exploit ways for FE and transfer learning,\\ne.g., in the application of ImageNet trained CNNs, to target datasets in which labeled data is\\nscarce. \\x04\\nSOL-162 \\uf14b CH.SOL- 7.6.\\nThere are two main reasons why this is possible:\\n1. The huge number of images inside the ImageNet dataset ensures a CNN model that gen-\\neralizes to additional domains, like the histopathology domain, which is substantially\\ndifferent from the original domain the model was trained one (e.g., cats and dogs).\\n2177.3. SOLUTIONS\\n2. A massive array of disparate visual patterns is produced by an ImageNet trained CNN,\\nsince it consists of 1, 000 different groups.\\n\\x04\\nSOL-163 \\uf14b CH.SOL- 7.7.\\nComplete the missing parts regarding the VGG19 CNN architecture:\\n1. The VGG19 CNN consists of 19 layers.\\n2. It consists of 5 convolutional and 3 FC layers.\\n3. The input image size is 244 , the default size most ImageNet trained CNNs work on.\\n4. The number of input channels is 3 .\\n5. Every image has its mean RGB value subtracted . (why?)\\n6. Each convolutional layer has a small kernel sized 3 × 3 . (why?)\\n7. The number of pixels for padding and stride is the same and equals 1 .\\n8. There are 5 convolutional layers having a kernel size of 2 × 2 and a stride of 2 pixels.\\n9. For non-linearity a rectiﬁed linear unit (ReLU [ 5]) is used.\\n10. The 3 FC layers are part of the linear classiﬁer.\\n11. The ﬁrst two FC layers consist of 4096 features.\\n12. The last FC layer has only 1000 features.\\n13. The last FC layer is terminated by a softmax activation layer.\\n14. Dropout is being used between the FC layers.\\n\\x04\\nSOL-164 \\uf14b CH.SOL- 7.8.\\n218Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. One or more layers of the VGG19 CNN are selected for extraction and a new CNN\\nis designed on top of it. Thus, during inference our target layers are extracted and\\nnot the original softmax layer. Subsequently, we iterate and run inference over all\\nthe images in our pancreatic cancer data-set, extract the features, and persist them to\\npermanent storage such as a solid-state drive (SSD) device. Ultimately, each image has\\na corresponding FV .\\n2. Regarding the VGG19 CNN, there are numerous ways of extracting and combining\\nfeatures from different layers. Of course, these different layers, e.g., the FC, conv4_3,\\nand fc7 layer may be combined together to form a larger feature vector. T o determine\\nwhich method works best, you shall have to experiment on your data-set; there is no way\\nof a-priory determining the optimal combination of layers. Here are several examples:\\n(a) Accessing the last FC layer resulting in a 1000-D FV . The output is the score for\\neach of the 1000 classes of the ImageNet data-set.\\n(b) Removing the last FC layer leaves the fc7 layer, resulting in a 4096-D FV .\\n(c) Directly accessing the conv4_3 layer results in a 512-D FV .\\n3. Once the FVs are extracted, we can train any linear classiﬁer such as an SVM or\\nsoftmax classiﬁer on the FV data-set, and not on the original images.\\n\\x04\\nSOL-165 \\uf14b CH.SOL- 7.9.\\nOne bene�'),\n",
              " Document(metadata={}, page_content=' fc7 layer, resulting in a 4096-D FV .\\n(c) Directly accessing the conv4_3 layer results in a 512-D FV .\\n3. Once the FVs are extracted, we can train any linear classiﬁer such as an SVM or\\nsoftmax classiﬁer on the FV data-set, and not on the original images.\\n\\x04\\nSOL-165 \\uf14b CH.SOL- 7.9.\\nOne beneﬁt of using the FC layer is that other ImageNet CNNs can be used in tandem\\nwith the VGG19 to create an ensemble since they all produce the same 1000-D sized FV . \\x04\\nSOL-166 \\uf14b CH.SOL- 7.10. The full code is presented in Fig. ( 7.10).\\n2197.3. SOLUTIONS\\n1 import torchvision.models as models\\n2 ...\\n3 class VGG19FE(torch.nn.Module):\\n4 def __init__(self):\\n5 super(VGG19FE, self).__init__()\\n6 original_model = models.VGG19(pretrained=True)\\n7 self.real_name = (((type(original_model).__name__)))\\n8 self.real_name = \"vgg19\"\\n9\\n10 self.features = original_model.features\\n11 self.classifier = torch.nn.Sequential(\\n12 (*list(original_model.classifier.\\n13 children())[:-1]))\\n14 self.num_feats = 4096\\n15\\n16 def forward(self, x):\\n17 f = self.features(x)\\n18 f = f.view(f.size(0), -1) # (1, 4096) -> (4096,)\\n19 f = self.classifier(f)\\n20 print (f.data.size())\\n21 return f\\nFIGURE 7.10: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n1. The value of the parameter pretrained should be T rue in order to instruct PyT orch to\\nload an ImageNet trained weights.\\n2. The value of self.features should be original_model.features . This is because we like to\\nretain the layers of the original classiﬁer (original_model).\\n3. The value of self.num_feats should be 4096 . (Why?)\\n4. The value of f should be self.classiﬁer(f) since our newly created CNN has to be in-\\nvoked to generate the FV .\\n220Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n\\x04\\nSOL-167 \\uf14b CH.SOL- 7.11.\\n1. Line number 7 in Fig. ( 7.11) takes care of extracting the the correct 512-D FV .\\n2. Line number 11 in Fig. ( 7.11) extracts the correct 512-D FV by creating a sequential\\nmodule on top of the existing features.\\n1 import torchvision.models as models\\n2 res_model = models.resnet34(pretrained=True)\\n3 class ResNetBottom(torch.nn.Module):\\n4 def __init__(self, original_model):\\n5 super(ResNetBottom, self).__init__()\\n6 self.features = [???]\\n7 def forward(self, x):\\n8 x = [???]\\n9 x = x.view(x.size(0), -1)\\n10 return x\\nFIGURE 7.11: PyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model.\\n\\x04\\nSOL-168 \\uf14b CH.SOL- 7.12.\\n1. T ransforms are incorporated into deep learning pipelines in order to apply one or more\\noperations on images which are represented as tensors. Different transforms are usu-\\nally utilized during training and inference. For instance, during training we can use a\\ntransform to augment our data-set, while during inference our transform may be lim-\\nited only to normalizing an image. PyT orch allows the use of transforms either during\\ntraining or inference. The purpose of test_trans in line 5 is to normalize the data.\\n2217.3. SOLUTIONS\\n2. The parameter requires_grad is set to False in line 14 since during inference the com-\\nputation of gradients is obsolete.\\n3. The purpose of f.cpu() in line 11 is to move a tensor that was allocated on the GPU\\nto the CPU. This may be required if we want to apply a CPU-based method from the\\nPython numpy package on a T ensor that does not live in the CPU.\\n4. detach() in line 23 returns a newly created tensor without affecting the current tensor.\\nIt also detaches the output from the current computational graph, hence no gradient is\\nbackpropagated for this speciﬁc variable.\\n5. The purpose of numpy()[0] in line 23 is to convert the variable ('),\n",
              " Document(metadata={}, page_content=\" This may be required if we want to apply a CPU-based method from the\\nPython numpy package on a T ensor that does not live in the CPU.\\n4. detach() in line 23 returns a newly created tensor without affecting the current tensor.\\nIt also detaches the output from the current computational graph, hence no gradient is\\nbackpropagated for this speciﬁc variable.\\n5. The purpose of numpy()[0] in line 23 is to convert the variable (an array) to a numpy\\ncompatible variable and also to retrieve the ﬁrst element of the array.\\n\\x04\\n7.3.2 Fine-tuning CNNs\\nSOL-169 \\uf14b CH.SOL- 7.13.\\nThe term ﬁne-tuning (FT) of an ImageNet pre-trained CNN refers to the method by which\\none or more of the weights of the CNN are re-trained on a new target data-set, which may or\\nmay-not have similarities with the ImageNet data-set. \\x04\\nSOL-170 \\uf14b CH.SOL- 7.14. The three methods are as follows:\\n1. Replacing and re-training only the classiﬁer (usually the FC layer) of the ImageNet\\npre-trained CNN, on a target data-set.\\n2. FT all of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n3. FT part of the layers of the ImageNet pre-trained CNN, on a target data-set.\\n\\x04\\nSOL-171 \\uf14b CH.SOL- 7.15.\\n222Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The categories have to be represented numerically. One such option is presented in Code\\n(7.1).\\n1 'MEL' : 0, 'NV' : 1, 'BCC' : 2, 'AKIEC' : 3, 'BKL' : 4, 'DF' : 5,\\n'VASC' : 6↪→\\nCODE 7.1: The seven categories of skin lesions.\\n2. Several possible augmentations are presented in Code ( 7.2). It is usually, that by trial\\nand error one ﬁnds the best possible augmentation for a target data-set. However, meth-\\nods such as AutoAugment may render the manual selection of augmentations obsolete.\\n1 self.transforms = []\\n2 if rotate:\\n3 self.transforms.append(RandomRotate())\\n4 if flip:\\n5 self.transforms.append(RandomFlip())\\n6 if brightness != 0:\\n7 self.transforms.append(PILBrightness())\\n8 if contrast != 0:\\n9 self.transforms.append(PILContrast())\\n10 if colorbalance != 0:\\n11 self.transforms.append(PILColorBalance())\\n12 if sharpness != 0:\\n13 self.transforms.append(PILSharpness())\\nCODE 7.2: Pseudeo code for augmentations.\\n3. In contrast to the ResNet CNN which ends by an FC layer, the ImageNet pre-trained\\nDPN CNN family, in this case the pretrainedmodels.dpn107, terminated by a Conv2d\\n2237.3. SOLUTIONS\\nlayer and hence must be adapted accordingly if one wishes to change the number fo\\nclasses from the 1000 (ImageNet) classes to our skin lession classiﬁcation problem (7\\nclasses). Line 7 in Code ( 7.3) demonstrated this idiom.\\n1 import torch\\n2 class Dpn107Finetune(nn.Module):\\n3 def __init__(self, num_classes: int, net_kwards):\\n4 super().__init__()\\n5 self.net = pretrainedmodels.dpn107(**net_kwards)\\n6 self.net.__name__= str (self.net)\\n7 self.net.classifier = torch.nn.Conv2d(2688,\\nnum_classes,kernel_size=1)↪→\\n8 print(self.net)\\nCODE 7.3: Change between 1000 classes to 7 classes for the ImageNet pre-trained DPN\\nCNN family .\\n\\x04\\n7.3.3 Neural style transfer\\nSOL-172 \\uf14b CH.SOL- 7.16.\\nThe images are: a content image, a style image and lastly a combined image. \\x04\\nSOL-173 \\uf14b CH.SOL- 7.17.\\nThe algorithm presented in the paper suggests how to combine the content a ﬁrst image\\nwith the style of a second image to generate a third, stylized image using CNNs.\\n\\x04\\nSOL-174 \\uf14b CH.SOL- 7.18.\\nThe answers are as follows:\\n224Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The training pipeline uses a combined loss which consists of a weighted average of the\\nstyle loss and\"),\n",
              " Document(metadata={}, page_content='7.17.\\nThe algorithm presented in the paper suggests how to combine the content a ﬁrst image\\nwith the style of a second image to generate a third, stylized image using CNNs.\\n\\x04\\nSOL-174 \\uf14b CH.SOL- 7.18.\\nThe answers are as follows:\\n224Chapter 7 DEEP LEARNING: CNN FEATURE EXTRACTION\\n1. The training pipeline uses a combined loss which consists of a weighted average of the\\nstyle loss and the content loss.\\n2. Different CNN layers at different levels are utilized to capture both ﬁne-grained styl-\\nistic details as well as larger stylistic features.\\n\\x04\\nSOL-175 \\uf14b CH.SOL- 7.19.\\n1. The content loss is the mean square error (MSE) calculated as the difference between\\nthe CNN activations of the last convolutional layer of both the content image and the\\nstyle images.\\n2. The style loss amalgamates the losses of several layers together. For each layer, the gram\\nmatrix (see 7.2) for the activations at that layer is obtained for both the style and the\\ncombined images. Then, just like in the content loss, the MSE of the Gram matrices is\\ncalculated.\\n\\x04\\nSOL-176 \\uf14b CH.SOL- 7.20.\\nFor each feature map, a feature vector is extracted. The gram matrix captures the correl-\\nation between these feature vectors which is then being used in the loss function. Provided a\\nlist of feature vectors extracted from the images, u1, . . . , uk ∈ Rn, the Gram matrix is deﬁned\\nas: \\uf8eb\\n\\uf8ec\\uf8ec\\uf8ec\\uf8ed\\nu1 · u1 . . . u 1 · uk\\n... . . . ...\\nuk · u1 . . . u k · uk\\n\\uf8f6\\n\\uf8f7\\uf8f7\\uf8f7\\uf8f8 (7.2)\\nThe Gram matrix \\x04\\nReferences\\n[1] B. Chu et al. ‘Best Practices for Fine-Tuning Visual Classiﬁers to New Domains’.\\nIn: Computer Vision – ECCV 2016 Workshops . Ed. by G. Hua and H. Jégou. Cham:\\nSpringer International Publishing, 2016, pp. 435–442 (cit. on p. 206).\\n225REFERENCES\\n[2] L. A. Gatys, A. S. Ecker and M. Bethge. A Neural Algorithm of Artistic Style . 2015.\\narXiv: 1508.06576 [cs.CV] (cit. on p. 214).\\n[3] S. Kornblith, J. Shlens and Q. V . Le. Do Better ImageNet Models T ransfer Better?\\n2018. arXiv: 1805.08974 [cs.CV] (cit. on pp. 206, 213).\\n[4] A. Krizhevsky. One weird trick for parallelizing convolutional neural networks . 2014.\\narXiv: 1404.5997 [cs.NE] (cit. on p. 207).\\n[5] V . Nair and G. E. Hinton. ‘Rectiﬁed Linear Units Improve Restricted Boltzmann\\nMachines’. In: ICML 10 . Madison, WI, USA: Omnipress, 2010, pp. 807–814 (cit.\\non pp. 208, 218).\\n[6] A. J. R. L. Siegel K. D. Miller. ‘Cancer statistics 2016’. In: CA: a cancer journal for\\nclinicians 66,1 (2016), pp. 7–30 (cit. on p. 213).\\n[7] Russakovsky. ‘ImageNet Large Scale Visual Recognition Challenge’. In: Journal\\nof Computer Vision 115.3 (Apr. 2015), pp. 211–252 (cit. on pp. 206, 207).\\n[8] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 207–209, 214).\\n226CHAPTER\\n8\\nDEEP LEARNING\\nIt is the weight, not numbers of experiments that is to be regarded.\\n— Isaac Newton.\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . .'),\n",
              " Document(metadata={}, page_content='1556 [cs.CV] (cit. on pp. 207–209, 214).\\n226CHAPTER\\n8\\nDEEP LEARNING\\nIt is the weight, not numbers of experiments that is to be regarded.\\n— Isaac Newton.\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 234\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 235\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 236\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 239\\nConvolution and correlation in python . . . . . . . . . . . . . . 240\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 241\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 241\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 244\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 246\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 246The Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 247\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 248\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 249\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 251\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 251\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 253\\nSigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nTanh . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . 251\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 253\\nSigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 260\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 268\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 273\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 274\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 276\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 280\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 283\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 284\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\n228Chapter 8 DEEP LEARNING\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 286\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nSolutions . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . 286\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCross Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nK-Fold CV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289\\nStratiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290\\nConvolution and correlation . . . . . . . . . . . . . . . . . . . . . . . . . 291\\nThe convolution operator . . . . . . . . . . . . . . . . . . . . . . 291\\nThe correlation operator . . . . . . . . . . . . . . . . . . . . . . . 291\\nPadding and stride . . . . . . . . . . . . . . . . . . . . . . . . . . 292\\nKernels and ﬁlters . . . . . . . . . . . . . . . . . . . . . . . . . . 293\\nConvolution and correlation in python . . . . . . . . . . . . . . 294\\nSeparable convolutions . . . . . . . . . . . . . . . . . . . . . . . 295\\nSimilarity measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nImage, text similarity . . . . . . . . . . . . . . . . . . . . . . . . . 296\\nJacard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . 297\\nThe Kullback-Leibler Distance . . . . . . . . . . . . . . . . . . . 297\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299\\nThe Single Layer Perceptron . . . . . . . . . . . . . . . . . . . . 299\\nThe Multi Layer Perceptron . . . . . . . . . . . . . . . . . . . . . 300\\nActivation functions in perceptrons . . . . . . . . . . . . . . . . 301\\nBack-propagation in perceptrons . . . . . . . . . . . . . . . . . . 301\\nThe theory of perceptrons . . . . . . . . . . . . . . . . . . . . . . 304\\nLearning logical gates . . . . . . . . . . . . . . . . . . . . . . . . 305\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 306\\n229Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nTanh . . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . 305\\nActivation functions (rectiﬁcation) . . . . . . . . . . . . . . . . . . . . . 306\\n229Sigmoid . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310\\nReLU . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315\\nPerformance Metrics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nConfusion matrix, precision, recall . . . . . . . . . . . . . . . . . 316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nNN Layers, topologies, blocks . . . . . . . . . . . . . . . . . . . . . . . . 318\\nCNN arithmetics . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\\nDropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319\\nConvolutional Layer . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nPooling Layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322\\nBatch normalization, Gaussian PDF . . . . . . . . . . . . . . . . 324\\nThe Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . 324\\nBN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325\\nTheory of CNN design . . . . . . . . . . . . . . . . . . . . . . . . 326\\nCNN residual blocks . . . . . . . . . . . . . . . . . . . . . . . . . 326\\nTraining, hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nHyperparameter optimization . . . . . . . . . . . . . . . . . . . 327\\nLabelling and bias . . . . . . . . . . . . . . . . . . . . . . . . . . 328\\nValidation curve ACC . . . . . . . . . . . . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . . . . . . . . . . . . 329\\nInference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330\\nOptimization, Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 331\\nStochastic gradient descent, SGD . . . . . . . . . . . . . . . . . . 331\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333\\n230Chapter 8 DEEP LEARNING\\n8.1 Introduction\\nI\\nT was Alex Kriz'),\n",
              " Document(metadata={}, page_content=' . 331\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332\\nNorms, L1, L2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 333\\n230Chapter 8 DEEP LEARNING\\n8.1 Introduction\\nI\\nT was Alex Krizhevsky who ﬁrst demonstrated that a convolutional neural\\nnetwork (CNN) can be effectively trained on the ImageNet large scale visual\\nrecognition challenge. A CNN automatically provides some degree of trans-\\nlation and assumes that we wish to learn ﬁlters, in a data-driven fashion, as\\na means to extract features describing the inputs. CNNs are applied to numerous com-\\nputer vision, imaging, and computer graphics tasks as in [ 24], [ 23], [ 15], [ 5]. Further-\\nmore, they have become extremely popular, and novel architectures and algorithms\\nare continually popping up overnight.\\n8.2 Problems\\n8.2.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nPRB-177 \\uf059 CH.PRB- 8.1.\\nFig (8.1) depicts two different cross-validation approaches. Name them.\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\n1 2 3 4 5 6 7 8 10 9\\nTRAIN VAL\\nFIGURE 8.1: Two CV approaches\\n2318.2. PROBLEMS\\nPRB-178 \\uf059 CH.PRB- 8.2.\\n1. What is the purpose of the following Python code snippet 8.2 ?\\n1 skf = StratifiedKFold(y, n_folds =5, random_state =989,\\nshuffle=True)↪→\\nFIGURE 8.2: Stratiﬁed K-fold\\n2. Explain the beneﬁts of using the K-fold cross validation approach.\\n3. Explain the beneﬁts of using the Stratiﬁed K-fold cross validation approach.\\n4. State the difference between K-fold cross validation and stratiﬁed cross validation.\\n5. Explain in your own words what is meant by “We adopted a 5-fold cross-validation\\napproach to estimate the testing error of the model”.\\nK-Fold CV\\nPRB-179 \\uf059 CH.PRB- 8.3.\\nT rue or False: In a K-fold CV approach, the testing set is completely excluded from the\\nprocess and only the training and validation sets are involved in this approach.\\nPRB-180 \\uf059 CH.PRB- 8.4.\\nT rue or False: In a K-fold CV approach, the ﬁnal test error is:\\nCV (k) = 1\\nk\\nk∑\\ni=1\\nMSEi (8.1)\\n232Chapter 8 DEEP LEARNING\\nPRB-181 \\uf059 CH.PRB- 8.5.\\nMark all the correct choices regarding a cross-validation approach:\\n(i) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted.\\n(ii) A 5-fold cross-validation approach results in 1 model instance being ﬁtted over and\\nover again 5 times.\\n(iii) A 5-fold cross-validation approach results in 5-different model instances being ﬁtted\\nover and over again 5 times.\\n(iv) Uses K-different data-folds.\\nPRB-182 \\uf059 CH.PRB- 8.6.\\nMark all the correct choices regarding the approach that should be taken to compute the\\nperformance of K-fold cross-validation:\\n(i) We compute the cross-validation performance as the arithmetic mean over the K per-\\nformance estimates from the validation sets.\\n(ii) We compute the cross-validation performance as the best one over the K performance\\nestimates from the validation sets.\\nStratification\\nPRB-183 \\uf059 CH.PRB- 8.7.\\nA data-scientist who is interested in classifying cross sections of histopathology image\\nslices (8.3) decides to adopt a cross-validation approach he once read about in a book. Name\\nthe approach from the following options:\\n2338.2. PROBLEMS\\n1st\\n2nd\\n3rd\\nK-fold CV\\nVAL FOLD TRAIN F'),\n",
              " Document(metadata={}, page_content=' validation sets.\\nStratification\\nPRB-183 \\uf059 CH.PRB- 8.7.\\nA data-scientist who is interested in classifying cross sections of histopathology image\\nslices (8.3) decides to adopt a cross-validation approach he once read about in a book. Name\\nthe approach from the following options:\\n2338.2. PROBLEMS\\n1st\\n2nd\\n3rd\\nK-fold CV\\nVAL FOLD TRAIN FOLD\\nFIGURE 8.3: A speciﬁc CV approach\\n(i) 3-fold CV\\n(ii) 3-fold CV with stratiﬁcation\\n(iii) A (repeated) 3-fold CV\\nLOOCV\\nPRB-184 \\uf059 CH.PRB- 8.8.\\n1. T rue or false: The leave-one-out cross-validation (LOOCV) approach is a sub-case of\\nk-fold cross-validation wherein K equals N , the sample size.\\n2. T rue or false: It is always possible to ﬁnd an optimal value n, K = n in K-fold\\ncross-validation.\\n8.2.2 Convolution and correlation\\nThe convolution operator\\nPRB-185 \\uf059 CH.PRB- 8.9.\\nEquation 8.2 is commonly used in image processing:\\n(f ∗ g)(t) =\\n∫ ∞\\n−∞\\nf (τ )g(t − τ )dτ (8.2)\\n234Chapter 8 DEEP LEARNING\\n1. What does equation 8.2 represent?\\n2. What does g(t) represent?\\nPRB-186 \\uf059 CH.PRB- 8.10.\\nA data-scientist assumes that:\\ni A convolution operation is both linear and shift invariant.\\nii A convolution operation is just like correlation, except that we ﬂip over the ﬁlter before\\napplying the correlation operator.\\niii The convolution operation reaches a maximum, only in cases where the ﬁlter is mostly\\nsimilar to a speciﬁc section of the input signal.\\nIs he right in assuming so? Explain in detail the meaning of these statements.\\nThe correlation operator\\nPRB-187 \\uf059 CH.PRB- 8.11.\\nMark the correct choice(s):\\n1. The cross-correlation operator is used to ﬁnd the location where two different signals\\nare most similar.\\n2. The autocorrelation operator is used to ﬁnd when a signal is similar to a delayed ver-\\nsion of itself.\\nPRB-188 \\uf059 CH.PRB- 8.12.\\nA data-scientist provides you with a formulae for a discrete 2D convolution operation\\n(8.3):\\nf (x, y) ∗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf (m, n)h(x − m, y − n) (8.3)\\n2358.2. PROBLEMS\\nUsing only (8.3), write the equivalent 2D correlation operation.\\nPadding and stride\\nRecommended reading : “A guide to convolution arithmetic for deep learning ” by Vincent\\nDumoulin and Francesco Visin (2016) [ 22].\\nPRB-189 \\uf059 CH.PRB- 8.13.\\nWhen designing a convolutional neural network layer, one must also deﬁne how the ﬁlter\\nor kernel slides through the input signal. This is controlled by what is known as the stride\\nand padding parameters or modes. The two most commonly used padding approached in\\nconvolutions are the V ALIDand the SAME modes. Given an input stride of 1:\\n1. Deﬁne SAME\\n2. Deﬁne V ALID\\nPRB-190 \\uf059 CH.PRB- 8.14.\\nTrue or False: A valid convolution is a type of convolution operation that does not use\\nany padding on the input.\\nPRB-191 \\uf059 CH.PRB- 8.15.\\nY ou are provided with aK × K input signal and a θ × θ ﬁlter. The signal is subjected to\\nthe valid padding mode convolution. What are the resulting dimensions?\\narr = [\\n0 ... 0\\n0 ... 0\\n0 ... 0\\n] (8.4)\\nPRB-192 \\uf059 CH.PRB- 8.16.\\nAs depicted in ( 8.4), a ﬁlter is applied to a ×3 input signal. Identify the correct choice\\ngiven a stride of 1 and Same padding mode.\\n236Chapter 8 DEEP LEARNING\\nFIGURE 8.4: A padding approach\\n'),\n",
              " Document(metadata={}, page_content=' V ALID\\nPRB-190 \\uf059 CH.PRB- 8.14.\\nTrue or False: A valid convolution is a type of convolution operation that does not use\\nany padding on the input.\\nPRB-191 \\uf059 CH.PRB- 8.15.\\nY ou are provided with aK × K input signal and a θ × θ ﬁlter. The signal is subjected to\\nthe valid padding mode convolution. What are the resulting dimensions?\\narr = [\\n0 ... 0\\n0 ... 0\\n0 ... 0\\n] (8.4)\\nPRB-192 \\uf059 CH.PRB- 8.16.\\nAs depicted in ( 8.4), a ﬁlter is applied to a ×3 input signal. Identify the correct choice\\ngiven a stride of 1 and Same padding mode.\\n236Chapter 8 DEEP LEARNING\\nFIGURE 8.4: A padding approach\\nPRB-193 \\uf059 CH.PRB- 8.17.\\nAs depicted in in ( 8.5), a ﬁlter is applied to a 3 × 3 input signal, mark the correct choices\\ngiven a stride of 1.\\n(i) A represents a V ALID convolution and B represents a SAME convolution\\n(ii) A represents a SAME convolution and B represents a V ALID convolution\\n(iii) Both A and B represent a V ALID convolution\\n(iv) Both A and B represent a SAME convolution\\n2378.2. PROBLEMS\\nFIGURE 8.5: A padding approach\\nPRB-194 \\uf059 CH.PRB- 8.18.\\nIn this question we discuss the two most commonly used padding approaches in convo-\\nlutions; V ALIDand SAME . Fig.8.6 presents python code for generating an input signal\\narr001 and a convolution kernel f ilter001. The input signal, arr001 is ﬁrst initialized to\\nall zeros as follows:\\narr001 = [\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n0 0 0 0 0 0\\n] (8.5)\\n1. Without actually executing the code, determine what would be the resulting shape of\\nthe convolve2d() operation.\\n2. Manually compute the result of convolving the input signal with the provided ﬁlter.\\n3. Elaborate why the size of the resulting convolutions is smaller than the size of the\\ninput signal.\\n238Chapter 8 DEEP LEARNING\\n1 import numpy\\n2 import scipy.signal\\n3\\n4 arr01 = numpy.zeros((6, 6),dtype=float)\\n5 print (arr01)\\n6 arr01[:,:3] = 3.0\\n7 arr01[:,3:] = 1.0\\n8\\n9 filter001 = numpy.zeros((3, 3), dtype =float)\\n10 filter001[:,0] = 2.0\\n11 filter001[:,2] = -2.0\\n12\\n13 output = scipy.signal.convolve2d(arr01, filter, mode =\\'valid\\' )\\nFIGURE 8.6: Convolution and correlation in python\\nKernels and filters\\nPRB-195 \\uf059 CH.PRB- 8.19.\\nEquation 8.6 is the discrete equivalent of equation 8.2 which is frequently used in image\\nprocessing:\\n(y ∗ k)[i, j] =\\n∑\\nn\\n∑\\nm\\ny[i − n, j − m]k[n, m] (8.6)\\n1. Given the following discrete kernel in the X direction, what would be the equivalent Y\\ndirection?\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 1\\n−1 1\\n\\uf8f9\\n\\uf8fb (8.7)\\n2. Identify the discrete convolution kernel presented in ( 8.7).\\n2398.2. PROBLEMS\\nFIGURE 8.7: A 3 by 3 convolution kernel\\nPRB-196 \\uf059 CH.PRB- 8.20.\\nGiven an image of size w × h, and a kernel with width K, how many multiplications and\\nadditions are required to convolve the image?\\nConvolution and correlation in python\\nPRB-197 \\uf059 CH.PRB- 8.21.\\nFig.8.8 presents two built-in Python functions for the convolution and correlation oper-\\nators.\\n1 import nympy as np\\n2 np.convolve(A,B,\"full\") #'),\n",
              " Document(metadata={}, page_content='RB- 8.20.\\nGiven an image of size w × h, and a kernel with width K, how many multiplications and\\nadditions are required to convolve the image?\\nConvolution and correlation in python\\nPRB-197 \\uf059 CH.PRB- 8.21.\\nFig.8.8 presents two built-in Python functions for the convolution and correlation oper-\\nators.\\n1 import nympy as np\\n2 np.convolve(A,B,\"full\") # for convolution\\n3 np.correlate(A,B,\"full\") # for cross correlation\\nFIGURE 8.8: Convolution and correlation in python\\n1. Implement the convolution operation from scratch in Python. Compare it with the\\n240Chapter 8 DEEP LEARNING\\nbuilt-in numpy equivalent.\\n2. Implement the correlation operation using the implementation of the convolution op-\\neration. Compare it with the built-in numpy equivalent.\\nSeparable convolutions\\nPRB-198 \\uf059 CH.PRB- 8.22.\\nThe Gaussian distribution in the 1D and 2D is shown in Equations 8.8 and 8.9.\\nG(x) = 1√\\n2πσ e− x2\\n2σ2 (8.8)\\nG(x, y) = 1\\n2πσ 2 e− x2+y2\\n2σ2 (8.9)\\nThe Gaussian ﬁlter, is an operator that is used to blur images and remove detail and\\nnoise while acting like a low-pass ﬁlter. This is similar to the way a mean ﬁlter works, but\\nthe Gaussian ﬁlter uses a different kernel. This kernel is represented with a Gaussian bell\\nshaped bump.\\nAnswer the following questions:\\n1. Can 8.8 be used directly on a 2D image?\\n2. Can 8.9 be used directly on a 2D image?\\n3. Is the Gaussian ﬁlter separable? if so, what are the advantages of separable ﬁlters.\\n8.2.3 Similarity measures\\nImage, text similarity\\nPRB-199 \\uf059 CH.PRB- 8.23.\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n2418.2. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 8.9: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\n1 void xxx(std::vector<float>& arr) {\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nAn unknown algorithm in C++11\\nFIGURE 8.10: listing\\nWhich results in this vector ( 8.11):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 8.11: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n242Chapter 8 DEEP LEARNING\\nPRB-200 \\uf059 CH.PRB- 8.24.\\nFurther to the above, the scientist then applies the following algorithm:\\nAlgorithm 3: Algo 1\\nData: Two vectors v1 and v2 are provided\\nApply algorithm xxx on the two vectors\\nRun algorithm 2\\nAlgorithm 4: Algo 2\\n1 float algo2(const std::vector<float>& v1, const\\nstd::vector<float>& v2){↪→\\n2 double mul = 0;\\n3 for (size_t i = 0; i < v1.size(); ++i){\\n4 mul += v1[i] * v2[i];\\n5 }\\n6 if (mul < 0) {\\n7 return 0;\\n8 }\\n9 return mul;\\n10 }\\nFIGURE 8.12: An unknown algorithm\\n1. Name the algorithm algo2 that he used and explain in detail what he used it for.\\n2. Write the mathematical formulae behind it.\\n3. What are the minimum and maximum values it can return?\\n4. An alternative similarity measures between two vectors is:\\nsimeuc(v1, v2) = −||v1 − v2||. (8.10)\\nName the measure.\\n2438.2. PROBLE'),\n",
              " Document(metadata={}, page_content='FIGURE 8.12: An unknown algorithm\\n1. Name the algorithm algo2 that he used and explain in detail what he used it for.\\n2. Write the mathematical formulae behind it.\\n3. What are the minimum and maximum values it can return?\\n4. An alternative similarity measures between two vectors is:\\nsimeuc(v1, v2) = −||v1 − v2||. (8.10)\\nName the measure.\\n2438.2. PROBLEMS\\nJacard similarity\\nPRB-201 \\uf059 CH.PRB- 8.25.\\n1. What is the formulae for the Jaccard similarity [ 12] of two sets?:\\n2. Explain the formulae in plain words.\\n3. Find the Jacard similarity given the sets depicted in ( 8.13)\\nFIGURE 8.13: Jaccard similarity .\\n4. Compute the Jaccard similarity of each pair of the following sets:\\ni 12, 14, 16, 18.\\nii 11, 12, 13, 14, 15.\\niii 11, 16, 17.\\nThe Kullback-Leibler Distance\\nPRB-202 \\uf059 CH.PRB- 8.26.\\nIn this problem, you have to actually read 4 different papers, so you will probably not\\nencounter such a question during an interview, however reading academic papers is an ex-\\ncellent skill to master for becoming a DL researcher.\\nRead the following papers which discuss aspects of the Kullback-Leibler divergence:\\ni Bennet [2]\\n244Chapter 8 DEEP LEARNING\\nii Ziv [29]\\niii Bigi [3]\\niv Jensen [1]\\nThe Kullback-Leibler divergence, which was discussed thoroughly in chap 4 is a meas-\\nure of how different two probability distribution are. As noted, the KL divergence of the\\nprobability distributions P , Q on a set X is deﬁned as shown in Equation 8.11.\\nDKL(P ||Q) =\\n∑\\nx∈X\\nP (x)log P (x)\\nQ(x) (8.11)\\nNote however that since KL divergence is a non-symmetric information theoretical meas-\\nure of distance of P from Q, then it is not strictly a distance metric. During the past years,\\nvarious KL based distance measures (rather than divergence based) have been introduced in\\nthe literature generalizing this measure.\\nName each of the following KL based distances:\\nDKLD 1(P ||Q) = DKL(P ||Q) + DKL(Q||P ) (8.12)\\nDKLD 2(P ||Q) =\\n∑\\nx∈X\\n(P (x) − Q(x))log P (x)\\nQ(x) (8.13)\\nDKLD 3(P ||Q) = 1\\n2\\n[\\nDKL\\n(\\nP ||P + Q\\n2\\n)\\n+ DKL\\n(\\nQ||P + Q\\n2\\n)]\\n(8.14)\\nDKLD 4(P ||Q) = max (DKL(P ||Q) + DKL(Q||P )) (8.15)\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nPRB-203 \\uf059 CH.PRB- 8.27.\\nWhat is the goal of hashing? Draw a simple HashMap of keys and values. Explain what\\nis a collision and the notion of buckets. Explain what is the goal of MinHash.\\n2458.2. PROBLEMS\\nPRB-204 \\uf059 CH.PRB- 8.28.\\nWhat is Locality Sensitive Hashing or LSH?\\nPRB-205 \\uf059 CH.PRB- 8.29.\\nComplete the sentence : LSH main goal is to [...] the probability of a colliding, for\\nsimilar items in a corpus.\\n8.2.4 Perceptrons\\nThe Single Layer Perceptron\\nPRB-206 \\uf059 CH.PRB- 8.30.\\n1. complete the sentence : In a single-layer feed-forward NN, there are [...] input(s)\\nand [...]. output layer(s) and no [...] connections at all.\\nPRB-207 \\uf059 CH.PRB- 8.31.\\nIn its simplest form, a perceptron (8.16) accepts only a binary input and emits a binary\\noutput. The output, can be evaluated as follows:\\noutput =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0, if ∑\\nj wjxj + b ≤ 0,\\n1, if\\n∑\\nj wjxj + b > 0\\n. (8.16)\\nWhere weights are denoted by'),\n",
              " Document(metadata={}, page_content=' 8.31.\\nIn its simplest form, a perceptron (8.16) accepts only a binary input and emits a binary\\noutput. The output, can be evaluated as follows:\\noutput =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n0, if ∑\\nj wjxj + b ≤ 0,\\n1, if\\n∑\\nj wjxj + b > 0\\n. (8.16)\\nWhere weights are denoted by wj and biases are denoted by b. Answer the following ques-\\ntions:\\n1. T rue or False: If such a perceptron is trained using a labelled corpus, for each parti-\\ncipating neuron the values wj and b are learned automatically.\\n2. T rue or False: If we instead use a new perceptron (sigmoidial) deﬁned as follows:\\nσ(wx + b) (8.17)\\n246Chapter 8 DEEP LEARNING\\nwhere σ is the sigmoid function:\\nσ(z) = 1\\n1 + e−z . (8.18)\\nThen the new perceptron can process inputs ranging between 0 and 1 and emit output\\nranging between 0 and 1.\\n3. Write the cost function associated with the sigmoidial neuron.\\n4. If we want to train the perceptron in order to obtain the best possible weights and\\nbiases, which mathematical equation do we have to solve?\\n5. Complete the sentence: T o solve this mathematical equation, we have to apply [...]\\n6. What does the following equation stands for?\\n∇C = 1\\nn\\n∑\\nx\\n∇Cx (8.19)\\nWhere:\\nCx = 1\\n2∥y(x) − a(x, w, b)∥2 (8.20)\\n7. Complete the sentence: Due to the time-consuming nature of computing gradients for\\neach entry in the training corpus, modern DL libraries utilize a technique that gauges\\nthe gradient by ﬁrst randomly sampling a subset from the training corpus, and then\\naveraging only this subset in every epoch. This approach is known as [...]. The actual\\nnumber of randomly chosen samples in each epoch is termed [...]. The gradient itself\\nis obtained by an algorithm known as [...].\\nThe Multi Layer Perceptron\\nPRB-208 \\uf059 CH.PRB- 8.32.\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\n2478.2. PROBLEMS\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 8.14: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the value resulting from the application the sum operator?\\n3. Verify the correctness of your results using PyT orch.\\nActivation functions in perceptrons\\nPRB-209 \\uf059 CH.PRB- 8.33.\\nThe following questions refer to the MLP depicted in ( 8.15).\\n1. Further to the above, the ReLU non-linear activation function g(z) = max {0, z} is\\napplied ( 8.15) to the output of the linear transformation. What is the value of the\\noutput (out2) now?\\nx1\\nH1\\nx2\\ng(x1, x2)\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1 out2\\n0.001\\nInputs Hidden ActivationSum\\nFIGURE 8.15: Several nodes in a MLP .\\n248Chapter 8 DEEP LEARNING\\n2. Conﬁrm your manual calculation using PyT orch tensors.\\nBack-propagation in perceptrons\\nPRB-210 \\uf059 CH.PRB- 8.34.\\nY our co-worker, an postgraduate student at M.I.T, suggests using the following activa-\\ntion functions in a MLP . Which ones can never be back-propagated and why?\\ni\\nf (x) = |x| (8.21)\\nii\\nf (x) = x (8.22)\\niii\\nf (x)'),\n",
              " Document(metadata={}, page_content=' orch tensors.\\nBack-propagation in perceptrons\\nPRB-210 \\uf059 CH.PRB- 8.34.\\nY our co-worker, an postgraduate student at M.I.T, suggests using the following activa-\\ntion functions in a MLP . Which ones can never be back-propagated and why?\\ni\\nf (x) = |x| (8.21)\\nii\\nf (x) = x (8.22)\\niii\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx sin(1/x) if x ̸= 0\\n0 if x = 0\\n(8.23)\\niv\\nf (x) =\\n\\uf8f1\\n\\uf8f4\\uf8f4\\uf8f2\\n\\uf8f4\\uf8f4\\uf8f3\\nx2 x > 0\\n−x x < 0\\n0 x = 0\\n(8.24)\\nPRB-211 \\uf059 CH.PRB- 8.35.\\nY ou are provided with the following MLP as depicted in 8.16.\\n2498.2. PROBLEMS\\nθ0\\nθ1\\nθ2\\nH1\\nH2\\nH3\\nγ1\\nγ2\\nFIGURE 8.16: A basic MLP\\nThe ReLU non-linear activation function g(z) = max {0, z} is applied to the hidden\\nlayers H1...H3 and the bias term equals 0.001.\\nAt a certain point in time it has the following values 8.17 all of which are belong to the\\ntype torch.F loatT ensor:\\n1 import torch\\n2 x= torch.tensor([0.9,0.7]) # Input\\n3 w= torch.tensor([\\n4 [-0.3,0.15],\\n5 [0.32,-0.91],\\n6 [0.37,0.47],\\n7 ]) # Weights\\n8 B= torch.tensor([0.002]) # Bias\\nFIGURE 8.17: MLP operations.\\n1. Using Python, calculate the output of the MLP at the hidden layers H1...H3.\\n2. Further to the above, you discover that at a certain point in time that the weights\\nbetween the hidden layers and the output layers γ1 have the following values:\\n1 w1= torch.tensor([\\n2 [0.15,-0.46,0.59],\\n3 [0.10,0.32,-0.79],\\n4 )\\n250Chapter 8 DEEP LEARNING\\nWhat is the value observed at the output nodes γ1..γ2?\\n3. Assume now that a Softmax activation is applied to the output. What are the resulting\\nvalues?\\n4. Assume now that a cross-entropy loss is applied to the output of the Softmax.\\nL = −\\n∑\\ni\\nˆyi log (yi) (8.25)\\nWhat are the resulting values?\\nThe theory of perceptrons\\nPRB-212 \\uf059 CH.PRB- 8.36. If someone is quoted saying:\\nMLP networks are universal function approximators.\\nWhat does he mean?\\nPRB-213 \\uf059 CH.PRB- 8.37.\\nT rue or False: the output of a perceptron is 0 or 1.\\nPRB-214 \\uf059 CH.PRB- 8.38.\\nT rue or False: A multi-layer perceptron falls under the category of supervised machine\\nlearning.\\nPRB-215 \\uf059 CH.PRB- 8.39.\\nT rue or False: The accuracy of a perceptron is calculated as the number of correctly\\nclassiﬁed samples divided by the total number of incorrectly classiﬁed samples.\\nLearning logical gates\\n2518.2. PROBLEMS\\nPRB-216 \\uf059 CH.PRB- 8.40.\\nThe following questions refer to the SLP depicted in ( 8.18). The weights in the SLP are\\nw1 = 1 and w2 = 1 respectively. There is a single hidden node, H1. The bias term, B1 equals\\n−2.5.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1 =\\n1\\nw2 =\\n1\\nout1\\n−2.5\\nInputs\\nHidden\\nSum\\nFIGURE 8.18: A single layer perceptron.\\n1. Assuming the inputs to the SLP in ( 8.18) are\\ni x1 = 0.0 and x2 = 0.0\\nii x1 = 0.0 and x2 = 1.0\\niii x1 = 1.0 and x2 = 0.0\\niv x1 = 1.'),\n",
              " Document(metadata={}, page_content='−2.5\\nInputs\\nHidden\\nSum\\nFIGURE 8.18: A single layer perceptron.\\n1. Assuming the inputs to the SLP in ( 8.18) are\\ni x1 = 0.0 and x2 = 0.0\\nii x1 = 0.0 and x2 = 1.0\\niii x1 = 1.0 and x2 = 0.0\\niv x1 = 1.0 and x2 = 1.0\\nWhat is the value resulting from the application the sum operator?\\n2. Repeat the above, assuming now that the bias term B1 was amended and equals −0.25.\\n3. Deﬁne what is the perceptron learning rule.\\n4. What was the most crucial difference between Rosenblatt’s original algorithm and\\nHinton’s fundamental papers of 1986:\\n“Learning representations by back-propagating errors ” [22]\\nand 2012:\\n“ImageNet Classiﬁcation with Deep Convolutional Neural Networks ” [18]?\\n5. The AND logic gate [ 7] is deﬁned by the following table ( 8.19):\\n252Chapter 8 DEEP LEARNING\\nx1 x2 y\\n1 1 1\\n1 0 0\\n0 1 0\\n0 0 0\\nFIGURE 8.19: Logical AND gate\\nCan a perceptron with only two inputs and a single output function as an AND logic\\ngate? If so, ﬁnd the weights and the threshold and demonstrate the correctness of your\\nanswer using a truth table.\\n8.2.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\nPRB-217 \\uf059 CH.PRB- 8.41.\\nThe Sigmoid sc(x) = 1\\n1+e−cx , also commonly known as the logistic function (Fig. 8.20),\\nis widely used in binary classiﬁcation and as a neuron activation function in artiﬁcial neural\\nnetworks. Typically, during the training of an ANN, a Sigmoid layer applies the Sigmoid\\nfunction to elements in the forward pass, while in the backward pass the chain rule is be-\\ning utilized as part of the backpropagation algorithm. In 8.20 the constant c was selected\\narbitrarily as 2 and 5 respectively.\\n2538.2. PROBLEMS\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n0,2\\n0,4\\n0,6\\n0,8\\n1,0\\nx\\nyσ(x) = 1\\n1+e−2x\\nσ(x) = 1\\n1+e−5x\\nσ(x) = 1\\n1+2−1.5x\\nFIGURE 8.20: Examples of two sigmoid functions and an approximation.\\nDigital hardware implementations of the sigmoid function do exist but they are expens-\\nive to compute and therefore several approximation methods were introduced by the research\\ncommunity. The method by [ 10] uses the following formulas to approximate the exponential\\nfunction:\\nex ≈ Ex(x) ≈ 21.44x (8.26)\\nBased on this formulation, one can calculate the sigmoid function as:\\nSigmoid (x) ≈ 1\\n1 + 2−1.44x ≈ 1\\n1 + 2−1.5x (8.27)\\n1. Code snippet 8.21 provides a pure C++ based (e.g. not using Autograd) implementa-\\ntion of the forward pass for the Sigmoid function. Implement the backward pass that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19] style tensors.\\n254Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001( const torch::Tensor & x ){\\n5 torch::Tensor sig = 1.0 / (1.0 + torch::exp(( -x)));\\n6 return sig;\\n7 }\\nFIGURE 8.21: Forward pass for the Sigmoid function using Libtorch\\n2. Code snippet 8.22 provides a skeleton for printing the values of the sigmoid and its\\nderivative for a range of values contained in the vector v. Complete the code (lines 7-8)\\nso that the values are printed.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0'),\n",
              " Document(metadata={}, page_content=';\\n7 }\\nFIGURE 8.21: Forward pass for the Sigmoid function using Libtorch\\n2. Code snippet 8.22 provides a skeleton for printing the values of the sigmoid and its\\nderivative for a range of values contained in the vector v. Complete the code (lines 7-8)\\nso that the values are printed.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 ...\\n8 ...\\n9 }\\n10 }\\n.\\nFIGURE 8.22: Evaluation of the sigmoid and its derivative using Libtorch\\n3. Manually derive the derivative of eq. 8.27, e.g:\\nd\\ndx\\n[ 1\\n1 + 2−1.5x\\n]\\n(8.28)\\n2558.2. PROBLEMS\\n4. Implement both the forward pass for the Sigmoid function approximation eq. 8.27 that\\ndirectly computes the analytical gradients in C++ using Libtorch [ 19].\\n5. Print the values of the Sigmoid function and the Sigmoid function approximation eq.\\n8.27 for the following vector:\\nv = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.99] (8.29)\\nTanh\\nPRB-218 \\uf059 CH.PRB- 8.42.\\nThe Hyperbolic tangent nonlinearity, or the tanh function (Fig. 8.23), is a widely used\\nneuron activation function in artiﬁcial neural networks:\\nftanh (x) = sinh(x)\\ncosh(x) = ex − e−x\\nex + e−x (8.30)\\n−4,0 −3,0 −2,0 −1,0 1,0 2,0 3,0 4,0\\n−4,0\\n−2,0\\n2,0\\n4,0\\nx\\nyσ(x) = 4 ∗ tanh x\\n4\\nσ(x) = tanh x\\n4\\nFIGURE 8.23: Examples of two tanh functions.\\n1. Manually derive the derivative of the tanh function.\\n256Chapter 8 DEEP LEARNING\\n2. Use this numpy array as an input [[0.37, 0.192, 0.571]] and evaluate the result using\\npure Python.\\n3. Use the PyT orch based torch.autograd.F unction class to write a custom Function\\nthat implements the forward and backward passes for the tanh function in Python.\\n4. Name the class T anhFunction, and using the gradcheck method from torch.autograd,\\nverify that your numerical values equate the analytical values calculated by gradcheck.\\nRemember you must implement a method entitled .apply(x) so that the function can\\nbe invoked by Autograd.\\nPRB-219 \\uf059 CH.PRB- 8.43.\\nThe code snippet in 8.24 makes use of the tanh function.\\n1 import torch\\n2\\n3 nn001 = nn.Sequential(\\n4 nn.Linear(200, 512),\\n5 nn.Tanh(),\\n6 nn.Linear(512, 512),\\n7 nn.Tanh(),\\n8 nn.Linear(512, 10),\\n9 nn.LogSoftmax(dim=1)\\n10 )\\nFIGURE 8.24: A simple NN based on tanh in PyTorch.\\n1. What type of a neural network does nn001 in 8.24 represent?\\n2. How many hidden layers does the layer entitles nn001 have?\\nPRB-220 \\uf059 CH.PRB- 8.44.\\n2578.2. PROBLEMS\\nY our friend, a veteran of the DL community claims that MLPs based on tanh activation\\nfunction, have a symmetry around 0 and consequently cannot be saturated. Saturation, so\\nhe claims is a phenomenon typical of the top hidden layers in sigmoid based MLPs. Is he\\nright or wrong?\\nPRB-221 \\uf059 CH.PRB- 8.45.\\nIf we initialize the weights of a tanh based NN, which of the following approaches will\\nlead to the vanishing gradients problem?.\\ni Using the normal distribution, with parameter'),\n",
              " Document(metadata={}, page_content=' on tanh activation\\nfunction, have a symmetry around 0 and consequently cannot be saturated. Saturation, so\\nhe claims is a phenomenon typical of the top hidden layers in sigmoid based MLPs. Is he\\nright or wrong?\\nPRB-221 \\uf059 CH.PRB- 8.45.\\nIf we initialize the weights of a tanh based NN, which of the following approaches will\\nlead to the vanishing gradients problem?.\\ni Using the normal distribution, with parameter initialization method as suggested by\\nKaiming [14].\\nii Using the uniform distribution, with parameter initialization method as suggested by\\nXavier Glorot [9].\\niii Initialize all parameters to a constant zero value.\\nPRB-222 \\uf059 CH.PRB- 8.46.\\nY ou friend, who is experimenting with the tanh activation function designed a small\\nCNN with only one hidden layer and a linear output ( 8.25):\\nFIGURE 8.25: A small CNN composed of tanh blocks.\\nHe initialized all the weights and biases (biases not shown for brevity) to zero. What is\\nthe most signiﬁcant design ﬂaw in his architecture?\\nHint: think about back-propagation.\\nReLU\\nPRB-223 \\uf059 CH.PRB- 8.47.\\n258Chapter 8 DEEP LEARNING\\nThe rectiﬁed linear unit, or ReLU g(z) = max {0, z} is the default for many CNN archi-\\ntectures. It is deﬁned by the following function:\\nfReLU(x) = max(0 , x) (8.31)\\nOr:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.32)\\n1. In what sense is the ReLU better than traditional sigmoidal activation functions?\\nPRB-224 \\uf059 CH.PRB- 8.48.\\nY ou are experimenting with the ReLU activation function, and you design a small CNN\\n(8.26) which accepts an RGB image as an input. Each CNN kernel is denoted by w.\\nFIGURE 8.26: A small CNN composed of ReLU blocks.\\nWhat is the shape of the resulting tensor W ?\\nPRB-225 \\uf059 CH.PRB- 8.49.\\nName the following activation function where a ∈ (0, 1):\\nf (x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\nx if x > 0\\nax otherwise\\n(8.33)\\nSwish\\n2598.2. PROBLEMS\\nPRB-226 \\uf059 CH.PRB- 8.50.\\nIn many interviews, you will be given a paper that you have never encountered before,\\nand be required to read and subsequently discuss it. Please read Searching for Activation\\nFunctions [21] before attempting the questions in this question.\\n1. In [21], researchers employed an automatic pipeline for searching what exactly?\\n2. What types of functions did the researchers include in their search space?\\n3. What were the main ﬁndings of their research and why were the results surprising?\\n4. Write the formulae for the Swish activation function.\\n5. Plot the Swish activation function.\\n8.2.6 Performance Metrics\\nComparing different machine learning models, tuning hyper parameters and learn-\\ning rates, ﬁnding optimal augmentations, are all important steps in ML research. Typ-\\nically our goal is to ﬁnd the best model with the lowest errors on both the training\\nand validation sets. To do so we need to be able to measure the performance of each\\napproach/model/parameter setting etc. and compare those measures. For valuable\\nreference, read: “Evaluating Learning Algorithms: A Classiﬁcation Perspective ” [22]\\nConfusion matrix, precision, recall\\nPRB-227 \\uf059 CH.PRB- 8.51.\\nY ou design a binary classiﬁer for detecting the presence of malfunctioning temperature\\nsensors. Non-malfunctioning (N) devices are the majority class in the training corpus. While\\nrunning inference on an unseen test-set, you discover that the Confusion Metrics (CM) has\\nthe following values 8.27:\\n260Chapter 8 DEEP LEARNING\\nPredicted\\nP N\\nActual P 12 7\\nN 24 1009\\nFIGURE 8.27: A confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices.\\n1. Find: TP , TN, FP , FN and correctly label the numbers in table 8.27.\\n2. What is the accuracy of the model?\\n3. What is the precision of'),\n",
              " Document(metadata={}, page_content='8.27:\\n260Chapter 8 DEEP LEARNING\\nPredicted\\nP N\\nActual P 12 7\\nN 24 1009\\nFIGURE 8.27: A confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices.\\n1. Find: TP , TN, FP , FN and correctly label the numbers in table 8.27.\\n2. What is the accuracy of the model?\\n3. What is the precision of the model?\\n4. What is the recall of the model?\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\nFIGURE 8.28: Receiver Operating Characteristic curve.\\n2618.2. PROBLEMS\\nPRB-228 \\uf059 CH.PRB- 8.52.\\nComplete the following sentences:\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween [...] and [...].\\n2. It is a plot of [...] vs. the [...]. In place of [...], one could also use [...] which are essen-\\ntially {1 - ‘true negatives’ }.\\n3. A typical ROC curve has a concave shape with [...] as the beginning and [...] as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely con-\\nfused and cannot at all distinguish between the two classes, has an AUC of [...] which\\nis the [...] line in an ROC curve plot.\\nPRB-229 \\uf059 CH.PRB- 8.53.\\nThe code 8.30 and Figure 8.29 are the output from running XGBOOST for a binary\\nclassiﬁcation task.\\nFIGURE 8.29: RUC AUC\\n262Chapter 8 DEEP LEARNING\\n1 XGBClassifier(base_score=0.5, colsample_bylevel =1,\\ncolsample_bytree=0.5,↪→\\n2 gamma=0.017, learning_rate =0.15, max_delta_step =0, max_depth =9,\\n3 min_child_weight=3, missing =None, n_estimators =1000, nthread =-1,\\n4 objective=\\'binary:logistic\\' , reg_alpha =0, reg_lambda =1,\\n5 scale_pos_weight=1, seed =0, silent =1,\\nsubsample=0.9)shape:(316200, 6)↪→\\n6\\n7 >ROC AUC: 0.984439608912\\n8 >LOG LOSS: 0.0421598347226\\nFIGURE 8.30: XGBOOST for binary classiﬁcation.\\nHow would you describe the results of the classiﬁcation?.\\n8.2.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nPRB-230 \\uf059 CH.PRB- 8.54.\\nGiven an input of size of n × n, ﬁlters of size f × f and a stride of s with padding of p,\\nwhat is the output dimension?\\nPRB-231 \\uf059 CH.PRB- 8.55.\\nReferring the code snippet in Fig. ( 8.31), answer the following questions regarding the\\nVGG11 architecture [25]:\\n2638.2. PROBLEMS\\n1 import torchvision\\n2 import torch\\n3 def main():\\n4 vgg11 = torchvision.models.vgg11(pretrained=True)\\n5 vgg_layers = vgg11.features\\n6 for param in vgg_layers.parameters():\\n7 param.requires_grad = False\\n8\\n9 example = [torch.rand(1, 3, 224, 224),\\n10 torch.rand(1, 3, 512, 512),\\n11 torch.rand(1, 3, 704, 1024)]\\n12 vgg11.eval()\\n13 for e in example:\\n14 out=vgg_layers(e)\\n15 print(out.shape)\\n16 if __name__ == \"__main__\":\\n17 main()^^I^^I\\nFIGURE 8.31: CNN arithmetics on the VGG11 CNN model.\\n1. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the VGG11 CNN to the respective input.\\n2. Choose the correct option. The last layer of the VGG11 architecture is:\\ni Conv2d\\nii MaxPool2d\\niii ReLU\\nPRB-232 \\uf059 CH.PRB- 8.56.\\nStill referring the code snippet in Fig. ( 8.31), and speciﬁcally'),\n",
              " Document(metadata={}, page_content=' case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the VGG11 CNN to the respective input.\\n2. Choose the correct option. The last layer of the VGG11 architecture is:\\ni Conv2d\\nii MaxPool2d\\niii ReLU\\nPRB-232 \\uf059 CH.PRB- 8.56.\\nStill referring the code snippet in Fig. ( 8.31), and speciﬁcally to line 7, the code is\\namended so that the line is replaced by the line:\\nvgg_layers=vgg11.features[:3] .\\n264Chapter 8 DEEP LEARNING\\n1. What type of block is now represented by the new line? Print it using PyT orch.\\n2. In each case for the input variable example , determine the dimensions of the tensor\\nwhich is the output of applying the block:\\nvgg_layers=vgg11.features[:3] to the respective input.\\nPRB-233 \\uf059 CH.PRB- 8.57.\\nT able (8.1) presents an incomplete listing of the of the VGG11 architecture [ 25]. As\\ndepicted, for each layer the number of ﬁlters (i. e., neurons with unique set of parameters) are\\npresented.\\nLayer #Filters\\nconv4_3 512\\nfc6 4,096\\nfc7 4,096\\noutput 1,000\\nTABLE 8.1: Incomplete listing of the VGG11 architecture.\\nComplete the missing parts regarding the dimensions and arithmetics of the VGG11\\nCNN architecture:\\n1. The VGG11 architecture consists of [...] convolutional layers.\\n2. Each convolutional layer is followed by a [...] activation function, and ﬁve [...] opera-\\ntions thus reducing the preceding feature map size by a factor of [...].\\n3. All convolutional layers have a [...] kernel.\\n4. The ﬁrst convolutional layer produces [...] channels.\\n5. Subsequently as the network deepens, the number of channels [...] after each [...] oper-\\nation until it reaches [...].\\n2658.2. PROBLEMS\\nDropout\\nPRB-234 \\uf059 CH.PRB- 8.58.\\nA Dropout layer [26] (Fig. 8.32) is commonly used to regularize a neural network model\\nby randomly equating several outputs (the crossed-out hidden node H) to 0.\\nθ0\\nH\\nH\\nDropout\\nFIGURE 8.32: A Dropout layer (simpliﬁed form).\\nFor instance, in PyT orch [20], a Dropout layer is declared as follows ( 8.2):\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Dropout(0.2)\\nCODE 8.2: Dropout in PyTorch\\nWhere nn.Dropout(0.2) (Line #3 in 8.2) indicates that the probability of zeroing an\\nelement is 0.2.\\n266Chapter 8 DEEP LEARNING\\nθ1\\nθ2\\nH1\\nH2\\nγ1\\nFIGURE 8.33: A Bayesian Neural Network Model\\nA new data scientist in your team suggests the following procedure for a Dropout layer\\nwhich is based on Bayesian principles. Each of the neurons θn in the neural network in (Fig.\\n8.33) may drop (or not) independently of each other exactly like a Bernoulli trial.\\nDuring the training of a neural network, the Dropout layer randomly drops out outputs\\nof the previous layer, as indicated in (Fig. 8.32). Here, for illustration purposes, all four\\nneurons are dropped as depicted by the crossed-out hidden nodes Hn.\\n1. Y ou are interested in the proportionθ of dropped-out neurons. Assume that the chance\\nof drop-out, θ, is the same for each neuron (e.g. a uniform prior for θ). Compute the\\nposterior of θ.\\n2. Describe the similarities of dropout to bagging.\\nPRB-235 \\uf059 CH.PRB- 8.59.\\nA co-worker claims he discovered an equivalence theorem where, two consecutive Dro-\\npout layers [26] can be replaced and represented by a single Dropout layer 8.34.\\nFIGURE 8.34: Two consecutive Dropout layers\\nHi realized two consecutive layers in PyT orch [20], declared as follows ( 8.3):\\n2678.2. PROBLEMS\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Sequential(\\n4 nn.Conv2d(1024, 32),\\n5 nn.ReLU(),\\n6 nn.Dropout(p=P, inplace =True),\\n7 nn.Dropout(p=Q, inplace =True)\\n8 )\\nCODE 8'),\n",
              " Document(metadata={}, page_content='.\\nFIGURE 8.34: Two consecutive Dropout layers\\nHi realized two consecutive layers in PyT orch [20], declared as follows ( 8.3):\\n2678.2. PROBLEMS\\n1 import torch\\n2 import torch.nn as nn\\n3 nn.Sequential(\\n4 nn.Conv2d(1024, 32),\\n5 nn.ReLU(),\\n6 nn.Dropout(p=P, inplace =True),\\n7 nn.Dropout(p=Q, inplace =True)\\n8 )\\nCODE 8.3: Consequtive dropout in PyTorch\\nWhere nn.Dropout(0.1) (Line #6 in 8.3) indicates that the probability of zeroing an\\nelement is 0.1.\\n1. What do you think about his idea, is he right or wrong?\\n2. Either prove that he is right or provide a single example that refutes his theorem.\\nConvolutional Layer\\nThe convolution layer is probably one of the most important layers in the theory and\\npractice of modern deep learning and computer vision in particular.\\nTo study the optimal number of convolutional layers for the classiﬁcation of two\\ndifferent types of the Ebola virus, a researcher designs a binary classiﬁcation pipeline\\nusing a small CNN with only a few layers ( 8.35):\\n268Chapter 8 DEEP LEARNING\\nFIGURE 8.35: A CNN based classiﬁcation system.\\nAnswer the following questions while referring to ( 8.35):\\nPRB-236 \\uf059 CH.PRB- 8.60.\\nIf he uses the following ﬁlter for the convolutional operation, what would be the resulting\\ntensor after the application of the convolutional layer?\\nFIGURE 8.36: A small ﬁlter for a CNN\\nPRB-237 \\uf059 CH.PRB- 8.61.\\nWhat would be the resulting tensor after the application of the ReLU layer ( 8.37)?\\n2698.2. PROBLEMS\\nFIGURE 8.37: The result of applying the ﬁlter.\\nPRB-238 \\uf059 CH.PRB- 8.62.\\nWhat would be the resulting tensor after the application of the MaxPool layer ( 8.78)?\\nPooling Layers\\nA pooling layer transforms the output of a convolutional layer, and neurons in a pool-\\ning layer accept the outputs of a number of adjacent feature maps and merge their\\noutputs into a single number.\\nMaxPooling\\nPRB-239 \\uf059 CH.PRB- 8.63.\\nThe following input 8.38 is subjected to a MaxPool2D(2,2) operation having 2 × 2 max-\\npooling ﬁlter with a stride of 2 and no padding at all.\\n270Chapter 8 DEEP LEARNING\\nFIGURE 8.38: Input to MaxPool2d operation.\\nAnswer the following questions:\\n1. What is the most common use of max-pooling layers?\\n2. What is the result of applying the MaxPool2d operation on the input?\\nPRB-240 \\uf059 CH.PRB- 8.64.\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and evaluate its behaviour during inference:\\n2718.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 8.4: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n272Chapter 8 DEEP LEARNING\\nFIGURE 8.39: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist'),\n",
              " Document(metadata={}, page_content='.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 8.4: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n272Chapter 8 DEEP LEARNING\\nFIGURE 8.39: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet a second MaxPool2D(2,2).\\nWhat is the resulting tensor shape after running line 9? and line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\nBatch normalization, Gaussian PDF\\nRecommended readings for this topic are “ Batch Normalization: Accelerating Deep Net-\\nwork T raining by Reducing Internal Covariate Shift ” [16] and “ Delving deep into rectiﬁers:\\nSurpassing human-level performance on imagenet classiﬁcation ” [14].\\nA discussion of batch normalization (BN) would not be complete without a discus-\\nsion of the Gaussian normal distribution. Though it would be instructive to develop\\nthe forward and backwards functions for a BN operation from scratch, it would also\\nbe quite complex. As an alternative we discuss several aspects of the BN operation\\nwhile expanding on the Gaussian distribution.\\n2738.2. PROBLEMS\\nThe Gaussian distribution\\nPRB-241 \\uf059 CH.PRB- 8.65.\\n1. What is batch normalization?\\n2. The normal distribution is deﬁned as follows:\\nP (x) = 1\\nσ\\n√\\n2π e−(x−µ)2/2σ2\\n(8.34)\\nGenerally i.i.d. X ∼ N (µ, σ2) however BN uses the standard normal distribution.\\nWhat mean and variance does the standard normal distribution have?\\n3. What is the mathematical process of normalization?\\n4. Describe, how normalization works in BN.\\nPRB-242 \\uf059 CH.PRB- 8.66.\\nIn python, the probability density function for a normal distribution is given by 8.40:\\n1 import scipy\\n2 scipy.stats.norm.pdf(x, mu, sigma)\\nFIGURE 8.40: Normal distribution in Python.\\n1. Without using Scipy, implement the normal distribution from scratch in Python.\\n2. Assume, you want to back propagate on the normal distribution, and therefore you\\nneed the derivative. Using Scipy write a function for the derivative.\\nBN\\nPRB-243 \\uf059 CH.PRB- 8.67.\\n274Chapter 8 DEEP LEARNING\\nY our friend, a novice data scientist, uses an RGB image ( 8.41) which he then subjects to\\nBN as part of training a CNN.\\nFIGURE 8.41: A convolution and BN applied to an RGB image.\\n1. Help him understand, during BN, is the normalization applied pixel-wise or per colour\\nchannel?\\n2. In the PyT orch implementation, he made a silly mistake 8.42, help him identify it:\\n2758.2. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class BNl001(nn.Module):\\n4 def __init__(self):\\n5 super(BNl001, self).__init__()\\n6 self.cnn = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 64, kernel_size =3, padding =2),\\n8 )\\n9 self.math= torch.nn.Sequential(\\n10 torch.nn.BatchNorm2d(32),\\n11 torch.nn.PReLU(),\\n12 torch.nn.Dropout2d(0.05)\\n13 )\\n14 def forward(self, x):\\n15 ...\\nFIGURE 8.42: A mistake in a CNN\\nTheory of CNN design\\nPRB-244 \\uf059 CH.PRB- 8.68.\\nTrue or false: An activation function applied after a Dropout, is equivalent to an activ-\\nation function applied before a'),\n",
              " Document(metadata={}, page_content='.math= torch.nn.Sequential(\\n10 torch.nn.BatchNorm2d(32),\\n11 torch.nn.PReLU(),\\n12 torch.nn.Dropout2d(0.05)\\n13 )\\n14 def forward(self, x):\\n15 ...\\nFIGURE 8.42: A mistake in a CNN\\nTheory of CNN design\\nPRB-244 \\uf059 CH.PRB- 8.68.\\nTrue or false: An activation function applied after a Dropout, is equivalent to an activ-\\nation function applied before a dropout.\\nPRB-245 \\uf059 CH.PRB- 8.69.\\nWhich of the following core building blocks may be used to construct CNNs? Choose all\\nthe options that apply:\\ni Pooling layers\\nii Convolutional layers\\niii Normalization layers\\niv Non-linear activation function\\n276Chapter 8 DEEP LEARNING\\nv Linear activation function\\nPRB-246 \\uf059 CH.PRB- 8.70.\\nY ou are designing a CNN which has a single BN layer. Which of the following core CNN\\ndesigns are valid? Choose all the options that apply:\\ni CONV → act → BN → Dropout → . . .\\nii CONV → act → Dropout → BN → . . .\\niii CONV → BN → act → Dropout → . . .\\niv BN → CONV → act → Dropout → . . .\\nv CONV → Dropout → BN → act → . . .\\nvi Dropout → CONV → BN → act → . . .\\nPRB-247 \\uf059 CH.PRB- 8.71.\\nThe following operator is known as the Hadamard product:\\nOUT = A ⊙ B (8.35)\\nWhere:\\n(A ⊙ B)i,j := (A)i,j(B)i,j (8.36)\\nA scientist, constructs a Dropout layer using the following algorithm:\\ni Assign a probability of p for zeroing the output of any neuron.\\nii Accept an input tensor T , having a shape S\\niii Generate a new tensor T ‘∈ {0, 1}S\\niv Assign each element in T ‘a randomly and independently sampled value from a Bernoulli\\ndistribution:\\nT ‘i ∼ B(1, p) (8.37)\\n2778.2. PROBLEMS\\nv Calculate the OU T tensor as follows:\\nOUT = T ‘⊙ T (8.38)\\nY ou are surprised to ﬁnd out that his last step is to multiply the output of a dropout layer\\nwith:\\n1\\n1 − p (8.39)\\nExplain what is the purpose of multiplying by the term 1\\n1−p .\\nPRB-248 \\uf059 CH.PRB- 8.72.\\nVisualized in (8.43) from a high-level view, is an MLP which implements a well-known\\nidiom in DL.\\nFIGURE 8.43: A CNN block\\n1. Name the idiom.\\n2. What can this type of layer learn?\\n3. A fellow data scientist suggests amending the architecture as follows ( 8.44)\\n278Chapter 8 DEEP LEARNING\\nFIGURE 8.44: A CNN block\\nName one disadvantage of this new architecture.\\n4. Name one CNN architecture where the input equals the output.\\nCNN residual blocks\\nPRB-249 \\uf059 CH.PRB- 8.73.\\nAnswer the following questions regarding residual networks ([ 13]).\\n1. Mathematically, the residual block may be represented by:\\ny = x + F(x) (8.40)\\nWhat is the function F?\\n2. In one sentence, what was the main idea behind deep residual networks (ResNets) as\\nintroduced in the original paper ([ 13])?\\nPRB-250 \\uf059 CH.PRB- 8.74.\\nY our friend was thinking about ResNet blocks, and tried to visualize them in ( 8.45).\\n2798.2. PROBLEMS\\nFIGURE 8.45: A resnet CNN block\\n1. Assuming a residual of the form y = x + F(x), complete the missing parts in Fig.\\n(8.45).\\n2. What does the symbol ⊕ denotes?\\n3. A fellow data scientist, who had coffee with you said that residual blocks may compute\\nthe identity function. Explain what he meant by that.\\n8.2.8 Training, hyperparameters\\nHyperparameter optimization\\nPRB-251 \\uf059 CH.PRB- 8.75.\\nA certain training pipeline for the classiﬁcation of large images (1024 x 1024) uses the\\nfollowing Hyperparameters (8.46):\\n280Chapter 8 DEEP LEARNING\\nHyperparameter Value\\nInitial learning rate 0.1\\nWeight decay 0.0001\\nMomentum 0.9\\nBatch size 1024\\n'),\n",
              " Document(metadata={}, page_content=\" Training, hyperparameters\\nHyperparameter optimization\\nPRB-251 \\uf059 CH.PRB- 8.75.\\nA certain training pipeline for the classiﬁcation of large images (1024 x 1024) uses the\\nfollowing Hyperparameters (8.46):\\n280Chapter 8 DEEP LEARNING\\nHyperparameter Value\\nInitial learning rate 0.1\\nWeight decay 0.0001\\nMomentum 0.9\\nBatch size 1024\\n1 optimizer = optim.SGD(model.parameters(), lr =0.1,\\n2 momentum=0.9,\\n3 weight_decay=0.0001)\\n4 ...\\n5 trainLoader = torch.utils.data.DataLoader(\\n6 datasets.LARGE('../data' , train =True, download =True,\\n7 transform=transforms.Compose([\\n8 transforms.ToTensor(),\\n9 ])),\\n10 batch\\\\_size=1024, shuffle =True)\\nFIGURE 8.46: Hyperparameters.\\nIn your opinion, what could possibly go wrong with this training pipeline?\\nPRB-252 \\uf059 CH.PRB- 8.76.\\nA junior data scientist in your team who is interested in Hyperparameter tuning, wrote\\nthe following code ( 8.5) for spiting his corpus into two distinct sets and ﬁtting an LR model:\\n2818.2. PROBLEMS\\n1 from sklearn.model_selection import train_test_split\\n2 dataset = datasets.load_iris()\\n3 X_train, X_test, y_train, y_test =\\n4 train_test_split(dataset.data, dataset .target, test_size =0.2)\\n5 clf = LogisticRegression(data_norm=12)\\n6 clf.fit(X_train, y_train)\\nCODE 8.5: Train and Validation split.\\nHe then evaluated the performance of the trained model on the Xtest set.\\n1. Explain why his methodology is far from perfect.\\n2. Help him resolve the problem by utilizing a difference splitting methodology.\\n3. Y our friend now amends the code an uses:\\n1 clf = GridSearchCV(method, params, scoring ='roc_auc' , cv =5)\\n2 clf.fit(train_X, train_y)\\nExplain why his new approach may work better.\\nPRB-253 \\uf059 CH.PRB- 8.77.\\nIn the context of Hyperparameter optimization, explain the difference between grid search\\nand random search.\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nPRB-254 \\uf059 CH.PRB- 8.78.\\n282Chapter 8 DEEP LEARNING\\nNon-invasive methods that forecast the existence of lung nodules ( 8.47), is a precursor\\nto lung cancer. Y et, in spite of acquisition standardization attempts, the manual detection of\\nlung nodules still remains predisposed to inter mechanical and observer variability. What is\\nmore, it is a highly laborious task.\\nFIGURE 8.47: Pulmonary nodules.\\nIn the majority of cases, the training data is manually labelled by radiologists who make\\nmistakes. Imagine you are working on a classiﬁcation problem and hire two radiologists for\\nlung cancer screening based on low-dose CT (LDCT). Y ou ask them to label the data, the\\nﬁrst radiologist labels only the training set and the second the validation set. Then you hire\\na third radiologist to label the test set.\\n1. Do you think there is a design ﬂow in the curation of the data sets?\\n2. A friend suggests that all there radiologists read all the scans and label them independ-\\nently thus creating a majority vote. What do you think about this idea?\\nValidation curve ACC\\nPRB-255 \\uf059 CH.PRB- 8.79.\\nAnswer the following questions regarding the validation curve visualized in ( 8.48):\\n2838.2. PROBLEMS\\n20 40 60 80 100\\n0,2\\n0,4\\n0,6\\n0,8\\nEPOCH\\nERR V ALID\\nTRAIN\\nFIGURE 8.48: A validation curve.\\n1. Describe in one sentence, what is a validation curve.\\n2. Which hyperparameter is being used in the curve?\\n3. Which well-known metric is being used in the curve? Which other metric is commonly\\nused?\\n4. Which positive phenomena happens when we train a NN longer?\\n5. Which negative phenomena happens when we train a NN longer than we should?\\n6. How this negative phenomena is reﬂected in 8.48?\\nValidation curve Loss\\nPRB-256 \\uf059 CH.PRB- 8.80.\\nRefer to the validation log-loss curve visualized in ( 8.49) and answer the following ques-\\ntions:\\n284Chapter \"),\n",
              " Document(metadata={}, page_content=' is commonly\\nused?\\n4. Which positive phenomena happens when we train a NN longer?\\n5. Which negative phenomena happens when we train a NN longer than we should?\\n6. How this negative phenomena is reﬂected in 8.48?\\nValidation curve Loss\\nPRB-256 \\uf059 CH.PRB- 8.80.\\nRefer to the validation log-loss curve visualized in ( 8.49) and answer the following ques-\\ntions:\\n284Chapter 8 DEEP LEARNING\\nFIGURE 8.49: Log-loss function curve.\\n1. Name the phenomena that starts happening right after the marking by the letter E and\\ndescribe why it is happening.\\n2. Name three different weight initialization methods.\\n3. What is the main idea behind these methods?\\n4. Describe several ways how this phenomena can be alleviated.\\n5. Y our friend, a fellow data-scientist, inspects the code and sees the following Hyper-\\nparameters are being used:\\nHyperparameter Value\\nInitial LR 0.00001\\nMomentum 0.9\\nBatch size 1024\\nHe then tells you that the learning rate (LR) is constant and suggests amending the\\ntraining pipeline by adding the following code ( 8.50):\\n2858.2. PROBLEMS\\n1 scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt)\\nFIGURE 8.50: A problem with the log-loss curve.\\nWhat do you think about his idea?\\n6. Provide one reason against the use of the log-loss curve.\\nInference\\nPRB-257 \\uf059 CH.PRB- 8.81.\\nY ou ﬁnished training a face recognition algorithm, which uses a feature vector of 128\\nelements. During inference, you notice that the performance is not that good. A friend tells\\nyou that in computer vision faces are gathered in various poses and perspectives. He there-\\nfore suggests that during inference you would augment the incoming face ﬁve times, run\\ninference on each augmented image and then fuse the output probability distributions by\\naveraging.\\n1. Name the method he is suggesting.\\n2. Provide several examples of augmentation that you might use during inference.\\nPRB-258 \\uf059 CH.PRB- 8.82.\\nComplete the sentence: If the training loss is insigniﬁcant while the test loss is signiﬁc-\\nantly higher, the network has almost certainly learned features which are not present in an\\n[...] set. This phenomena is referred to as [...]\\n8.2.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nPRB-259 \\uf059 CH.PRB- 8.83.\\nWhat does the term stochastic in SGD actually mean? Does it use any random number\\n286Chapter 8 DEEP LEARNING\\ngenerator?\\nPRB-260 \\uf059 CH.PRB- 8.84.\\nExplain why in SGD, the number of epochs required to surpass a certain loss threshold\\nincreases as the batch size decreases?\\nMomentum\\nPRB-261 \\uf059 CH.PRB- 8.85.\\nHow does momentum work? Explain the role of exponential decay in the gradient descent\\nupdate rule.\\nPRB-262 \\uf059 CH.PRB- 8.86.\\nIn your training loop, you are using SGD and a logistic activation function which is\\nknown to suffer from the phenomenon of saturated units.\\n1. Explain the phenomenon.\\n2. Y ou switch to using the tanh activation instead of the logistic activation, in your\\nopinion does the phenomenon still exists?\\n3. In your opinion, is using the tanh function makes the SGD operation to converge\\nbetter?\\nPRB-263 \\uf059 CH.PRB- 8.87.\\nWhich of the following statements holds true?\\ni In stochastic gradient descent we ﬁrst calculate the gradient and only then adjust weights\\nfor each data point in the training set.\\nii In stochastic gradient descent, the gradient for a single sample is not so different from\\nthe actual gradient, so this gives a more stable value, and converges faster.\\niii SGD usually avoids the trap of poor local minima.\\n2878.2. PROBLEMS\\niv SGD usually requires more memory.\\nNorms, L1, L2\\nPRB-264 \\uf059 CH.PRB- 8.88.\\nAnswer the following questions regarding norms.\\n1. Which norm does the following equation represent?\\n|x1 − x2| + |y1 − y2| (8.41)\\n2. Which formulae does the following equation represent?\\n\\ued6a\\ued6b\\ued6b√\\nn∑\\ni=1\\n(xi − yi)2 (8.42)\\n3. When your read that someone penalized the L2 norm, was the euclidean or the'),\n",
              " Document(metadata={}, page_content='.88.\\nAnswer the following questions regarding norms.\\n1. Which norm does the following equation represent?\\n|x1 − x2| + |y1 − y2| (8.41)\\n2. Which formulae does the following equation represent?\\n\\ued6a\\ued6b\\ued6b√\\nn∑\\ni=1\\n(xi − yi)2 (8.42)\\n3. When your read that someone penalized the L2 norm, was the euclidean or the Man-\\nhattan distance involved?\\n4. Compute both the Euclidean and Manhattan distance of the vectors:\\nx1 = [6 , 1, 4, 5] and x2 = [2 , 8, 3, −1].\\nPRB-265 \\uf059 CH.PRB- 8.89.\\nY ou are provided with a pure Python code implementation of the Manhattan distance\\nfunction (8.51):\\n1 from scipy import spatial\\n2 x1=[6,1,4,5]\\n3 x2=[2,8,3,-1]\\n4 cityblock = spatial.distance.cityblock(x1, x2)\\n5 print(\"Manhattan:\", cityblock)\\nFIGURE 8.51: Manhattan distance function.\\n288Chapter 8 DEEP LEARNING\\nIn many cases, and for large vectors in particular, it is better to use a GPU for imple-\\nmenting numerical computations. PyT orch has full support for GPU’s (and its my favourite\\nDL library ... ), use it to implement the Manhattan distance function on a GPU.\\nPRB-266 \\uf059 CH.PRB- 8.90.\\nY our friend is training a logistic regression model for a binary classiﬁcation problem\\nusing the L2 loss for optimization. Explain to him why this is a bad choice and which loss he\\nshould be using instead.\\n8.3 Solutions\\n8.3.1 Cross Validation\\nOn the signiﬁcance of cross validation and stratiﬁcation in particular, refer to “ A study\\nof cross-validation and bootstrap for accuracy estimation and model selection ” [17].\\nCV approaches\\nSOL-177 \\uf14b CH.SOL- 8.1.\\nThe ﬁrst approach is a leave-one-out CV (LOOCV) and the second is a K-fold cross-\\nvalidation approach. \\x04\\nSOL-178 \\uf14b CH.SOL- 8.2.\\nCross Validation is a cornerstone in machine learning, allowing data scientists to take\\nfull gain of restricted training data. In classiﬁcation, effective cross validation is essential to\\nmaking the learning task efﬁcient and more accurate. A frequently used form of the technique\\nis identiﬁed as K-fold cross validation. Using this approach, the full data set is divided into K\\nrandomly selected folds, occasionally stratiﬁed, meaning that each fold has roughly the\\nsame class distribution as the overall data set . Subsequently, for each fold, all the other\\n(K − 1) folds are used for training, while the present fold is used for testing. This process\\nguarantees that sets used for testing, are not used by a classiﬁer that also saw it during\\ntraining.\\n\\x04\\nK-Fold CV\\n2898.3. SOLUTIONS\\nSOL-179 \\uf14b CH.SOL- 8.3.\\nT rue. We never utilize the test set during a K-fold CV process. \\x04\\nSOL-180 \\uf14b CH.SOL- 8.4.\\nT rue. This is the average of the individual errors of K estimates of the test error:\\nMSE1, . . . ,MSEk (8.43)\\n\\x04\\nSOL-181 \\uf14b CH.SOL- 8.5.\\nThe correct answer is: A 5-fold cross-validation approach results in 5-different model in-\\nstances being ﬁtted. It is a common misconception to think that in a K-fold approach the same\\nmodel instance is repeatedly used. We must create a new model instance in each fold. \\x04\\nSOL-182 \\uf14b CH.SOL- 8.6.\\nThe correct answer is: we compute the cross-validation performance as the arithmetic\\nmean over the K performance estimates from the validation sets. \\x04\\nStratification\\nSOL-183 \\uf14b CH.SOL- 8.7.\\nThe correct answer is: 3-fold CV . A k-fold cross-validation is a special case of cross-\\nvalidation where we iterate over a dataset set k times. In each round, we split the dataset\\ninto k parts: one part is used for validation, and the remaining k − 1 parts are merged into\\na training subset for model evaluation. Stratiﬁcation is used'),\n",
              " Document(metadata={}, page_content='\\nStratification\\nSOL-183 \\uf14b CH.SOL- 8.7.\\nThe correct answer is: 3-fold CV . A k-fold cross-validation is a special case of cross-\\nvalidation where we iterate over a dataset set k times. In each round, we split the dataset\\ninto k parts: one part is used for validation, and the remaining k − 1 parts are merged into\\na training subset for model evaluation. Stratiﬁcation is used to balance the classes in the\\ntraining and validation splits in cases where the corpus is imbalanced. \\x04\\nLOOCV\\nSOL-184 \\uf14b CH.SOL- 8.8.\\n1. T rue: In (LOOCV) K = N the full sample size.\\n2. False: There is no way of a-priori ﬁnding an optimal value for K, and the relationship\\n290Chapter 8 DEEP LEARNING\\nbetween the actual sample size and the resulting accuracy is unknown.\\n\\x04\\n8.3.2 Convolution and correlation\\nThe convolution operator\\nSOL-185 \\uf14b CH.SOL- 8.9.\\n1. This is the deﬁnition of a convolution operation on the two signals f and g.\\n2. In image processing, the term g(t) represents a ﬁltering kernel.\\n\\x04\\nSOL-186 \\uf14b CH.SOL- 8.10.\\n1. T rue. These operations have two key features: they are shift invariant, and they are\\nlinear. Shift invariance means that we perform the same operation at every point in the\\nimage. Linearity means that this operation is linear, that is, we replace every pixel with\\na linear combination of its neighbours\\n2. T rue. See for instance Eq. (8.3).\\n3. T rue.\\n\\x04\\nThe correlation operator\\nSOL-187 \\uf14b CH.SOL- 8.11.\\n1. T rue.\\n2. T rue.\\n\\x04\\n2918.3. SOLUTIONS\\nSOL-188 \\uf14b CH.SOL- 8.12.\\nA convolution operation is just like correlation, except that we ﬂip over the ﬁlter both\\nhorizontally and vertically before correlating.\\nf (x, y) ⊗ h(x, y) =\\nM −1∑\\nm=0\\nN −1∑\\nn=0\\nf ∗(m, n)h(x + m, y + n) (8.44)\\n\\x04\\nPadding and stride\\nRecommended reading : “ A guide to convolution arithmetic for deep learning by Vincent\\nDumoulin and Francesco Visin (2016) ” [22].\\nSOL-189 \\uf14b CH.SOL- 8.13.\\n1. The Valid padding only uses values from the original input; however, when the data\\nresolution is not a multiple of the stride, some boundary values are ignored entirely in\\nthe feature calculation.\\n2. The Same padding ensures that every input value is included, but also adds zeros near\\nthe boundary which are not in the original input.\\n\\x04\\nSOL-190 \\uf14b CH.SOL- 8.14.\\nT rue. Contrast this with the two other types of convolution operations. \\x04\\nSOL-191 \\uf14b CH.SOL- 8.15.\\n⌊\\nK − θ\\nθ\\n⌋\\n+ 1 ×\\n⌊\\nn − θ\\nθ\\n⌋\\n+ 1 (8.45)\\n\\x04\\nSOL-192 \\uf14b CH.SOL- 8.16.\\n292Chapter 8 DEEP LEARNING\\nA is the correct choice. \\x04\\nSOL-193 \\uf14b CH.SOL- 8.17.\\nA represents the V ALID mode while B represents the SAME mode. \\x04\\nSOL-194 \\uf14b CH.SOL- 8.18.\\n1. The resulting output has a shape of 4 × 4.\\n2. Convolution operation\\n[[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]]\\n[[ 2. 0. -2.]\\n[ 2. 0. -2.]\\n[ 2. 0. -2'),\n",
              " Document(metadata={}, page_content='3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]\\n[3. 3. 3. 1. 1. 1.]]\\n[[ 2. 0. -2.]\\n[ 2. 0. -2.]\\n[ 2. 0. -2.]]\\n3. By deﬁnition, convolutions in the valid mode, reduce the size of the resulting input\\ntensor.\\n[[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]\\n[ 0. -12. -12. 0.]]\\n\\x04\\nKernels and filters\\nSOL-195 \\uf14b CH.SOL- 8.19.\\n2938.3. SOLUTIONS\\n1. Flipping by 180 degrees we get:\\nk = 1\\n2\\n\\uf8ee\\n\\uf8f0 −1 −1\\n1 1\\n\\uf8f9\\n\\uf8fb (8.46)\\n2. The Sobel ﬁlter which is being frequently used for edge detection in classical computer\\nvision.\\n\\x04\\nSOL-196 \\uf14b CH.SOL- 8.20.\\nThe resulting complexity is given by:\\nK 2wh (8.47)\\n\\x04\\nConvolution and correlation in python\\nSOL-197 \\uf14b CH.SOL- 8.21.\\n1. Convolution operation:\\n294Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 def convolution(A,B):\\n3 l_A = np.size(A)\\n4 l_B = np.size(B)\\n5 C = np.zeros(l_A + l_B -1)\\n6\\n7 for m in np.arange(l_A):\\n8 for n in np.arange(l_B):\\n9 C[m+n] = C[m+n] + A[m]*B[n]\\n10\\n11 return C\\nFIGURE 8.52: Convolution and correlation in python\\n2. Correlation operation:\\n1 def crosscorrelation(A,B):\\n2 return convolution(np.conj(A),B[::-1])\\nFIGURE 8.53: Convolution and correlation in python\\n\\x04\\nSeparable convolutions\\nSOL-198 \\uf14b CH.SOL- 8.22.\\n1. No.Since images are usually stored as discrete pixel values one would have to use a\\ndiscrete approximation of the Gaussian function on the ﬁltering mask before performing\\nthe convolution.\\n2. No.\\n2958.3. SOLUTIONS\\n3. Y es it is separable, a factor that has great implications. For instance, separability means\\nthat a 2D convolution can be reduced to two consequent 1D convolutions reducing the\\ncomputational runtime from O (n2 m2) to O (n2 m).\\n\\x04\\n8.3.3 Similarity measures\\nImage, text similarity\\nSOL-199 \\uf14b CH.SOL- 8.23.\\nThe algorithm presented in ( 8.12) normalizes the input vector. This is usually done prior\\nto applying any other method to the vector or before persisting a vector to a database of FVs.\\n\\x04\\nSOL-200 \\uf14b CH.SOL- 8.24.\\n1. The algorithm presented in ( 8.1) is one of the most commonly used image similarity\\nmeasures and is entitled cosine similarity. It can be applied to any pair of images.\\n2. The mathematical formulae behind it is:\\nThe cosine similarity between two vectors:\\nu = {u1, u2, . . . , uN } and v = {v1, v2, . . . , vN } is deﬁned as:\\nsim(u, v) = u · v\\n|u||v| =\\n∑N\\ni=1 uivi√( ∑N\\ni=1 u2\\ni\\n) ( ∑N\\ni=1 v2\\ni\\n)\\nThus, the cosine similarity between two vectors measures the cosine of the angle\\nbetween the vectors irrespective of their magnitude. It is calculated as the dot product\\nof two numeric vectors, and is normalized by the product of the length of the vectors.\\n3. The minimum and maximum values it can return are 0 and 1 respectively. Thus, a\\ncosine similarity value which is close to 1 indicated a very high similarity while that\\nclose to 0 indicates a very low similarity.\\n4. It represents the negative distance in Euclidean space between the vectors.\\n296Chapter 8 DEEP LEARNING\\n'),\n",
              " Document(metadata={}, page_content=' It is calculated as the dot product\\nof two numeric vectors, and is normalized by the product of the length of the vectors.\\n3. The minimum and maximum values it can return are 0 and 1 respectively. Thus, a\\ncosine similarity value which is close to 1 indicated a very high similarity while that\\nclose to 0 indicates a very low similarity.\\n4. It represents the negative distance in Euclidean space between the vectors.\\n296Chapter 8 DEEP LEARNING\\n\\x04\\nJacard similarity\\nSOL-201 \\uf14b CH.SOL- 8.25.\\n1. The general formulae for the Jaccard similarity of two sets is given as follows:\\nJ(A, B) = |A ∩ B|\\n|A ∪ B|\\n2. That is, the ratio of the size of the intersection of A and B to the size of their union.\\n3. The Jaccard similarity equals:\\n2\\n7\\n4. Given (8.13)\\nFor the three combinations of pairs above, we have\\nJ({11, 16, 17}, {12, 14, 16, 18}) = 1\\n6\\nJ({11, 12, 13, 14, 15}, {11, 16, 17}) = 1\\n7\\nJ({11, 12, 13, 14, 15}, {12, 14, 16, 18}) = 2\\n7\\n\\x04\\nThe Kullback-Leibler Distance\\nSOL-202 \\uf14b CH.SOL- 8.26.\\nEach KLD corresponds to the deﬁnition of:\\ni Jensen [1]\\n2978.3. SOLUTIONS\\nii Bennet [2]\\niii Bigi [3]\\niv Ziv [29]\\n\\x04\\nMinHash\\nRead the paper entitled Detecting near-duplicates for web crawling [12] and answer the\\nfollowing questions.\\nSOL-203 \\uf14b CH.SOL- 8.27.\\nA Hashing function ( 8.54) maps a value into a constant length string that can be com-\\npared with other hashed values.\\nFIGURE 8.54: The idea of hashing\\nThe idea behind hashing is that items are hashed into buckets, such that similar items\\nwill have a higher probability of hashing into the same buckets.\\nThe goal of MinHash is to compute the Jaccard similarity without actually computing the\\nintersection and union of the sets, which would be slower. The main idea behind MinHash\\nis to devise a signature scheme such that the probability that there is a match between the\\nsignatures of two sets, S1 and S2, is equal to the Jaccard measure [ 12].\\n\\x04\\n298Chapter 8 DEEP LEARNING\\nSOL-204 \\uf14b CH.SOL- 8.28.\\nLocality-Sensitive Hashing (LSH) is a method which is used for determining which items\\nin a given set are similar. Rather than using the naive approach of comparing all pairs of items\\nwithin a set, items are hashed into buckets, such that similar items will be more likely to hash\\ninto the same buckets.\\n\\x04\\nSOL-205 \\uf14b CH.SOL- 8.29.\\nMaximise.\\n\\x04\\n8.3.4 Perceptrons\\nThe Single Layer Perceptron\\nSOL-206 \\uf14b CH.SOL- 8.30.\\nAnswer: one, one, feedback.\\n\\x04\\nSOL-207 \\uf14b CH.SOL- 8.31.\\n1. T rue.\\n2. T rue.\\n3.\\nC(w, b) = 1\\n2n\\n∑\\nx\\n∥y(x) − a(x, w, b)∥2 (8.48)\\nwhere w denotes the collection of all weights in the network, b all the biases, n is the\\ntotal number of training inputs and a(x, w, b) is the vector of outputs from the network\\nwhich has weights w, biases b and the input x.\\n4.\\narg min\\nw,b\\nC(w, b). (8.49)\\n5. Gradient descent.\\n2998.3. SOLUTIONS\\n6. The gradient.\\n7. Stochastic gradient descent. Batch size. Back-propagation.\\n\\x04\\nThe Multi Layer Perceptron\\nSOL-208 \\uf14b CH.SOL- 8.32.\\n1. This operation is a dot product with the given weights. Therefore:\\nout = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 = −0.164 (8.50)\\n2. This operation ('),\n",
              " Document(metadata={}, page_content=' Back-propagation.\\n\\x04\\nThe Multi Layer Perceptron\\nSOL-208 \\uf14b CH.SOL- 8.32.\\n1. This operation is a dot product with the given weights. Therefore:\\nout = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 = −0.164 (8.50)\\n2. This operation (sum) is a dot product with the given weights and with the given bias\\nadded. Therefore:\\nout1 = x1 ∗ w1 + x2 ∗ w2 + b1 =\\n0.9 ∗ (−0.3) + 0.7 ∗ 0.15 + 0.001 = −0.165 (8.51)\\n3. Code snippet 8.55 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 # .type(torch.FloatTensor)\\n3 x= torch.tensor([0.9,0.7])\\n4 w= torch.tensor([-0.3,0.15])\\n5 B= torch.tensor([0.001])\\n6 print (torch.sum(x*w))\\n7 print (torch.sum(x*w) + B)\\nFIGURE 8.55: MLP operations.\\n\\x04\\n300Chapter 8 DEEP LEARNING\\nActivation functions in perceptrons\\nSOL-209 \\uf14b CH.SOL- 8.33.\\n1. Since by deﬁnition:\\nfReLU(x) =\\n\\uf8f1\\n\\uf8f2\\n\\uf8f3\\n1 if x > 0\\n0 if x ≤ 0\\n(8.52)\\nAnd the output of the linear sum operation was −0.164 then, the output out2 = 0 .\\n2. Code snippet 8.56 provides a pure PyT orch-based implementation of the MLP operation.\\n1 import torch\\n2 x= torch.tensor([0.9,0.7])\\n3 w= torch.tensor([-0.3,0.15])\\n4 B= torch.tensor([0.001])\\n5 print (torch.sum(x*w))\\n6 print (torch.sum(x*w) + B)\\n7 print (torch.relu(torch.sum(x*w + B)))\\nFIGURE 8.56: MLP operations.\\n\\x04\\nBack-propagation in perceptrons\\nSOL-210 \\uf14b CH.SOL- 8.34. The answers are as follows:\\n1. Non-differentiable at 0.\\n2. Non-differentiable at 0.\\n3018.3. SOLUTIONS\\n3. Even though for x ̸= 0:\\nf ′(x) = sin 1\\nx − 1\\nx cos 1\\nx, (8.53)\\nthe function is still non-differentiable at 0.\\n4. Non-differentiable at 0.\\n\\x04\\nSOL-211 \\uf14b CH.SOL- 8.35.\\n1. Fig 8.57 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 for i in range(0,w.size(0)):\\n2 print (torch.relu(torch.sum(x*w[i]) + B))\\n3 > tensor([0.])\\n4 > tensor([0.])\\n5 > tensor([0.6630])\\nFIGURE 8.57: MLP operations- values.\\n2. The values at each hidden layer are depicted in 8.58\\n302Chapter 8 DEEP LEARNING\\n0.0\\n0.0\\n0.6630\\nOutput\\nFIGURE 8.58: Hidden layer values, simple MLP .\\n3. Fig 8.59 uses a loop (inefﬁcient but easy to understand) to print the values:\\n1 x1= torch.tensor([0.0,0.0,0.6630])# Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 for i in range(0,w1.size(0)):\\n7 print (torch.sum(x1*w1[i]))\\n8 > tensor(0.3912)\\n9 > tensor(-0.5238)\\nFIGURE 8.59: MLP operations- values at the output.\\n4. We can apply the Softmax function like so 8.60:\\n3038.3. SOLUTIONS\\n1 x1= torch.tensor([0.0,0.0,0.6630]) # Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).'),\n",
              " Document(metadata={}, page_content=')\\nFIGURE 8.59: MLP operations- values at the output.\\n4. We can apply the Softmax function like so 8.60:\\n3038.3. SOLUTIONS\\n1 x1= torch.tensor([0.0,0.0,0.6630]) # Input\\n2 w1= torch.tensor([\\n3 [0.15,-0.46,0.59],\\n4 [0.10,0.32,-0.79],\\n5 ]).type(torch.FloatTensor) # Weights\\n6 out1 = torch.tensor([[torch.sum(x1*w1[0]).item()],\\n7 [torch.sum(x1*w1[1]).item()]])\\n8 print (out1)\\n9 yhat = torch.softmax(out1, dim =0)\\n10 print (yhat)\\n11 > tensor([[ 0.3912],\\n12 [-0.5238]])\\n13 > tensor([[0.7140],\\n14 [0.2860]])\\nFIGURE 8.60: MLP operations- Softmax.\\n5. For the cross-entropy loss, we use the Softmax values and calculate the result as follows:\\n−1.0 ∗ log(0.7140) − 0.0 ∗ log(0.2860) = 1 .31 (8.54)\\n\\x04\\nThe theory of perceptrons\\nSOL-212 \\uf14b CH.SOL- 8.36.\\nHe means that theoretically [ 6], a non-linear layer followed by a linear layer, can ap-\\nproximate any non-linear function with arbitrary accuracy, provided that there are enough\\nnon-linear neurons\\n\\x04\\nSOL-213 \\uf14b CH.SOL- 8.37. T rue \\x04\\nSOL-214 \\uf14b CH.SOL- 8.38. T rue \\x04\\n304Chapter 8 DEEP LEARNING\\nSOL-215 \\uf14b CH.SOL- 8.39.\\nFalse. Divided by the training samples, not the number of incorrectly classiﬁed samples. \\x04\\nLearning logical gates\\nSOL-216 \\uf14b CH.SOL- 8.40.\\n1. The values are presented in the following table ( 8.61):\\nBias = −2.5\\nInput Weighted sum Output\\n(0,0) -2.5 0\\n(0,1) -1.5 0\\n(1,0) -1.5 0\\n(1,1) -0.5 0\\nFIGURE 8.61: Logical AND: B=-2.5\\n2. The values are presented in the following table ( 8.62):\\nBias = −0.25\\nInput Weighted sum Output\\n(0,0) -0.25 0\\n(0,1) -0.75 0\\n(1,0) -0.75 0\\n(1,1) 1.75 1\\nFIGURE 8.62: Logical AND: B=-0.25\\n3. The perceptron learning rule is an algorithm that can automatically compute optimal\\nweights for the perceptron.\\n3058.3. SOLUTIONS\\n4. The main addition by [ 22] and [ 18] was the introduction of a differentiable activation\\nfunction.\\n5. if we select w1 = 1;w2 = 1 and threshold=1. We get:\\nx1 = 1, x2 = 1 :\\nn = 1 × 1 + 1 × 1 = 2 ,thus,y = 1\\nx1 = 1, x2 = −1 :\\nn = 1 × 1 + 1 × (−1) = 0 ,thus,y = −1\\nx1 = −1, x2 = 1 :\\nn = 1 × (−1) + 1 × 1 = 0 ,thus,y = −1\\nx1 = −1, x2 = −1 :\\nn = 1 × (−1) + 1 × (−1) = −2,thus,y = −1\\n(8.55)\\nOr summarized in a table ( 8.63):\\nAND gate\\nin1 in2 out\\n0 0 0\\n0 1 0\\n1 0 0\\n1 1 1\\nFIGURE 8.63: Logical AND gate\\n\\x04\\n8.3.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\n306Chapter 8 DEEP LEARNING\\nSOL-217 \\uf14b CH.SOL- 8.41.\\n1. Remember that the analytical derivative is'),\n",
              " Document(metadata={}, page_content='1 0 0\\n1 1 1\\nFIGURE 8.63: Logical AND gate\\n\\x04\\n8.3.5 Activation functions (rectification)\\nWe concentrate only on the most commonly used activation functions, those which\\nthe reader is more likely to encounter or use during his daily work.\\nSigmoid\\n306Chapter 8 DEEP LEARNING\\nSOL-217 \\uf14b CH.SOL- 8.41.\\n1. Remember that the analytical derivative is of the sigmoid:\\nd\\ndxs(x) = d\\ndx((1 + e−x)−1) (8.56)\\nd\\ndxs(x) = −1((1 + e−x)(−1−1)) d\\ndx(1 + e−x) (8.57)\\nd\\ndxs(x) = −1((1 + e−x)(−2))( d\\ndx (1) + d\\ndx(e−x)) (8.58)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(0 + e−x( d\\ndx(−x))) (8.59)\\nd\\ndxs(x) = −1((1 + e−x)(−2))(e−x)(−1) (8.60)\\nd\\ndx s(x) = ((1 + e−x)(−2))(e−x) (8.61)\\nd\\ndxs(x) = 1\\n(1 + e−x)2 (e−x) (8.62)\\nd\\ndxs(x) = (e−x)\\n(1 + e−x)2 (8.63)\\nCode snippet 8.64 provides a pure C++ based implementation of the backward pass that\\ndirectly computes the analytical gradients in C++.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3\\n4 torch::Tensor sigmoid001_d(torch ::Tensor & x) {\\n5 torch::Tensor s = sigmoid001(x);\\n6 return (1 - s) * s;\\n7 }\\nFIGURE 8.64: Backward pass for the Sigmoid function using Libtorch.\\n3078.3. SOLUTIONS\\n2. Code snippet 8.65 depicts one way of printing the values.\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"\\n9 << sigmoid001_d (t0).data().detach().item().toFloat()\\n10 << \\'\\\\n\\' ;\\n11 }\\n12 }\\nFIGURE 8.65: Evaluation of the sigmoid and its derivative in C++ using Libtorch.\\n3. The manual derivative of eq. 8.27 is:\\n3 ln(2)×\\n[\\n2−1.5x\\n(2−1.5x + 1)2\\n]\\n(8.64)\\n4. The forward pass for the Sigmoid function approximation eq. 8.27 is presented in code\\nsnippet 8.66:\\n308Chapter 8 DEEP LEARNING\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 torch::Tensor sig_approx( const torch::Tensor & x ){\\n4 torch::Tensor sig = 1.0 / (1.0 + torch::pow(2,( -1.5*x)));\\n5 return sig;\\n6 }\\nFIGURE 8.66: Forward pass for the Sigmoid function approximation in C++ using Libtorch.\\n5. The values are 8.67: :\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"<< sig_approx (t0).data().detach().item().\\n9 toFloat()<<\\'\\\\'),\n",
              " Document(metadata={}, page_content='5*x)));\\n5 return sig;\\n6 }\\nFIGURE 8.66: Forward pass for the Sigmoid function approximation in C++ using Libtorch.\\n5. The values are 8.67: :\\n1 #include <torch/script.h>\\n2 #include <vector>\\n3 int main() {\\n4 std::vector<float> v{0.0, 0.1, 0.2, 0.3,\\n0.4,0.5,0.6,0.7,0.8,0.9,0.99};↪→\\n5 for (auto it = v.begin(); it != v.end(); ++it) {\\n6 torch::Tensor t0 = torch::tensor((*it));\\n7 std::cout << (*it) << \",\" <<\\nsigmoid001(t0).data().detach().item()↪→\\n8 .toFloat()<< \",\"<< sig_approx (t0).data().detach().item().\\n9 toFloat()<<\\'\\\\n\\' ;\\n10 }\\nFIGURE 8.67: Printing the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch.\\nAn the values are presented in T able 8.2:\\n3098.3. SOLUTIONS\\nValue Sig Approx\\n0 0.5 0.5\\n0.1 0.524979 0.52597\\n0.2 0.549834 0.5518\\n0.3 0.574443 0.577353\\n0.4 0.598688 0.602499\\n0.5 0.622459 0.627115\\n0.6 0.645656 0.65109\\n0.7 0.668188 0.674323\\n0.8 0.689974 0.69673\\n0.9 0.710949 0.71824\\n0.99 0.729088 0.736785\\nTABLE 8.2: Computed values for the Sigmoid and the Sigmoid approximation.\\n\\x04\\nTanh\\nSOL-218 \\uf14b CH.SOL- 8.42.\\nThe answers are as follows:\\n1. The derivative is:\\nftanh(x) = 1 − ftanh(x)2 (8.65)\\n2. Code snippet 8.68 implements the forward pass using pure Python.\\n310Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 xT =\\ntorch.abs(torch.tensor([[0.37,0.192,0.571]],requires_grad=True))↪→\\n3 .type(torch.DoubleTensor)\\n4 xT_np=xT.detach().cpu().numpy()\\n5 print (\"Input: \\\\n\",xT_np)\\n6 tanh_values = np.tanh(xT_np)\\n7 print (\"Numpy:\", tanh_values)\\n8 > Numpy: [[ 0.35399172 0.18967498 0.51609329]]\\nFIGURE 8.68: Forward pass for tanh using pure Python.\\n3. In order to implement a PyT orch based torch.autograd.F unction function such as\\ntanh, we must provide both the forward and backward passes implementation. The\\nmechanism behind this idiom in PyT orch is via the use of a context, abbreviated ctx\\nwhich is like a state manager for automatic differentiation. The implementation is de-\\npicted in 8.69:\\n3118.3. SOLUTIONS\\n1 import torch\\n2\\n3 class TanhFunction(torch.autograd.Function):\\n4 @staticmethod\\n5 def forward(ctx, x):\\n6 ctx.save_for_backward( x )\\n7 y = x.tanh()\\n8 return y\\n9\\n10 @staticmethod\\n11 def backward(ctx, grad_output):\\n12 input, = ctx.saved_tensors\\n13 dy_dx = 1 / (input.cosh() ** 2)\\n14 out = grad_output * dy_dx\\n15 print (\"backward:{}\".format(out))\\n16 return out\\nFIGURE 8.69: Tanh in PyTorch.\\n4. Code snippet 8.70 veriﬁes the correctness of the implementation using gradcheck.\\n312Chapter 8 DEEP LEARNING\\n1 import numpy as np\\n2 import numpy as np\\n3 xT = torch.abs(torch.tensor([[0.37,0.192,0.571]],\\n4 requires_grad=True))\\n5 .type(torch.DoubleTensor)\\n6 xT_np=xT.detach().cpu().numpy()\\n7 tanh_values = np.tanh(xT_np)\\n8 tanh_values_torch = tanhPyTorch(xT)\\n9 print (\"Torch:\", tanh_values_torch)\\n10 from torch.autograd import gradcheck, Variable\\n11 f = TanhFunction.apply\\n12 test=gradcheck(lambda t: f(t), xT)\\n13'),\n",
              " Document(metadata={}, page_content='.571]],\\n4 requires_grad=True))\\n5 .type(torch.DoubleTensor)\\n6 xT_np=xT.detach().cpu().numpy()\\n7 tanh_values = np.tanh(xT_np)\\n8 tanh_values_torch = tanhPyTorch(xT)\\n9 print (\"Torch:\", tanh_values_torch)\\n10 from torch.autograd import gradcheck, Variable\\n11 f = TanhFunction.apply\\n12 test=gradcheck(lambda t: f(t), xT)\\n13 print(test)\\n14 > PyTorch version: 1.7.0\\n15 > Torch: tensor([[ 0.3540, 0.1897, 0.5161]], dtype =torch.float64)\\n16 > backward:tensor([[0.8747, 0.9640, 0.7336]],dtype=torch.float64)\\nFIGURE 8.70: Invoking gradcheck on tanh.\\n\\x04\\nSOL-219 \\uf14b CH.SOL- 8.43.\\n1. The type of NN is a MultiLayer Perceptron or MLP .\\n2. There are two hidden layers.\\n\\x04\\nSOL-220 \\uf14b CH.SOL- 8.44.\\nHe is partially correct , see for example Understanding the difﬁculty of training deep\\nfeedforward neural networks [9]. \\x04\\n3138.3. SOLUTIONS\\nSOL-221 \\uf14b CH.SOL- 8.45.\\nInitialize all parameters to a constant zero value. When we apply the tanh function to an\\ninput which is very large, the output which is almost zero, will be propagated to the remaining\\npartial derivatives leading to the well known phenomenon.\\n\\x04\\nSOL-222 \\uf14b CH.SOL- 8.46.\\nDuring the back-propagation process, derivatives are calculated with respect to (W (1))\\nand also (W (2)). The design ﬂaw:\\ni Y our friend initialized all weights and biases to zero.\\nii Therefore any gradient with respect to (W (2)) would also be zero.\\niii Subsequently, (W (2)) will never be updated.\\niv This would inadvertently cause the derivative with respect to (W (1)) to be always zero.\\nv Finally, would also never be updated (W (1)).\\n\\x04\\nReLU\\nSOL-223 \\uf14b CH.SOL- 8.47.\\nThe ReLU function has the beneﬁt of not saturating for positive inputs since its derivative\\nis one for any positive value.\\n\\x04\\nSOL-224 \\uf14b CH.SOL- 8.48.\\nThe shape is:\\n3 × 3 × 3 × 16\\n\\x04\\nSOL-225 \\uf14b CH.SOL- 8.49.\\nThe activation function is a leaky ReLU which in some occasions may outperform the\\n314Chapter 8 DEEP LEARNING\\nReLU activation function. \\x04\\nSwish\\nSOL-226 \\uf14b CH.SOL- 8.50.\\n1. They intended to ﬁnd new better-performing activation functions.\\n2. They had a list of basic mathematical functions to choose from, for instance the expo-\\nnential families exp(), sin(), min and max.\\n3. Previous research found several activation function properties which were considered\\nvery useful. For instance, gradient preservation and non-monotonicity. However the\\nsurprising discovery was that the swish function violates both of these previously deemed\\nuseful properties.\\n4. The equation is:\\nf (x) = x · σ(x) (8.66)\\n5. The plot is 8.71\\n−1,0 −0,8 −0,6 −0,4 −0,2 0,2 0,4 0,6 0,8 1,0\\n−1,0\\n−0,5\\n0,5\\n1,0\\nx\\nyx ∗ σ(x) = x ∗ 1\\n1+e−4x\\nFIGURE 8.71: A plot of the Swish activation function.\\n\\x04\\n3158.3. SOLUTIONS\\n8.3.6 Performance Metrics\\nConfusion matrix, precision, recall\\nSOL-227 \\uf14b CH.SOL- 8.51.\\n1. The values are labelled inside 8.27:\\nPredicted\\nP N\\nTruth P TP=12 FN=7\\nN FP=24 TN=1009\\nFIGURE 8.72: TP , TN, FP , FN.\\n2.\\nacc = 12 + 1009\\n12 + 7 + 24 + 1009 = 0.97 (8.67)\\n3.\\nprec = 12\\n12 + 24 = 0.333 (8.68)\\n4'),\n",
              " Document(metadata={}, page_content=' labelled inside 8.27:\\nPredicted\\nP N\\nTruth P TP=12 FN=7\\nN FP=24 TN=1009\\nFIGURE 8.72: TP , TN, FP , FN.\\n2.\\nacc = 12 + 1009\\n12 + 7 + 24 + 1009 = 0.97 (8.67)\\n3.\\nprec = 12\\n12 + 24 = 0.333 (8.68)\\n4.\\nrecall = 12\\n12 + 7 = 0.631 (8.69)\\n\\x04\\nROC-AUC\\nThe area under the receiver operating characteristic (ROC) curve, 8.73 known as the\\nAUC, is currently considered to be the standard method to assess the accuracy of\\npredictive distribution models.\\n316Chapter 8 DEEP LEARNING\\nFIGURE 8.73: Receiver Operating Characteristic curve.\\nSOL-228 \\uf14b CH.SOL- 8.52.\\nROC allows to attest the relationship between sensitivity and speciﬁcity of a binary clas-\\nsiﬁer. Sensitivity or true positive rate measures the proportion of positives correctly classiﬁed;\\nspeciﬁcity or true negative rate measures the proportion of negatives correctly classiﬁed. Con-\\nventionally, the true positive rate tpr is plotted against the false positive rate fpr, which is one\\nminus true negative rate.\\n1. Receiver Operating Characteristics of a classiﬁer shows its performance as a trade off\\nbetween selectivity and sensitivity.\\n2. It is a plot of ‘true positives’ vs. the ‘true negatives’ . In place of ‘true negatives’ ,\\none could also use ‘false positives’ which are essentially 1 - ‘true negatives’ .\\n3. A typical ROC curve has a concave shape with (0,0) as the beginning and (1,1) as the\\nend point\\n4. The ROC curve of a ‘random guess classiﬁer’, when the classiﬁer is completely confused\\nand cannot at all distinguish between the two classes, has an AUC of 0.5, the ‘x = y’\\nline in an ROC curve plot.\\n3178.3. SOLUTIONS\\n\\x04\\nSOL-229 \\uf14b CH.SOL- 8.53.\\nThe ROC curve of an ideal classiﬁer (100% accuracy) has an AUC of 1, with 0.0 ‘false\\npositives’ and 1.0 ‘true positives’ . The ROC curve in our case, is almost ideal, which may\\nindicate over-ﬁtting of the XGBOOST classiﬁer to the training corpus. \\x04\\n8.3.7 NN Layers, topologies, blocks\\nCNN arithmetics\\nSOL-230 \\uf14b CH.SOL- 8.54.\\nOutput dimension: L × L × M where L = n−f +2p\\ns + 1 \\x04\\nSOL-231 \\uf14b CH.SOL- 8.55.\\nThe answers are as follows:\\n1. Output dimensions:\\ni torch.Size([1, 512, 7, 7])\\nii torch.Size([1, 512, 16, 16])\\niii torch.Size([1, 512, 22, 40])\\n2. The layer is MaxPool2d.\\n\\x04\\nSOL-232 \\uf14b CH.SOL- 8.56.\\nThe answers are as follows:\\n1. A convolutional block 8.74.\\n318Chapter 8 DEEP LEARNING\\n1 Sequential(\\n2 (0): Conv2d( 3, 64, kernel_size =(3, 3), stride =(1, 1), padding =(1,\\n1))↪→\\n3 (1): ReLU(inplace =True)\\n4 (2): MaxPool2d(kernel_size =2, stride =2, padding =0, dilation =1,\\nceil_mode=False↪→\\n5 )\\nFIGURE 8.74: Convolutional block from the VGG11 architecture.\\n2. The shapes are as follows:\\ni torch.Size([1, 64, 112, 112])\\nii torch.Size([1, 64, 256, 256])\\niii torch.Size([1, 64, 352, 512])\\n\\x04\\nSOL-233 \\uf14b CH.SOL- 8.57.\\nThe VGG11 architecture contains seven convolutional layers, each followed by a ReLU\\nactivation function, and ﬁve max-polling operations, each reducing the respective feature\\nmap by a factor of 2. All convolutional layers have a 3 × 3 kernel. The ﬁrst convolutional\\n'),\n",
              " Document(metadata={}, page_content='256])\\niii torch.Size([1, 64, 352, 512])\\n\\x04\\nSOL-233 \\uf14b CH.SOL- 8.57.\\nThe VGG11 architecture contains seven convolutional layers, each followed by a ReLU\\nactivation function, and ﬁve max-polling operations, each reducing the respective feature\\nmap by a factor of 2. All convolutional layers have a 3 × 3 kernel. The ﬁrst convolutional\\nlayer produces 64 channels and subsequently, as the network deepens, the number of channels\\ndoubles after each max-pooling operation until it reaches 512. \\x04\\nDropout\\nSOL-234 \\uf14b CH.SOL- 8.58.\\n1. The observed data, e.g the dropped neurons are distributed according to:\\n(x1, . . . , xn)|θ\\niid\\n∼ Bern(θ) (8.70)\\n3198.3. SOLUTIONS\\nDenoting s and f as success and failure respectively, we know that the likelihood is:\\np (x1, . . . , xn|θ) = θs(1 − θ)f (8.71)\\nWith the following parameters α = β = 1 the beta distribution acts like Uniform prior:\\nθ ∼ Beta(α, β), given α = β = 1 (8.72)\\nHence, the prior density is:\\np(θ) = 1\\nB(α, β)θα−1(1 − θ)β−1 (8.73)\\nTherefore the posterior is:\\np (θ|x1, . . . , xn) ∝ p (x1, . . . , xn|θ) p(θ)\\n∝ θS(1 − θ)f θα−1(1 − θ)β−1\\n= θα+s−1(1 − θ)β+f −1\\n(8.74)\\n2. In dropout, in every training epoch, neurons are randomly pruned with probability\\nP = p sampled from a Bernoulli distribution. During inference, all the neurons are used\\nbut their output is multiplied by the a-priory probability P . This approach resembles to\\nsome degree the model averaging approach of bagging.\\n\\x04\\nSOL-235 \\uf14b CH.SOL- 8.59.\\nThe answers are as follows:\\n1. The idea is true and a solid one.\\n2. The idiom may be exempliﬁed as follows 8.75:\\n320Chapter 8 DEEP LEARNING\\nFIGURE 8.75: Equivalence of two consecutive dropout layers\\nThe probabilities add up by multiplication at each layer, resulting in a single dropout\\nlayer with probability:\\n1 − (1 − p)(1 − q) (8.75)\\n\\x04\\nConvolutional Layer\\nSOL-236 \\uf14b CH.SOL- 8.60.\\nThe result is ( 8.76):\\nFIGURE 8.76: The result of applying the ﬁlter.\\n\\x04\\n3218.3. SOLUTIONS\\nSOL-237 \\uf14b CH.SOL- 8.61.\\nThe result is ( 8.77):\\nFIGURE 8.77: The result of applying a ReLU activation.\\n\\x04\\nSOL-238 \\uf14b CH.SOL- 8.62.\\nThe result is ( 8.78):\\nFIGURE 8.78: The result of applying a MaxPool layer.\\n\\x04\\nPooling Layers\\nMaxPooling\\n322Chapter 8 DEEP LEARNING\\nSOL-239 \\uf14b CH.SOL- 8.63.\\nThe answers are as follows:\\n1. A max-pooling layer is most commonly used after a convolutional layer in order to\\nreduce the spatial size of CNN feature maps.\\n2. The result is 8.79:\\nFIGURE 8.79: Output of the MaxPool2d operation.\\n\\x04\\nSOL-240 \\uf14b CH.SOL- 8.64.\\n1. In MaxPool2D(2,2), the ﬁrst parameter is the size of the pooling operation and the\\nsecond is the stride of the pooling operation.\\n2. The BatchNorm2D operation does not change the shape of the tensor from the previous\\nlayer and therefore it is:\\ntorch.Size ([1, 32, 222, 222]).\\n3. During the training of a CNN we use model.train() so that Dropout layers are ﬁred.\\nHowever, in order to run inference, we would like to turn this ﬁring mechanism off,\\nand this is accomplished by model.eval() instructing the PyT orch computation graph\\nnot to activate dropout layers.\\n4. The resulting tensor shape is:\\n'),\n",
              " Document(metadata={}, page_content=' of the tensor from the previous\\nlayer and therefore it is:\\ntorch.Size ([1, 32, 222, 222]).\\n3. During the training of a CNN we use model.train() so that Dropout layers are ﬁred.\\nHowever, in order to run inference, we would like to turn this ﬁring mechanism off,\\nand this is accomplished by model.eval() instructing the PyT orch computation graph\\nnot to activate dropout layers.\\n4. The resulting tensor shape is:\\ntorch.Size ([1, 32, 55, 55])\\nIf we reshape the tensor like in line 17 using:\\nx = x.view(x.size(0), −1)\\n3238.3. SOLUTIONS\\nThen the tensor shape becomes:\\ntorch.Size ([1, 96800])\\n5. Y es, you should agree with him, as depicted by the following plot 8.80:\\nFIGURE 8.80: A single MaxPool layer.\\n\\x04\\nBatch normalization, Gaussian PDF\\nThe Gaussian distribution\\nSOL-241 \\uf14b CH.SOL- 8.65.\\nThe answers are as follows:\\n1. BN is a method that normalizes the mean and variance of each of the elements during\\ntraining.\\n2. X ∼ N (0, 1) a mean of zero and a variance of one. The standard normal distribution\\noccurs when (σ)2 = 1 and µ = 0.\\n3. In order to normalize we:\\ni Step one is to subtract the mean to shift the distribution.\\nii Divide all the shifted values by their standard deviation (the square root of the\\nvariance).\\n4. In BN, the normalization is applied on an element by element basis. During training at\\neach epoch, every element in the batch has to be shifted and scaled so that it has a zero\\nmean and unit variance within the batch.\\n\\x04\\n324Chapter 8 DEEP LEARNING\\nSOL-242 \\uf14b CH.SOL- 8.66.\\n1. One possible realization is as follows 8.81:\\n1 from math import sqrt\\n2 import math\\n3 def normDist(x, mu, sigSqrt):\\n4 return (1 / sqrt(2 * math.pi * sigSqrt)) * math.e ** ((-0.5) *\\n(x - mu) ** 2 / sigSqrt)↪→\\nFIGURE 8.81: Normal distribution in Python: from scratch.\\n2. The derivative is given by 8.82:\\n1 scipy.stats.norm.pdf(x, mu, sigma) *(mu - x)/sigma**2\\nFIGURE 8.82: The derivative of a Normal distribution in Python.\\n\\x04\\nBN\\nSOL-243 \\uf14b CH.SOL- 8.67.\\n1. During training of a CNN, when a convolution is being followed by a BN layer, for\\neach of the three RGB channels a single separate mean and variance is being computed.\\n2. The mistake he made is using a BN with a batch size of 32, while the output from the\\nconvolutional layer is 64.\\n\\x04\\n3258.3. SOLUTIONS\\nTheory of CNN design\\nSOL-244 \\uf14b CH.SOL- 8.68.\\nT rue.\\n\\x04\\nSOL-245 \\uf14b CH.SOL- 8.69.\\nAll the options may be used to build a CNN. \\x04\\nSOL-246 \\uf14b CH.SOL- 8.70. While the original paper ([ 16]) suggests that BN layers be\\nused before an activation function, it is also possible to use BN after the activation function.\\nIn some cases, it actually leads to better results ([ 4]).\\n\\x04\\nSOL-247 \\uf14b CH.SOL- 8.71.\\nWhen dropout is enabled during the training process, in order to keep the expected output\\nat the same value, the output of a dropout layer must be multiplied with this term. Of course,\\nduring inference no dropout is taking place at all. \\x04\\nSOL-248 \\uf14b CH.SOL- 8.72.\\n1. The idiom is a bottleneck layer ([ 27]), which may act much like an autoencoder.\\n2. Reducing and then increasing the activations, may force the MLP to learn a more com-\\npressed representation.\\n3. The new architecture has far more connections and therefore it would be prone to over-\\nﬁtting.\\n4. Once such architecture is an autoencoder ([ 28]).\\n\\x04\\nCNN residual blocks\\nSOL-249 \\uf14b CH.SOL- 8.73.\\n326Chapter 8 DEEP LEARNING\\n1. The function F is the residual function.\\n2. The main idea was to add an identity connection which skips two layers all together.\\n\\x04\\nSOL-'),\n",
              " Document(metadata={}, page_content='3. The new architecture has far more connections and therefore it would be prone to over-\\nﬁtting.\\n4. Once such architecture is an autoencoder ([ 28]).\\n\\x04\\nCNN residual blocks\\nSOL-249 \\uf14b CH.SOL- 8.73.\\n326Chapter 8 DEEP LEARNING\\n1. The function F is the residual function.\\n2. The main idea was to add an identity connection which skips two layers all together.\\n\\x04\\nSOL-250 \\uf14b CH.SOL- 8.74.\\n1. The missing parts are visualized in ( 8.83).\\nFIGURE 8.83: A resnet CNN block\\n2. The symbol represents the addition operator.\\n3. Whenever F returns a zero, then the input X will reach the output without being\\nmodiﬁed. Therefore, the term identity function.\\n\\x04\\n8.3.8 Training, hyperparameters\\nHyperparameter optimization\\nSOL-251 \\uf14b CH.SOL- 8.75.\\nThe question states that image size is quite large, and the batch size is 1024, therefore it\\nmay fail to allocate memory on the GPU with an Out Of Memory (OOM) error message. This\\n3278.3. SOLUTIONS\\nis one of the most commonly faced errors when junior data-scientist start training models.\\n\\x04\\nSOL-252 \\uf14b CH.SOL- 8.76.\\n1. Since hs is tuning his Hyperparameters on the validation set, he would most probably\\noverﬁt to the validation set which he also used for evaluating the performance of the\\nmodel.\\n2. One way would be to amend the splitting, is by ﬁrst keeping a fraction of the training set\\naside, for instance 0.1, and then split the remaining .90 into a training and a validation\\nset, for instance 0.8 and 0.1.\\n3. His new approach uses GridSearchCV with 5-fold cross-validation to tune his Hyper-\\nparameters. Since he is using cross validation with ﬁve folds, his local CV metrics would\\nbetter reﬂect the performance on an unseen data set.\\n\\x04\\nSOL-253 \\uf14b CH.SOL- 8.77.\\nIn grid search, a set of pre-determined values is selected by a user for each dimension in\\nhis search space, and then thoroughly attempting each and every combination. Naturally, with\\nsuch a large search space the number of the required combinations that need to be evaluated\\nscale exponentially in the number of dimensions in the grid search.\\nIn random search the main difference is that the algorithm samples completely random\\npoints for each of the dimensions in the search space. Random search is usually faster and may\\neven produce better results.\\n\\x04\\nLabelling and bias\\nRecommended reading:\\n“Added value of double reading in diagnostic radiology,a systematic review ” [8].\\nSOL-254 \\uf14b CH.SOL- 8.78.\\nThere is a potential for bias in certain settings such as this. If the whole training set\\nis labelled only by a single radiologist, it may be possible that his professional history would\\n328Chapter 8 DEEP LEARNING\\ninadvertently generate bias into the corpus. Even if we use the form of radiology report reading\\nknown as double reading it would not be necessarily true that the annotated scans would be\\ndevoid of bias or that the quality would be better [ 8].\\n\\x04\\nValidation curve ACC\\nSOL-255 \\uf14b CH.SOL- 8.79.\\nThe answers are as follows:\\n1. A validation curve displays on a single graph a chosen hyperparameter on the hori-\\nzontal axis and a chosen metric on the vertical axis.\\n2. The hyperparameter is the number of epochs\\n3. The quality metric is the error (1 -accuracy). Accuracy, error = (1`accuracy) or loss are\\ntypical quality metrics.\\n4. The longer the network is trained, the better it gets on the training set.\\n5. At some point the network is ﬁt too well to the training data and loses its capability to\\ngeneralize. While the classiﬁer is still improving on the training set, it gets worse on\\nthe validation and the test set.\\n6. At this point the quality curve of the training set and the validation set diverge.\\n\\x04\\nValidation curve Loss\\nSOL-256 \\uf14b CH.SOL- 8.80.\\nThe answers are as follows:\\n1. What we are witnessing is phenomena entitled a plateau. This may happen when the\\noptimization protocol can not improve the loss for several epochs.\\n2. There possible methods are:\\ni Constant\\nii Xavier/Glorot uniform\\n3298.3. SOLUTIONS\\niii Xavier/G'),\n",
              " Document(metadata={}, page_content=' the quality curve of the training set and the validation set diverge.\\n\\x04\\nValidation curve Loss\\nSOL-256 \\uf14b CH.SOL- 8.80.\\nThe answers are as follows:\\n1. What we are witnessing is phenomena entitled a plateau. This may happen when the\\noptimization protocol can not improve the loss for several epochs.\\n2. There possible methods are:\\ni Constant\\nii Xavier/Glorot uniform\\n3298.3. SOLUTIONS\\niii Xavier/Glorot normal\\n3. Good initialization would optimally generate activations that produce initial gradients\\nthat are larger than zero. One idea is that the training process would converge faster if\\nunit variance is achieved ([ 16]). Moreover, weights should be selected carefully so that:\\ni They are large enough thus preventing gradients from decaying to zero.\\nii They are not too large causing activation functions to over saturate.\\n4. There are several ways to reduce the problem of plateaus:\\ni Add some type of regularization.\\nii In cases wherein the plateau happens right at the beginning, amend the way weights\\nare initialized.\\niii Amending the optimization algorithm altogether, for instance using SGD instead\\nof Adam and vice versa.\\n5. Since the initial LR is already very low, his suggestion may worsen the situation since\\nthe optimiser would not be able to jump off and escape the plateau.\\n6. In contrast to accuracy, Log loss has no upper bounds and therefore at times may be\\nmore difﬁcult to understand and to explain.\\n\\x04\\nInference\\nSOL-257 \\uf14b CH.SOL- 8.81.\\n1. Usually data augmentation, is a technique that is heavily used during training, espe-\\ncially for increasing the number of instances of minority classes. In this case, augment-\\nations are using during inference and this method is entitled T est Time Augmentation\\n(TTA).\\n2. Here are several image augmentation methods for TTA, with two augmentations shown\\nalso in PyT orch.\\n330Chapter 8 DEEP LEARNING\\nHorizontal ﬂip\\nV ertical ﬂip\\nRotation\\nScaling\\nCrops\\n1 transforms.HorizolntalFlip(p=1)(image)\\n2 transforms.VerticalFlip(p=1)(image)\\nFIGURE 8.84: Several image augmentation methods for TTA.\\n\\x04\\nSOL-258 \\uf14b CH.SOL- 8.82.\\ni Unseen\\nii Overﬁtting\\n\\x04\\n8.3.9 Optimization, Loss\\nStochastic gradient descent, SGD\\nSOL-259 \\uf14b CH.SOL- 8.83.\\nThere is no relation to random number generation, the true meaning is the use of batches\\nduring the training process.\\n\\x04\\nSOL-260 \\uf14b CH.SOL- 8.84.\\nA larger batch size decreases the variance of the gradient estimation of SGD. Therefore, if\\nyour training loop uses larger batches, the model will converge faster. On the other hand, smal-\\n3318.3. SOLUTIONS\\nler batch sizes increase the variance, leading to the opposite phenomena; longer convergence\\ntimes.\\n\\x04\\nMomentum\\nSOL-261 \\uf14b CH.SOL- 8.85.\\nMomentum introduces an extra term which comprises a moving average which is used\\nin gradient descent update rule to exponentially decay the historical gradients Using such\\nterm has been demonstrated to accelerate the training process ([ 11]) requiring less epochs to\\nconverge.\\n\\x04\\nSOL-262 \\uf14b CH.SOL- 8.86.\\nThe answers are as follows:\\n1. The derivative of the logistic activation function is extremely small for either negtive or\\npositive large inputs.\\n2. The use of the tanh function does not alleviate the problem since we can scale and\\ntranslate the sigmoid function to represent the tanh function:\\ntanh(z) = 2 σ(2z) − 1 (8.76)\\nWhile the sigmoid function is centred around 0.5, the tanh activation is centred around\\nzero. Similar to the application of BN, centring the activations may aid the optimizer con-\\nverge faster. Note: there is no relation to SGD; the issue exists when using other optimization\\nfunctions as well. \\x04\\nSOL-263 \\uf14b CH.SOL- 8.87.\\nThe answers are as follows:\\ni T rue.\\nii False. In stochastic gradient descent, the gradient for a single sample is quite different\\n332Chapter 8 DEEP LEARNING\\nfrom the actual gradient, so this gives a more noisy value, and converges slower\\niii T rue.\\niv False. SGD requires less memory.\\n\\x04\\nNorms, L1, L2\\nSOL-264 \\uf14b CH.SOL- 8.88.\\n1'),\n",
              " Document(metadata={}, page_content=' 8.87.\\nThe answers are as follows:\\ni T rue.\\nii False. In stochastic gradient descent, the gradient for a single sample is quite different\\n332Chapter 8 DEEP LEARNING\\nfrom the actual gradient, so this gives a more noisy value, and converges slower\\niii T rue.\\niv False. SGD requires less memory.\\n\\x04\\nNorms, L1, L2\\nSOL-264 \\uf14b CH.SOL- 8.88.\\n1. The L2 norm.\\n2. The Euclidean distance which is calculated as the square root of the sum of differences\\nbetween each point in a set of two points.\\n3. The Manhattan distance is an L1 norm (introduced by Hermann Minkowski) while the\\nEuclidean distance is an L2 norm.\\n4. The Manhattan distance is:\\n|6 − 2| + |1 − 8| + |4 − 3| + |5 − (−1)|\\n= 4 + 7 + 1 + 6 = 18 (8.77)\\n5. The Euclidean distance is:\\n√\\n(6 − 2)2 + (1 − 8)2 + (4 − 3)2 + (5 − (−1))2\\n=\\n√\\n102\\n(8.78)\\n\\x04\\nSOL-265 \\uf14b CH.SOL- 8.89.\\nThe PyT orch implementation is in ( 8.85). Note that we are allocating tensors on a GPU\\nbut ﬁrst they are created on a CPU using numpy. This is also always the interplay between\\nthe CPU and the GPU when training NN models. Note that this only work if you have GPU\\navailable; in case there is no GPU detected, the code has a fallback to the CPU.\\n333REFERENCES\\n1 %reset -f\\n2 import torch\\n3 import numpy\\n4\\n5 use_cuda = torch.cuda.is_available()\\n6 device = torch.device(\"cuda\" if use_cuda else \"cpu\")\\n7 print (device)\\n8 x1np=numpy.array([6,1,4,5])\\n9 x2np=numpy.array([2,8,3,-1])\\n10 x1t=torch.FloatTensor(x1np).to(device) # Move to GPU if available\\n11 x2t=torch.FloatTensor(x2np).to(device)\\n12 dist = torch.sqrt (torch .pow(x1t - x2t, 2).sum())\\n13 dist\\n14 >cuda\\n15 >tensor(10.0995, device =\\'cuda:0\\' )\\nFIGURE 8.85: Manhattan distance function in PyTorch.\\n\\x04\\nSOL-266 \\uf14b CH.SOL- 8.90.\\nThe L2 loss is suitable for a target, or a response variable that is continuous. On the other\\nhand, in a binary classiﬁcation problem using LR we would like the output to match either\\nzero or one and a natural candidate for a loss function is the binary cross-entropy loss. \\x04\\nReferences\\n[1] F. T. B. Fuglede. ‘Jensen-Shannon Divergence and Hilbert space embedding’. In:\\nIEEE Int Sym. Information Theory (2004) (cit. on pp. 245, 297).\\n[2] C. Bennett. ‘Information Distance’. In: IEEE T rans. Pattern Anal. Inform. Theory.\\n44:4 (1998), pp. 1407–1423 (cit. on pp. 244, 298).\\n[3] B. Bigi. ‘Using Kullback-Leibler Distance for Text Categorization’. In: In Pro-\\nceedings of the ECIR-2003, Lecture Notes in Computer Science, Springer-Verlag 2633\\n(2003), pp. 305–319 (cit. on pp. 245, 298).\\n334Chapter 8 DEEP LEARNING\\n[4] G. Chen. Rethinking the Usage of Batch Normalization and Dropout in the T raining of\\nDeep Neural Networks. 2019. arXiv: 1905.05928 [cs.LG] (cit. on p. 326).\\n[5] Y . S. Chen et al. ‘Deep photo enhancer: Unpaired learning for image enhance-\\nment from photographs with gans’. In: IEEE Conference on Computer Vision and\\nPattern Recognition. 2018, p. 6306 (cit. on p. 231).\\n[6] I. Ciuca and J. A. Ware. ‘Layered neural networks as universal approximators’.\\nIn: Computational Intelligence Theory and Applications . Ed. by B. Reusch. Berlin,\\nHeidelberg: Springer Berlin Heidelberg, 1997, pp'),\n",
              " Document(metadata={}, page_content='paired learning for image enhance-\\nment from photographs with gans’. In: IEEE Conference on Computer Vision and\\nPattern Recognition. 2018, p. 6306 (cit. on p. 231).\\n[6] I. Ciuca and J. A. Ware. ‘Layered neural networks as universal approximators’.\\nIn: Computational Intelligence Theory and Applications . Ed. by B. Reusch. Berlin,\\nHeidelberg: Springer Berlin Heidelberg, 1997, pp. 411–415 (cit. on p. 304).\\n[7] T. Floyd. Digital Fundamentals. Prentice Hall, 2003 (cit. on p. 252).\\n[8] H. Geijer and M. Geijer. ‘Added value of double reading in diagnostic radi-\\nology ,a systematic review’. In: Insights into Imaging 9 (Mar. 2018). DOI : 10.1007/\\ns13244-018-0599-0 (cit. on pp. 282, 328, 329).\\n[9] X. Glorot and Y . Bengio. ‘Understanding the difﬁculty of training deep feedfor-\\nward neural networks’. In: Journal of Machine Learning Research - Proceedings T rack\\n9 (Jan. 2010), pp. 249–256 (cit. on pp. 258, 313).\\n[10] S. Gomar, M. Mirhassani and M. Ahmadi. ‘Precise digital implementations of\\nhyperbolic tanh and sigmoid function’. In: 2016 50th Asilomar Conference on Sig-\\nnals, Systems and Computers (2016) (cit. on p. 254).\\n[11] I. Goodfellow, Y . Bengio and A. Courville. Adaptive computation and machine\\nlearning. MIT Press, 2016 (cit. on p. 332).\\n[12] J. Gurmeet Singh Manku. ‘Detecting near-duplicates for web crawling’. In: Pro-\\nceedings of the 16th International Conference on World Wide Web (2007), p. 141 (cit.\\non pp. 244, 245, 298).\\n[13] K. He. Deep Residual Learning for Image Recognition . 2015. arXiv: 1512 . 03385\\n(cit. on p. 279).\\n[14] K. He et al. Delving Deep into Rectiﬁers: Surpassing Human-Level Performance on\\nImageNet Classiﬁcation. 2015. arXiv: 1502.01852 [cs.CV] (cit. on pp. 258, 273).\\n[15] A. Ignatov et al. ‘Dslr-quality photos on mobile devices with deep convolu-\\ntional networks’. In: IEEE International Conference on Computer Vision (ICCV) .\\n2017, pp. 3297–3305 (cit. on p. 231).\\n[16] S. Ioffe and C. Szegedy. ‘Batch Normalization’. In: CoRR abs/1502.03167 (2015).\\narXiv: 1502.03167 (cit. on pp. 273, 326, 330).\\n335REFERENCES\\n[17] R. Kohavi. ‘A Study of Cross-Validation and Bootstrap for Accuracy Estima-\\ntion and Model Selection’. In: Morgan Kaufmann, 1995, pp. 1137–1143 (cit. on\\npp. 231, 289).\\n[18] A. Krizhevsky , I. Sutskever and G. E. Hinton. ‘ImageNet Classiﬁcation with\\nDeep Convolutional Neural Networks’. In: Advances in Neural Information Pro-\\ncessing Systems . Ed. by F. Pereira et al. V ol. 25. Curran Associates, Inc., 2012,\\npp. 1097–1105 (cit. on pp. 252, 306).\\n[19] Libtorch: The PyT orch C++ frontend is a C++14 library for CPU and GPU tensor com-\\nputation. 2020 (cit. on pp. 254, 256).\\n[20] A. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on pp. 266, 267).\\n[21] P . Ramachandran.Searching for Activation Functions . 2017. arXiv: 1710.05941\\n[cs.NE] (cit. on p. 260).\\n[22] D. E. Rumelhart and G'),\n",
              " Document(metadata={}, page_content='. Paszke et al. ‘Automatic differentiation in PyTorch’. In: 31st Conference on\\nNeural Information Processing Systems . 2017 (cit. on pp. 266, 267).\\n[21] P . Ramachandran.Searching for Activation Functions . 2017. arXiv: 1710.05941\\n[cs.NE] (cit. on p. 260).\\n[22] D. E. Rumelhart and G. E. Hinton. ‘Learning Representations by Back Propagat-\\ning Errors’. In: Neurocomputing: Foundations of Research . Cambridge, MA, USA:\\nMIT Press, 1988, pp. 696–699 (cit. on pp. 236, 252, 260, 292, 306).\\n[23] S. Sengupta et al. ‘Sfsnet: Learning shape, reﬂectance and illuminance of faces\\nin the wild’. In: Computer Vision and Pattern Regognition (CVPR) . 2018 (cit. on\\np. 231).\\n[24] Z. Shu, E. Yumer and S. Hadap. ‘Neural face editing with intrinsic image dis-\\nentangling’. In: Computer Vision and Pattern Recognition (CVPR) IEEE Conference .\\n2017, pp. 5444–5453 (cit. on p. 231).\\n[25] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale\\nImage Recognition. 2014. arXiv: 1409.1556 [cs.CV] (cit. on pp. 263, 265).\\n[26] P . Sledzinski et al. ‘The current state and future perspectives of cannabinoids in\\ncancer biology’. In: Cancer Medicine 7.3 (2018), pp. 765–775 (cit. on pp. 266, 267).\\n[27] C. Szegedy et al. ‘Inception v4, Inception-ResNet and the Impact of Residual\\nConnections on Learning’. In: ICLR 2016 Workshop. 2016 (cit. on p. 326).\\n[28] P . Vincent et al. ‘Extracting and composing robust features with denoising au-\\ntoencoders’. In: Proceedings of the 25th international conference on Machine learning .\\n2008, pp. 1096–1103 (cit. on p. 326).\\n336Chapter 8 DEEP LEARNING\\n[29] J. Ziv and N. Merhav . ‘A measure of relative entropy between individual se-\\nquences with application to universal classiﬁcation’. In: IEEE T ransactions on In-\\nformation Theory 39(4) (1993), pp. 1270–1279 (cit. on pp. 245, 298).\\n337REFERENCES\\n338PRACTICE EXAM\\nPART VCHAPTER\\n9\\nJOB INTER VIEW MOCK EXAM\\nA man who dares to waste one hour of time has not discovered the value of life.\\n— Charles Darwin\\nContents\\nRules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342\\nProblems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nPerceptrons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nClassiﬁcation, Logistic regression . . . . . . . . . . . . . . . . . . . . . . 345\\nInformation theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nFeature extraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nStressful events, such as a job interview, prompt concern and anxiety (as they do for\\nvirtually every person), but it’s the lack of preparation that fuels unnecessary'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nBayesian deep learning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nStressful events, such as a job interview, prompt concern and anxiety (as they do for\\nvirtually every person), but it’s the lack of preparation that fuels unnecessary nervous-\\nness. Many perceive the interview as a potentially threatening event. Testing your\\nknowledge in AI using a mock exam, is an effective way to not only identifying your\\nweaknesses and to pinpointing the concepts and topics that need brushing up, but\\nalso to becoming more relaxed in similar situations. Remember that at the heart of job\\ninterview conﬁdence is feeling relaxed.\\nDoing this test early enough, gives you a head-start before the actual interview, so\\nthat you can target areas that require perfection. The exam includes questions from\\na wide variety of topics in AI, so that these areas are recognised and it would then\\nbe a case of solving all the problems in this book over a period of few months to be\\nproperly prepared. Do not worry even if you can not solve any of the problems in the\\nexam as some of them are quite difﬁcult.DEEP LEARNING JOB INTER VIEW MOCK EXAM\\nEXAM INSTRUCTIONS :\\nYOU SHOULD NOT SEARCH FOR SOLUTIONS ON THE WEB . M ORE GENERALLY , YOU\\nARE URGED TO TRY AND SOLVE THE PROBLEMS WITHOUT CONSULTING ANY REFER -\\nENCE MATERIAL , AS WOULD BE THE CASE IN A REAL JOB INTERVIEW .\\n9.0.1 Rules\\nREMARK: In order to receive credits, you must:\\ni Show all work neatly .\\nii A sheet of formulas and calculators are permitted but not notes or texts.\\niii Read the problems CAREFULLY\\niv Do not get STUCK at any problem (or in local minima ...) for too much time!\\nv After completing all problems, a double check is STRONGLY advised.\\nvi You have three hours to complete all questions.\\n342Chapter 9 JOB INTER VIEW MOCK EXAM\\n9.1 Problems\\n9.1.1 Perceptrons\\nPRB-267 \\uf059 CH.PRB- 9.1. [PERCEPTRONS]\\nThe following questions refer to the MLP depicted in ( 9.1).The inputs to the MLP in\\n(9.1) are x1 = 0 .9 and x2 = 0 .7 respectively, and the weights w1 = −0.3 and w2 = 0 .15\\nrespectively. There is a single hidden node, H1. The bias term, B1 equals 0.001.\\nx1\\nH1\\nx2\\n∑\\nB1\\nw1=\\n−0.3\\nw2=\\n0.15\\nout1\\n0.001\\nInputs\\nHidden\\nSum\\nFIGURE 9.1: Several nodes in a MLP .\\n1. We examine the mechanism of a single hidden node, H1. The inputs and weights go\\nthrough a linear transformation. What is the value of the output ( out1) observed at\\nthe sum node?\\n2. What is the resulting value from the application of the sum operator?\\n3. Using PyT orch tensors, verify the correctness of your answers.\\n9.1.2 CNN layers\\nPRB-268 \\uf059 CH.PRB- 9.2. [CNN LAYERS]\\nWhile reading a paper about the MaxPool operation, you encounter the following code\\nsnippet 9.1 of a PyT orch module that the authors implemented. Y ou download their pre-\\ntrained model, and examine its behaviour during inference:\\n3439.1. PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 9.'),\n",
              " Document(metadata={}, page_content=' PROBLEMS\\n1 import torch\\n2 from torch import nn\\n3 class MaxPool001(nn.Module):\\n4 def __init__(self):\\n5 super(MaxPool001, self).__init__()\\n6 self.math = torch.nn.Sequential(\\n7 torch.nn.Conv2d(3, 32, kernel_size =7, padding =2),\\n8 torch.nn.BatchNorm2d(32),\\n9 torch.nn.MaxPool2d(2, 2),\\n10 torch.nn.MaxPool2d(2, 2),\\n11 )\\n12 def forward(self, x):\\n13 print (x.data.shape)\\n14 x = self.math(x)\\n15 print (x.data.shape)\\n16 x = x.view(x.size(0), -1)\\n17 print (\"Final shape:{}\" ,x.data.shape)\\n18 return x\\n19 model = MaxPool001()\\n20 model.eval()\\n21 x = torch.rand(1, 3, 224, 224)\\n22 out=model.forward(x)\\nCODE 9.1: A CNN in PyTorch\\nThe architecture is presented in 9.2:\\n344Chapter 9 JOB INTER VIEW MOCK EXAM\\nFIGURE 9.2: Two consecutive MaxPool layers.\\nPlease run the code and answer the following questions:\\n1. In MaxPool2D(2,2), what are the parameters used for?\\n2. After running line 8, what is the resulting tensor shape?\\n3. Why does line 20 exist at all?\\n4. In line 9, there is a MaxPool2D(2,2) operation, followed by yet\\na second MaxPool2D(2,2). What is the resulting tensor shape after running line 9?\\nand line 10?\\n5. A friend who saw the PyT orch implementation, suggests that lines 9 and 10 may\\nbe replaced by a single MaxPool2D(4,4,) operation while producing the exact same\\nresults. Do you agree with him? Amend the code and test your assertion.\\n9.1.3 Classification, Logistic regression\\nPRB-269 \\uf059 CH.PRB- 9.3. [CLASSIFICATION, LR]\\nT o study factors that affect the survivability of humans infected with COVID19 using\\nlogistic regression, a researcher considers the link between lung cancer and COVID19 as a\\n3459.1. PROBLEMS\\nplausible risk factor. The predictor variable is a count of removed pulmonary nodules (Fig.\\n9.3) in the lungs.\\nFIGURE 9.3: Pulmonary nodules.\\nThe response variable Y measures whether the patient shows any remission (as in the\\nmanifestations of a disease, e. g. yes=1, no=0) when the pulmonary nodules count shifts up\\nor down. The output from training a logistic regression classiﬁer is as follows:\\nStandard\\nParameter DF Estimate Error\\nIntercept 1 -4.8792 1.0732\\nPulmonary nodules 1 0.0258 0.0194\\n1. Estimate the probability of improvement when the count of removed pulmonary nod-\\nules of a patient is 33.\\n2. Find out the removed pulmonary nodules count at which the estimated probability of\\nimprovement is 0.5.\\n3. Find out the estimated odds ratio of improvement for an increase of 1, in the total\\nremoved pulmonary nodule count.\\n4. Obtain a 99% conﬁdence interval for the true odds ratio of improvement increase of\\n1 in the total removed pulmonary nodule count. Remember that The most common\\nconﬁdence levels are 90%, 95%, 99%, and 99.9%.\\n346Chapter 9 JOB INTER VIEW MOCK EXAM\\nConﬁdence Level z\\n90% 1.645\\n95% 1.960\\n99% 2.576\\n99.9% 3.291\\nTABLE 9.1: Common conﬁdence levels\\nT able9.1 lists the z values for these levels.\\n9.1.4 Information theory\\nPRB-270 \\uf059 CH.PRB- 9.4. [INFORMATION THEORY]\\nThis question discusses the link between binary classiﬁcation, information gain and\\ndecision trees. Recent research suggests that the co-existence of inﬂuenza (Fig. 9.4) and\\nCOVID19 virus may decrease the survivability of humans infected with the COVID 19\\nvirus. The data (T able 9.2) comprises a training set of feature vectors with corresponding\\nclass labels which a researcher intents classifying using a decision tree.\\nT o study factors affecting COVID19 eradication, the deep-learning researcher collects\\ndata regrading two independent binary variables; θ1 (T/F)'),\n",
              " Document(metadata={}, page_content=' inﬂuenza (Fig. 9.4) and\\nCOVID19 virus may decrease the survivability of humans infected with the COVID 19\\nvirus. The data (T able 9.2) comprises a training set of feature vectors with corresponding\\nclass labels which a researcher intents classifying using a decision tree.\\nT o study factors affecting COVID19 eradication, the deep-learning researcher collects\\ndata regrading two independent binary variables; θ1 (T/F) indicating whether the patient is\\na female, and θ2 (T/F) indicating whether the human tested positive for the inﬂuenza virus.\\nThe binary response variable, γ, indicates whether eradication was observed (e.g. eradica-\\ntion=+, no eradication=-).\\n3479.1. PROBLEMS\\nFIGURE 9.4: The inﬂuenza virus.\\nReferring to T able ( 9.2), each row indicates the observed values, columns ( θi) denote\\nfeatures and rows (< θ i, γi >) denote labelled instances while class label ( γ) denotes whether\\neradication was observed.\\nγ θ1 θ2\\n+ T T\\n- T F\\n+ T F\\n+ T T\\n- F T\\nTABLE 9.2: Decision trees and the COVID19 virus.\\n1. Describe what is meant by information gain.\\n2. Describe in your own words how does a decision tree work.\\n3. Using log2, and the provided dataset, calculate the sample entropy H(γ).\\n4. What is the information gain IG(X1) ≡ H(γ) − H(|θ1) for the provided training\\ncorpus?\\n348Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-271 \\uf059 CH.PRB- 9.5.\\nWhat is the entropy of a biased coin? Suppose a coin is biased such that the probability\\nof ‘heads’ is p(xh) = 0 .98.\\n1. Complete the sentence: We can predict ‘heads’ for each ﬂip with an accuracy of [__-\\n_]%.\\n2. Complete the sentence: If the result of the coin toss is ‘heads’, the amount of Shannon\\ninformation gained is [___] bits.\\n3. Complete the sentence: If the result of the coin toss is ‘tails’, the amount of Shannon\\ninformation gained is [___] bits.\\n4. Complete the sentence: It is always true that the more information is associated with\\nan outcome, the [more/less] surprising it is.\\n5. Provided that the ratio of tosses resulting in ‘heads’ is p(xh), and the ratio of tosses\\nresulting in ‘tails’ is p(xt), and also provided that p(xh) + p(xt) = 1 , what is the\\nformula for the average surprise?\\n6. What is the value of the average surprise in bits?\\nPRB-272 \\uf059 CH.PRB- 9.6.\\nComplete the sentence: The relative entropy D(p||q) is the measure of (a) [___] between\\ntwo distributions. It can also be expressed as a measure of the (b)[___] of assuming that the\\ndistribution is q when the (c)[___] distribution is p.\\n9.1.5 Feature extraction\\nPRB-273 \\uf059 CH.PRB- 9.7. [FEATURE EXTRACTION]\\nA data scientist extracts a feature vector from an image using a pre-trained ResNet34\\nCNN (9.5).\\n3499.1. PROBLEMS\\n1 import torchvision.models as models\\n2 ...\\n3 res_model = models.resnet34(pretrained=True)\\nFIGURE 9.5: PyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed).\\nHe then applies the following algorithm, entitled xxx on the image ( 9.2).\\nCODE 9.2: An unknown algorithm in C++11\\n1 void xxx(std::vector<float>& arr){\\n2 float mod = 0.0;\\n3 for (float i : arr) {\\n4 mod += i * i;\\n5 }\\n6 float mag = std::sqrt(mod);\\n7 for (float & i : arr) {\\n8 i /= mag;\\n9 }\\n10 }\\nWhich results in this vector ( 9.6):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 9.6: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n350Chapter 9 JOB INTER VIEW MOCK EXAM\\n'),\n",
              " Document(metadata={}, page_content=' results in this vector ( 9.6):\\n0.7766 0.4455 0.8342 0.6324 · · · k = 512\\nValues after applying xxx to a k-element FV .\\nFIGURE 9.6: A one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture.\\nName the algorithm that he used and explain in detail why he used it.\\n350Chapter 9 JOB INTER VIEW MOCK EXAM\\nPRB-274 \\uf059 CH.PRB- 9.8.\\n[FEATURE EXTRACTION]\\nThe following question discusses the method of ﬁxed feature extraction from layers of the\\nVGG19 architecture for the classiﬁcation of the COVID19 pathogen. It depicts FE principles\\nwhich are applicable with minor modiﬁcations to other CNNs as well. Therefore, if you hap-\\npen to encounter a similar question in a job interview, you are likely be able to cope with it\\nby utilizing the same logic.\\nIn (Fig. 9.7), 2 different classes of human cells are displayed; infected and not-infected,\\nwhich were curated from a dataset of 4K images labelled by a majority vote of two expert\\nvirologists. Y our task is to use FE to correctly classify the images in the dataset.\\nFIGURE 9.7: A dataset of human cells infected by the COVID19 pathogen.\\nT able (9.3) presents an incomplete listing of the of the VGG19 architecture. As depicted,\\nfor each layer the number of ﬁlters (i. e. neurons with unique set of parameters), learnable\\nparameters (e. g. weights and biases), and FV size are presented.\\n3519.1. PROBLEMS\\nLayer name #Filters #Parameters # Features\\nconv4_3 512 2.3M 512\\nfc6 4,096 103M 4,096\\nfc7 4,096 17M 4,096\\noutput 1,000 4M -\\nT otal 13,416 138M 12,416\\nTABLE 9.3: Incomplete listing of the of the VGG19 architecture\\n1. Describe how the VGG19 CNN may be used as ﬁxed FE for a classiﬁcation task. In\\nyour answer be as detailed as possible regarding the stages of FE and the method used\\nfor classiﬁcation.\\n2. Referring to T able (9.3), suggest three different ways in which features can be extrac-\\nted from a trained VGG19 CNN model. In each case, state the extracted feature layer\\nname and the size of the resulting FE.\\n3. After successfully extracting the features for the 4k images from the dataset, how can\\nyou now classify the images into their respective categories?\\n9.1.6 Bayesian deep learning\\nPRB-275 \\uf059 CH.PRB- 9.9. [BAYESIAN DEEP LEARNING]\\nA recently published paper presents a new layer for Bayesian neural networks (BNNs).\\nThe layer behaves as follows. During the feed-forward operation, each of the hidden neurons\\nHn , n ∈ { 1, 2, } in the neural network in (Fig. 9.8) may, or may not ﬁre, independently\\nof each other, according to a known prior distribution.\\n352Chapter 9 JOB INTER VIEW MOCK EXAM\\nθ1\\nθ2\\nH1\\nH2\\nFIGURE 9.8: Likelihood in a BNN model.\\nThe chance of ﬁring, γ, is the same for each hidden neuron. Using the formal deﬁnition,\\ncalculate the likelihood function of each of the following cases:\\n1. The hidden neuron is distributed according to X ∼ B(n, γ ) random variable and ﬁres\\nwith a probability of γ. There are 100 neurons and only 20 are ﬁred.\\n2. The hidden neuron is distributed according to X ∼ U (0, γ) random variable and ﬁres\\nwith a probability of γ.\\nPRB-276 \\uf059 CH.PRB- 9.10.\\nDuring pregnancy, the Placenta Chorion T est is commonly used for the diagnosis of\\nhereditary diseases (Fig. 9.9).\\nFIGURE 9.9: Foetal surface of the placenta\\nAssume, that a new test entitled the Placenta COVID19 T est has the exact same proper-\\nties as the Placenta Chorion T est. The test has a probability of 0.95 of being correct whether\\nor not a COVID19 pathogen is present. It is known that 1/100 of pregnancies result'),\n",
              " Document(metadata={}, page_content=' the diagnosis of\\nhereditary diseases (Fig. 9.9).\\nFIGURE 9.9: Foetal surface of the placenta\\nAssume, that a new test entitled the Placenta COVID19 T est has the exact same proper-\\nties as the Placenta Chorion T est. The test has a probability of 0.95 of being correct whether\\nor not a COVID19 pathogen is present. It is known that 1/100 of pregnancies result in\\n3539.1. PROBLEMS\\nCOVID19 virus being passed to foetal cells. Calculate the probability of a test indicating\\nthat a COVID19 virus is present.\\nPRB-277 \\uf059 CH.PRB- 9.11.\\nA person who was unknowingly infected with the COVID19 pathogen takes a walk in\\na park crowded with people. Let y be the number of successful infections in 5 independent\\nsocial interactions or infection attempts (trials), where the probability of “success\" (infecting\\nsomeone else) is θ in each trial. Suppose your prior distribution for θ is as follows: P (θ =\\n1/2) = 0 .25, P (θ = 1/6) = 0 .5, and P (θ = 1/4) = 0 .25.\\n1. Derive the posterior distribution p(θ|y).\\n2. Derive the prior predictive distribution for y.\\nPRB-278 \\uf059 CH.PRB- 9.12.\\nThe 2014 west African Ebola (Fig. 9.10) epidemic has become the largest and fastest-\\nspreading outbreak of the disease in modern history with a death tool far exceeding all past\\noutbreaks combined. Ebola (named after the Ebola River in Zaire) ﬁrst emerged in 1976 in\\nSudan and Zaire and infected over 284 people with a mortality rate of 53%.\\nFIGURE 9.10: The Ebola virus.\\nThis rare outbreak, underlined the challenge medical teams are facing in containing epi-\\ndemics. A junior data scientist at the centre for disease control (CDC) models the possible\\nspread and containment of the Ebola virus using a numerical simulation. He knows that out\\nof a population of k humans (the number of trials), x are carriers of the virus (success in\\n354Chapter 9 JOB INTER VIEW MOCK EXAM\\nstatistical jargon). He believes the sample likelihood of the virus in the population, follows a\\nBinomial distribution:\\nL(γ) =\\n\\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 γy(1 − γ)n−y,\\nγ ∈ [0, 1], y = 1, 2, . . . , n ,\\n(9.1)\\nwhere: \\uf8eb\\n\\uf8ed n\\ny\\n\\uf8f6\\n\\uf8f8 = n!\\n(n − y)!y!. (9.2)\\nAs the senior researcher in the team, you guide him that his parameter of interest is γ, the\\nproportion of infected humans in the entire population.\\nThe expectation and variance of the binomial are:\\nE(y|γ, n) = nγ, , V (y|γ, n) = nγ(1 − γ). (9.3)\\nAnswer the following:\\n1. For the likelihood function of the form lx(γ) = log Lx(γ) what is the log-likelihood\\nfunction?\\n2. Find the log-likelihood function ln (L(γ))\\n3. Find the gradient vector g(γ)\\n4. Find the Hessian matrix H(γ)\\n5. Find the Fisher information I(γ)\\n6. In a population spanning 10,000 individuals, 300 were infected by Ebola. Find the\\nMLE for γ and the standard error associated with it.\\n3559.1. PROBLEMS\\n356VOLUME TWO\\nPART VICHAPTER\\n10\\nVOLUME TWO - PLAN\\nNothing exists until it is measured.\\n— Niels Bohr, 1985\\nContents\\nIntroduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAI system design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nAdvanced CNN topologies . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n1D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\n3D CNN’s . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nData augmentations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject detection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nObject segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nSemantic segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nInstance segmentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage classiﬁcation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nImage captioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nNLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 360\\nRNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nLSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nGANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nAdversarial attacks and defences . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nV ariational auto encoders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nFCN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSeq2Seq . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nMonte carlo, ELBO, Re-parametrization . . . . . . . . . . . . . . . . . . . . 36110.1. INTRODUCTION\\nT ext to speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content='361\\nCRF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nQuantum computing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\nRL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 361\\n10.1 Introduction\\nI\\nT is important at the outset to understand we could not possibly include\\neverything we wanted to include in the ﬁrst VOLUME of this series. While\\nthe ﬁrst volume is meant to introduce many of the core subjects in AI, the\\nsecond volume takes another step down that road and includes numerous,\\nmore advanced subjects. This is a short glimpse into the plan for VOLUME-2 of this\\nseries. This second volume focuses on more advanced topics in AI\\n10.2 AI system design\\n10.3 Advanced CNN topologies\\n10.4 1D CNN’s\\n10.5 3D CNN’s\\n10.6 Data augmentations\\n10.7 Object detection\\n10.8 Object segmentation\\n10.9 Semantic segmentation\\n10.10 Instance segmentation\\n10.11 Image classification\\n10.12 Image captioning\\n10.13 NLP\\n360Chapter 10 VOLUME TWO - PLAN\\n10.14 RNN\\n10.15 LSTM\\n10.16 GANs\\n10.17 Adversarial attacks and defences\\n10.18 Variational auto encoders\\n10.19 FCN\\n10.20 Seq2Seq\\n10.21 Monte carlo, ELBO, Re-parametrization\\n10.22 Text to speech\\n10.23 Speech to text\\n10.24 CRF\\n10.25 Quantum computing\\n10.26 RL\\n36110.26. RL\\n362List of Tables\\nTumour eradication statistics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\nCommon conﬁdence levels. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nTumour shrinkage in rats. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nProbability values of hereditary-disease detection. . . . . . . . . . . . . . . . . 67\\nDecision trees and frogs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\\nDecision trees and Cannabinoids administration . . . . . . . . . . . . . . . . . 96\\nDecision trees and star expansion. . . . . . . . . . . . . . . . . . . . . . . . . . 97\\nDecision trees and radiation therapy . . . . . . . . . . . . . . . . . . . . . . . . . 98\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\\nSplitting on θ1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nSplitting on θ2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 to compute ∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . 169\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3'),\n",
              " Document(metadata={}, page_content=' setting ˙x1 = 1 to compute ∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . 169\\nForward-mode AD table for y = g(x1, x2) = ln( x1)+x1x2 evaluated at (x1, x2) =\\n(e2; π) and setting ˙x1 = 1 (seed values are mentioned here: 3) to compute\\n∂y\\n∂x1\\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171\\nImageNet-pretrained CNNs. Ensembles of these CNN architectures have been\\nextensively studies and evaluated in various ensembling approaches. . . 193\\nIncomplete listing of the VGG19 architecture . . . . . . . . . . . . . . . . . . . 209\\nIncomplete listing of the VGG11 architecture. . . . . . . . . . . . . . . . . . . . 265\\nComputed values for the Sigmoid and the Sigmoid approximation. . . . . . . 310\\nCommon conﬁdence levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347\\nDecision trees and the COVID19 virus. . . . . . . . . . . . . . . . . . . . . . . . 348\\nIncomplete listing of the of the VGG19 architecture . . . . . . . . . . . . . . . . 352LIST OF TABLES\\n364List of Figures\\nExamples of two sigmoid functions. . . . . . . . . . . . . . . . . . . . . . . . . 15\\nPulmonary nodules (left) and breast cancer (right). . . . . . . . . . . . . . . . . 16\\nA multi-detector positron scanner used to locate tumours. . . . . . . . . . . . 18\\nA dental amalgam. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\nA chain of spherical bacteria. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\nCannabis. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\nLogistic regression in CPP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\nA linear model in PyTorch . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 25\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 26\\nLogistic regression methods in Python. . . . . . . . . . . . . . . . . . . . . . . . 27\\nOdds vs. probability values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\nBinary entropy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nLogistic regression in C++ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39\\nHistopathology for pancreatic cancer cells. . . . . . . . . . . . . . . . . . . . . 44\\nBosons and fermions: particles with half-integer spin are fermions. . . . . . . 46\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe Dercum disease .'),\n",
              " Document(metadata={}, page_content=\"opathology for pancreatic cancer cells. . . . . . . . . . . . . . . . . . . . . 44\\nBosons and fermions: particles with half-integer spin are fermions. . . . . . . 46\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe Dercum disease . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47\\nThe New York Stock Exchange. . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\\nHedge funds and monkeys. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nDialect detection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49\\nThe Morse telegraph code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55\\nOnOffLayer in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 56\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 57\\nThe Maxwell-Boltzmann distribution. . . . . . . . . . . . . . . . . . . . . . . . 58\\nA QuantumDrop layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58\\nThe binomial distribution. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\\nZ-score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62LIST OF FIGURES\\nConditional probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63\\nV enn diagram of the intersected events A and B in probability space H . . . . 63\\nAnnotated components of the Bayes formula (eq. 3.23) . . . . . . . . . . . . . . 64\\nMutual information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86\\nReﬂection on the motive power of ﬁre. . . . . . . . . . . . . . . . . . . . . . . . 87\\nNatural (ln), binary (log2) and common ( log10) logarithms. . . . . . . . . . . . . 88\\nA Frog in its natural habitat. Photo taken by my son. . . . . . . . . . . . . . . . 95\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\\nShannon's ﬁve element communications system. . . . . . . . . . . . . . . . . . 99\\nAn octahedral dice. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\"),\n",
              " Document(metadata={}, page_content=\" . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96\\nShannon's ﬁve element communications system. . . . . . . . . . . . . . . . . . 99\\nAn octahedral dice. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\\nLogarithms in information theory . . . . . . . . . . . . . . . . . . . . . . . . . . 102\\nH vs. Probability . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106\\nShannon information gain for a biased coin toss. . . . . . . . . . . . . . . . . . 107\\nAverage surprise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108\\nFirst split. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\\nEntropy before splitting. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114\\nMutual Information between H(S) & H(D). . . . . . . . . . . . . . . . . . . . . 117\\nIntermediate value theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124\\nA Computation graph with intermediate values as nodes and operations as\\narcs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 127\\nx2 Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133\\nForward pass for the sigmoid function. . . . . . . . . . . . . . . . . . . . . . . . 135\\nPyTorch syntax for autograd. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 137\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 139\\nAn expression graph for g(x). Constants are shown in gray , crossed-out since\\nderivatives should not be propagated to constant operands. . . . . . . . 140\\nA computation graph for g(x) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141\\nA Tangent line . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147\\n366Chapter 10 LIST OF FIGURES\\nForward and backward passes for the sigmoid activation function in pure\\nPython. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\\nForward and backward for the sigmoid function in Autograd. . . . . . . . . . 159\\nForward and backward for the ReLU function in Autograd. . . . . . . . . . . . 160\\nForward pass for\"),\n",
              " Document(metadata={}, page_content=' activation function in pure\\nPython. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157\\nForward and backward for the sigmoid function in Autograd. . . . . . . . . . 159\\nForward and backward for the ReLU function in Autograd. . . . . . . . . . . . 160\\nForward pass for equation ( 5.23) using pure Python. . . . . . . . . . . . . . . . 161\\nForward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . . 161\\nBackward pass for equation ( 5.23). . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nInvoking arctanh using gradcheck . . . . . . . . . . . . . . . . . . . . . . . . . 162\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165\\nAutograd . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166\\nA Computation graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . 168\\nA derivative graph for g(x1, x2) in 5.1 . . . . . . . . . . . . . . . . . . . . . . . . 169\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 170\\nPython code- AD of the function g(x1, x2) . . . . . . . . . . . . . . . . . . . . . 172\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSigmoid gradient in SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173\\nSymPy gradient of the Sigmoid() function . . . . . . . . . . . . . . . . . . . . . 174\\nSymPy imports . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175\\nLikelihood function using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . 176\\nBeta distribution using SymPy . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178\\nA plot of the Beta distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179\\nA plot of the Posterior with the provided data samples. . . . . . . . . . . . . . 181\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nA speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nSampling approaches . . . . . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content='A speciﬁc ensembling approach . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nSampling approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 191\\nA typical binary classiﬁcation problem. . . . . . . . . . . . . . . . . . . . . . . 194\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 195\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 196\\nPyTorch code snippet for an ensemble . . . . . . . . . . . . . . . . . . . . . . . 197\\nA learning rate schedule. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198\\n367LIST OF FIGURES\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. While any neural network can be used for FE, depic-\\nted is the ResNet CNN architecture with 34 layers. . . . . . . . . . . . . . 206\\nPyTorch decleration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 206\\nA dataset of 4K histopathology WSI from three severity classes: A, B and C. . 209\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211\\nPyTorch code skeleton for extracting a 512-dimensional FV from a pre-trained\\nResNet34 CNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212\\nSkin lesion categories. An exemplary visualization of melanoma. . . . . . . . 214\\nArtistic style transfer using the style of Francis Picabia’s Udnie painting. . . . 215\\nPyTorch declaration for a pre-trained ResNet34 CNN. . . . . . . . . . . . . . . 216\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220\\nPyTorch code snippet for extracting the f c7 layer from a pre-trained VGG19\\nCNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221\\nTwo CV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nStratiﬁed K-fold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nA speciﬁc CV approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\nA padding approach . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . 221\\nTwo CV approaches . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231\\nStratiﬁed K-fold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232\\nA speciﬁc CV approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237\\nA padding approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 239\\nA 3 by 3 convolution kernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 240\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 242\\nlisting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242\\nAn unknown algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243\\nJaccard similarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248\\nA basic MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 250\\n368Chapter 10 LIST OF FIGURES\\nA single layer perceptron. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\\nExamples of two sigmoid functions and an approximation. . . . . . . . . . . . 254\\nForward pass for the Sigmoid function using Libtorch . . . . . . . . . . . . . . 255\\nEvaluation of the sigmoid and its derivative using Libtorch . . . . . . . . . . . 255\\nExamples of two tanh functions. . . . . . . . . . . . . . . . . . . . . . . . . . . 256\\nA simple NN based on tanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 257\\nA small CNN composed of tanh blocks. . . . . . . . . . . . . . . . . . . . . . . 258\\nA small CNN composed of ReLU blocks. . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' 256\\nA simple NN based on tanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 257\\nA small CNN composed of tanh blocks. . . . . . . . . . . . . . . . . . . . . . . 258\\nA small CNN composed of ReLU blocks. . . . . . . . . . . . . . . . . . . . . . 259\\nA confusion metrics for functioning (N) temperature sensors. P stands for\\nmalfunctioning devices. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 261\\nRUC AUC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262\\nXGBOOST for binary classiﬁcation. . . . . . . . . . . . . . . . . . . . . . . . . . 263\\nCNN arithmetics on the VGG11 CNN model. . . . . . . . . . . . . . . . . . . . 264\\nA Dropout layer (simpliﬁed form). . . . . . . . . . . . . . . . . . . . . . . . . . 266\\nA Bayesian Neural Network Model . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nTwo consecutive Dropout layers . . . . . . . . . . . . . . . . . . . . . . . . . . 267\\nA CNN based classiﬁcation system. . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nA small ﬁlter for a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 270\\nInput to MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . . . . 271\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 273\\nNormal distribution in Python. . . . . . . . . . . . . . . . . . . . . . . . . . . . 274\\nA convolution and BN applied to an RGB image. . . . . . . . . . . . . . . . . . 275\\nA mistake in a CNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278\\nA CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280\\nHyperparameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283\\nA validation curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog-loss function curve. . . . . . . . . . . . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . . . . . 283\\nA validation curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog-loss function curve. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285\\nA problem with the log-loss curve. . . . . . . . . . . . . . . . . . . . . . . . . . 286\\nManhattan distance function. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\nConvolution and correlation in python . . . . . . . . . . . . . . . . . . . . . . . 295\\n369LIST OF FIGURES\\nThe idea of hashing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300\\nMLP operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301\\nMLP operations- values. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302\\nHidden layer values, simple MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- values at the output. . . . . . . . . . . . . . . . . . . . . . . . 303\\nMLP operations- Softmax. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304\\nLogical AND: B=-2.5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND: B=-0.25 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305\\nLogical AND gate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306\\nBackward pass for the Sigmoid function using Libtorch. . . . . . . . . . . . . . 307\\nEvaluation of the sigmoid and its derivative in C++ using Libtorch. . . . . . . 308\\nForward pass for the Sigmoid function approximation in C++ using Libtorch. 309\\nPrinting the values for Sigmoid and Sigmoid function approximation in C++\\nusing Libtorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309\\nForward pass for tanh using pure Python. . . . . . . . . . . . . . . . . . . . . . 311\\nTanh in PyTorch. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312\\nInvoking gradcheck on tanh. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 313\\nA plot of the Swish activation function. . . . . . . . . . . . . . . . . . . . . . . 315\\nTP , TN, FP , FN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' plot of the Swish activation function. . . . . . . . . . . . . . . . . . . . . . . 315\\nTP , TN, FP , FN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic curve. . . . . . . . . . . . . . . . . . . . . . . 317\\nConvolutional block from the VGG11 architecture. . . . . . . . . . . . . . . . . 319\\nEquivalence of two consecutive dropout layers . . . . . . . . . . . . . . . . . . 321\\nThe result of applying the ﬁlter. . . . . . . . . . . . . . . . . . . . . . . . . . . . 321\\nThe result of applying a ReLU activation. . . . . . . . . . . . . . . . . . . . . . 322\\nThe result of applying a MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . 322\\nOutput of the MaxPool2d operation. . . . . . . . . . . . . . . . . . . . . . . . . 323\\nA single MaxPool layer. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324\\nNormal distribution in Python: from scratch. . . . . . . . . . . . . . . . . . . . 325\\nThe derivative of a Normal distribution in Python. . . . . . . . . . . . . . . . . 325\\nA resnet CNN block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327\\nSeveral image augmentation methods for TTA. . . . . . . . . . . . . . . . . . . 331\\nManhattan distance function in PyTorch. . . . . . . . . . . . . . . . . . . . . . . 334\\nSeveral nodes in a MLP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\\nTwo consecutive MaxPool layers. . . . . . . . . . . . . . . . . . . . . . . . . . . 345\\nPulmonary nodules. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346\\n370Chapter 10 LIST OF FIGURES\\nThe inﬂuenza virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 348\\nPyTorch declaration for a pre-trained ResNet34 CNN (simpliﬁed). . . . . . . . 350\\nA one-dimensional 512-element embedding for a single image from the Res-\\nNet34 architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350\\nA dataset of human cells infected by the COVID19 pathogen. . . . . . . . . . . 351\\nLikelihood in a BNN model. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nFoetal surface of the placenta . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353\\nThe Ebola virus. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354\\n371LIST OF FIGURES\\n372Alphabetical Index\\nA\\nA 2D convolution . . . . . . . . . . . . . . . . . .235\\nA 512 dimension embedding . . . . . . . 206\\nA mathematical theory of\\ncommunication . . . . . . . . . . . . . 90\\nA random forest .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . 354\\n371LIST OF FIGURES\\n372Alphabetical Index\\nA\\nA 2D convolution . . . . . . . . . . . . . . . . . .235\\nA 512 dimension embedding . . . . . . . 206\\nA mathematical theory of\\ncommunication . . . . . . . . . . . . . 90\\nA random forest . . . . . . . . . . . . . . . . . . . 187\\nACC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .329\\nAccuracy . . . . . . . . . . . . . . . . .251, 283, 329\\nActivation functions . 125, 135 ff., 139 ff.,\\n157 f., 160, 163, 165, 168, 248,\\n256, 301, 306\\nActivation layer . . . . . . . . . . . . . . .253, 306\\nAD . . . . . . . . . . . . . . . . .123 f., 137, 140, 166\\nAdam . . . . . . . . . . . . . . . . . . . . . . . . . . . . .330\\nAdditivity property . . . . . . . . . . . . . . . .103\\nAlexNet . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nAlgorithmic differentiation . . . .125, 135,\\n137, 139 ff., 146, 157 f., 160, 163,\\n165, 168\\nAlzheimer’s disease . . . . . . . . . . . . . . . . . 20\\nAmalgam ﬁllings . . . . . . . . . . . . . . . . . . . 18\\nAnalytical gradients . . . . . . . . . . . . . . . 134\\nAnalyze a paper . . . . . . . . . . . . . . . . . . . 260\\nAND logic gate . . . . . . . . . . . . . . . . . . . . 252\\nANN . . . . . . . . . . . . . . . . . . . . . . . . . . .15, 135\\nAnnotated probabilities . . . . . . . . . . . . .62\\nAnnotations . . . . . . . . . . . . . . . . . . . . . . .282\\nANNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . .134\\nANOV A . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nApproaches for combining predictors\\n190, 199\\nArithmetic operations . . . . . . . . . 138, 163\\nArithmetical methods . . . . . . . . . . . . . . .41\\nArtiﬁcial neural networks . . . . . . . 12, 15\\nAUC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nAugmentation . . . . . . . . . . . . . . . . . . . . .222\\nAugmentations . . . . . . . . . . . . . . . . . . . . . . 8\\nAuto correlation . . . . . . . . . . . . . . .235, 291\\nAutoAugment . . . . . . . . . . . . . . . . . . . . .223\\nAutoencoder . . . . . . . . . . . . . . . . . .279, 326\\nAutoGrad . . . . . . . . . . . . . . . . . . . . .158, 173\\nAutograd124 f., 135–141, 157 f., 160, 163,\\n165, 168, 310\\nAutomatic differentiation . . . .123 f., 173\\nAveraging and majority voting . . . . .202\\nB\\nBack-propagation in perceptrons . . 249,\\n301\\nBack-propogation . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . .158, 173\\nAutograd124 f., 135–141, 157 f., 160, 163,\\n165, 168, 310\\nAutomatic differentiation . . . .123 f., 173\\nAveraging and majority voting . . . . .202\\nB\\nBack-propagation in perceptrons . . 249,\\n301\\nBack-propogation . . . . . . . . . . . . . . . . . .247\\nBackprop learning . . . . . . . . . . . . . . . . .134\\nBackprop learning rule . . . . . . . . . . . . 134\\nBackpropagation . . . . . . . . . 123, 134, 158\\nBackpropagation algorithm . . . 135, 156\\nBackward pass125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nBagging . . . . . . . . . . . . . .186, 189, 193, 198\\nBasic laws of logarithms . . . . . . . . . . . . 88\\nBatch normalization . . . . . . . . . . .273, 324\\nBatchNorm2D . . . . . . . . . . . . . . . . 271, 343\\nBayes formulae . . . . . . . . . . . . . . . . . .45, 64\\nBayes rule . . . . . . . . . . . . . 45, 47, 66, 353 f.ALPHABETICAL INDEX\\nBayes theorem . . . . 42, 46–50, 65 f., 68 ff.\\nBayesian . . . . . . . . . . . . . . . . . . . . . . . . . . . .77\\nBayesian analysis . . . . . . . . . . . . . . . .65, 77\\nBayesian approximation . . . . . . . . . . . 192\\nBayesian deep learning . . . . . 55, 77, 352\\nBayesian dropout . . . . . . . . . . . . . . . . . .352\\nBayesian inference . . . . . . . . . . . . . . .42, 45\\nBayesian machine learning . . . . . . . . . .54\\nBayesian neural networks . . . . . .55 f., 79\\nBayesian paradigm . . . . . . . . . . . . . . . . . 42\\nBayesian statistical conclusions . . . . . 65\\nBayesian statistics . . . . . . . . . . . . . . . 42, 65\\nBernoulli . . . . . . . . . . . . . . . . . . . . . . .75, 277\\nBernoulli distribution . . . . . . . . . . . . . . .53\\nBernoulli random variable . . . . . . . . . . 18\\nBernoulli trial . . . . . . . . . . . . . . 42 f., 59, 62\\nBeta binomial . . . . . . . . . . . . . . . . . . . . . .146\\nBeta binomial distribution . . . . . . . . .54 f.\\nBeta distribution . . . . . . . 42, 55, 146, 176\\nBeta prior . . . . . . . . . . . . . . . . . . . . . . . . . . .55\\nBias . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .282\\nBiased coin . . . . . . . . . . . . . . . . . . . . .92, 349\\nBiased coin toss . . . . . . . . . . . . . . . . . 64, 92\\nBiases . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nBinary class . . . . . . . . . . . . . . . . . . . . . . . . .38\\nBinary classiﬁcation 12, 15, 96, 137, 190,\\n193 f., 246\\nBinary code . .'),\n",
              " Document(metadata={}, page_content=' . 64, 92\\nBiases . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nBinary class . . . . . . . . . . . . . . . . . . . . . . . . .38\\nBinary classiﬁcation 12, 15, 96, 137, 190,\\n193 f., 246\\nBinary code . . . . . . . . . . . . . . . . . . . . . . . . .90\\nBinary logistic regression . . . . . . . . 14, 31\\nBinary options . . . . . . . . . . . . . . . . . . . . 48 f.\\nBinary response . . . . . . . . . . . . . . . . . . . . .14\\nBinary response variable . . . . . 19, 94, 97\\nBinomial . . . . . . . . . . . . . . . . . . . .43, 53, 354\\nBinomial distribution31, 43, 52 f., 55, 59,\\n78\\nBinomial likelihood . . . . . . . . . . . . 54, 178\\nBinomial random variable . . . . . 43, 59 f.\\nBlocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . .318\\nBN . . . . . . . . . . . . . . . . . . .273 f., 277, 324 ff.\\nBNN . . . . . . . . . . . . . . . . . . . . . . . . . . 55 f., 79\\nBNNs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352\\nBohm and Hiley . . . . . . . . . . . . . . . . . . . . 87\\nBoltzmann . . . . . . . . . . . .58, 86, 100 f., 118\\nBoltzmann entropy . . . . . . . . . . . . . . . . 118\\nBoltzmann’s constant . . . . . . . . . . . . . . 100\\nBoltzmanns entropy . . . . . . . . . . . . . . . 101\\nBoosting . . . . . . . . .186, 189, 193, 198, 200\\nBootstrap aggregation . . . . . . . . .189, 192\\nBosons . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nBosons and fermions . . . . . . . . . . . . . . . .46\\nBottleneck . . . . . . . . . . . . . . . . . . . . 279, 326\\nBrazilian rain forest . . . . . . . . . . . . . . . . .94\\nBreast cancer . . . . . . . . . . . . . . . . . . . . . . . 17\\nC\\nCalculus . . . . . . . . . . . . . . . . .80, 122 f., 143\\nCalculus in deep learning . . . . . . . . . . 123\\nCancer . . . . . . . . . . . . . . . . . . . . . .16, 43, 208\\nCannabinoids . . . . . . . . . . . . . . . . . . . . . . .96\\nCannabis . . . . . . . . . . . . . . . . . . . . . . . . . . .96\\nCDC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354\\nCE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nChain of spherical bacteria . . . . . . . . . . 20\\nChain rule . . . . . . . . . . . . . . . . . . . . . . . . .163\\nChaotic distribution . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . .354\\nCE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nChain of spherical bacteria . . . . . . . . . . 20\\nChain rule . . . . . . . . . . . . . . . . . . . . . . . . .163\\nChaotic distribution . . . . . . . . . . . . . . . . 38\\nCI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .35\\nClass probabilities . . . . . . . . . . . . .190, 199\\nClassic bagging . . . . . . . . . . . . . . . . . . . .199\\nClassic logistic regression . . . . . . . . . . . 35\\nClassic normalization . . . . . . . . . . . . . . .29\\nClassical committee machines . . . . . .189\\nClassical machine learning . . . . . . . . . 201\\nClassical probability . . . . . . . . . . . . . . . . 42\\n374Chapter 10 ALPHABETICAL INDEX\\nClassiﬁcation . . . . . 32, 206, 208, 289, 345\\nClassiﬁcation and information gain . 94,\\n110\\nClaud Shannon . . . . . . . . . . . . . . . . . . . . .90\\nCM . . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nCNN . . . 8, 190, 192, 205 f., 216, 272, 274,\\n318, 326, 344, 349\\nCNN arithmetics . . . . . . . . . . . . . . . . . . 318\\nCNN as Fixed Feature Extractor . . . 206,\\n216\\nCNN classiﬁers . . . . . . . . . . . . . . . . . . . .192\\nCNN feature extraction . . . . . . . . . . . . 206\\nCNN layers . . . . . . . . . . . . . . . . . . . . . . . .343\\nCNN model predictions . . . . . . . . . . . 190\\nCNN parameters . . . . . . . . . . . . . . . . . . 207\\nCNN residual blocks . . . . . . . . . . . . . . .326\\nCoefﬁcients . . . . . . . . . . . . . . . . . . 12, 16, 27\\nCoffee consumption . . . . . . . . . . . . . . . . 36\\nCoin toss . . . . . . . . . . . . . . . . . . . . . . . . . . 349\\nCoin toss probabillity . . . . . . . . . . . . . . . 93\\nCommon conﬁdence levels . . . . . . . . . .21\\nComplementary probability . . . . . . . . .63\\nComputational graph . . . . . . . . . . . . . .140\\nComputational graphs . . 127, 140 f., 165,\\n168\\nConcave . . . . . . . . . . . . . . . . . . . . . . 154, 202\\nConcave and Convex functions . . . . 101\\nConcavity . . . . . . . . . . . . . . . . . . . . .106, 154\\nConcavity of the logarithm . . . . . . . . 106\\nConditional entropy . . . . . . . . . . . . . . . 118\\nConditional independence . . . . . . . . . . 66\\nConditional probability42, 44–50, 62, 69\\nConﬁdence intervals . . . . . . . . . . . . . . . . 37\\nConfusion matrics . . . . . . . . . . . . .261, 316\\nConfusion matrix . . . . . . . . . . . . . . . . . .316\\nConjugate prior . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . 66\\nConditional probability42, 44–50, 62, 69\\nConﬁdence intervals . . . . . . . . . . . . . . . . 37\\nConfusion matrics . . . . . . . . . . . . .261, 316\\nConfusion matrix . . . . . . . . . . . . . . . . . .316\\nConjugate prior . . . . . . . . . . . . . . . . . . . . 54\\nConjugate priors . . . . . . . . . . . . . . .54 f., 77\\nContent loss . . . . . . . . . . . . 214, 216, 224 f.\\nConv2D . . . . . . . . . . . . . . . . . . . . . . .271, 343\\nConv2d layer . . . . . . . . . . . . . . . . . . . . . .223\\nConv4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nConvex . . . . . . . . . . . . . . . . . . . . . . . 132, 202\\nConvex down function . . . . . . . . . . . . 119\\nConvex functions . . . . . . . . . . . . . . . . . .132\\nConvNet’s as ﬁxed feature extractors\\n206\\nConvolution . . . . . . . . . . . . . .234, 277, 291\\nConvolution and correlation in python\\n294\\nConvolution complexity . . . . . . . . . . . 240\\nConvolution layer . . . . . . . . . . . . .268, 321\\nConvolutional layer . . . . . . . . . 268, 321 f.\\nConvolutional neural network . . . . . . . 8\\nConvolutional neural networks192, 198\\nCorrelation . . . . . . . . . . . . . . . . . .234 f., 291\\nCost . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247\\nCost function . . . . . . . . . . . . . . . . . . . . . .247\\nCovariance . . . . . . . . . . . . . . . . . . . . . . . .189\\nCovariates . . . . . . . . . . . . . . . . . . . . . . . . . .17\\nCOVID19 . . . . . . . . . . . . . . . . . . . . .345, 351\\nCPP 23 f., 38 f., 142 f., 168 f., 242 f., 254 f.,\\n307 ff.\\nCPP hypothesis . . . . . . . . . . . . . . . . . . . . .23\\nCPU . . . . . . . . . . . . . . . . . . . . . . . . . .222, 289\\nCPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\nCross correlation . . . . . . . . . . . . . .235, 291\\nCross entropy . . . . . . . . . . . . . . . . 25 f., 251\\nCross entropy loss . . . . . . . . . . . . .214, 251\\nCross validation . . . . . . . . . . 231, 289, 328\\nCross validation approaches . . .231, 289\\nCUDA . . . . . . . . . . . . . . . . . . . . . . . . . . . . .289\\nCV . . . . . . . . . . . . . . . . . . . . . . . . . . . .231, 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . 289\\n375ALPHABETICAL INDEX\\nD\\nDAG . . . . . . . . . . . . . . . . .123, 126, 141, 168\\nData Science . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . .231, 289\\nCV approaches . . . . . . . . . . . . . . . . . . . . 289\\n375ALPHABETICAL INDEX\\nD\\nDAG . . . . . . . . . . . . . . . . .123, 126, 141, 168\\nData Science . . . . . . . . . . . . . . . . . . . . . . . . .4\\nDecision boundary . . . . . . . . . . . . . . . . . .14\\nDecision tree . . . 94 f., 97 f., 111, 187, 198\\nDecision trees . . . . . . . . . . . . . 94, 96 f., 348\\nDecision trees and cannabinoids\\nadministration . . . . . . . . . . . . . . 96\\nDeep Learning . . . . . . . . . . . . . . . . . . . . . . .4\\nDeep learning . . . . . 22, 77, 123, 196, 352\\nDeep Learning Job Interviews . . . . . . . . 6\\nDeep learning pipelines . . . . . . . . . . . .221\\nDental amalgam . . . . . . . . . . . . . . . . . . . .19\\nDercum disease . . . . . . . . . . . . . . . . . . . . .47\\nDifferentiation . . . . . . . . . .122, 143 f., 150\\nDifferentiation in deep learning . . . . 123\\nDirect derivation . . . . . . . . . . . . . . . . . . . .32\\nDirected Acyclic Graph . . . . . . . . . . . . 168\\nDirected acyclic graph . . . . . . . . . . . . . 141\\nDirected acyclic graphs . . . . . . . .126, 147\\nDirectional derivative . . . . . . . . . . . . . .131\\nDirectional derivatives . . . . . . . . . . . . .125\\nDistribution . . . . . . . . . . . . . . . . . . . . . . . . 45\\nDL . . . . . . . . . . . . . . 123, 196, 206, 221, 352\\nDL classiﬁcation pipeline . . . . . . . . . . . 91\\nDL job interviews . . . . . . . . . . . . . . . . . .206\\nDN . . . . . . . . . . . . . . . . . . . . . . . . . .138 f., 163\\nDouble reading . . . . . . . . . . . . . .282 f., 329\\nDPN CNN . . . . . . . . . . . . . . . . . . . . . . . . .223\\nDropout8, 57, 267 f., 277, 319 f., 326, 352\\nDropout as a bayesian approximation\\n192\\nDropout in PyTorch . . . . . . . . . . . . . . . . .56\\nDropout layer . . . . . . . . . . 57, 267 f., 319 f.\\nDropped out neurons . . . . . . . . . . . . . . . 57\\nDual numbers . . . . . . . . . .138 ff., 163, 165\\nDual numbers in AD . . . . . . . . . . 138, 163\\nE\\nEbola . . . . . . . . . . . . . . . . . . . . . . . . .53, 354 f.\\nEmbedding . . . . . . . . . . . . . . . . . . . . . . . .206\\nEncoded messages . . . . . . . . . . . . . . . . . .51\\nEncrypted communications . . . . . . . . . 50\\nEnigma machine . . . . . . . . . . . . . . . . . . . .50\\nEnsemble averaging . . . . . . . . . . . . . . . 193\\nEnsemble learning . . . . . . . .186, 194, 201\\nEnsemble methods . . . . . . . . . . . . '),\n",
              " Document(metadata={}, page_content=' . .51\\nEncrypted communications . . . . . . . . . 50\\nEnigma machine . . . . . . . . . . . . . . . . . . . .50\\nEnsemble averaging . . . . . . . . . . . . . . . 193\\nEnsemble learning . . . . . . . .186, 194, 201\\nEnsemble methods . . . . . . . . . . . . 190, 195\\nEnsembling . . . . . .186 ff., 190, 194 f., 197\\nEntropy 22, 38, 86 f., 89, 93, 95, 97 f., 106,\\n108, 214, 349\\nEntry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .186\\nEpidemic . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nEquiprobable events . 90 f., 103, 105, 118\\nEquiprobable sample . . . . . . . . . . . . . . 189\\nEquivocation . . . . . . . . . . . . . . . . . . . . . . . 99\\nEradication . . . . . . . . . . . . . . . . . . . . . . . .347\\nEradication probabillity . . . . . . . . . . . . .18\\nEuclidean . . . . . . . . . . . . . . . . . . . . .288, 333\\nExpansion of stars . . . . . . . . . . . . . . . . . . 97\\nExpectation . . . . . . . . . . . . . . . . . . . . . . . . .62\\nExpectation and variance . . . . . . . . 42, 59\\nExplanatory variable . . . . . . . . . . . . . . . .17\\nExponential family . . . . . . . . . . . . . . . . . .78\\nF\\nFc7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219\\nFeature extraction 214 f., 224 f., 349, 351\\nFeature vector . . . . . . . . . . . . . . . . .205, 350\\nFeature vectors . . . . . . . . . . . . . . . . . . . . . 96\\nFeed forward neural networks 135, 158\\nFermions . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nFFNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\n376Chapter 10 ALPHABETICAL INDEX\\nFiltering . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nFiltering kernel . . . . . . . . . . . . . . . . . . . . 234\\nFilters . . . . . . . . . . . . . . . . . . . . . . . . .239, 293\\nFinancial mathematics . . . . . . . . . . . . . . 42\\nFine tuning CNNs . . . . . . . . . . . . 213, 222\\nFinite difference rule . . . . . . . . . . 125, 147\\nFisher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nFisher information . . . . . . . . . 51, 53, 73 f.\\nFisher score . . . . . . . . . . . . . . . . . . . . . . . . .73\\nFliping . . . . . . . . . . . . . . . . . . . . . . . . . . . .294\\nForward mode . . . . . . . . . .131, 140 f., 168\\nForward mode AD . 140 f., 163, 166, 168\\nForward mode AD table construction\\n142, 168\\nForward pass . 125'),\n",
              " Document(metadata={}, page_content=' . . 213, 222\\nFinite difference rule . . . . . . . . . . 125, 147\\nFisher . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73\\nFisher information . . . . . . . . . 51, 53, 73 f.\\nFisher score . . . . . . . . . . . . . . . . . . . . . . . . .73\\nFliping . . . . . . . . . . . . . . . . . . . . . . . . . . . .294\\nForward mode . . . . . . . . . .131, 140 f., 168\\nForward mode AD . 140 f., 163, 166, 168\\nForward mode AD table construction\\n142, 168\\nForward pass . 125, 127, 135, 137, 139 ff.,\\n157 f., 160, 163, 165, 168\\nG\\nGausiian distribution . . . . . . . . . .241, 295\\nGaussian . . . . . . . . . . . . . . . . . . . . . . . . . . . 62\\nGaussian bell . . . . . . . . . . . . . . . . . . . . . .241\\nGaussian distribution . . . . . . . . . 274, 324\\nGaussian PDF . . . . . . . . . . . . . . . . . . . . . 324\\nGeneral concepts . . . . . . . . . . . . . . . . 12, 27\\nGeneralization . . . . . . . . . . . . . . . . 186, 206\\nGeneralized delta rule . . . . . . . . . . . . . 135\\ngeneralized linear models . . . . . . . . . . .14\\nGLM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .31\\nGLMs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\nGPU . . . . . . . . . . . . . . . . .222, 281, 289, 327\\nGPU tensor . . . . . . . . . . . . . . . . . . . . . . . .222\\ngradcheck . . . . . . . . . . . . . . . . . . . . . . . . .310\\nGradient . . . . . . . . . . . . . . . . . . . . . .130, 247\\nGradient descent 123, 130, 146, 158, 247\\nGradient descent algorithm . . . . . . . . 132\\nGradient descent and backpropagation\\n124\\nGradients . . . . . . . . . . . . . . . . . . . . . . . . . .222\\nGram matrix . . . . . . . . . . . . . . . . . . . . . . .225\\nGrid search . . . . . . . . . . . . . . . . . . . 282, 328\\nGum bacteria . . . . . . . . . . . . . . . . . . . . . . .20\\nGUR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135\\nH\\nHereditary disease . . . . . . . . . . . . . . . . . .66\\nHereditary diseases . . . . . . . . . . . . . . . . .47\\nHessian . . . . . . . . . . . . . . . . . . . . . . . . . . . . .74\\nHessian matrix . . . . . . . . . . . . . . . . . . . . . 52\\nHeterogeneous ensembling . . . .191, 200\\nHidden layer . . . . . . . . . . . . . . . . . . .78, 248\\nHidden layers . . . . . . . . . . . . . . . . . . . . . 250\\nHidden node . . . . . . . . . . . . . '),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . 52\\nHeterogeneous ensembling . . . .191, 200\\nHidden layer . . . . . . . . . . . . . . . . . . .78, 248\\nHidden layers . . . . . . . . . . . . . . . . . . . . . 250\\nHidden node . . . . . . . . . . . . . 248, 252, 343\\nHinton . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nHistopathology . . . . . . . . . . . .43, 217, 351\\nHuang1704snapshot . . . . . . . . . . . . . . .202\\nHuman voice activity . . . . . . . . . . . . . . . 31\\nHyperbolic tangent . . . . . . . . . . . . . . . . 134\\nHyperbolig tangent . . . . . . . . . . . . . . . .138\\nHyperparameter optimization . . . . . 282,\\n327 f.\\nHyperparameters . . . . . . . . . . . . . . . . . .328\\nHypotheis . . . . . . . . . . . . . . . . . . . . . . . . . .16\\nI\\nIdeal classiﬁer . . . . . . . . . . . . . . . . .262, 317\\nIdentity connection . . . . . . . . . . . . . . . . 326\\nImage analysis . . . . . . . . . . . . . . . . . . . . .110\\nImage and text similarity . . . . . . . . . . 296\\nImage processing . . . . . . . . . . . . . . . . . .234\\nImageNet . . . . . . . . . . . . . . . . . .206 f., 222 f.\\nImageNet pre trained CNNs . . . . . . . 213\\n377ALPHABETICAL INDEX\\nImageNet pretrained CNN classiﬁers\\n192\\nImproper prior . . . . . . . . . . . . . . . . . . . . . 54\\nIndependent binary co variates . . . . . 94\\nIndependent events . . . . . . . . . . . . . . . . .45\\nIndependent variables . . . . . . . . . . .19, 97\\nIndividual predictions . . . . . . . . . . . . . 192\\nInductive inference . . . . . . . . . . . . . . . . . 86\\nInference . . . . . . . . . . . . . . . . . . . . . .286, 330\\nInformation gain . . . . . . . . . . 94–98, 106 f.\\nInformation gain values . . . . . . . . . . . . .95\\nInformation matrix . . . . . . . . . . . . . . . . . 53\\nInformation theory . . . . . . . 58, 86, 88–93,\\n98–101, 106, 347\\nInteractions . . . . . . . . . . . . . . . . . . . . . . . . .13\\nIntermediate value theorem . . . . . . . .124\\nIntersected events . . . . . . . . . . . . . . . . . . .63\\nIntroduction . . . .12, 42, 86, 122, 186, 205\\nJ\\nJacard similarity . . . . . . . . . . . . . . . . . . .297\\nJAX . . . . . . . . . . . . . . . . . . . . . . . . . . .136, 158\\nJensen . . . . . . . . . . . . . . . . . . . . . . . . 101, 119\\nJensen’s inequality . . . . . . . . . . . . 101, 118\\nJob Interview . . . . . . . . . . . . . . . . . . . . . . . . 4\\nJohn von Neumann . . . . . . . . . . . . . . . . . 41\\nJoint distribution . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . 101, 119\\nJensen’s inequality . . . . . . . . . . . . 101, 118\\nJob Interview . . . . . . . . . . . . . . . . . . . . . . . . 4\\nJohn von Neumann . . . . . . . . . . . . . . . . . 41\\nJoint distribution . . . . . . . . . . . . . . . . . . 110\\nJupyter notebook . . . . . . . . . . . . . . . . . . 143\\nK\\nK Fold cross validation . . . . . . . . . . . . 289\\nK way FC layer . . . . . . . . . . . . . . . . . . . . 217\\nK-Fold cross validation . . . . . . . . . . . . 232\\nKaggle . . . . . . . . . . . . . . . . . . . . . . . .186, 201\\nKaggle competitions . . . . . . . . . . . . . . .201\\nKaiming . . . . . . . . . . . . . . . . . . . . . . . . . . .258\\nKernel . . . . . . . . . . . . . . . . . . . . . . . . . . . . .234\\nKernels . . . . . . . . . . . . . . . . . . . . . . . 239, 293\\nKL divergence . . . . . . . .53, 93, 100 f., 109\\nKLD . . . . . . . . . . . . . . . . . . . . . . .93, 119, 297\\nKullback Leibler . . . . . . . . . . . . . . . . . . .297\\nKullback Leibler divergence 87, 93, 108\\nL\\nL1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288, 333\\nL2 . . . . . . . . . . . . . . . . . . . . . . . . . . .288, 333 f.\\nLabelling and bias . . . . . . . . . . . . . . . . . 328\\nLaTeX . . . . . . . . . . . . . . . . . . . . . . . . .174, 176\\nLaw of total probability42, 46–50, 66–70\\nLaws of data compression . . . . . . . . . . 86\\nLDCT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282\\nLeaky ReLU . . . . . . . . . . . . . . . . . . . . . . .259\\nLearning logical gates . . . . . . . . . . . . . .305\\nLearning rate schedules in ensembling\\n197, 202\\nLeave one out CV . . . . . . . . . . . . . . . . . .290\\nLeave-one-out CV . . . . . . . . . . . . . . . . . 234\\nLibtorch . . . . . . . . . . . . . .254 f., 257, 307 ff.\\nLikelihood . . . . . . . . . . . . . . . . . . . .44 f., 353\\nLikelihood function . . . 51, 53, 56, 73, 79\\nLikelihood parameter . . . . . . . . . . . . . . .45\\nLimits and continuity . . . . . . . . . 130, 151\\nLinear classiﬁers . . . . . . . . . . . . . . . . . . .219\\nLinear combination of regression . . 201\\nLinear decision boundary . . . . . . . . . . . 14\\nLinear logistic regression model . . . . . 33\\nLinear model in PyTorch . . . . . . . . . . . .24\\nLinear regression . . . . . . . . . . . . . . . . . . 133\\nLinear transformation . . . . . . . . . . . . . 343\\nLine'),\n",
              " Document(metadata={}, page_content='Linear combination of regression . . 201\\nLinear decision boundary . . . . . . . . . . . 14\\nLinear logistic regression model . . . . . 33\\nLinear model in PyTorch . . . . . . . . . . . .24\\nLinear regression . . . . . . . . . . . . . . . . . . 133\\nLinear transformation . . . . . . . . . . . . . 343\\nLinearity . . . . . . . . . . . . . . . . . . . . . . . . . . 235\\nLink function . . . . . . . . . . . . . . . . . . . . . . .31\\nLocal minima . . . . . . . . . . . . . . . . . 198, 202\\n378Chapter 10 ALPHABETICAL INDEX\\nLog likelihood . . . . . . . . . . . . . . . . . . . . . .13\\nLog likelihood function . . 51, 53, 73, 355\\nLog loss . . . . . . . . . . . . . . . . . . . . . . . . . . . 284\\nLog odds . . . . . . . . . . . . 13 f., 17 f., 20 f., 29\\nLogarithm . . . . . . . . . . . . . . . . . . . 35, 53, 72\\nLogarithmic function . . . . . . . . . . . . . . 166\\nLogarithms . . . . . . . . . . . .88 f., 101 ff., 172\\nLogarithms in information theory . . . 87\\nLogic gate . . . . . . . . . . . . . . . . . . . . . . . . . 252\\nLogical gates . . . . . . . . . . . . . . . . . .251, 305\\nLogistic . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogistic inverse . . . . . . . . . . . . . . . . . . . . .14\\nLogistic regression 12–16, 24 ff., 28 f., 31,\\n36, 137, 345\\n• Sigmoid . . . . . . . . . . . . . . . . . . . . . .253\\nLogistic regression classiﬁer . . . . . . . . .19\\nLogistic regression coefﬁcients . . . . . . 16\\nLogistic regression implementation23 f.\\nLogistic regression in C++ . . . . . . . . . . 39\\nLogistic regression in Python . . . . . . . 26\\nLogistic regression model . . . . . . . .27, 35\\nLogistic regression predictor variable12\\nLogistic regression threashold . . . . . . .39\\nLogistic response function . . . . . . . . . . 33\\nLogit . . . . . . . . . . . . . . . . . . . . . . . . . . . .14, 32\\nLogit equation . . . . . . . . . . . . . . . . . . . . . .16\\nLogit function . . . . . . . . . . . . . . . .14, 22, 31\\nLogit inverse . . . . . . . . . . . . . . . . . . . . . . . .14\\nLogit transformation . . . . . . . . . . . . . . . .14\\nLogit value . . . . . . . . . . . . . . . . . . . . . . . . . 33\\nLOOCV . . . . . . . . . . . . . . . . . . . . . . .234, 290\\nLoss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .334\\nLoss function . . . . . . . . . . . . . . . . . . . . . .133\\nLow model generalization . . . . . . . . . 109\\nLow standard error . . . . . . . . . . . . . . . . . 75\\nLower entropy . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . . .334\\nLoss function . . . . . . . . . . . . . . . . . . . . . .133\\nLow model generalization . . . . . . . . . 109\\nLow standard error . . . . . . . . . . . . . . . . . 75\\nLower entropy . . . . . . . . . . . . . . . . . . . . . .38\\nLR . . . . . . . . . . . . . 16, 27, 33, 133, 137, 345\\nLR coefﬁcients . . . . . . . . . . . . . . . . . . . . . .16\\nLung cancer . . . . . . . . . . . . . . . . . . . .17, 282\\nM\\nM.Sc in Artiﬁcial Intelligence . . . . . . . . . 4\\nMachine learning . . . . . . 13 f., 25, 28, 316\\nMachine learning terminology . . . . . . 13\\nMacLaurin expansion . . . . . . . . . . . . . .128\\nMacLaurin series . . . . . . . . . . . . . . . . .128 f.\\nMagna Carta . . . . . . . . . . . . . . . . . . . . . . . .90\\nMajority voting . . . . . . . . . . .186, 190, 202\\nMalignant tumour . . . . . . . . . . . . . . . . . . 17\\nMalignant tumours . . . . . . . . . . . . . . . . . 96\\nManhattan . . . . . . . . . . . . . . . . . . . .288, 333\\nManual differentiation . . . . . . . . 124, 170\\nMaster’s programme in Artiﬁcial\\nIntelligence . . . . . . . . . . . . . . . . . . .4\\nMasters programme . . . . . . . . . . . . . . . . . 4\\nMathJax . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nMaximum likelihood estimatator . . . .73\\nMaximum likelihood estimation . 51, 71\\nMaxpool2D . . . . . . . . . . . . . . . . . . .271, 343\\nMaxPooling . . . . . . . . . . . . . . . . . . . . . . . 322\\nMaxwell Boltzmann distribution . . . . 57\\nMaxwell distribution . . . . . . . . . . . . . . . 58\\nMean ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .241\\nMean square error . . . . . . . . . . . . . . . . . 225\\nMeasurement vector . . . . . . . . . . . . . . . . 16\\nMechanical statistics . . . . . . . 42, 100, 118\\nMedical AI . . . . . . . . . . . . . . . . . . . . . . . . 217\\nMelanoma . . . . . . . . . . . . . . . . . . . . . . . . .213\\nMigraine probabillity . . . . . . . . . . . . . . . 20\\nMinHash . . . . . . . . . . . . . . . . . . . . . . . . . .298\\nML . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .316\\nMLE . . . . . . . . . . . . . . . . . . .51, 53, 72 f., 355\\nMLP . . . . . . . . . . . . . . .246 ff., 252, 299, 343\\n379ALPHABETICAL INDEX\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . .332\\nMonolithic and heterogeneous\\nensembling'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . .51, 53, 72 f., 355\\nMLP . . . . . . . . . . . . . . .246 ff., 252, 299, 343\\n379ALPHABETICAL INDEX\\nMomentum . . . . . . . . . . . . . . . . . . . . . . . .332\\nMonolithic and heterogeneous\\nensembling . . . . . . . . . . . .191, 200\\nMonolithic architectures . . . . . . . . . . . 200\\nMonolithic ensembling . . . . . . . . . . . . 191\\nMonotonically increasing function . . 72\\nMonte Carlo dropout . . . . . . . . . . . . . . 192\\nMSE . . . . . . . . . . . . . . . . . . . . . .225, 288, 333\\nMulti class responses . . . . . . . . . . . . . . . 29\\nMulti Layer Perceptrons . . . . . . . . . . . 246\\nMulti layer perceptrons . . . . . . . . . . . . 299\\nMulti model ensembling . . . . . . 196, 202\\nMulticlass classiﬁcation . . . . . . . . . . . . . 12\\nMulticlass classiﬁcation problems . . . 12\\nMultivariable . . . . . . . . . . . . . . . . . . . . . . .12\\nMultivariable methods . . . . . . . . . . . . . .12\\nMutual information . . .86, 94, 98 ff., 110,\\n116\\nMutual information formulae . . . . . . 117\\nN\\nN dimensional feature vector . . . . . . 205\\nNatural logistic function . . . . . . . . . . . . 14\\nNatural logistic sigmoid . . . . . . . . . . . . 14\\nNegative log likelihood . . . . . . . . . . . . . 13\\nNeural network . . . . . . . . . . . . . . .195, 202\\nNeural network ensembles . . . . 186, 191\\nNeural networks . . 55, 57, 127, 135, 158,\\n186\\nNeural style transfer . . . . . . . . . . . . . 214 f.\\nNeuron activation function . . . . . . . . . 15\\nNew York stock exchange . . . . . . . . . . .48\\nNLL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .13\\nNN . . . . . . . . . . 55, 127, 135, 158, 186, 202\\nNN Layers . . . . . . . . . . . . . . . . . . . . . . . . 318\\nNoise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99\\nNon convex neural networks . . . . . . 203\\nNon informative prior . . . . . . . . . . . . . . 54\\nNon informative priors . . . . . . . . . . . . . 77\\nNon interacting identical particles . 118\\nNon linearity . . . . . . . . . . . . . . . . . . . . . .301\\nNon-differentiable . . . . . . . . . . . . . . . . .301\\nNon-linearity . . . . . . . . . . . . . . . . . . . . . .248\\nNonlinear layer . . . . . . . . . . . . . . . 253, 306\\nNormal distribution . . . . . . . . . . .274, 324\\nNormalization constant . . . . . . . . . . . . .64\\nNST . . . . . . . . . . . . . . . . . . . . . . . . . . . . .214 f.\\nNumerical Differentiation . . . . . . . . . .147\\nNumerical differentiation . . .124 ff., 146,\\n173\\nNumerical instability . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=', 324\\nNormalization constant . . . . . . . . . . . . .64\\nNST . . . . . . . . . . . . . . . . . . . . . . . . . . . . .214 f.\\nNumerical Differentiation . . . . . . . . . .147\\nNumerical differentiation . . .124 ff., 146,\\n173\\nNumerical instability . . . . . . . . . . . . . . 146\\nNumpy . . . . . . . . . . . . . . . . . . . . . . . . . . . .221\\nO\\nOctahedral dice . . . . . . . . . . . . . . . . . . . .101\\nOdds . . . . . . . . . . . . . . . . . . . . . . . . . .12 f., 29\\nOdds of success in a binary response 14\\nOnOffLayer . . . . . . . . . . . . . . . . . . . . .56, 78\\nOOM . . . . . . . . . . . . . . . . . . . . . . . . .281, 327\\nOptimization . . . . . . . . . . . . . . . . . .131, 153\\nOptimization loss . . . . . . . . . . . . . . . . . .331\\nOrdinary predictors . . . . . . . . . . . . . . . . .28\\nOut of memory . . . . . . . . . . . . . . . 281, 327\\nOverﬁtting . . . . . . . . . . . . . . . . . .12, 27, 194\\nP\\nP value . . . . . . . . . . . . . . . . . . . . . . . . . . . . .36\\nPadding . . . . . . . . . . . . . . . . . . . . . . 236, 292\\nPancreactic cancer . . . . . . . . . . . . . . . . . . 43\\nPancreatic cancer classiﬁcation . . . . . 208\\nPartial derivative . . . . . . . . . . . . . . . . . . . 53\\nPartial derivatives . . . . . .130 ff., 142, 152\\n380Chapter 10 ALPHABETICAL INDEX\\nParticle physics . . . . . . . . . . . . . . . . . . . . .45\\nPDF . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .53\\nPerceptron . . . . . . . . . . . . . . . . . . . .246, 299\\nPerceptron learning rule . . . . . . . . . . . 252\\nPerceptrons . . . . . . . . . .299, 301, 304, 343\\nPerformance metrics . . . . . . . . . . . . . . .316\\nPhysical constants . . . . . . . . . . . . . . . . . 100\\nPlacenta Chorion Test . . . . . . . . . . . . . .353\\nPlacenta chorion test . . . . . . . . . . . . . . 46 f.\\nPlanck’s constant . . . . . . . . . . . . . . . . . . 100\\nPlateau . . . . . . . . . . . . . . . . . . . . . . . . . . . .284\\nPMF . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43, 59\\nPoisson . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75\\nPoisson distribution . . . . . . . . . . . . . . . . 53\\nPooling Layer . . . . . . . . . . . . . . . . . . . . . 270\\nPooling layer . . . . . . . . . . . . . . . . . . . . . . 322\\nPosterior . . . . . . . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content='oisson distribution . . . . . . . . . . . . . . . . 53\\nPooling Layer . . . . . . . . . . . . . . . . . . . . . 270\\nPooling layer . . . . . . . . . . . . . . . . . . . . . . 322\\nPosterior . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPosterior and prior predictive\\ndistributions . . . . . . . . . . . . . . . . 54\\nPosterior distribution . 54, 146, 180, 354\\nPosterior predictive distributions . . . 76\\nPre trained CNN . . . . . . . . . . . . . . . . . . 349\\nPre trained CNNs . . . . . . . . . . . . . . . . . .205\\nPre trained VGG19 CNN model . . . . 220\\nPrecision . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nPredictor variables . . . . . . . . . . . . . . . . . .28\\nPrior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .45\\nPrior distribution . . . . . . . . . . . . . . . . . . . 45\\nPrior distributions . . . . . . . . . . . . . . . . . . 77\\nPrior predictive distribution . . . . 54, 354\\nProbabilistic programming . . . . . . . . . .42\\nProbability distribution . . . . . . . . . .13, 94\\nProbability mass function . . . . . . . .43, 60\\nProbability of failure . . . . . . . . . . . . . . . .28\\nProbability space . . . . . . . . . . . . . . . . . . . 44\\nProbability statements . . . . . . . . . . . . . . 65\\nProblems . . . . . . . . . . . . . . . . . .12, 186, 206\\nProton theraphy . . . . . . . . . . . . . . . . . . . . 43\\nProton therapy . . . . . . . . . . . . . . . . . . 16, 43\\nPT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .16, 43\\nPulmonary nodules . . . . . . . . . . . 282, 345\\nPyMc3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nPython . 7, 23–27, 38 ff., 42, 56 f., 88, 102,\\n107 f., 112, 114, 123, 134, 136,\\n138, 140, 143 f., 157, 159 f., 163,\\n165 f., 170, 172 f., 175 ff., 179,\\n181, 191, 195–198, 202, 206,\\n210 f., 218, 221, 223 f., 232,\\n239 ff., 250 f., 256 f., 263 f., 266 ff.,\\n272, 282, 288, 294 f., 300–304,\\n312, 319 f., 330, 343 f., 349\\nPython coin toss . . . . . . . . . . . . . . . . . . . 108\\nPython interpreter . . . . . . . . . . . . . . . . . . 88\\nPyTorch . 7, 23–26, 38, 40, 56 f., 123, 134,\\n136, 138, 140, 143, 157, 159 f.,\\n163, 165 f., 170, 173, 176 f., 181,\\n191, 195 ff., 202, 206, 210 f., 218,\\n221, 223 f., 254–257, 267 f., 272,\\n288, 307 ff., 319 f., 343 f., 349\\nPytorch . . . . . .'),\n",
              " Document(metadata={}, page_content=',\\n136, 138, 140, 143, 157, 159 f.,\\n163, 165 f., 170, 173, 176 f., 181,\\n191, 195 ff., 202, 206, 210 f., 218,\\n221, 223 f., 254–257, 267 f., 272,\\n288, 307 ff., 319 f., 343 f., 349\\nPytorch . . . . . . . . . . . . . . . . . . . . . . . . . . . .143\\nPyTorch code snippet for an ensemble\\n191\\nPyTorch sequential . . . . . . . . . . . . . . . . 257\\nPyTorch tanh . . . . . . . . . . . . . . . . . . . . . .257\\nQ\\nQuadratic equation . . . . . . . . . . . . . . . . . 80\\nQuantum drop . . . . . . . . . . . . . . . . . . . . . .57\\nQuantum physics . . . . . . . . . . . . . . . . . .100\\nQuantum states . . . . . . . . . . . . . . . . . . . . .45\\nQuantum term speed . . . . . . . . . . . . . . . 79\\n381ALPHABETICAL INDEX\\nR\\nRadiation therapy . . . . . . . . . . . . . . . 17, 98\\nRadiation therapy planning . . . . . . . . . 17\\nRadiology . . . . . . . . . . . . . . . . . . . . . . . . .282\\nRandom guess classiﬁer . . . . . . . 262, 317\\nRandom number seeds . . . . . . . . . . . . 186\\nRandom search . . . . . . . . . . . . . . . 282, 328\\nRecall . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 316\\nReceiver Operating Characteristic . . 261\\nReceiver operating characteristic . . . 316\\nRectiﬁcation . . . . . . . . . . . . . . . . . . . . . . .306\\nRelative entropy . . . . .98 f., 109, 117, 349\\nRelative maxima and minima . . . . . . 132\\nRelative risk . . . . . . . . . . . . . . . . . . . . . . . .34\\nRelative shrinkage frequency . . . . . . 112\\nRelative star expansion frequency . . 115\\nReLU . . . .248 f., 253, 258 f., 301, 306, 314\\nRendering sympy in Google colab . 143\\nResNet . . . . . . . . . . 205, 207, 211, 217, 223\\nResNet152 . . . . . . . . . . . . . . . . . . . . . . . . .205\\nResNet18 . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nResNet34 . . . . . . . . . . . . . . . . .205, 211, 349\\nResNet34 CNN . . . . . . . . . . . . . . . . . . . .211\\nResNetBottom . . . . . . . . . . . . . . . . . . . . .211\\nResNets . . . . . . . . . . . . . . . . . . . . . . . . . . .326\\nResponse variable . . . . . . . . . . 12 f., 17, 29\\nReversing probabilities . . . . . . . . . . . . . 47\\nROC . . . . . . . . . . . . . . . . . . . . . . . . . .261, 316\\nROC AUC . . . . . . . . . . . . . . . . . . . . . . . . .316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . .261\\nRosenblatt . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . .261, 316\\nROC AUC . . . . . . . . . . . . . . . . . . . . . . . . .316\\nROC-AUC . . . . . . . . . . . . . . . . . . . . . . . . .261\\nRosenblatt . . . . . . . . . . . . . . . . . . . . . . . . .252\\nRR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34\\nRussakovsky . . . . . . . . . . . . . . . . . . . . . . 206\\nRussakovsky 2015 . . . . . . . . . . . . . . . . . 206\\nS\\nSaddle points . . . . . . . . . . . . . . . . . . . . . .155\\nSame padding . . . . . . . . . . . . 236, 238, 292\\nSample odds ratio . . . . . . . . . . . . . . . . . . 37\\nSampling approaches . . . . . . . . . . . . . .189\\nSampling with replacement . . . 189, 199\\nSampling without replacement 189, 199\\nSearch space . . . . . . . . . . . . . . . . . . 282, 328\\nSecond derivative test . . . . . . . . . . . . . 132\\nSeed values in AD . . . . . . . . . . . . .142, 170\\nSequential . . . . . . . . . . . . . . . . . . . . . . . . .221\\nSGD . . . . . . . . . . . . . . . . . . . . . .286 f., 330 ff.\\nShannon . . . . . . . 86 f., 89, 100, 103 f., 117\\nShannon bit . . . . . . . . . . . . . . . . . . . . . . . . .90\\nShannon’s famous general formulae\\n103\\nShannon’s general formulae . . . . . . . . 89\\nShift-invariance . . . . . . . . . . . . . . . . . . . .235\\nSigmoid . . . 15, 23, 32, 134, 137, 144, 160,\\n253, 306\\nSigmoid activation function . . . . 33, 137,\\n157 f., 160\\nSigmoid derivative . . . . . . . . . . . . . . . . . 15\\nSigmoid function . . . . . . . . . . . . . . . . . . 157\\nSigmoid gradient . . . . . . . . . . . . . .144, 173\\nSigmoid in SymPy . . . . . . . . . . . . . . . . . 173\\nSigmoidal neuron . . . . . . . . . . . . . . . . . .247\\nSigmoidal perceptron . . . . . . . . . . . . . .246\\nSimilarity measures . . . . . . . . . . . . . . . .296\\nSimple differentiation . . . . . . . . . 144, 172\\nSingle Layer Perceptrons . . . . . . . . . . .246\\nSingle layer perceptrons . . . . . . . . . . . 299\\nSingle model based AI systems . . . . 186\\nSingle predictors . . . . . . . . . . . . . . . . . . .201\\nSkip connection . . . . . . . . . . . . . . . . . . . .326\\nSnapshot ensembling . . . 189 f., 195, 201\\n382Chapter 10 ALPHABETICAL INDEX\\nSobel ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .294\\nSoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nsoftmax . . . . . . . . . . . . . . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' 10 ALPHABETICAL INDEX\\nSobel ﬁlter . . . . . . . . . . . . . . . . . . . . . . . . .294\\nSoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . .251\\nsoftmax . . . . . . . . . . . . . . . . . . . . . . . . . . . .217\\nSoftmax activation . . . . . . . . . . . . . . . . .251\\nSoftmax activation function . . . . . . . . . 32\\nSoftmax derivation . . . . . . . . . . . . . . . . . 32\\nSoftmax function . . . . . . . . . . . . . . . . 32, 40\\nSoftmax layers . . . . . . . . . . . . . . . . . . . . . .29\\nSoftmax neurons . . . . . . . . . . . . . . . . . . .214\\nSolutions . . . . . . . . . . . . . . . . . . . . . . . . . .198\\nSpeech to text . . . . . . . . . . . . . . . . . . . . . . .49\\nSpeed of light in vacum . . . . . . . . . . . . 100\\nSperable convolutions . . . . . . . . .241, 295\\nSplitting criterion . . . . . . . . . . . . . . . . . .111\\nStacking . . . . . . . . . . . . . . . . . .186, 189, 198\\nStacking and bagging . . . . . . . . . . . . . .187\\nStan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42\\nStandard deviation . . . . . . . . . . . . . . . . . 61\\nStar density . . . . . . . . . . . . . . . . . . . . . . . . .97\\nStar expansion . . . . . . . . . . . . . . . . . . . . .115\\nStatic committee machines . . . . . . . . . 201\\nStatistical distribution . . . . . . . . . . . . . . .44\\nStatistical independence . . . . . . . . . . . . 45\\nStatistical mechanics . . . . . . . . . . . . .11, 86\\nStochastic . . . . . . . . . . . . . . . . . . . . . . . . . .287\\nStochastic gradient descent . . . . 247, 331\\nStochastic gradient descent, SGD . . 286\\nStock markets . . . . . . . . . . . . . . . . . . . . . . .48\\nStocks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .48\\nStratiﬁcation . . . . . . . . . . . . . . . . . . 233, 290\\nStratiﬁed K fold . . . . . . . . . . . . . . . . . . . 290\\nStratiﬁed K-Fold . . . . . . . . . . . . . . . . . . .233\\nStride . . . . . . . . . . . . . . . . . . . . 236, 292, 323\\nSTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\nStyle loss . . . . . . . . . . . . . . . 214, 216, 224 f.\\nStyle transfer . . . . . . . . . . . . . . 214 f., 224 f.\\nSupervised learning . . . . . . . . . . . . . . . . 28\\nSupervised machine learning . . . . . . . 12\\nSurprise . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nSwish . . . . . . . . . . . . .'),\n",
              " Document(metadata={}, page_content=' . . . . . . . . . . . . . . . . . . . . 236, 292, 323\\nSTT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .49\\nStyle loss . . . . . . . . . . . . . . . 214, 216, 224 f.\\nStyle transfer . . . . . . . . . . . . . . 214 f., 224 f.\\nSupervised learning . . . . . . . . . . . . . . . . 28\\nSupervised machine learning . . . . . . . 12\\nSurprise . . . . . . . . . . . . . . . . . . . . . . . . . . . .90\\nSwish . . . . . . . . . . . . . . . . . . . . . . . . .260, 315\\nSymbolic differentiation . . . 123 f., 143 f.,\\n172 f.\\nSymPy . . . . . . . . .124, 143 f., 146, 173, 177\\nT\\nTanh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310\\ntanh . . . . . . . . . . . . . . . . . . . . 253, 256 f., 306\\nTaylor series . . . . . . . . . . . . . . . . .122, 128 f.\\nTaylor series and dual numbers . . . . 163\\nTaylor series expansion . . . . . . 128 f., 150\\nTest set . . . . . . . . . . . . . . . . . . . . . . . . . . . .328\\nThe backpropagation algorithm . . . . 134\\nThe bayesian school of thought . . . . . 42\\nThe beta binomial model . . . . . . 144, 174\\nThe chain rule . . . . . . . . . . . . . . . . .127, 149\\nThe convolution operator . . . . . 234, 291\\nThe correlation operator . . . . . . .234, 291\\nThe gaussian distribution . . . . . . . . . . 324\\nThe gradient descent algorithm . . . . 155\\nThe gram matrix . . . . . . . . . . . . . . . . . . .225\\nThe hyperplane . . . . . . . . . . . . . . . . . 14, 31\\nThe Kullback Leibler distance . . . . . . 297\\nThe Likelihood function . . . . . . . . . . . 174\\nThe logit function and entropy . . . . . . 38\\nThe multi layer perceptron . . . . . . . . . 300\\nThe Sigmoid . . . . . . . . . . . . . . . . . . . . . . . .32\\nThe sigmoid . . . . . . . . . . . . . . . . . . . . . . . . 15\\nThe sigmoid function . . . . . . . . . . . . . . . 29\\nThe theory of perceptrons . . . . . . . . . .304\\nTheory of CNN design . . . . . . . . . . . . .326\\nThermodynamics . . . . . . . . . . 86, 100, 103\\nTopologies . . . . . . . . . . . . . . . . . . . . . . . . .318\\nToxic mercury fumes . . . . . . . . . . . . . .18 f.\\n383ALPHABETICAL INDEX\\nTrain validation split . . . . . . . . . . . . . . .281\\nTraining corpus . . . . . . . . . . . . . . . 189, 200\\nTraining curve curve . . . . . . . . . . 283, 329\\nTraining hyperparameters . . . . . . . . . 327\\nTraining validation epoch . . . . . . . . . .196\\nTransformation . . . . . . . . . . . . . . . . . . . .222\\nTriangle inequality . . . . . . . . . . . . . . . . .109\\nTrue probability distribution . . . . . . . . '),\n",
              " Document(metadata={}, page_content=' . . . . . . . . 283, 329\\nTraining hyperparameters . . . . . . . . . 327\\nTraining validation epoch . . . . . . . . . .196\\nTransformation . . . . . . . . . . . . . . . . . . . .222\\nTriangle inequality . . . . . . . . . . . . . . . . .109\\nTrue probability distribution . . . . . . . . 93\\nTruly understanding LR . . . . . . . . . 16, 33\\nTTS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .69\\nTumors . . . . . . . . . . . . . . . . . . . . . . . . . . . . .98\\nTumour eradication . . . . . . . . . . . . . 17, 34\\nTumour shrinkage . . . . . . . . . . . . . . . . . .96\\nTumour shrinkage in rats . . . . . . . . . . . 22\\nTwo dimensional matrix . . . . . . . . . . . . 24\\nU\\nUncertainty . . . . . . . . . . . . . . . . . . . . . . .89 f.\\nUniversal function approximators . 251\\nV\\nValid padding . . . . . . . . . . . . 236, 238, 292\\nValidation curve . . . . . . . . . . . . . . 283, 329\\nValidation curve ACC . . . . . . . . . . . . . 329\\nValidation curve Loss . . . . . . . . . . . . . .329\\nValidation set . . . . . . . . . . . . . . . . . . . . . .328\\nVanilla linear regression . . . . . . . . . . . . .14\\nVanishing gradients . . . . . . . . . . . . . . . .258\\nVariance . . . . . . . . . . . .42 f., 59, 62, 74, 201\\nV enn diagram . . . . . . . . . . . . . . . . .44 f., 99\\nVGG . . . . . . . . . . . . . . . . . . . . . . . . . .205, 207\\nVGG conv43 layer . . . . . . . . . . . . . . . . . 209\\nVGG fc7 layer . . . . . . . . . . . . . . . . . . . . . 209\\nVGG Net . . . . . . . . . . . . . . . . . . . . . .205, 216\\nVGG16 . . . . . . . . . . . . . . . . . . . . . . . . . . . .201\\nVGG19 . . . . . . . . . . . . . . . . . . . 209, 221, 351\\nVGG19 architecture . . . . . . . . . . . . . . . .208\\nVGG19 CNN . . . . . . . . . . . . . 208, 218, 351\\nV oting power . . . . . . . . . . . . . . . . . . . . . .201\\nVumulative distribution . . . . . . . . . . . . .62\\nW\\nWald chi squared test . . . . . . . . . . . . . . . 28\\nWeight initialization247, 253, 258, 299 f.,\\n314\\nWest African ebola . . . . . . . . . . . . . . . . . .52\\nWSI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .208\\nWW2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .50\\nX\\nXavier . . . . . . . . . . . . . . . . . . . . . . . . 258, 330\\n384')]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "305fe551",
        "outputId": "fafe75cf-3505-4551-9dc8-21722a47877c"
      },
      "source": [
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "\n",
        "# Replace 'YOUR_NEW_HUGGINGFACE_TOKEN' with your actual, valid Hugging Face API token\n",
        "huggingface_key = 'YOUR_NEW_HUGGINGFACE_TOKEN' # Update this line with your new token\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = huggingface_key\n",
        "\n",
        "llm = HuggingFaceEndpoint(\n",
        "    repo_id=\"Qwen/Qwen1.5-7B-Chat\",\n",
        "    temperature=0.1,\n",
        "    max_length=500\n",
        ")"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template=\"\"\"\n",
        "you are an expert at ccreating questions based on coding materials an documentation,\n",
        "your goal is to prepare a coder or programmer for their exam and coding tests\n",
        "youdo this by asking questions about the text below:\n",
        "\n",
        "-------------------------\n",
        "{text}\n",
        "-------------------------\n",
        "create questions that will prepare the coders or programers for the test\n",
        "make sure ot to lose any important information.\n",
        "\n",
        "QUESTIONS:\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "KwoOUDheFyp8"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_s2nIAn_HAeQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}